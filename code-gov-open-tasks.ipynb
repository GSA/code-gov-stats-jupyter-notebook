{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphqlclient import GraphQLClient\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "from dotenv import DotEnv\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = DotEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gh_query(repo_owner, repo_name, gh_cursor=None):\n",
    "    str_cursor = 'null'\n",
    "    if gh_cursor:\n",
    "        str_cursor = f'\"{gh_cursor}\"'\n",
    "\n",
    "    query = '''\n",
    "        query {\n",
    "            repository(owner: \"%s\", name: \"%s\") {\n",
    "                owner{\n",
    "                    ... on Organization {\n",
    "                        name\n",
    "                        url\n",
    "                        email\n",
    "                        login\n",
    "                    }\n",
    "                    ... on User {\n",
    "                        name\n",
    "                        url\n",
    "                        email\n",
    "                        login\n",
    "                    }\n",
    "                }\n",
    "                issues(first: 100, labels: [\"help wanted\", \"code.gov\"], after: %s) {\n",
    "                    nodes {\n",
    "                        title\n",
    "                        bodyHTML\n",
    "                        url\n",
    "                        state\n",
    "                        createdAt\n",
    "                        lastEditedAt\n",
    "                        publishedAt\n",
    "                        updatedAt\n",
    "                        labels(first:20) {\n",
    "                            nodes {\n",
    "                                name\n",
    "                            }\n",
    "                        }\n",
    "                        locked\n",
    "                        participants {\n",
    "                            totalCount\n",
    "                        }\n",
    "                    }\n",
    "                    pageInfo {\n",
    "                        hasNextPage\n",
    "                        endCursor\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            rateLimit {\n",
    "                limit\n",
    "                cost\n",
    "                remaining\n",
    "                resetAt\n",
    "            }\n",
    "        }\n",
    "    '''\n",
    "    return query % (repo_owner, repo_name, str_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gh_issues(gh_api_token, repo_owner, repo_name, gh_cursor=None):\n",
    "    client = GraphQLClient('https://api.github.com/graphql')\n",
    "    client.inject_token(f'token {gh_api_token}')\n",
    "\n",
    "    query = get_gh_query(repo_owner, repo_name, gh_cursor)\n",
    "\n",
    "    response = client.execute(query)\n",
    "    json_response = json.loads(response)\n",
    "\n",
    "    if json_response is None:\n",
    "        error_msg = f'[ERROR] while getting issues for {repo_owner}/{repo_name}. Error: Not Found'\n",
    "        logging.error(error_msg)\n",
    "        raise Exception(error_msg)\n",
    "\n",
    "    if 'errors' in json_response:\n",
    "        errors = json_response['errors']\n",
    "        error_msg = f'[ERROR] while getting issues for {repo_owner}/{repo_name}. Errors: {errors}'\n",
    "        logging.error(error_msg)\n",
    "        raise Exception(error_msg)\n",
    "    \n",
    "    issues = json_response['data']['repository']['issues']\n",
    "    repository_owner_data = json_response['data']['repository']['owner']\n",
    "    return_issues = []\n",
    "\n",
    "    if issues['nodes']:\n",
    "        for issue in issues['nodes']:\n",
    "            return_issues.append({\n",
    "                'repo_name': repo_name,\n",
    "                'repo_owner_name': repository_owner_data['name'],\n",
    "                'repo_owner_email': repository_owner_data['email'],\n",
    "                'repo_owner_user_name': repository_owner_data['login'],\n",
    "                'repo_owner_profile_url': repository_owner_data['url'],\n",
    "                'title': issue['title'],\n",
    "                'bodyHTML': issue['bodyHTML'],\n",
    "                'url': issue['url'],\n",
    "                'state': issue['state'],\n",
    "                'createdAt': issue['createdAt'],\n",
    "                'lastEditedAt': issue['lastEditedAt'],\n",
    "                'publishedAt': issue['publishedAt'],\n",
    "                'updatedAt': issue['updatedAt'],\n",
    "                'labels': [node['name'] for node in issue['labels']['nodes']],\n",
    "                'is_locked': issue['locked'],\n",
    "                'total_participants': issue['participants']['totalCount'],\n",
    "            })\n",
    "\n",
    "        hasNext = issues['pageInfo']['hasNextPage']\n",
    "\n",
    "        if hasNext:\n",
    "            cursor = issues['pageInfo']['endCursor']\n",
    "            remaining = json_response['data']['rateLimit']['remaining']\n",
    "            limit = json_response['data']['rateLimit']['limit']\n",
    "            reset_at = json_response['data']['rateLimit']['resetAt']\n",
    "\n",
    "            percent_remaining = remaining / limit\n",
    "            if percent_remaining < 0.15:\n",
    "                reset_at = datetime.strptime(reset_at, '%Y-%m-%dT%H:%M:%SZ')\n",
    "                current_time = datetime.now()\n",
    "                time_diff = current_time - reset_at\n",
    "                seconds = time_diff.total_seconds()\n",
    "                time.sleep(seconds)\n",
    "            else:\n",
    "                time.sleep(2)\n",
    "            \n",
    "            return return_issues.extend(get_gh_issues(gh_api_token, repo_owner, repo_name, cursor))\n",
    "        else:\n",
    "            return return_issues\n",
    "    else:\n",
    "        logging.debug(f'No issues found for {repo_owner}/{repo_name}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_owner_and_name(gh_url):\n",
    "    if re.match(r'(https|http)://github.com', gh_url):\n",
    "        url_split = gh_url.split('/')\n",
    "        \n",
    "        # Naively Verify that the url is complete and correct.\n",
    "        # Split should have 5 items if the github url includes the owner and repo name\n",
    "        if len(url_split) > 4:\n",
    "            repo_name = url_split[-1]\n",
    "            owner = url_split[-2]\n",
    "            # Removes the .git suffix if it is present\n",
    "            if '.git' in repo_name:\n",
    "                repo_name = repo_name[:-4]\n",
    "\n",
    "            return owner, repo_name\n",
    "        else:\n",
    "            owner = url_split[-1]\n",
    "            return owner, None\n",
    "\n",
    "    if re.match(r'git@github.com', gh_url):\n",
    "        url_split = gh_url.split(':')\n",
    "\n",
    "        owner_repo = url_split[-1].split('/')\n",
    "\n",
    "        if len(owner_repo) > 1:\n",
    "            owner = owner_repo[0]\n",
    "            repo_name = owner_repo[1]\n",
    "\n",
    "            # Removes the .git suffix if it is present\n",
    "            if '.git' in repo_name:\n",
    "                repo_name = repo_name[:-4]\n",
    "\n",
    "            return owner, repo_name\n",
    "        else:\n",
    "            return owner_repo[0], None\n",
    "\n",
    "    logging.info(f'URL: {gh_url} is not a valida Github URL')\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repos_from_code_gov(api_token):\n",
    "    logging.info('Getting repos from Code.gov')\n",
    "    headers = {\n",
    "        'X-API-KEY': api_token,\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    response = requests.get('https://api.code.gov/repos?permissions.usageType=openSource&size=5000', headers=headers)\n",
    "    json_response = response.json()\n",
    "\n",
    "    return json_response['repos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(file_name, data, fields):\n",
    "    logging.info('Creating issues csv file')\n",
    "    with open(file_name, 'a') as issues_csv:\n",
    "        \n",
    "        writer = csv.DictWriter(issues_csv, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_github_issues_csv(data):\n",
    "    fields = [\n",
    "        'repo_name',\n",
    "        'repo_owner_name',\n",
    "        'repo_owner_email',\n",
    "        'repo_owner_user_name',\n",
    "        'repo_owner_profile_url',\n",
    "        'title',\n",
    "        'bodyHTML',\n",
    "        'url',\n",
    "        'state',\n",
    "        'createdAt',\n",
    "        'lastEditedAt',\n",
    "        'publishedAt',\n",
    "        'updatedAt',\n",
    "        'labels',\n",
    "        'is_locked',\n",
    "        'total_participants',\n",
    "    ]\n",
    "    \n",
    "    create_csv('github_issues.csv', data, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_repos_with_errors_csv(data):\n",
    "    fields = [\n",
    "        'repo_name',\n",
    "        'repo_url',\n",
    "        'errors',\n",
    "    ]\n",
    "    \n",
    "    create_csv('repos_with_error.csv', data, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[ERROR] while getting issues for USEPA/QA-SDMP-Project. Errors: [{'message': \"Could not resolve to a Repository with the name 'QA-SDMP-Project'.\", 'type': 'NOT_FOUND', 'path': ['repository'], 'locations': [{'line': 3, 'column': 13}]}]\n",
      "ERROR:root:[ERROR] while getting issues for losalamos/NHPP-for-FRBs. Errors: [{'message': \"Could not resolve to a Repository with the name 'NHPP-for-FRBs'.\", 'type': 'NOT_FOUND', 'path': ['repository'], 'locations': [{'line': 3, 'column': 13}]}]\n",
      "ERROR:root:[ERROR] while getting issues for ktoddbrown/soils-long-tail-recovery. Errors: [{'message': \"Could not resolve to a Repository with the name 'soils-long-tail-recovery'.\", 'type': 'NOT_FOUND', 'path': ['repository'], 'locations': [{'line': 3, 'column': 13}]}]\n",
      "ERROR:root:[ERROR] while getting issues for USEPA/LCI-Primer. Errors: [{'message': \"Could not resolve to a Repository with the name 'LCI-Primer'.\", 'type': 'NOT_FOUND', 'path': ['repository'], 'locations': [{'line': 3, 'column': 13}]}]\n",
      "ERROR:root:[ERROR] while getting issues for USArmyResearchLab/DCCSO. Errors: [{'message': \"Could not resolve to a Repository with the name 'DCCSO'.\", 'type': 'NOT_FOUND', 'path': ['repository'], 'locations': [{'line': 3, 'column': 13}]}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-51b429eff6da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_owner\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrepo_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0missues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gh_issues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GITHUB_TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_owner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mgithub_issues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0missues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-6f2053165f33>\u001b[0m in \u001b[0;36mget_gh_issues\u001b[0;34m(gh_api_token, repo_owner, repo_name, gh_cursor)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gh_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_owner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh_cursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/code-gov-stats-jupyter-notebook-7_nsoUuA/lib/python3.7/site-packages/graphqlclient/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, variables)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minject_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Authorization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/code-gov-stats-jupyter-notebook-7_nsoUuA/lib/python3.7/site-packages/graphqlclient/client.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, query, variables)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "logging.info(f'Execution started: {start_time}')\n",
    "\n",
    "repos = get_repos_from_code_gov(environment.get('CODE_GOV_API_TOKEN'))\n",
    "\n",
    "github_repos = [repo for repo in repos if 'github.com' in repo['repositoryURL']]\n",
    "# github_repos = list(filter(lambda repo: re.match(r'(https:\\/\\/||git@)github.com', repo['repositoryURL']), repos))\n",
    "\n",
    "github_issues = []\n",
    "repos_with_errors = []\n",
    "\n",
    "logging.info('Getting Github Issues')\n",
    "fields = []\n",
    "for repo in github_repos:\n",
    "    repo_url = repo['repositoryURL']\n",
    "\n",
    "    repo_owner, repo_name = get_repo_owner_and_name(repo_url)\n",
    "    \n",
    "    if repo_owner and repo_name:\n",
    "        try:\n",
    "            issues = get_gh_issues(environment.get('GITHUB_TOKEN'), repo_owner, repo_name)\n",
    "            github_issues.extend(issues)\n",
    "        except Exception as errors:\n",
    "            repos_with_errors.append({\n",
    "                'repo_name': repo['name'], \n",
    "                'repo_url': repo_url,\n",
    "                'errors': errors\n",
    "            })\n",
    "    else:\n",
    "        repos_with_errors.append({\n",
    "            'repo_name': repo['name'], \n",
    "            'repo_url': repo_url,\n",
    "            'errors': f'Owner: {repo_owner} or Repo name: {repo_name} as missing'\n",
    "        })\n",
    "\n",
    "finish_time = datetime.now()\n",
    "delta = finish_time - start_time\n",
    "\n",
    "logging.info(f'Execution finished: {finish_time}')\n",
    "logging.info(f'Execution took {delta.seconds} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_github_issues_csv(github_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 'errors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ef426c41ef73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_repos_with_errors_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepos_with_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-324dd22c588b>\u001b[0m in \u001b[0;36mcreate_repos_with_errors_csv\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcreate_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'repos_with_error.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-cc426f2bcc54>\u001b[0m in \u001b[0;36mcreate_csv\u001b[0;34m(file_name, data, fields)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0missues_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/csv.py\u001b[0m in \u001b[0;36mwriterows\u001b[0;34m(self, rowdicts)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# Guard Sniffer's type checking against builds that exclude complex()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/csv.py\u001b[0m in \u001b[0;36m_dict_to_list\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 raise ValueError(\"dict contains fields not in fieldnames: \"\n\u001b[0;32m--> 151\u001b[0;31m                                  + \", \".join([repr(x) for x in wrong_fields]))\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dict contains fields not in fieldnames: 'errors'"
     ]
    }
   ],
   "source": [
    "create_repos_with_errors_csv(repos_with_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'repo_name': 'fec-pattern-library', 'repo_owner_name': 'Federal Election Commission', 'repo_owner_email': 'webmanager@fec.gov', 'repo_owner_user_name': 'fecgov', 'repo_owner_profile_url': 'https://github.com/fecgov', 'title': '[High risk] Prototype Override Protection Bypass', 'bodyHTML': '<p><strong>[High risk] SNYK alert:</strong> <a href=\"https://snyk.io/vuln/npm:qs:20170213\" rel=\"nofollow\">https://snyk.io/vuln/npm:qs:20170213</a></p>\\n<p><strong>Vulnerable module:</strong> qs<br>\\n<strong>Introduced through:</strong> @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3</p>\\n<p><strong>Fix:</strong> Upgrade qs to version 6.4.0 or higher. Note: The fix was backported to the following versions 6.3.2, 6.2.3, 6.1.2, 6.0.4.</p>', 'url': 'https://github.com/fecgov/fec-pattern-library/issues/114', 'state': 'CLOSED', 'createdAt': '2018-04-26T13:47:29Z', 'lastEditedAt': None, 'publishedAt': '2018-04-26T13:47:29Z', 'updatedAt': '2018-04-30T14:08:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'fec-pattern-library', 'repo_owner_name': 'Federal Election Commission', 'repo_owner_email': 'webmanager@fec.gov', 'repo_owner_user_name': 'fecgov', 'repo_owner_profile_url': 'https://github.com/fecgov', 'title': '[High risk] Regex Denial of Service (ReDoS)', 'bodyHTML': '<p><strong>[High risk] SNYK alert:</strong> <a href=\"https://snyk.io/vuln/npm:fresh:20170908\" rel=\"nofollow\">https://snyk.io/vuln/npm:fresh:20170908</a></p>\\n<p><strong>Vulnerable module:</strong> fresh<br>\\n<strong>Introduced through:</strong> @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3</p>\\n<p><strong>Fix:</strong> Upgrade fresh to version 0.5.2 or higher.</p>', 'url': 'https://github.com/fecgov/fec-pattern-library/issues/115', 'state': 'CLOSED', 'createdAt': '2018-04-26T13:49:07Z', 'lastEditedAt': None, 'publishedAt': '2018-04-26T13:49:07Z', 'updatedAt': '2018-04-30T14:09:56Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'fec-pattern-library', 'repo_owner_name': 'Federal Election Commission', 'repo_owner_email': 'webmanager@fec.gov', 'repo_owner_user_name': 'fecgov', 'repo_owner_profile_url': 'https://github.com/fecgov', 'title': '[Med risk] ua-parser-js module - Regular Expression Denial of Service (ReDoS)', 'bodyHTML': '<p><strong>[Med risk] SNYK alert:</strong> <a href=\"https://snyk.io/vuln/npm:ua-parser-js:20171012\" rel=\"nofollow\">https://snyk.io/vuln/npm:ua-parser-js:20171012</a></p>\\n<p><strong>Vulnerable module:</strong> ua-parser-js<br>\\n<strong>Introduced through:</strong> @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3</p>\\n<p><strong>Fix:</strong> Upgrade ua-parser-js to version 0.7.16 or higher.</p>', 'url': 'https://github.com/fecgov/fec-pattern-library/issues/116', 'state': 'CLOSED', 'createdAt': '2018-04-26T13:50:46Z', 'lastEditedAt': None, 'publishedAt': '2018-04-26T13:50:46Z', 'updatedAt': '2018-09-17T14:32:02Z', 'labels': ['Security', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'fec-pattern-library', 'repo_owner_name': 'Federal Election Commission', 'repo_owner_email': 'webmanager@fec.gov', 'repo_owner_user_name': 'fecgov', 'repo_owner_profile_url': 'https://github.com/fecgov', 'title': '[Low risk] Two vulnerabilities introduced through @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3', 'bodyHTML': '<p>Update 7/12/18 - these issues remain:</p>\\n<ul>\\n<li><a href=\"https://snyk.io/org/fecgov/project/0e33b068-0c21-4956-8f86-a63eec4b306e/?severity=low#npm:braces:20180219\" rel=\"nofollow\">braces</a><br>\\nRegular Expression Denial of Service (ReDoS)<br>\\nVulnerable module: braces<br>\\nIntroduced through: @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3<br>\\nRemediation: No remediation path available.</li>\\n<li><a href=\"https://snyk.io/org/fecgov/project/0e33b068-0c21-4956-8f86-a63eec4b306e/?severity=low#npm:lodash:20180130\" rel=\"nofollow\">lodash</a> Prototype Pollution<br>\\nVulnerable module: lodash<br>\\nIntroduced through: @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3<br>\\nRemediation: No remediation path available.</li>\\n</ul>\\n<p>These have been addressed:<br>\\n<del><a href=\"https://snyk.io/org/fecgov/project/0e33b068-0c21-4956-8f86-a63eec4b306e/?severity=low#npm:debug:20170905\" rel=\"nofollow\">debug</a><br>\\nRegular Expression Denial of Service (ReDoS)<br>\\nVulnerable module: debug<br>\\nIntroduced through: @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3<br>\\nRemediation: Run snyk wizard to patch debug<br>\\n<a href=\"https://snyk.io/org/fecgov/project/0e33b068-0c21-4956-8f86-a63eec4b306e/?severity=low#npm:ms:20170412\" rel=\"nofollow\">ms</a><br>\\nRegular Expression Denial of Service (ReDoS)<br>\\nVulnerable module: ms<br>\\nIntroduced through: @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3<br>\\nRemediation: Run snyk wizard to patch ms<br>\\n<a href=\"https://snyk.io/org/fecgov/project/0e33b068-0c21-4956-8f86-a63eec4b306e/?severity=low#npm:hoek:20180212\" rel=\"nofollow\">hoek</a><br>\\nPrototype Pollution<br>\\nVulnerable module: hoek<br>\\nIntroduced through: @frctl/fractal@1.1.7 and @frctl/nunjucks@1.0.3<br>\\nRemediation: No remediation path available.</del></p>', 'url': 'https://github.com/fecgov/fec-pattern-library/issues/117', 'state': 'CLOSED', 'createdAt': '2018-04-26T14:30:28Z', 'lastEditedAt': '2018-07-12T20:32:59Z', 'publishedAt': '2018-04-26T14:30:28Z', 'updatedAt': '2018-09-17T14:31:43Z', 'labels': ['Security', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'nara-scripts', 'repo_owner_name': 'U.S. National Archives', 'repo_owner_email': 'developer@nara.gov', 'repo_owner_user_name': 'usnationalarchives', 'repo_owner_profile_url': 'https://github.com/usnationalarchives', 'title': 'Convert PDFs to JPGs', 'bodyHTML': '<p>Seeking a script to convert all PDFs in a directory to JPGs, preferably in Python 2.7.</p>\\n<p>May require <a href=\"http://www.imagemagick.org/script/index.php\" rel=\"nofollow\">ImageMagick</a>.</p>', 'url': 'https://github.com/usnationalarchives/nara-scripts/issues/1', 'state': 'CLOSED', 'createdAt': '2016-10-27T11:11:55Z', 'lastEditedAt': None, 'publishedAt': '2016-10-27T11:11:55Z', 'updatedAt': '2017-05-03T14:42:43Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'nara-scripts', 'repo_owner_name': 'U.S. National Archives', 'repo_owner_email': 'developer@nara.gov', 'repo_owner_user_name': 'usnationalarchives', 'repo_owner_profile_url': 'https://github.com/usnationalarchives', 'title': 'Add header and footer to each XML file generated by combinexml-py2.py', 'bodyHTML': '<p>I would like to improve <a href=\"https://github.com/usnationalarchives/nara-scripts/blob/master/python/combinexml-py2.py\">combinexml-py2.py</a> so the script adds the following header and footer (i.e. first line and last line) to each XML file generated.</p>\\n<ul>\\n<li>Header: <code>&lt;import xmlns=\"http://ui.das.nara.gov/\"&gt;&lt;fileUnitArray&gt;</code></li>\\n<li>Footer: <code>&lt;/fileUnitArray&gt;&lt;/import&gt;</code></li>\\n</ul>', 'url': 'https://github.com/usnationalarchives/nara-scripts/issues/2', 'state': 'CLOSED', 'createdAt': '2016-10-28T18:27:09Z', 'lastEditedAt': None, 'publishedAt': '2016-10-28T18:27:09Z', 'updatedAt': '2016-12-12T17:36:50Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'nara-scripts', 'repo_owner_name': 'U.S. National Archives', 'repo_owner_email': 'developer@nara.gov', 'repo_owner_user_name': 'usnationalarchives', 'repo_owner_profile_url': 'https://github.com/usnationalarchives', 'title': 'dir file for contents of opaexport-conv.s3.amazonaws.com/ bucket  (directory listing) - Manifester', 'bodyHTML': '<p>For importing the partner images we need to map the digital object file locations to the descriptions.</p>\\n<p>These are scattered in an s3 bucket:<br>\\nopaexport-conv.s3.amazonaws.com/</p>\\n<p>A previous contractor wrote a script that basically performs an old DOS \"dir\" directory listing, but it is slow and not always \"accurate,\" (the file bombs out, and we\\'ve been running until we get three files of the same file size.</p>\\n<p>I have an exe file, but I can\\'t save it here. Let me know if you want to get access to it.</p>\\n<p>The Search-bat.txt [bat] file might shed some clues?</p>\\n<pre><code>@ECHO off\\ncls\\nGOTO Getkey\\n\\n:Getkey\\nset /p SVER=What is the keyword search? \\nECHO .\\n\\nif \"%SVER%\"==\"\" GOTO Fail\\n@ECHO ON\\n\\ns3_manifester.exe -bucket opaexport-conv -akid [ACCESS KEY] -seckey [SECRET ACCESS KEY]+ -csv yes -search %SVER%\\n\\n@ECHO OFF\\nECHO .\\npause\\nexit\\n\\n:Fail\\nECHO No Keyword\\nECHO .\\nGOTO :Getkey\\n</code></pre>\\n<p>Here is an example of the output.<br>\\n<a href=\"https://github.com/usnationalarchives/nara-scripts/files/569520/opaexport-conv_m2062_1470425366-csv.xlsx\">opaexport-conv_m2062_1470425366-csv.xlsx</a></p>\\n<p>We then run the python scripts that you guys have been working on.</p>\\n<p>Please let me know if this makes or doesn\\'t make any sense.</p>\\n<p>Thanks!<br>\\n-Gary</p>', 'url': 'https://github.com/usnationalarchives/nara-scripts/issues/3', 'state': 'CLOSED', 'createdAt': '2016-11-03T16:27:56Z', 'lastEditedAt': '2016-11-03T16:36:28Z', 'publishedAt': '2016-11-03T16:27:56Z', 'updatedAt': '2018-03-29T11:37:54Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'nara-scripts', 'repo_owner_name': 'U.S. National Archives', 'repo_owner_email': 'developer@nara.gov', 'repo_owner_user_name': 'usnationalarchives', 'repo_owner_profile_url': 'https://github.com/usnationalarchives', 'title': 'file-units.py: Add import header and footer', 'bodyHTML': '<p>Need the script to add the following XML snippets to the top and bottom of the final output document:</p>\\n<p><strong>Top</strong><br>\\n<code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt; &lt;import xmlns=\"http://ui.das.nara.gov/\"&gt; &lt;fileUnitArray&gt;</code></p>\\n<p><strong>Bottom</strong><br>\\n<code>&lt;/fileUnitArray&gt; &lt;/import&gt;</code></p>', 'url': 'https://github.com/usnationalarchives/nara-scripts/issues/4', 'state': 'CLOSED', 'createdAt': '2018-02-20T16:55:29Z', 'lastEditedAt': None, 'publishedAt': '2018-02-20T16:55:29Z', 'updatedAt': '2018-02-22T14:13:50Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'goSecure', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'Add option for server running in Docker?', 'bodyHTML': '<p>Would it make sense to add a Dockerfile to this repo to allow users to run the VPN server inside a Docker container?  This could simplify server setup on multiple OSes and cloud providers.</p>', 'url': 'https://github.com/nsacyber/goSecure/issues/16', 'state': 'OPEN', 'createdAt': '2017-06-24T05:48:40Z', 'lastEditedAt': None, 'publishedAt': '2017-06-24T05:48:40Z', 'updatedAt': '2017-06-26T17:18:58Z', 'labels': ['enhancement', 'help wanted', 'question'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'Constant Altitude Plan Position Indicator (CAPPI)', 'bodyHTML': '<p>It would be convenient to create a griddisplay class in line with the radardisplay class to be able to plot CAPPIs in km units.</p>\\n<p>In addition it may be convenient to be able to plot gridmapdisplay and radarmapdisplay in km units.</p>', 'url': 'https://github.com/ARM-DOE/pyart/issues/597', 'state': 'OPEN', 'createdAt': '2016-09-19T06:06:51Z', 'lastEditedAt': None, 'publishedAt': '2016-09-19T06:06:51Z', 'updatedAt': '2018-05-22T13:27:50Z', 'labels': ['Enhancement', 'component: pyart.graph', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'add convenience drop_sweeps function to radar class', 'bodyHTML': '<p>Per conversation on the <a href=\"https://groups.google.com/forum/#!topic/pyart-users/DKH1eYdIPuM\" rel=\"nofollow\">mailing list</a>, it might be nice to have a convenient way to remove sweeps from a radar volume.</p>\\n<p>This may also be of interest in Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"225822431\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/ARM-DOE/pyart/issues/649\" data-hovercard-type=\"issue\" data-hovercard-url=\"/ARM-DOE/pyart/issues/649/hovercard\" href=\"https://github.com/ARM-DOE/pyart/issues/649\">#649</a> ?</p>', 'url': 'https://github.com/ARM-DOE/pyart/issues/652', 'state': 'OPEN', 'createdAt': '2017-05-19T17:37:11Z', 'lastEditedAt': None, 'publishedAt': '2017-05-19T17:37:11Z', 'updatedAt': '2018-05-22T13:33:54Z', 'labels': ['Easy Fix', 'Enhancement', 'Moderate', 'component: pyart.util', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'Breaks when trying to read an ODIM HDF5 file with missing tilts.', 'bodyHTML': '<p>We had a problem at the BOM with some ODIM HDF5 files. Some scan can be missing some data types.</p>\\n<p>For example, on one of the file, tilt 10 does not contain reflectivity.  The file itself is valid, but the volume scan does not contain all the data it normally would.</p>\\n<p>This can happen for lots of reasons but the most common one is that the communications line to the radar was running slowly so some of the moments were dropped.</p>\\n<p>It would be nice if the reading of ODIM HDF5 files was robust enough to still cope with files like this.  In general, it is not guaranteed that every tilt will always contain the same set of data types.</p>\\n<p>One solution could be to change l.323 of pyart/aux_io/odim_h5.py to:</p>\\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">try</span>:\\n    sweep_data <span class=\"pl-k\">=</span> _get_odim_h5_sweep_data(fid[dset][h_field_key])\\n<span class=\"pl-k\">except</span> <span class=\"pl-c1\">Exception</span>:\\n    sweep_data <span class=\"pl-k\">=</span> np.zeros((rays_in_sweep, nbins))\\n    sweep_data <span class=\"pl-k\">=</span> np.ma.masked_where(sweep_data <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>, sweep_data)</pre></div>', 'url': 'https://github.com/ARM-DOE/pyart/issues/694', 'state': 'OPEN', 'createdAt': '2017-10-30T01:09:49Z', 'lastEditedAt': None, 'publishedAt': '2017-10-30T01:09:49Z', 'updatedAt': '2018-05-23T00:48:46Z', 'labels': ['component: pyart.aux_io', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'Improving plot_ppi_section for unordered VCPs (e.g., 88D SAILS)', 'bodyHTML': '<p>When WSR-88D data are in a SAILS VCP mode (elevation pattern below), it causes the PPI cross section plot to drop or oddly overplot some rays. This can be worked around with a manual call to <code>extract_sweeps</code>, but I propose that this situation be automatically detected and corrected for the user.</p>\\n<p>The list of elevations angles is:<br>\\n<code>[0.48339844, 0.48339844, 0.87890625, 0.87890625, 1.31835938, 1.31835938, 0.48339844, 0.48339844, 1.80175781, 2.41699219, 3.12011719, 0.48339844, 0.48339844, 3.99902344, 5.09765625, 6.41601562, 7.99804688, 0.48339844, 0.48339844, 10.01953125, 12.48046875, 15.60058594, 19.51171875]</code></p>\\n<p>Before <code>extract_sweeps</code><br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1325771/37308205-522b22c2-260b-11e8-926c-d586b49818d0.png\"><img src=\"https://user-images.githubusercontent.com/1325771/37308205-522b22c2-260b-11e8-926c-d586b49818d0.png\" alt=\"ppi_crosssections_22102017_reflectivity\" style=\"max-width:100%;\"></a></p>\\n<p>After <code>extract_sweeps</code><br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1325771/37308221-5d019faa-260b-11e8-86eb-3e054707b5f6.png\"><img src=\"https://user-images.githubusercontent.com/1325771/37308221-5d019faa-260b-11e8-86eb-3e054707b5f6.png\" alt=\"ppi_crosssections_22102017_reflectivity\" style=\"max-width:100%;\"></a></p>\\n<p>Thanks to Jessica S., an undergraduate working with me, for pointing out this bug and finding the workaround.</p>', 'url': 'https://github.com/ARM-DOE/pyart/issues/718', 'state': 'OPEN', 'createdAt': '2018-03-12T20:43:52Z', 'lastEditedAt': '2018-03-12T20:45:52Z', 'publishedAt': '2018-03-12T20:43:52Z', 'updatedAt': '2018-05-22T13:15:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'SIGMET missing rays', 'bodyHTML': '<p>When reading RAW sigmet files (pyart.io.read()), the data array in the PyART radar object does not contain the missing rays, not even in the form of masked values.<br>\\nIt is still possible (although somewhat cumbersome) to decipher which are the rays missing using additional information (azimuth/elevation). However it  may be important to take this into account when the data processing relies on continuity. Is this a desired behaviour? Am I missing anything?</p>', 'url': 'https://github.com/ARM-DOE/pyart/issues/732', 'state': 'OPEN', 'createdAt': '2018-04-23T12:03:43Z', 'lastEditedAt': None, 'publishedAt': '2018-04-23T12:03:43Z', 'updatedAt': '2018-05-22T13:20:18Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'MDV File Problem ', 'bodyHTML': '<p>I run pyart in python on my linux virtualbox, from my windows pc. For some reason when I try to read an mdv file, it gives me an error. See the code below:<br>\\n\"<br>\\nPython 2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42)<br>\\n[GCC 7.2.0] on linux2<br>\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.</p>\\n<blockquote>\\n<blockquote>\\n<blockquote>\\n<p>import matplotlib.pyplot as plt<br>\\nimport pyart</p>\\n</blockquote>\\n</blockquote>\\n</blockquote>\\n<h2>You are using the Python ARM Radar Toolkit (Py-ART), an open source</h2>\\n<h2>library for working with weather radar data. Py-ART is partly</h2>\\n<h2>supported by the U.S. Department of Energy as part of the Atmospheric</h2>\\n<h2>Radiation Measurement (ARM) Climate Research Facility, an Office of</h2>\\n<h2>Science user facility.</h2>\\n<h2></h2>\\n<h2>If you use this software to prepare a publication, please cite:</h2>\\n<h2></h2>\\n<h2>JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119</h2>\\n<blockquote>\\n<blockquote>\\n<blockquote>\\n<p>filename = \\'/home/todd/RadarData/3hr/180000.mdv\\'<br>\\nradar = pyart.io.read_mdv(filename)<br>\\nTraceback (most recent call last):<br>\\nFile \"\", line 1, in <br>\\nFile \"/home/todd/anaconda2/lib/python2.7/site-packages/pyart/io/mdv_radar.py\", line 83, in read_mdv<br>\\naz_deg, range_km, el_deg = mdvfile._calc_geometry()<br>\\nFile \"/home/todd/anaconda2/lib/python2.7/site-packages/pyart/io/mdv_common.py\", line 1106, in _calc_geometry<br>\\nraise NotImplementedError(message)<br>\\nNotImplementedError: Unsupported projection type: 0, is MDV file in antenna coordinates?</p>\\n</blockquote>\\n</blockquote>\\n</blockquote>\\n<p>\"<br>\\nTo take into consideration:</p>\\n<ul>\\n<li>I am relatively new to programming, enough to be considered a beginner</li>\\n<li>A very detailed solution (like VERY detailed) would be appreciated.</li>\\n</ul>\\n<p>Thank you</p>', 'url': 'https://github.com/ARM-DOE/pyart/issues/740', 'state': 'OPEN', 'createdAt': '2018-05-18T08:48:27Z', 'lastEditedAt': None, 'publishedAt': '2018-05-18T08:48:27Z', 'updatedAt': '2018-08-10T07:29:19Z', 'labels': ['Low Priority', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'pyart', 'repo_owner_name': 'ARM Climate Research Facility', 'repo_owner_email': '', 'repo_owner_user_name': 'ARM-DOE', 'repo_owner_profile_url': 'https://github.com/ARM-DOE', 'title': 'written error', 'bodyHTML': '<p><div class=\"border rounded-1 my-2\">\\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\\n    <p class=\"mb-0 text-bold\">\\n      <a href=\"https://github.com/ARM-DOE/pyart/blob/dbe4d70eccc1b88260d44720cf133694d127df0a/pyart/graph/radarmapdisplay.py#L264\">pyart/pyart/graph/radarmapdisplay.py</a>\\n    </p>\\n    <p class=\"mb-0 text-gray-light\">\\n         Line 264\\n      in\\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/ARM-DOE/pyart/commit/dbe4d70eccc1b88260d44720cf133694d127df0a\">dbe4d70</a>\\n    </p>\\n    </div>\\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\\n\\n        <tbody><tr class=\"border-0\">\\n          <td id=\"L264\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"264\"></td>\\n          <td id=\"LC264\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> width <span class=\"pl-k\">=</span> (x.max() <span class=\"pl-k\">-</span> y.min()) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1000</span>. </td>\\n        </tr>\\n    </tbody></table>\\n  </div>\\n</div>\\n</p>\\n<p>width = (x.max() - x.min()) * 1000.</p>', 'url': 'https://github.com/ARM-DOE/pyart/issues/742', 'state': 'CLOSED', 'createdAt': '2018-05-21T01:21:14Z', 'lastEditedAt': None, 'publishedAt': '2018-05-21T01:21:14Z', 'updatedAt': '2018-05-22T13:40:52Z', 'labels': ['Easy Fix', 'Great First Pull Request', 'component: pyart.graph', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'FEC', 'repo_owner_name': 'Federal Election Commission', 'repo_owner_email': 'webmanager@fec.gov', 'repo_owner_user_name': 'fecgov', 'repo_owner_profile_url': 'https://github.com/fecgov', 'title': 'Good ideas for visualizing political contributions?', 'bodyHTML': '<p>We have some endpoints that we would like to display in a visual, interactive way but are still developing ideas. Maybe it\\'s best to do a choropleth map, or something more creative.</p>\\n<p>I outlined some of the good visualizing datasets in this post:<br>\\n<a href=\"https://18f.gsa.gov/2015/07/15/openfec-api-update/\" rel=\"nofollow\">https://18f.gsa.gov/2015/07/15/openfec-api-update/</a></p>\\n<p>There are a lot of good political results maps and visuals, but we are focusing on the campaign finance data.</p>\\n<p>Thanks!</p>', 'url': 'https://github.com/fecgov/FEC/issues/47', 'state': 'CLOSED', 'createdAt': '2015-07-16T15:59:41Z', 'lastEditedAt': None, 'publishedAt': '2015-07-16T15:59:41Z', 'updatedAt': '2017-06-20T18:27:57Z', 'labels': ['help wanted', 'questions-comments'], 'is_locked': False, 'total_participants': 8}, {'repo_name': 'FEC', 'repo_owner_name': 'Federal Election Commission', 'repo_owner_email': 'webmanager@fec.gov', 'repo_owner_user_name': 'fecgov', 'repo_owner_profile_url': 'https://github.com/fecgov', 'title': 'Gathering feedback on time period selection tool', 'bodyHTML': '<p>We\\'re exploring several options that will allow users to personalize timespans on candidate pages.</p>\\n<p>Below are four options, using a Senate election as an example. We eventually plan to apply these concepts to presidential and House candidates, too.</p>\\n<p>Please leave your thoughts on each option in the comment fields below. Your feedback will help us improve our designs.</p>\\n<h3>Option A: single drop down</h3>\\n<p>The user can select either:</p>\\n<ul>\\n<li>Two-year periods within each election cycle, or</li>\\n<li>The full cycle for each election the candidate \\u2028ran in.</li>\\n</ul>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/11636908/10526094/bfacaa92-7356-11e5-984a-882a0bb04157.png\"><img src=\"https://cloud.githubusercontent.com/assets/11636908/10526094/bfacaa92-7356-11e5-984a-882a0bb04157.png\" alt=\"candidate - senate copy\" style=\"max-width:100%;\"></a></p>\\n<h3>Option B: two steps drop down and toggle</h3>\\n<ol>\\n<li>The drop down shows every election the candidate ran in.</li>\\n<li>The toggle button breaks down the selected election into two-year periods or the full cycle.</li>\\n</ol>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/11636908/10526105/cbe963a4-7356-11e5-85a2-474a9cf22800.png\"><img src=\"https://cloud.githubusercontent.com/assets/11636908/10526105/cbe963a4-7356-11e5-85a2-474a9cf22800.png\" alt=\"candidate - senate copy 2\" style=\"max-width:100%;\"></a></p>\\n<h3>Option C: two drop downs</h3>\\n<ol>\\n<li>The first drop down shows every election the candidate ran in</li>\\n<li>The second drop down breaks the selected election into two-year periods or the full cycle.</li>\\n</ol>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/11636908/10526106/cbee51b6-7356-11e5-879c-51e032d56b84.png\"><img src=\"https://cloud.githubusercontent.com/assets/11636908/10526106/cbee51b6-7356-11e5-879c-51e032d56b84.png\" alt=\"candidate - senate copy 3\" style=\"max-width:100%;\"></a></p>\\n<h3>Option D: two steps drop down and slider</h3>\\n<ol>\\n<li>The drop down shows every election the candidate ran in.</li>\\n<li>The slider allows users to select any amount of time from the selected election, broken down by quarters.</li>\\n</ol>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/11636908/10526108/cc01e078-7356-11e5-99f3-445c74b93966.png\"><img src=\"https://cloud.githubusercontent.com/assets/11636908/10526108/cc01e078-7356-11e5-99f3-445c74b93966.png\" alt=\"candidate - senate copy 4\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/fecgov/FEC/issues/73', 'state': 'CLOSED', 'createdAt': '2015-10-16T15:29:47Z', 'lastEditedAt': None, 'publishedAt': '2015-10-16T15:29:47Z', 'updatedAt': '2015-12-18T16:44:04Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'Add a metrics page to the dashboard ', 'bodyHTML': '<p>Currently the back-end supports some limited metrics of workflow and app actions. This information is not visible on the UI.</p>', 'url': 'https://github.com/nsacyber/WALKOFF/issues/85', 'state': 'CLOSED', 'createdAt': '2017-05-26T11:58:00Z', 'lastEditedAt': None, 'publishedAt': '2017-05-26T11:58:00Z', 'updatedAt': '2018-09-12T15:25:13Z', 'labels': ['[effort] medium', '[issue-type] enhancement', '[skill-level] intermediate', 'enhancement', 'front-end', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'requirements.txt support in custom interfaces', 'bodyHTML': '<p>Custom interfaces may require additional dependencies, but currently, there is no straightforward mechanism to install them like there is for app dependencies. The install dependencies script could be modified to install dependencies for apps as well as interfaces</p>', 'url': 'https://github.com/nsacyber/WALKOFF/issues/167', 'state': 'CLOSED', 'createdAt': '2017-12-01T22:41:25Z', 'lastEditedAt': None, 'publishedAt': '2017-12-01T22:41:25Z', 'updatedAt': '2018-06-15T13:42:12Z', 'labels': ['[effort] small', '[issue-type] good first issue', '[skill-level] beginner', 'back-end', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'client-side dependency installation support for interfaces', 'bodyHTML': '<p>Currently, there is no clean way to install client dependencies for custom interfaces. If the <code>install_dependencies.py</code> script could look for a <code>package.json</code> file in the interfaces and run <code>npm install</code> in that directory, then this issue would be resolved</p>', 'url': 'https://github.com/nsacyber/WALKOFF/issues/168', 'state': 'CLOSED', 'createdAt': '2017-12-01T22:44:29Z', 'lastEditedAt': None, 'publishedAt': '2017-12-01T22:44:29Z', 'updatedAt': '2018-09-12T15:28:10Z', 'labels': ['[effort] small', '[issue-type] good first issue', '[skill-level] beginner', 'back-end', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'Create and use a JSON schema for workflows', 'bodyHTML': '<p>A JSON Schema for workflows should be created and workflows should be verified against it inside <code>core.jsonplaybookloader</code>. Additionally, it would be good documentation to put on the <code>gh-pages</code> branch.</p>', 'url': 'https://github.com/nsacyber/WALKOFF/issues/169', 'state': 'CLOSED', 'createdAt': '2017-12-01T22:47:18Z', 'lastEditedAt': None, 'publishedAt': '2017-12-01T22:47:18Z', 'updatedAt': '2018-02-08T18:57:28Z', 'labels': ['back-end', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'Split up the App API JSON Schema into multiple files', 'bodyHTML': '<p>Currently the App API JSON Schema in <code>data/walkoff_schema.json</code> is about 1000 lines long and is getting a bit bloated and hand to maintain. It would be better if it is split up into manageable files and placed in its own directory inside data. This should only involve using the <code>{\"#ref\" : \"../path/to/new/file\"}</code> feature of JSON schemas (see this issue here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"14003486\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/Julian/jsonschema/issues/98\" data-hovercard-type=\"issue\" data-hovercard-url=\"/Julian/jsonschema/issues/98/hovercard\" href=\"https://github.com/Julian/jsonschema/issues/98\">Julian/jsonschema#98</a>). This may also involve a teak in <code>core.config.config</code> depending on the reference resolver being used and possibly a change to <code>core.config.paths</code> if the path to the schema changes.</p>', 'url': 'https://github.com/nsacyber/WALKOFF/issues/171', 'state': 'OPEN', 'createdAt': '2017-12-01T23:07:25Z', 'lastEditedAt': None, 'publishedAt': '2017-12-01T23:07:25Z', 'updatedAt': '2018-09-20T19:25:56Z', 'labels': ['[effort] small', '[issue-type] enhancement', '[issue-type] good first issue', '[skill-level] beginner', 'back-end', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'Better front-end packaging', 'bodyHTML': \"<p>Currently the front end is using Angular and SystemJS as the module loader. SystemJS is pretty inefficient and loads tons of files, making the initial load take much longer than it should.</p>\\n<p>We've looked at switching to Webpack or something similar but haven't gotten a chance to implement this. Webpack would be able to compress most of our JavaScript into a few files to make loading the site easier rather than making a bajillion HTTP requests. Other solutions would be considered, but Webpack seems like the most applicable right now.</p>\", 'url': 'https://github.com/nsacyber/WALKOFF/issues/174', 'state': 'CLOSED', 'createdAt': '2017-12-05T16:08:10Z', 'lastEditedAt': None, 'publishedAt': '2017-12-05T16:08:10Z', 'updatedAt': '2018-02-02T23:53:38Z', 'labels': ['enhancement', 'front-end', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'WALKOFF', 'repo_owner_name': 'NSA Cybersecurity', 'repo_owner_email': '', 'repo_owner_user_name': 'nsacyber', 'repo_owner_profile_url': 'https://github.com/nsacyber', 'title': 'Allow Angular components as Interfaces', 'bodyHTML': '<p>Currently Interfaces are limited to relatively simple JS (or whatever plugin libraries are loaded by the interface). It would be very nice to be able to just add an additional component and somehow load it into the main module (or add in a new app module just for this), so interface developers can utilize Angular functionality to make writing interfaces easier (and better utilize our apis).</p>', 'url': 'https://github.com/nsacyber/WALKOFF/issues/181', 'state': 'OPEN', 'createdAt': '2017-12-14T15:37:51Z', 'lastEditedAt': None, 'publishedAt': '2017-12-14T15:37:51Z', 'updatedAt': '2018-02-08T18:53:48Z', 'labels': ['[effort] large', '[issue-type] enhancement', '[skill-level] advanced', 'enhancement', 'front-end', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'include a screenshot/demo', 'bodyHTML': '<p>Would be really useful to show how this can be used.</p>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/14', 'state': 'CLOSED', 'createdAt': '2016-02-12T22:25:25Z', 'lastEditedAt': None, 'publishedAt': '2016-02-12T22:25:25Z', 'updatedAt': '2016-02-17T03:25:37Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add tests for JavaScript code', 'bodyHTML': '<p>Underway in <a href=\"https://github.com/mbland/jekyll_pages_api_search/tree/add-tests\">mbland/jekyll_pages_api_search#add-tests</a>.</p>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/26', 'state': 'OPEN', 'createdAt': '2016-03-11T18:45:43Z', 'lastEditedAt': None, 'publishedAt': '2016-03-11T18:45:43Z', 'updatedAt': '2017-08-25T15:28:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Display snippet of matching result in results', 'bodyHTML': '<p>Currently, a search returns a list with page/post titles.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5249443/16735722/09576260-473f-11e6-8450-062d2f0b3f3a.png\"><img width=\"597\" alt=\"screen shot 2016-07-11 at 8 10 48 am\" src=\"https://cloud.githubusercontent.com/assets/5249443/16735722/09576260-473f-11e6-8450-062d2f0b3f3a.png\" style=\"max-width:100%;\"></a></p>\\n<p>This doesn\\'t give much context of where the result was found to see if it\\'s relevant for what I was looking for. Is it possible to display a snippet of content containing where the matching terms were located, just like Google does?</p>\\n<p>Below is a search for Jekyll and <strong>jekyll</strong> is highlighted in the content.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5249443/16735651/bfb42602-473e-11e6-8251-c98aa4bf22dd.png\"><img width=\"665\" alt=\"screen shot 2016-07-11 at 8 07 55 am\" src=\"https://cloud.githubusercontent.com/assets/5249443/16735651/bfb42602-473e-11e6-8251-c98aa4bf22dd.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/33', 'state': 'OPEN', 'createdAt': '2016-07-11T15:12:19Z', 'lastEditedAt': None, 'publishedAt': '2016-07-11T15:12:19Z', 'updatedAt': '2017-08-25T15:26:19Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 're-create preview GIF', 'bodyHTML': '<p>The one in the README is stretched.</p>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/36', 'state': 'OPEN', 'createdAt': '2016-08-04T06:41:04Z', 'lastEditedAt': None, 'publishedAt': '2016-08-04T06:41:04Z', 'updatedAt': '2017-08-25T15:26:11Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': \"Error on 'jekyll build' after adding and configuring the plugin\", 'bodyHTML': '<p>Added and configured the plugin as described in the README. I get this error when running <code>bundle exec jekyll build</code> afterwards.</p>\\n<pre><code>Configuration file: /home/jf/search-test/_config.yml\\n            Source: /home/jf/search-test\\n       Destination: /home/jf/search-test/_site\\n Incremental build: disabled. Enable with --incremental\\n      Generating... \\njekyll_pages_api_search: checking for Node.js: v6.7.0\\n  Liquid Exception: undefined method `start_with?\\' for nil:NilClass in index.html\\njekyll 3.2.1 | Error:  undefined method `start_with?\\' for nil:NilClass\\n</code></pre>\\n<p>Jekyll 3.2.1<br>\\nRuby 2.3.1<br>\\nNode.js 6.7.0</p>\\n<p>Minimal test case here, it is a fresh Jekyll site with the jekyll_pages_api_search plugin installed: <a href=\"https://github.com/jfredrickson5/search-test\">https://github.com/jfredrickson5/search-test</a></p>\\n<p>Site builds and renders normally if I remove the plugin from <code>_config.yml</code>.</p>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/37', 'state': 'OPEN', 'createdAt': '2016-10-05T20:56:56Z', 'lastEditedAt': None, 'publishedAt': '2016-10-05T20:56:56Z', 'updatedAt': '2017-08-29T16:16:55Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 8}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'test against multiple versions of Jekyll', 'bodyHTML': '<p>We need to ensure that we\\'re remaining both forward- and backward-compatible, for some range of versions that are reasonable to support. Options:</p>\\n<ul>\\n<li><a href=\"https://docs.travis-ci.com/user/languages/ruby/#Testing-against-multiple-versions-of-dependencies\" rel=\"nofollow\">https://docs.travis-ci.com/user/languages/ruby/#Testing-against-multiple-versions-of-dependencies</a></li>\\n<li><a href=\"https://github.com/thoughtbot/appraisal\">https://github.com/thoughtbot/appraisal</a></li>\\n</ul>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/39', 'state': 'OPEN', 'createdAt': '2017-01-10T23:48:57Z', 'lastEditedAt': None, 'publishedAt': '2017-01-10T23:48:57Z', 'updatedAt': '2017-01-10T23:49:05Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'jekyll_pages_api_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'upgrade Code Climate test coverage reporter', 'bodyHTML': '<pre><code>$ bundle exec rake ci_build\\n...\\nW, [2017-01-10T20:00:39.686967 #71706]  WARN -- :       This usage of the Code Climate Test Reporter is now deprecated. Since version\\n      1.0, we now require you to run `SimpleCov` in your test/spec helper, and then\\n      run the provided `codeclimate-test-reporter` binary separately to report your\\n      results to Code Climate.\\n\\n      More information here: https://github.com/codeclimate/ruby-test-reporter/blob/master/README.md\\n</code></pre>', 'url': 'https://github.com/18F/jekyll_pages_api_search/issues/40', 'state': 'OPEN', 'createdAt': '2017-01-11T01:03:02Z', 'lastEditedAt': None, 'publishedAt': '2017-01-11T01:03:02Z', 'updatedAt': '2017-01-11T01:03:02Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Support oEmbed for various third party services', 'bodyHTML': '<p>As a blog editor, I want an simpler way to embed content so that I can spend less time properly embedding tweets, YouTube videos and other resources blog authors might include in their posts.</p>\\n<p>Sketch of what we might want:</p>\\n<pre><code>The following code will embed the video below the current paragraph:\\n{% oembed https://www.youtube.com/watch?v=5l-7vmArLJY %}\\n</code></pre>\\n<p>Regardless of whether oEmbed is the ultimate solution, we should support:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> YouTube videos</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Instagram photos</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Tweets</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IFTTT recipes</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> GitHub Gists</li>\\n<li>Embedding should be done over https</li>\\n<li>Embedding should be done without cookies</li>\\n<li>Embedding should be done without introducing new embedded third-party applications</li>\\n</ul>\\n<p><a href=\"http://oembed.com/#section7\" rel=\"nofollow\">oEmbed supports almost all these</a> except, perhaps, GitHub Gists</p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/487', 'state': 'CLOSED', 'createdAt': '2015-01-26T20:39:41Z', 'lastEditedAt': None, 'publishedAt': '2015-01-26T20:39:41Z', 'updatedAt': '2017-02-28T22:31:48Z', 'labels': ['help wanted', 'type:blog-feature'], 'is_locked': False, 'total_participants': 4}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Automate bylines', 'bodyHTML': '<p>Right now blog posts require the following to get a simple byline:</p>\\n<div class=\"highlight highlight-source-yaml\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> in the frontmatter</span>\\n<span class=\"pl-ent\">authors</span>:\\n- <span class=\"pl-s\">author1</span>\\n- <span class=\"pl-s\">author2</span></pre></div>\\n<p>and in the post body</p>\\n<pre><code>&lt;p class=\"authors\"&gt;\\n  by {% author author1 %} and {% author author2 %}\\n&lt;/p&gt;\\n</code></pre>\\n<p>Let\\'s eliminate the redundancy and see if it\\'s possible to auto-generate the byline in the post template. We accidentally publish too many posts without bylines.</p>\\n<p>Desired state:<br>\\nSomething like this in <code>layouts/post.html</code></p>\\n<pre><code>&lt;p class=\"authors\"&gt;{% authors %}&lt;/p&gt;\\n</code></pre>\\n<p>Considerations:</p>\\n<ul>\\n<li>some of our posts have illustrators</li>\\n<li>authors are available in the site object at: <code>site.data.authors</code> in templates. There are different ways to tap into this depending on what kind of plugin you\\'re making.</li>\\n<li>there are probably other Jekyll sites that have done this; <a href=\"https://github.com/InternationalUnderground/internationalunderground.org/blob/master/_plugins/feature.rb#L143-L146\">I did it for a side project of mine</a>, but that might not be the best model.</li>\\n</ul>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/633', 'state': 'CLOSED', 'createdAt': '2015-03-19T18:46:03Z', 'lastEditedAt': None, 'publishedAt': '2015-03-19T18:46:03Z', 'updatedAt': '2016-10-18T15:16:45Z', 'labels': ['help wanted', 'type:blog-feature'], 'is_locked': False, 'total_participants': 2}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Option to disable jekyll-get in certain environments', 'bodyHTML': '<p>Esp. on slower connections, <code>jekyll-get</code> fetching all the data it does can add several seconds to build time.</p>\\n<p>slower connection:</p>\\n<pre><code>      Regenerating: 1 file(s) changed at 2015-03-20 10:26:39 ...done in 8.639929 seconds.\\n      Regenerating: 4 file(s) changed at 2015-03-20 10:26:48 ...done in 8.339296 seconds.\\n      Regenerating: 6 file(s) changed at 2015-03-20 10:26:56 ...done in 10.461097 seconds.\\n</code></pre>\\n<p>normal:</p>\\n<pre><code>      Regenerating: 1 file(s) changed at 2015-03-18 10:50:16 ...done in 3.690993 seconds.\\n      Regenerating: 1 file(s) changed at 2015-03-18 10:52:11 ...done in 4.006066 seconds.\\n      Regenerating: 3 file(s) changed at 2015-03-18 11:35:38 ...done in 4.453949 seconds.\\n</code></pre>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/640', 'state': 'CLOSED', 'createdAt': '2015-03-20T14:32:50Z', 'lastEditedAt': None, 'publishedAt': '2015-03-20T14:32:50Z', 'updatedAt': '2015-04-09T14:59:16Z', 'labels': ['help wanted', 'type:bug'], 'is_locked': False, 'total_participants': 2}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Discuss improvement(s) for /dashboard page and whether /projects page is needed in addition to /dashboard page', 'bodyHTML': '<p>do we have a /projects in addition to /dashboard? If we do have both, why and how are they different?</p>\\n<p>Need to get better descriptions for the Dashboard: \"how do you describe this project to people at a dinner party?\"</p>\\n<p>Clarify what the stages mean on Dashboard (they\\'re stolen from GDS now)</p>\\n<p>could this task be reworded \"Make Dashboard Better\"</p>\\n', 'url': 'https://github.com/18F/18f.gsa.gov/issues/703', 'state': 'CLOSED', 'createdAt': '2015-04-10T17:11:28Z', 'lastEditedAt': None, 'publishedAt': '2015-04-10T17:11:28Z', 'updatedAt': '2016-10-18T15:18:02Z', 'labels': ['help wanted', 'research'], 'is_locked': False, 'total_participants': 3}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Design template for case studies on site', 'bodyHTML': \"<p>It might be possible to re-use the interior page templates we're building out for everything else as a baseline. We might also want to have a different template or style for each case study.</p>\\n\", 'url': 'https://github.com/18F/18f.gsa.gov/issues/712', 'state': 'CLOSED', 'createdAt': '2015-04-10T17:59:20Z', 'lastEditedAt': None, 'publishedAt': '2015-04-10T17:59:20Z', 'updatedAt': '2016-10-18T15:19:00Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Print stylesheet', 'bodyHTML': '<p>We should provide a stylesheet that leverages <a href=\"https://www.smashingmagazine.com/2011/11/how-to-set-up-a-print-style-sheet/\" rel=\"nofollow\">best</a> <a href=\"http://alistapart.com/article/goingtoprint\" rel=\"nofollow\">practices</a> and helps people print our blog posts :)</p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/1606', 'state': 'CLOSED', 'createdAt': '2016-03-29T20:59:31Z', 'lastEditedAt': None, 'publishedAt': '2016-03-29T20:59:31Z', 'updatedAt': '2016-04-15T13:57:01Z', 'labels': ['help wanted', 'type:blog-feature'], 'is_locked': False, 'total_participants': 5}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Blog archive pages for guest authors and former employees', 'bodyHTML': '<p>Right now guest authors and people who leave 18F don\\'t get an archive of blog posts they authored for us. I\\'d be great for our own tracking purposes and for alums to have a easy list to point at to have these archive pages.</p>\\n<p>We get archives for current team members at <code>/team/&lt;name&gt;/</code> (where <code>name</code> matches a common <code>name</code> field in <code>_team</code> and <code>_data/authors.yml</code>. If no file matches <code>_team/&lt;name&gt;.md</code> for an author, no page generates. If the author has a <code>url</code> listed, we link to that url on the blog post. It\\'d be great if instead we generated a <code>/author/&lt;name&gt;/</code> page with the author\\'s full name, a list of blog posts, and <em>maybe</em> some indication they\\'re a guest or alum.</p>\\n<div class=\"highlight highlight-text-gherkin-feature\"><pre><span class=\"pl-k\">Feature</span>:<span class=\"pl-s\"> All authors of blog posts should have an archive of their writing</span>\\n  Readers should be have a reference for all posts written by an author, regardless of whether they work for 18F right now.\\n  Authors are kept in a data file located at `_data/authors.yml`. Current team members have a file in `_team`, that file generates an archive at `/team/<span class=\"pl-smi\">&lt;name&gt;</span>.\\n  The final solution should \\n  1. Ensure `_data/authors.yml` contains all authors\\n  2. Generate an archive page for every author listed in `_data/authors.yml` with a url structure: `/author/<span class=\"pl-smi\">&lt;name&gt;</span>`\\n  3. The [default_profile](https://github.com/18F/18f.gsa.gov/blob/master/_layouts/default-profile.html) layout can be used or adapted for the archive template\\n\\n<span class=\"pl-k\">Scenario</span>:<span class=\"pl-s\"> A guest author or former team member writes a blog post for 18f.gsa.gov</span>\\n<span class=\"pl-k\">Given </span>the author is listed in `_data/authors.yml`\\n<span class=\"pl-k\">When </span>I click on the author\\'s name on the blog post\\n<span class=\"pl-k\">Then </span>I am taken to a page listing all the posts written by that author.\\n\\n<span class=\"pl-k\">Scenario</span>:<span class=\"pl-s\"> An 18F team member writes a blog post for 18f.gsa.gov</span>\\n<span class=\"pl-k\">Given </span>the team member is listed in `_data/authors.yml`\\n<span class=\"pl-k\">When </span>I click on the team member\\'s name on the blog post\\n<span class=\"pl-k\">Then </span>I am taken to a page listing all the posts written by that team member\\n\\n<span class=\"pl-k\">Scenario</span>:<span class=\"pl-s\"> Builds fail if all authors on a post are not found</span>\\n<span class=\"pl-k\">Given </span>a blog post is drafted\\n  <span class=\"pl-k\">And </span>one or more of the post\\'s authors are not listed in `_data/authors.yml`\\n<span class=\"pl-k\">When </span>I issue a pull request or build the site\\n<span class=\"pl-k\">Then </span>Jekyll will fail to build \\n  <span class=\"pl-k\">And </span>a descriptive error will be printed in the console\\n\\n<span class=\"pl-k\">Scenario</span>:<span class=\"pl-s\"> Author links should have a predictable URL</span>\\n<span class=\"pl-k\">Given </span>A team member leaves 18F\\n  <span class=\"pl-k\">And </span>that team member has written &gt;= 1 blog posts\\n<span class=\"pl-k\">When </span>I click on the team member\\'s name or otherwise navigate to their archive page\\n<span class=\"pl-k\">Then </span>I am taken to a page listing all the posts written by that team member\\n\\n<span class=\"pl-k\">Scenario</span>:<span class=\"pl-s\"> Existing links to team member profiles should redirect to their blog archive</span>\\n<span class=\"pl-k\">Given </span>a user navigates to an existing team profile page (example: /team/boone/)\\n<span class=\"pl-k\">When </span>The page loads\\n<span class=\"pl-k\">Then </span>the user should be redirected to their author profile page (example: /author/boone)</pre></div>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/1637', 'state': 'CLOSED', 'createdAt': '2016-04-12T20:39:07Z', 'lastEditedAt': '2016-10-18T17:29:46Z', 'publishedAt': '2016-04-12T20:39:07Z', 'updatedAt': '2016-10-28T16:51:36Z', 'labels': ['dev:back-end', 'dev:front-end', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update chat.18f.gov links to specific channels', 'bodyHTML': '<p>As referenced in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"148545468\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/18f.gsa.gov/issues/1641\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/18f.gsa.gov/pull/1641/hovercard\" href=\"https://github.com/18F/18f.gsa.gov/pull/1641\">#1641</a>, we can now link directly to open chat channels. We should go back through old posts and look for links to chat.18f.gov that can be updated.</p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/1643', 'state': 'CLOSED', 'createdAt': '2016-04-15T13:56:10Z', 'lastEditedAt': None, 'publishedAt': '2016-04-15T13:56:10Z', 'updatedAt': '2016-04-15T14:56:58Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Broken links', 'bodyHTML': '<p>From a member of the public, via email, we have a couple of broken links on this page:<br>\\n<a href=\"https://18f.gsa.gov/2016/03/23/how-to-integrate-the-draft-us-web-design-standards-into-existing-projects/\" rel=\"nofollow\">https://18f.gsa.gov/2016/03/23/how-to-integrate-the-draft-us-web-design-standards-into-existing-projects/</a></p>\\n<p>eg <a href=\"https://playbook.cio.gov/designstandards/sidenav/\" rel=\"nofollow\">https://playbook.cio.gov/designstandards/sidenav/</a></p>\\n<p>and <a href=\"https://playbook.cio.gov/designstandards/form-templates/\" rel=\"nofollow\">https://playbook.cio.gov/designstandards/form-templates/</a></p>\\n<p>The correct links for those are <a href=\"https://standards.usa.gov/sidenav/\" rel=\"nofollow\">https://standards.usa.gov/sidenav/</a> and <a href=\"https://standards.usa.gov/form-templates/\" rel=\"nofollow\">https://standards.usa.gov/form-templates/</a></p>\\n<p>We should check the post for any other links to the playbook.cio.gov domain to make sure they\\'re working properly.</p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/1669', 'state': 'CLOSED', 'createdAt': '2016-04-27T18:39:37Z', 'lastEditedAt': None, 'publishedAt': '2016-04-27T18:39:37Z', 'updatedAt': '2016-05-06T13:16:12Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Solidify grid system', 'bodyHTML': '', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2013', 'state': 'CLOSED', 'createdAt': '2016-11-02T20:48:40Z', 'lastEditedAt': '2016-11-30T15:53:09Z', 'publishedAt': '2016-11-02T20:48:40Z', 'updatedAt': '2016-12-05T18:11:59Z', 'labels': ['help wanted', 'workflow:blocked'], 'is_locked': False, 'total_participants': 4}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Certain collections have an empty primary path', 'bodyHTML': '<h2>Expected Behavior</h2>\\n<p>All collections that have subpages should also have a parent. Even if it is only a parent landing page the shows the different subpages</p>\\n<h2>Actual Behavior</h2>\\n<p>Parent urls are 404s or empty</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a href=\"https://18f.gsa.gov/author/\" rel=\"nofollow\">https://18f.gsa.gov/author/</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> <a href=\"https://18f.gsa.gov/project/\" rel=\"nofollow\">https://18f.gsa.gov/project/</a> <strong><em>this is now <code>/what-we-deliver/</code></em></strong></li>\\n</ul>\\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1450354\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/coreycaitlin\">@coreycaitlin</a></p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2244', 'state': 'OPEN', 'createdAt': '2017-01-30T19:59:59Z', 'lastEditedAt': '2017-03-02T18:45:37Z', 'publishedAt': '2017-01-30T19:59:59Z', 'updatedAt': '2018-01-19T18:47:32Z', 'labels': ['content', 'dev:back-end', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'old 18F blog feed URL not redirected', 'bodyHTML': '<p>The old feed URL attempts to redirect to the new feed using an HTML meta-refresh (see <a href=\"https://github.com/18F/18f.gsa.gov/blob/master/pages/feed.md\">feed.md</a>), rather then redirecting to the new URL with an HTTP 301.</p>\\n<p>Many Feed readers (Safari, NetNewsWire, etc) won\\'t follow a meta-refresh. Only by chance did I notice I hadn\\'t been seeing any 18F posts for the last 6 months! From searching around, I gather a redirect might be setup via the S3/CloudFront console...</p>\\n<h2>Expected Behavior</h2>\\n<pre><code>$ curl -I https://18f.gsa.gov/feed/\\nHTTP/1.1 301 Moved Permanently\\nLocation: https://18f.gsa.gov/feed.xml\\n...\\n</code></pre>\\n<h2>Actual Behavior</h2>\\n<pre><code>$ curl -I https://18f.gsa.gov/feed/\\nHTTP/1.1 200 OK\\nContent-Type: text/html\\n...\\n</code></pre>\\n<h2>Steps to reproduce the behavior</h2>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Run <code>curl -I https://18f.gsa.gov/feed/</code></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Observe 200 result</li>\\n</ul>\\n<h2>This is issue is done when:</h2>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Curl command produces 301 and Location header with new URL (<a href=\"https://18f.gsa.gov/feed.xml\" rel=\"nofollow\">https://18f.gsa.gov/feed.xml</a>)</li>\\n</ul>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2260', 'state': 'OPEN', 'createdAt': '2017-02-05T22:22:41Z', 'lastEditedAt': None, 'publishedAt': '2017-02-05T22:22:41Z', 'updatedAt': '2018-01-19T18:43:44Z', 'labels': ['dev:dev-ops', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Suggestions for how to improve the site', 'bodyHTML': '<p>After doing development work on the site for several months, I have put together a series of suggestions for potential ways the site could be improved</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Improve the search functionality of the site</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Update/streamline plugins\\n<ul>\\n<li>Replace <code>_plugins/team.rb</code> with a complex include.</li>\\n<li>remove <code>find_collection</code> filter</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Layouts\\n<ul>\\n<li>Rename layouts to be less confusing</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> How we work\\n<ul>\\n<li>update page icons. The different colors on the SVGs is a bit off-putting</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Mobile footer: could be visually refined</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Author pages\\n<ul>\\n<li>improve header</li>\\n<li>potentially include tags of all author posts in one consolidated section on the page</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Tag pages:\\n<ul>\\n<li>Make header of page match other pages throughout site (blue top ribbon)</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Blog\\n<ul>\\n<li>Consider changing page of all posts to more closely resemble blog cards used in the related posts section of an individual post</li>\\n<li>In list of blog posts, the last list has a border bottom that should be removed</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Homepage\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> make hero more closely resemble hero in project pages, with image not going full width</li>\\n</ul>\\n</li>\\n</ul>\\n<p>cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7362915\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/elainekamlley\">@elainekamlley</a></p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2404', 'state': 'OPEN', 'createdAt': '2017-04-24T16:55:38Z', 'lastEditedAt': '2018-01-19T18:38:20Z', 'publishedAt': '2017-04-24T16:55:38Z', 'updatedAt': '2018-01-19T18:38:20Z', 'labels': ['design', 'dev', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Remove accesslint-ci', 'bodyHTML': '<p>From AccessLint:</p>\\n<blockquote>\\n<p>With the release of the new GitHub App, weve deprecated accesslint-ci and, as of now, it will no longer comment on your Pull Requests. On October 1st well also be revoking all tokens for the accesslint-ci bot. Please note that this has the potential to disrupt your CircleCI build. We suggest removing accesslint-ci as part of your build process.</p>\\n</blockquote>\\n<p>This means that we will need to</p>\\n<ul>\\n<li>remove accesslint-ci from <code>_config.yml</code></li>\\n<li>potentially replace its functionality with the new-and-improved <a href=\"https://www.accesslint.com/\" rel=\"nofollow\">AccessLint GitHub integration</a></li>\\n</ul>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2522', 'state': 'OPEN', 'createdAt': '2017-08-29T21:02:01Z', 'lastEditedAt': '2017-08-29T21:03:57Z', 'publishedAt': '2017-08-29T21:02:01Z', 'updatedAt': '2018-09-04T19:30:13Z', 'labels': ['dev:back-end', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Re-organize what we deliver page', 'bodyHTML': '<p>The <code>/what-we-deliver</code> page should</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> reflect two areas of work - platforms and custom solutions</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> contact us to be more prominent</li>\\n</ul>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2621', 'state': 'CLOSED', 'createdAt': '2017-12-26T19:09:59Z', 'lastEditedAt': '2018-01-22T18:28:13Z', 'publishedAt': '2017-12-26T19:09:59Z', 'updatedAt': '2018-02-07T15:48:11Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Capture our current rates for conversion, button', 'bodyHTML': '<p>Add analytics to our contact button so we can track where folks were on the page that resulted in contacting us</p>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2624', 'state': 'CLOSED', 'createdAt': '2017-12-26T19:17:47Z', 'lastEditedAt': None, 'publishedAt': '2017-12-26T19:17:47Z', 'updatedAt': '2018-02-06T16:47:46Z', 'labels': ['dev:back-end', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': '18f.gsa.gov', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Be able to add multiple github repos to project page sidebar', 'bodyHTML': '<h2>Expected Behavior</h2>\\n<p>Be able to add multiple repos to a project page side bar.</p>\\n<h2>Actual Behavior</h2>\\n<p>Currently the layout only renders one link and not multiple</p>\\n<h2>This is issue is done when:</h2>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> you can add multiple github repo links</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> they in a unordered list under GitHub repo header</li>\\n</ul>', 'url': 'https://github.com/18F/18f.gsa.gov/issues/2645', 'state': 'CLOSED', 'createdAt': '2018-01-19T18:35:32Z', 'lastEditedAt': '2018-03-19T16:04:45Z', 'publishedAt': '2018-01-19T18:35:32Z', 'updatedAt': '2018-03-19T16:04:45Z', 'labels': ['dev:back-end', 'dev:front-end', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'knowledge-sharing-toolkit', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Templatize the URLs', 'bodyHTML': '<p>Currently, the URLs for each service is hard-coded into the nginx config files, etc. This is a problem for deploying to multiple environments (as seen in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138284824\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/knowledge-sharing-toolkit/issues/15\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/knowledge-sharing-toolkit/pull/15/hovercard\" href=\"https://github.com/18F/knowledge-sharing-toolkit/pull/15\">#15</a>), but this would be an obstacle for anyone trying to deploy in a different agency.</p>', 'url': 'https://github.com/18F/knowledge-sharing-toolkit/issues/16', 'state': 'OPEN', 'createdAt': '2016-03-03T20:16:04Z', 'lastEditedAt': None, 'publishedAt': '2016-03-03T20:16:04Z', 'updatedAt': '2016-03-04T21:25:00Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Extra pipe `|` showing in header-extended when only search is present', 'bodyHTML': '<p>When search is the only item in the header there is an empty <code>&lt;li&gt;</code> generated which causes a <code>|</code> to be added after the search. <a href=\"https://github.com/18F/uswds-jekyll/blob/master/_includes/components/header--extended.html#L72\">header--extended.html</a> is where this functionality lives.</p>\\n<h3>Screenshots</h3>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1449852/30868171-ddc01484-a2ab-11e7-8cd8-fb4a2251b5d2.png\"><img src=\"https://user-images.githubusercontent.com/1449852/30868171-ddc01484-a2ab-11e7-8cd8-fb4a2251b5d2.png\" alt=\"screen shot 2017-09-26 at 11 14 01 am\" style=\"max-width:100%;\"></a></p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1449852/30868205-f1bb4f12-a2ab-11e7-9d4c-be05a2a0899d.png\"><img src=\"https://user-images.githubusercontent.com/1449852/30868205-f1bb4f12-a2ab-11e7-9d4c-be05a2a0899d.png\" alt=\"screen shot 2017-09-26 at 11 14 24 am\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/46', 'state': 'CLOSED', 'createdAt': '2017-09-26T15:18:33Z', 'lastEditedAt': None, 'publishedAt': '2017-09-26T15:18:33Z', 'updatedAt': '2017-12-01T15:31:31Z', 'labels': ['[issue-type] bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add footer variations for slim and big', 'bodyHTML': '<p><strong>Issue description:</strong><br>\\nCurrently we have the option of setting the header type in the <code>header.yml</code> file. I think it would be nice to be able to set the footer type as well between <code>slim</code>, <code>medium</code>, and <code>big</code> in the <code>footer.yml file</code>. At the moment the default footer is medium.</p>\\n<p>You can see the footer code here:</p>\\n<ul>\\n<li><a href=\"https://components.standards.usa.gov/components/detail/footer--slim.html\" rel=\"nofollow\">slim footer</a></li>\\n<li><a href=\"https://components.standards.usa.gov/components/detail/footer--default.html\" rel=\"nofollow\">medium footer</a></li>\\n<li><a href=\"https://components.standards.usa.gov/components/detail/footer--big.html\" rel=\"nofollow\">big footer</a></li>\\n</ul>\\n<p>The slim footer would be easier to implement while the big footer would need some thought around how to set up the topic links in the footer.</p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/53', 'state': 'OPEN', 'createdAt': '2017-10-26T14:06:33Z', 'lastEditedAt': '2018-02-28T17:04:48Z', 'publishedAt': '2017-10-26T14:06:33Z', 'updatedAt': '2018-10-04T11:46:11Z', 'labels': ['[effort] large', '[impact] open government', '[issue-type] enhancement', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add sub navigation option for sidenav', 'bodyHTML': '<p>Currently if you set the sidenav to the primary set of links which contains nested links the sub links do not show and sub links are only rendered in the top nav. I would expect the sidenav to render the same nested elements as the top navigation.</p>\\n<p>This is loosely related to the PR put in by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=24941490\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/AminPIC\">@AminPIC</a> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"267498722\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/uswds-jekyll/issues/52\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/uswds-jekyll/pull/52/hovercard\" href=\"https://github.com/18F/uswds-jekyll/pull/52\">#52</a>, I\\'d love to pull some functionality from the guides-style for rendering sub nav links.</p>\\n<ul>\\n<li><a href=\"https://github.com/18F/guides-style/blob/master/_includes/sidebar.html\">https://github.com/18F/guides-style/blob/master/_includes/sidebar.html</a></li>\\n<li><a href=\"https://github.com/18F/guides-style/blob/master/_includes/sidebar-children.html\">https://github.com/18F/guides-style/blob/master/_includes/sidebar-children.html</a></li>\\n<li><a href=\"https://github.com/18F/guides-style#selectively-expanding-navigation-bar-items\">https://github.com/18F/guides-style#selectively-expanding-navigation-bar-items</a></li>\\n</ul>\\n<h3>Screenshot</h3>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1449852/32179442-c93a6b2a-bd65-11e7-9539-cd40988e114b.png\"><img src=\"https://user-images.githubusercontent.com/1449852/32179442-c93a6b2a-bd65-11e7-9539-cd40988e114b.png\" alt=\"screen shot 2017-10-30 at 11 30 25 am\" style=\"max-width:100%;\"></a></p>\\n<h3>Navigation code</h3>\\n<pre><code>primary:\\n  - text: Documentation\\n    href: /docs/\\n  - text: Navigation section\\n    links:\\n      - text: Demo link A\\n        href: /two/a/\\n      - text: Demo link B\\n        href: /two/b/\\n      - text: Demo link C\\n        href: /two/c/\\n  - text: Referenced section\\n    links: footer\\n  - text: External link\\n    href: https://18f.gsa.gov\\n</code></pre>', 'url': 'https://github.com/18F/uswds-jekyll/issues/55', 'state': 'OPEN', 'createdAt': '2017-10-30T15:36:12Z', 'lastEditedAt': '2017-10-31T13:11:23Z', 'publishedAt': '2017-10-30T15:36:12Z', 'updatedAt': '2018-06-06T15:15:21Z', 'labels': ['[effort] large', '[impact] open government', '[issue-type] enhancement', '[skill-level] advanced', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Search box width changes', 'bodyHTML': '<p>On the landing page and docs page the search box width is different than on the search results page... <g-emoji class=\"g-emoji\" alias=\"thinking\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f914.png\"></g-emoji>  They are using the same component <a href=\"https://github.com/18F/uswds-jekyll/blob/master/_includes/components/header--extended.html\">header--extended.html</a></p>\\n<h3>Landing page</h3>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1449852/34528121-e0d12592-f075-11e7-98b0-30841e1c311c.png\"><img src=\"https://user-images.githubusercontent.com/1449852/34528121-e0d12592-f075-11e7-98b0-30841e1c311c.png\" alt=\"screen shot 2018-01-03 at 11 01 44 am\" style=\"max-width:100%;\"></a></p>\\n<h3>Search results page</h3>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1449852/34528123-e3d5595c-f075-11e7-9453-5880a1ce9d17.png\"><img src=\"https://user-images.githubusercontent.com/1449852/34528123-e3d5595c-f075-11e7-9453-5880a1ce9d17.png\" alt=\"screen shot 2018-01-03 at 11 02 00 am\" style=\"max-width:100%;\"></a></p>\\n<p>live examples:<br>\\n<a href=\"https://federalist-proxy.app.cloud.gov/site/18f/uswds-jekyll/\" rel=\"nofollow\">https://federalist-proxy.app.cloud.gov/site/18f/uswds-jekyll/</a> - short search box width<br>\\n<a href=\"https://federalist-proxy.app.cloud.gov/site/18f/uswds-jekyll/search/\" rel=\"nofollow\">https://federalist-proxy.app.cloud.gov/site/18f/uswds-jekyll/search/</a> - normal search box width</p>\\n<p>compare to the component here:<br>\\n<a href=\"https://components.standards.usa.gov/components/detail/header--extended.html\" rel=\"nofollow\">https://components.standards.usa.gov/components/detail/header--extended.html</a></p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/90', 'state': 'CLOSED', 'createdAt': '2018-01-03T16:07:30Z', 'lastEditedAt': None, 'publishedAt': '2018-01-03T16:07:30Z', 'updatedAt': '2018-01-03T19:03:12Z', 'labels': ['[issue-type] bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add the ability to make the sidenav sticky', 'bodyHTML': '<p>This should be a configuration option that can be toggled on and off.</p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/100', 'state': 'CLOSED', 'createdAt': '2018-01-16T15:14:04Z', 'lastEditedAt': None, 'publishedAt': '2018-01-16T15:14:04Z', 'updatedAt': '2018-04-05T15:21:01Z', 'labels': ['[effort] medium', '[impact] open government', '[issue-type] enhancement', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add optional logo to header.yml', 'bodyHTML': '<p><strong>Issue Description:</strong><br>\\nAdd the ability to specify a header logo image in the <code>header.yml</code> data file with a URL. <a href=\"https://github.com/18F/uswds-jekyll/blob/master/_data/header.yml\">https://github.com/18F/uswds-jekyll/blob/master/_data/header.yml</a></p>\\n<p>Adding a logo should be optional and if not wanted could be commented out from <code>header.yml</code>.</p>\\n<p>See <a href=\"https://oes.gsa.gov/\" rel=\"nofollow\">https://oes.gsa.gov/</a> for an example of a logo in the header and see the following component guide for the different header types <a href=\"https://components.designsystem.digital.gov/components/detail/header--default.html\" rel=\"nofollow\">https://components.designsystem.digital.gov/components/detail/header--default.html</a></p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/124', 'state': 'OPEN', 'createdAt': '2018-02-16T16:14:56Z', 'lastEditedAt': '2018-02-28T17:00:50Z', 'publishedAt': '2018-02-16T16:14:56Z', 'updatedAt': '2018-03-02T19:49:09Z', 'labels': ['[effort] small', '[impact] open government', '[issue-type] enhancement', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Compress SASS in the _config.yml', 'bodyHTML': '<p><strong>Issue Description:</strong><br>\\nSet the config.yml file to compress the scss output</p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/125', 'state': 'CLOSED', 'createdAt': '2018-02-16T18:45:30Z', 'lastEditedAt': '2018-03-02T21:33:56Z', 'publishedAt': '2018-02-16T18:45:30Z', 'updatedAt': '2018-06-15T22:24:07Z', 'labels': ['[effort] small', '[impact] open government', '[issue-type] enhancement', '[issue-type] good first issue', '[skill-level] beginner', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add spacing for multiple logos in footer ', 'bodyHTML': '<p>When you add multiple logos into the footer their is no spacing between the logos.<br>\\nAdd some spacing when multiple logos are used.</p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/127', 'state': 'OPEN', 'createdAt': '2018-02-20T18:17:56Z', 'lastEditedAt': None, 'publishedAt': '2018-02-20T18:17:56Z', 'updatedAt': '2018-03-02T21:37:26Z', 'labels': ['[effort] small', '[impact] open government', '[issue-type] enhancement', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update to USWDS 1.5.0', 'bodyHTML': '<p>Running <code>npm run update-uswds</code> should do the trick to get the updates from USWDS<br>\\n<a href=\"https://www.npmjs.com/package/uswds\" rel=\"nofollow\">https://www.npmjs.com/package/uswds</a></p>\\n<p>Release notes -  <a href=\"https://github.com/uswds/uswds/releases/tag/v1.5.0\">https://github.com/uswds/uswds/releases/tag/v1.5.0</a></p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/132', 'state': 'CLOSED', 'createdAt': '2018-02-27T16:01:25Z', 'lastEditedAt': '2018-03-02T21:44:58Z', 'publishedAt': '2018-02-27T16:01:25Z', 'updatedAt': '2018-06-15T22:23:53Z', 'labels': ['[effort] small', '[impact] open government', '[issue-type] enhancement', '[skill-level] advanced', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'uswds-jekyll', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add header component for basic header with mega menu and extended header with mega menu', 'bodyHTML': '<p>Add 2 additional header options for  <a href=\"https://designsystem.digital.gov/components/headers/#basic-mega-menu\" rel=\"nofollow\">basic-mega-menu</a> and <a href=\"https://designsystem.digital.gov/components/headers/#extended-mega-menu\" rel=\"nofollow\">extended mega menu</a> that are part of the USWDS</p>', 'url': 'https://github.com/18F/uswds-jekyll/issues/158', 'state': 'CLOSED', 'createdAt': '2018-06-13T15:13:57Z', 'lastEditedAt': '2018-06-13T15:14:09Z', 'publishedAt': '2018-06-13T15:13:57Z', 'updatedAt': '2018-11-01T14:34:22Z', 'labels': ['[effort] medium', '[impact] open government', '[issue-type] enhancement', '[issue-type] good first issue', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'anet', 'repo_owner_name': 'NCI Agency', 'repo_owner_email': '', 'repo_owner_user_name': 'NCI-Agency', 'repo_owner_profile_url': 'https://github.com/NCI-Agency', 'title': 'Authentication module', 'bodyHTML': '<p>Add:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> the ability to identify people based on more than one identity (i.e. several domain usernames, mix of accounts below)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> the ability to authenticate through either:\\n<ul>\\n<li>windows authentication as currently implemented</li>\\n<li>an established standard (i.e. OAuth 2.0, OpenID ...)</li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> UI to allow users to chose (when applicable) between Windows single sign-on, local account sign-in/ creation or delegation to 3rd party identity providers</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> update public demo/training server to use delegation to public cloud identity providers</li>\\n</ul>', 'url': 'https://github.com/NCI-Agency/anet/issues/619', 'state': 'OPEN', 'createdAt': '2018-05-30T09:06:47Z', 'lastEditedAt': '2018-08-23T09:19:44Z', 'publishedAt': '2018-05-30T09:06:47Z', 'updatedAt': '2018-08-23T09:19:44Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'recruiter', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Tab and form UI have mobile styles', 'bodyHTML': '<p>Consult with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=113896\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/shawnbot\">@shawnbot</a> on how this might work in context of USWDS styles -<br>\\nfor some reason USWDS Jekyll demo site isn\\'t responsive in current deploy.</p>', 'url': 'https://github.com/GSA/recruiter/issues/9', 'state': 'CLOSED', 'createdAt': '2017-05-09T21:26:49Z', 'lastEditedAt': '2017-05-09T21:52:23Z', 'publishedAt': '2017-05-09T21:26:49Z', 'updatedAt': '2017-09-07T16:20:58Z', 'labels': ['enhancement', 'help wanted', 'ui'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'recruiter', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Escape should close the recruiter modal', 'bodyHTML': '<p>Escape and/or clicking anywhere else but the modal window should close the modal.</p>', 'url': 'https://github.com/GSA/recruiter/issues/13', 'state': 'CLOSED', 'createdAt': '2017-08-10T00:09:23Z', 'lastEditedAt': '2017-08-18T17:04:49Z', 'publishedAt': '2017-08-10T00:09:23Z', 'updatedAt': '2017-10-10T23:26:01Z', 'labels': ['enhancement', 'help wanted', 'ui'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'recruiter', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Form should open with focus in first field', 'bodyHTML': '', 'url': 'https://github.com/GSA/recruiter/issues/14', 'state': 'OPEN', 'createdAt': '2017-08-10T19:23:36Z', 'lastEditedAt': None, 'publishedAt': '2017-08-10T19:23:36Z', 'updatedAt': '2017-08-10T19:24:46Z', 'labels': ['enhancement', 'help wanted', 'ui'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'recruiter', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Tab nav and cmd+enter should work', 'bodyHTML': '', 'url': 'https://github.com/GSA/recruiter/issues/15', 'state': 'OPEN', 'createdAt': '2017-08-10T19:25:14Z', 'lastEditedAt': None, 'publishedAt': '2017-08-10T19:25:14Z', 'updatedAt': '2017-08-24T19:09:36Z', 'labels': ['enhancement', 'help wanted', 'ui'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'recruiter', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Background overlay when recruiter form is visible', 'bodyHTML': '<p>There is apparently an extant class for this in USWDS standards, hidden by default, I think.</p>', 'url': 'https://github.com/GSA/recruiter/issues/19', 'state': 'CLOSED', 'createdAt': '2017-08-23T18:17:36Z', 'lastEditedAt': None, 'publishedAt': '2017-08-23T18:17:36Z', 'updatedAt': '2017-09-07T16:24:22Z', 'labels': ['enhancement', 'help wanted', 'ui'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'gsa-doc-digital-signature', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Unpack feature no longer creates *.up7 extension', 'bodyHTML': '<p>The Unpack feature of the GSA signing tool no longer renders a filename with the *.up7 extension.  It renders a Word document that simply overwrites the original document, negating the whole point of unpacking.  Is it possible to get the *.up7 extension reinstituted?</p>\\n<p>Lee Powell<br>\\nOFR</p>', 'url': 'https://github.com/GSA/gsa-doc-digital-signature/issues/18', 'state': 'OPEN', 'createdAt': '2016-10-19T12:44:43Z', 'lastEditedAt': None, 'publishedAt': '2016-10-19T12:44:43Z', 'updatedAt': '2016-11-28T15:46:58Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'gsa-doc-digital-signature', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'PKCS7 2.0 Hangs during Cert Checking with Java JRE u141', 'bodyHTML': '<p>We recently had Java JRE u141 installed and found an issue with PKCS7 2.0. During the \"checking expiration date of signing certificate\" step of PKCS7, the application just hangs and does not move forward to signing the document. The status bar gets to 80% and hangs accordingly.</p>\\n<p>The workaround we have this is to go to Options with in PKCS7 and uncheck the Enable Revocation Checking. Once this is done, it will sign the document.</p>\\n<p>Any settings that need to be modified within PKCS7 or Java? Is this a known behavior?</p>', 'url': 'https://github.com/GSA/gsa-doc-digital-signature/issues/27', 'state': 'OPEN', 'createdAt': '2017-09-13T18:21:58Z', 'lastEditedAt': None, 'publishedAt': '2017-09-13T18:21:58Z', 'updatedAt': '2017-09-28T17:25:37Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'guides-style', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '`internal` should be implicit', 'bodyHTML': \"<p>If a <code>navigation[].url</code> starts with <code>https?://</code>, it's not an external link, otherwise, it is. This shouldn't need to be specified in the <code>_config.yml</code>.</p>\", 'url': 'https://github.com/18F/guides-style/issues/69', 'state': 'OPEN', 'createdAt': '2016-07-01T06:09:31Z', 'lastEditedAt': None, 'publishedAt': '2016-07-01T06:09:31Z', 'updatedAt': '2016-07-01T06:09:31Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'guides-style', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'consider converting to a Jekyll Theme', 'bodyHTML': '<p>Will likely make the project simpler, though this requires Jekyll 3.2+.</p>\\n<p><a href=\"https://jekyllrb.com/docs/themes/\" rel=\"nofollow\">https://jekyllrb.com/docs/themes/</a></p>', 'url': 'https://github.com/18F/guides-style/issues/73', 'state': 'CLOSED', 'createdAt': '2016-08-24T04:54:55Z', 'lastEditedAt': None, 'publishedAt': '2016-08-24T04:54:55Z', 'updatedAt': '2017-10-27T20:02:55Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'guides-style', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Determine content for footer', 'bodyHTML': '<p>Using the <a href=\"https://standards.usa.gov/components/footers/\" rel=\"nofollow\">medium footer</a>. Needs the updated logo and whatever text we decide should be in there.</p>', 'url': 'https://github.com/18F/guides-style/issues/81', 'state': 'CLOSED', 'createdAt': '2017-03-29T23:24:24Z', 'lastEditedAt': None, 'publishedAt': '2017-03-29T23:24:24Z', 'updatedAt': '2017-04-03T20:44:02Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'guides-style', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update version of Jekyll used', 'bodyHTML': \"<p>I'm totally not sure where this is in the codebase, but I know it relies on a really old version of Jekyll <em>somewhere</em>. That's no gud.</p>\", 'url': 'https://github.com/18F/guides-style/issues/84', 'state': 'CLOSED', 'createdAt': '2017-03-30T19:44:03Z', 'lastEditedAt': None, 'publishedAt': '2017-03-30T19:44:03Z', 'updatedAt': '2017-10-27T20:12:34Z', 'labels': ['blocked', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'open-source-policy', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Standardize LICENSE across 18F projects', 'bodyHTML': '<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> create snippet.md with prototypical 18F license</li>\\n</ul>\\n<p><del>- [ ] ping project owners to update repos</del></p>', 'url': 'https://github.com/18F/open-source-policy/issues/5', 'state': 'CLOSED', 'createdAt': '2014-06-02T14:33:45Z', 'lastEditedAt': None, 'publishedAt': '2014-06-02T14:33:45Z', 'updatedAt': '2014-08-02T04:20:14Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'open-source-policy', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Resource to Argue that Secure Agencies are using Open Source', 'bodyHTML': '<p>I was recently question by an executive from the Department of Labor for support for the use of Open Source---in particular, she wanted to know what other agencies were using open source.  I composed (essentially) the following response to her.  I believe something like this could be added as a new document, perhaps as a one-page \"Look who is using open source\", or something more formal.</p>\\n<p>Thank you for your question about the use of Open Source in other agencies.  As I mentioned in my off-the-cuff remarks, 18F alone is currently working on open-source projects for the Navy Reserve (and I forgot to mention the Air Force and Treasury, as well as traditionally less security-oriented agencies, such as the Peace Corps.)  In fact, 18F\\'s basic policy is to always use Open Source, in accordance with the OMB\\'s U.S. Digital Services Playbook Play <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"39134360\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/open-source-policy/issues/13\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/open-source-policy/pull/13/hovercard\" href=\"https://github.com/18F/open-source-policy/pull/13\">#13</a>, \"Default to Open\".  A cross-governmental set of open-source policy documents has been collected here.</p>\\n<p>However, you may find the following references add gravitas to this position.</p>\\n<p>A collection of 970 Federal open-source projects specifically hosted at GitHub, which is one of several cloud-based code repository systems, can be found here (prepare to scroll a lot, or narrow your search on the right!): <a href=\"https://www.govcode.org\" rel=\"nofollow\">https://www.govcode.org</a></p>\\n<p>A different DoD-specific list is the Defense Advanced Research Projects Agency catalog of open-source projects: <a href=\"http://www.darpa.mil/OpenCatalog/index.html\" rel=\"nofollow\">http://www.darpa.mil/OpenCatalog/index.html</a></p>\\n<p>There are two very active email listservs discussing and promoting the use of open source.  You need not subscribe to these listservs to review all the conversations there. For government generally:</p>\\n<p><a href=\"https://groups.google.com/forum/?nomobile=true#!forum/government-open-source\" rel=\"nofollow\">https://groups.google.com/forum/?nomobile=true#!forum/government-open-source</a></p>\\n<p>And for the military use of open source in particular:</p>\\n<p><a href=\"https://groups.google.com/forum/?nomobile=true#!forum/mil-oss\" rel=\"nofollow\">https://groups.google.com/forum/?nomobile=true#!forum/mil-oss</a></p>\\n<p>A cross-governmental variety of formal policies in support of open source can be found here: <a href=\"http://18f.github.io/open-source-program/pages/policy_documents/\" rel=\"nofollow\">http://18f.github.io/open-source-program/pages/policy_documents/</a></p>', 'url': 'https://github.com/18F/open-source-policy/issues/30', 'state': 'OPEN', 'createdAt': '2015-01-17T19:37:38Z', 'lastEditedAt': None, 'publishedAt': '2015-01-17T19:37:38Z', 'updatedAt': '2015-02-02T18:36:25Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'partner-data-transform', 'repo_owner_name': 'U.S. National Archives', 'repo_owner_email': 'developer@nara.gov', 'repo_owner_user_name': 'usnationalarchives', 'repo_owner_profile_url': 'https://github.com/usnationalarchives', 'title': 'Repeating digital objects when script encounters missing images', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2243767\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/DominicBM\">@DominicBM</a> When the script encounters images that are listed in the original partner metadata but not in the objects CSV, it repeats the previous valid file name from the CSV as many times as it takes to get to the next match between the two. Example below repeats 2777.jpg:</p>\\n<pre><code>&lt;digitalObject&gt;&lt;objectType&gt;&lt;termName&gt;Image (JPG)&lt;/termName&gt;&lt;/objectType&gt;&lt;labelFlag&gt;2776.jpg&lt;/labelFlag&gt;\\n&lt;objectDesignator&gt;Fold3 File #8795155&lt;/objectDesignator&gt;\\n&lt;objectDescription&gt;Image provided by Fold3.&lt;/objectDescription&gt;\\n&lt;accessFilename&gt;https://opaexport-conv.s3.amazonaws.com/TB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2776.jpg&lt;/accessFilename&gt;&lt;accessFileSize&gt;1522921&lt;/accessFileSize&gt;\\n&lt;thumbnailFilename&gt;http://media.nara.gov/dc-metro/jpg_t.jpg&lt;/thumbnailFilename&gt;&lt;thumbnailFileSize&gt;1234&lt;/thumbnailFileSize&gt;&lt;/digitalObject&gt;\\n\\n&lt;digitalObject&gt;&lt;objectType&gt;&lt;termName&gt;Image (JPG)&lt;/termName&gt;&lt;/objectType&gt;&lt;labelFlag&gt;2777.jpg&lt;/labelFlag&gt;\\n&lt;objectDesignator&gt;Fold3 File #8795159&lt;/objectDesignator&gt;\\n&lt;objectDescription&gt;Image provided by Fold3.&lt;/objectDescription&gt;\\n&lt;accessFilename&gt;https://opaexport-conv.s3.amazonaws.com/TB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2777.jpg&lt;/accessFilename&gt;&lt;accessFileSize&gt;1493678&lt;/accessFileSize&gt;\\n&lt;thumbnailFilename&gt;http://media.nara.gov/dc-metro/jpg_t.jpg&lt;/thumbnailFilename&gt;&lt;thumbnailFileSize&gt;1234&lt;/thumbnailFileSize&gt;&lt;/digitalObject&gt;\\n\\n&lt;digitalObject&gt;&lt;objectType&gt;&lt;termName&gt;Image (JPG)&lt;/termName&gt;&lt;/objectType&gt;&lt;labelFlag&gt;2777.jpg&lt;/labelFlag&gt;\\n&lt;objectDesignator&gt;Fold3 File #8729037&lt;/objectDesignator&gt;\\n&lt;objectDescription&gt;Image provided by Fold3.&lt;/objectDescription&gt;\\n&lt;accessFilename&gt;https://opaexport-conv.s3.amazonaws.com/TB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2777.jpg&lt;/accessFilename&gt;&lt;accessFileSize&gt;&lt;/accessFileSize&gt;\\n&lt;thumbnailFilename&gt;http://media.nara.gov/dc-metro/jpg_t.jpg&lt;/thumbnailFilename&gt;&lt;thumbnailFileSize&gt;1234&lt;/thumbnailFileSize&gt;&lt;/digitalObject&gt;\\n\\n&lt;digitalObject&gt;&lt;objectType&gt;&lt;termName&gt;Image (JPG)&lt;/termName&gt;&lt;/objectType&gt;&lt;labelFlag&gt;2777.jpg&lt;/labelFlag&gt;\\n&lt;objectDesignator&gt;Fold3 File #8834153&lt;/objectDesignator&gt;\\n&lt;objectDescription&gt;Image provided by Fold3.&lt;/objectDescription&gt;\\n&lt;accessFilename&gt;https://opaexport-conv.s3.amazonaws.com/TB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2777.jpg&lt;/accessFilename&gt;&lt;accessFileSize&gt;&lt;/accessFileSize&gt;\\n&lt;thumbnailFilename&gt;http://media.nara.gov/dc-metro/jpg_t.jpg&lt;/thumbnailFilename&gt;&lt;thumbnailFileSize&gt;1234&lt;/thumbnailFileSize&gt;&lt;/digitalObject&gt;\\n\\n&lt;digitalObject&gt;&lt;objectType&gt;&lt;termName&gt;Image (JPG)&lt;/termName&gt;&lt;/objectType&gt;&lt;labelFlag&gt;2777.jpg&lt;/labelFlag&gt;\\n&lt;objectDesignator&gt;Fold3 File #8834173&lt;/objectDesignator&gt;\\n&lt;objectDescription&gt;Image provided by Fold3.&lt;/objectDescription&gt;\\n&lt;accessFilename&gt;https://opaexport-conv.s3.amazonaws.com/TB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2777.jpg&lt;/accessFilename&gt;&lt;accessFileSize&gt;&lt;/accessFileSize&gt;\\n&lt;thumbnailFilename&gt;http://media.nara.gov/dc-metro/jpg_t.jpg&lt;/thumbnailFilename&gt;&lt;thumbnailFileSize&gt;1234&lt;/thumbnailFileSize&gt;&lt;/digitalObject&gt;\\n</code></pre>\\n<p>This is happening because the objects CSV has a gap between 2777.jpg and 3171.jpg (see below):</p>\\n<pre><code>TB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2776.jpg\\t\"1522921\"\\t\"TB0104\"\\t\"M1676-NaturalizationIndex-NYSouthernPetitions\"\\t\"M1676_0006\"\\t\"images\"\\t\"2776.jpg\"\\n\\nTB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/2777.jpg\\t\"1493678\"\\t\"TB0104\"\\t\"M1676-NaturalizationIndex-NYSouthernPetitions\"\\t\"M1676_0006\"\\t\"images\"\\t\"2777.jpg\"\\n\\nTB0104/M1676-NaturalizationIndex-NYSouthernPetitions/M1676_006/images/3171.jpg\\t\"1421791\"\\t\"TB0104\"\\t\"M1676-NaturalizationIndex-NYSouthernPetitions\"\\t\"M1676_0006\"\\t\"images\"\\t\"3171.jpg\"\\n</code></pre>\\n<p>Is there anyway we could modify the script so that when it encounters images in the original partner data that aren\\'t in the objects CSV, that it creates a description without any digital objects but still with the metadata?</p>\\n<p>Relevant files for this reel (M1676_0006) are attached.<br>\\n<a href=\"https://github.com/usnationalarchives/partner-data-transform/files/968543/M1676_0006.zip\">M1676_0006.zip</a></p>', 'url': 'https://github.com/usnationalarchives/partner-data-transform/issues/1', 'state': 'OPEN', 'createdAt': '2017-05-01T18:55:04Z', 'lastEditedAt': '2017-05-01T18:57:18Z', 'publishedAt': '2017-05-01T18:55:04Z', 'updatedAt': '2018-05-04T16:18:53Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Claims > Frequently Asked Questions: Add page content', 'bodyHTML': '<ul>\\n<li>URL: <a href=\"http://beta.move.mil/claims/faqs\" rel=\"nofollow\">http://beta.move.mil/claims/faqs</a></li>\\n<li>File location: <code>src/claims/faqs/index.html</code></li>\\n<li>Content: TBD</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/15', 'state': 'CLOSED', 'createdAt': '2017-05-30T16:02:48Z', 'lastEditedAt': '2017-06-14T14:26:57Z', 'publishedAt': '2017-05-30T16:02:48Z', 'updatedAt': '2017-08-22T16:12:00Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Helpful Resources: Add page content', 'bodyHTML': '<ul>\\n<li>URL: <a href=\"http://beta.move.mil/resources\" rel=\"nofollow\">http://beta.move.mil/resources</a></li>\\n<li>File location: <code>src/resources/index.html</code></li>\\n<li>Content: TBD</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/17', 'state': 'CLOSED', 'createdAt': '2017-05-30T16:03:11Z', 'lastEditedAt': '2017-06-14T14:26:50Z', 'publishedAt': '2017-05-30T16:03:11Z', 'updatedAt': '2017-08-22T16:12:00Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Schedule Your Move > Estimate Weight Allowance: Add page content', 'bodyHTML': '<ul>\\n<li>URL: <a href=\"http://beta.move.mil/schedule-your-move/estimate-weight-allowance\" rel=\"nofollow\">http://beta.move.mil/schedule-your-move/estimate-weight-allowance</a></li>\\n<li>File location: <code>src/schedule-your-move/estimate-weight-allowance/index.html</code></li>\\n<li>Content: TBD</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/19', 'state': 'CLOSED', 'createdAt': '2017-05-30T16:03:36Z', 'lastEditedAt': '2017-06-14T14:26:33Z', 'publishedAt': '2017-05-30T16:03:36Z', 'updatedAt': '2017-08-22T16:12:00Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Schedule Your Move > Learn How to Use DPS: Add page content', 'bodyHTML': '<ul>\\n<li>URL: <a href=\"http://beta.move.mil/schedule-your-move/learn-how-to-use-dps\" rel=\"nofollow\">http://beta.move.mil/schedule-your-move/learn-how-to-use-dps</a></li>\\n<li>File location: <code>src/schedule-your-move/learn-how-to-use-dps/index.html</code></li>\\n<li>Content: TBD</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/20', 'state': 'CLOSED', 'createdAt': '2017-05-30T16:03:48Z', 'lastEditedAt': '2017-06-14T14:26:27Z', 'publishedAt': '2017-05-30T16:03:48Z', 'updatedAt': '2017-08-22T16:12:00Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Service-Specific Information: Add page content', 'bodyHTML': '<ul>\\n<li>URL: <a href=\"http://beta.move.mil/service-specific-information\" rel=\"nofollow\">http://beta.move.mil/service-specific-information</a></li>\\n<li>File location: <code>src/service-specific-information/index.html</code></li>\\n<li>Content: TBD</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/21', 'state': 'CLOSED', 'createdAt': '2017-05-30T16:04:00Z', 'lastEditedAt': '2017-06-14T14:26:21Z', 'publishedAt': '2017-05-30T16:04:00Z', 'updatedAt': '2017-07-11T15:32:43Z', 'labels': ['help wanted', 'waiting on design'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Moving Allowances > Frequently Asked Questions: Update page content', 'bodyHTML': '<p>The <a href=\"http://beta.move.mil/moving-allowances/faqs/\" rel=\"nofollow\">current page</a> content was pulled directly from <a href=\"https://www.move.mil/dod/faq.cfm\" rel=\"nofollow\">https://www.move.mil/dod/faq.cfm</a> and should be reevaluated for utility and clarity for the new site organization and design.</p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/28', 'state': 'CLOSED', 'createdAt': '2017-06-14T14:23:46Z', 'lastEditedAt': None, 'publishedAt': '2017-06-14T14:23:46Z', 'updatedAt': '2017-08-22T16:12:01Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Claims: Fill in `#TODO` URLs', 'bodyHTML': '<p>In the content pulled from the visual designs, there are a handful of links that need proper URLs (marked in bold):</p>\\n<blockquote>\\n<p>As questions arise, your <strong>Transportation Office (TO)</strong> or your <strong>Military Claims Office (MCO)</strong> can provide further information and generally is the best place to get help related to your move.</p>\\n</blockquote>\\n<blockquote>\\n<p>If anything obviously appears missing or damaged, make sure you and the TSP both sign the <strong>DD-1840: Notification of Loss/Damage at Delivery Form</strong> before the carrier leaves.</p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Learn how to file a claim in DPS</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>What financial compensation is my TSP required to provide for my lost or damaged items?</strong></p>\\n</blockquote>\\n<blockquote>\\n<p>If you are unable to negotiate a settlement with your Transportation Service Provider (TSP) through DPS, or if you have any questions regarding claims benefits or deadlines, you should contact your <strong>Military Claims Office (MCO)</strong> or service-specific claims group for additional assistance.</p>\\n</blockquote>', 'url': 'https://github.com/deptofdefense/move.mil/issues/30', 'state': 'CLOSED', 'createdAt': '2017-06-14T15:14:25Z', 'lastEditedAt': None, 'publishedAt': '2017-06-14T15:14:25Z', 'updatedAt': '2017-08-22T16:12:01Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Homepage: Fill in `#TODO` URLs', 'bodyHTML': '<p>In the content pulled from the visual designs, there are a handful of links that need proper URLs (marked in bold):</p>\\n<blockquote>\\n<p><strong>Research your new base</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Speak to a Transportation Counselor (optional)</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Plan how you want to move</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Get access to DPS by creating an ETA Log In</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Learn how to use DPS to schedule your move</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Estimate your moving weight</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Learn what to prepare ahead of time</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Review what to do if anything goes wrong</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>What happens if something arrives lost or broken</strong></p>\\n</blockquote>\\n<blockquote>\\n<p><strong>Review your transporter in DPS</strong></p>\\n</blockquote>', 'url': 'https://github.com/deptofdefense/move.mil/issues/31', 'state': 'CLOSED', 'createdAt': '2017-06-14T15:18:38Z', 'lastEditedAt': '2017-06-14T15:20:13Z', 'publishedAt': '2017-06-14T15:18:38Z', 'updatedAt': '2017-08-22T16:12:01Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Moving Allowances > Fill in `#TODO` URLs', 'bodyHTML': '<p>In the content pulled from the visual designs, there are a handful of links that need proper URLs (marked in bold):</p>\\n<blockquote>\\n<p>As questions arise, your <strong>Transportation Office (TO)</strong> can provide further information and generally is the best place to get help related to your move.</p>\\n</blockquote>', 'url': 'https://github.com/deptofdefense/move.mil/issues/32', 'state': 'CLOSED', 'createdAt': '2017-06-14T15:36:44Z', 'lastEditedAt': None, 'publishedAt': '2017-06-14T15:36:44Z', 'updatedAt': '2017-08-22T16:12:01Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Moving Allowances > Determine Your Moving Allowance: Fill in `#TODO` URLs', 'bodyHTML': '<p>In the content pulled from the visual designs, there are a handful of links that need proper URLs (marked in bold):</p>\\n<blockquote>\\n<p>Enter your rank, dependency status, and move type to determine your moving allowance. If additional questions arise, your <strong>Transportation Office (TO)</strong> can provide further information and generally is the best place to get help related to your move.</p>\\n</blockquote>\\n<p>and from the \"Alcohol\" moving allowances section:</p>\\n<blockquote>\\n<p>You can ship alcohol as part of you total household good shipment, assuming that the alcohol you are shipping doesnt violate any state-specific import laws. You can check specific <strong>state and local laws</strong> related to alcohol transportation for more information.</p>\\n</blockquote>', 'url': 'https://github.com/deptofdefense/move.mil/issues/33', 'state': 'CLOSED', 'createdAt': '2017-06-14T15:40:29Z', 'lastEditedAt': None, 'publishedAt': '2017-06-14T15:40:29Z', 'updatedAt': '2017-08-22T16:12:01Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Move.mil Homepage', 'bodyHTML': '<p>Move.mil Homepage needs:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Designs</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Content</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Implementation</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/62', 'state': 'CLOSED', 'createdAt': '2017-08-23T15:24:28Z', 'lastEditedAt': '2017-11-09T19:51:07Z', 'publishedAt': '2017-08-23T15:24:28Z', 'updatedAt': '2017-11-09T19:51:07Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Nightmare moves page', 'bodyHTML': '<p>Needs:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Page Design</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Content (created in several locations, needs aggregated?)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Implementation</li>\\n</ul>', 'url': 'https://github.com/deptofdefense/move.mil/issues/67', 'state': 'CLOSED', 'createdAt': '2017-08-23T15:40:34Z', 'lastEditedAt': '2017-08-23T16:52:00Z', 'publishedAt': '2017-08-23T15:40:34Z', 'updatedAt': '2017-09-11T14:49:12Z', 'labels': ['help wanted', 'waiting on design'], 'is_locked': True, 'total_participants': 5}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'What to expect ... Civilians Article', 'bodyHTML': '<p>Needs:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Content</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Implementation</p>\\n</li>\\n</ul>\\n<p>*Will follow the Move types template in article format.</p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/69', 'state': 'CLOSED', 'createdAt': '2017-08-23T15:42:49Z', 'lastEditedAt': None, 'publishedAt': '2017-08-23T15:42:49Z', 'updatedAt': '2017-11-30T12:56:41Z', 'labels': ['backlog', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Updated Tutorial Content: Schedule a Move', 'bodyHTML': '<p>Here\\'s the new content for Schedule a Move (HHG) labeled by Steps &amp; Content.</p>\\n<p>Step | Text<br>\\n1 | Scheduling your move is called Self Counseling in DPS. First, log into ETA, and choose DPS from your list of approved applications.</p>\\n<p>PRO TIP: Turn off your pop-up blocker, otherwise the DPS window won\\'t be able to open.</p>\\n<p>2 | On the DPS homepage, select Self Counsel to begin your application. PRO TIP: You should have a copy of your Orders, pick-up and delivery information, as well as information about your dependents and Power of Attorney if you need one.</p>\\n<p>4 | You\\'ll find an overview of the Counseling Process, but to get to the first step, you\\'ll need to click on the Customer Information button in the Counseling Menu on the left side of the page. PRO TIP: If you\\'ve moved before, DPS will save your information so that it\\'s pre-poulated here, and you won\\'t have to fill it out again.</p>\\n<p>5 | Fill out your Customer Information and Permanent Contact Address. The \"Permanent Contact Address\" is the place where you\\'re living right now. This information is saved in DPS so you don\\'t have to fill it out each time you schedule a move.</p>\\n<p>PRO TIP: You can check your progress in the Counseling Menu on the left side of the page.<br>\\nCONUS stands for Continental United States<br>\\nOCONUS stands for Outside Continental United States</p>\\n<p>6 | Enter an Emergency Contact who will be traveling or moving with you. This person will have access to shipment status, and information. PRO TIP: A Letter of Authorization allows you to give another person permission to act on your behalf. Only the service member who has official orders can write this letter of authorization.</p>\\n<p>9 | Specify your authorized Order Type, and upload a copy of your Order document. Create your shipment based on your orders by first selecting the type. PRO TIP: Can\\'t find your type? Check out the category \"Various\" to see miscellaneous move types.</p>\\n<p>12 | The Order Summary allows you to review and certify the information you entered is accurate.<br>\\nPRO TIP: Your weight allowance is listed here in the second paragraph.</p>\\n<p>13 | Now that you\\'ve entered your Orders information, you must \"Create New Shipment\" specific for those orders. Select the type of shipment you want to create, like \"HHG\", and specify whether or not it will be a Personally Procured Move (PPM).<br>\\nPRO TIP: You can create more than one type of shipment per Order. For example, you can schedule an HHG shipment for the majority of your belongings, and an additional PPM shipment for the ones you\\'ll move yourself in your car.</p>\\n<p>14 | Then you\\'ll get some helpful information about a Household Goods (HHG) move. Later on, there will be PPM specific information.</p>\\n<p>21 | Here you\\'ll choose a Personal Property Office for counseling, who you\\'ll be in contact with after submitting your shipment through DPS. They\\'ll need the forms generated on the next page.</p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/75', 'state': 'CLOSED', 'createdAt': '2017-08-23T20:11:54Z', 'lastEditedAt': None, 'publishedAt': '2017-08-23T20:11:54Z', 'updatedAt': '2017-08-28T17:18:25Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Add DFAS contact information', 'bodyHTML': '<p>Coming out of last week\\'s Design Sprint, I have a Post-It note on my laptop:</p>\\n<blockquote>\\n<p>Get DFAS phone number to add to beta.move.mil</p>\\n</blockquote>\\n<p><g-emoji class=\"g-emoji\" alias=\"point_up\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/261d.png\"></g-emoji> I poked around <a href=\"https://www.dfas.mil\" rel=\"nofollow\">dfas.mil</a> and found <a href=\"https://corpweb1.dfas.mil/askDFAS/welcome.action\" rel=\"nofollow\">this askDFAS page</a> that has a phone number listed at the top: <code>1-888-332-7411</code>.</p>\\n<p>There\\'s also <a href=\"https://www.facebook.com/DefenseFinanceandAccountingService\" rel=\"nofollow\">a DFAS Facebook page</a> with nearly 100,000 \"likes.\"</p>\\n<p>It\\'s not clear from the Post-It note where we might want to include this phone number (or any other DFAS-related information). <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25456509\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Elliottdotgov\">@Elliottdotgov</a>, can you clarify?</p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/91', 'state': 'CLOSED', 'createdAt': '2017-09-18T14:21:24Z', 'lastEditedAt': '2017-09-18T14:29:23Z', 'publishedAt': '2017-09-18T14:21:24Z', 'updatedAt': '2018-01-17T15:12:26Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Tools & Resources top-level page', 'bodyHTML': '<p>If you click on \"Tools &amp; Resources\" in the side or top nav to go to the category page instead of one of the subcategories (like the Locator Maps), you get a \"Coming Soon\" page.</p>\\n<p>I\\'m not sure what we <em>need</em> on this page, probably not much. At a minimum, it needs links to the subcategories. Do you have any thoughts, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=22291512\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lfantano\">@lfantano</a>?</p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/108', 'state': 'CLOSED', 'createdAt': '2017-10-12T15:19:32Z', 'lastEditedAt': None, 'publishedAt': '2017-10-12T15:19:32Z', 'updatedAt': '2018-02-07T18:01:15Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 4}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Tutorials Mobile View', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/29074069/34536068-1bfe7f2c-f092-11e7-8587-8873a86177fe.png\"><img src=\"https://user-images.githubusercontent.com/29074069/34536068-1bfe7f2c-f092-11e7-8587-8873a86177fe.png\" alt=\"screenshot_2018-01-03-14-25-08\" style=\"max-width:100%;\"></a><br>\\nThe tutorial titles get mashed onto the \\'next\\' buttons in mobile view.</p>\\n<ol>\\n<li>Create a PPM Shipment</li>\\n<li>Dual</li>\\n<li>CSS</li>\\n</ol>\\n<p>could we move the buttons below the title?</p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/271', 'state': 'CLOSED', 'createdAt': '2018-01-03T19:24:33Z', 'lastEditedAt': '2018-01-03T19:26:40Z', 'publishedAt': '2018-01-03T19:24:33Z', 'updatedAt': '2018-01-03T21:24:59Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'move.mil', 'repo_owner_name': 'U.S. Dept of Defense', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'deptofdefense', 'repo_owner_profile_url': 'https://github.com/deptofdefense', 'title': 'Top Header / Home button ', 'bodyHTML': '<p>Location: In the banner area with the TRANSCOM logo and Move.Mil page name.</p>\\n<p>The whole area from the TRANSCOM logo almost across the entire top section has the ability to click and select and when done, it takes you to the home screen. This happens across all browsers (FireFox, IE, and Chrome) and no matter where in the site you are located, it returns you right back to the home page.</p>\\n<p>Request clean up and or notification so that the customer is not confused as to if the button is a back to the top, and or thinking its an additional link to somewhere else and they just cannot see verbiage.</p>\\n<p>The below is a rough estimate of the entire clickable location and the .doc highlights the original issue brought to our attention.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/36198616/38311131-043f1d6c-37e4-11e8-97b5-6f2c81d8e10a.PNG\"><img src=\"https://user-images.githubusercontent.com/36198616/38311131-043f1d6c-37e4-11e8-97b5-6f2c81d8e10a.PNG\" alt=\"home\" style=\"max-width:100%;\"></a></p>\\n<p><a href=\"https://github.com/deptofdefense/move.mil/files/1875959/Move.mil.Back.to.top.button.docx\">Move mil Back to top button.docx</a></p>', 'url': 'https://github.com/deptofdefense/move.mil/issues/411', 'state': 'OPEN', 'createdAt': '2018-04-04T13:49:37Z', 'lastEditedAt': None, 'publishedAt': '2018-04-04T13:49:37Z', 'updatedAt': '2018-05-24T19:27:33Z', 'labels': ['help wanted', 'question', 'ustc reviewed'], 'is_locked': True, 'total_participants': 6}, {'repo_name': 'before-you-ship', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'consolidate information about selecting the Level', 'bodyHTML': '<p>There are a few pages that have overlap:</p>\\n<ul>\\n<li><a href=\"https://pages.18f.gov/before-you-ship/ato/walkthrough/#step-2--select-controls\" rel=\"nofollow\">https://pages.18f.gov/before-you-ship/ato/walkthrough/#step-2--select-controls</a></li>\\n<li><a href=\"https://pages.18f.gov/before-you-ship/ato/categorize/\" rel=\"nofollow\">https://pages.18f.gov/before-you-ship/ato/categorize/</a></li>\\n<li><a href=\"https://pages.18f.gov/before-you-ship/ato/levels/\" rel=\"nofollow\">https://pages.18f.gov/before-you-ship/ato/levels/</a></li>\\n</ul>', 'url': 'https://github.com/18F/before-you-ship/issues/166', 'state': 'CLOSED', 'createdAt': '2016-05-13T16:08:15Z', 'lastEditedAt': '2016-05-13T16:23:13Z', 'publishedAt': '2016-05-13T16:08:15Z', 'updatedAt': '2017-02-27T23:54:27Z', 'labels': ['High Priority', 'HighBar', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Remove repetitive layout for /tock/timesheet/<time-period/ url', 'bodyHTML': '<p><strong>Issue</strong><br>\\nCurrently, the page duplicates the fields when adding a new project to your timecard.</p>\\n<p><strong>Fix</strong><br>\\nRemove \"Project\", \"Billable\" and \"Time Percentage\" per added set of project fields, see screenshot below for reference.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/955558/7006448/3bb637d8-dc4f-11e4-90a1-2088095dee7a.png\"><img src=\"https://cloud.githubusercontent.com/assets/955558/7006448/3bb637d8-dc4f-11e4-90a1-2088095dee7a.png\" alt=\"screen_shot_2015-04-06_at_11_13_31_am\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/tock/issues/45', 'state': 'CLOSED', 'createdAt': '2015-04-06T15:22:48Z', 'lastEditedAt': None, 'publishedAt': '2015-04-06T15:22:48Z', 'updatedAt': '2015-04-13T11:54:56Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add ability to remove project lines once added to timesheet', 'bodyHTML': '<p><strong>Issue</strong><br>\\nOnce you have added a project line item to a timesheet, there is not way to remove it.</p>\\n<p><strong>Fix</strong><br>\\nAdd ability to remove a project line item from timesheet once it has been added.</p>', 'url': 'https://github.com/18F/tock/issues/47', 'state': 'CLOSED', 'createdAt': '2015-04-06T15:25:37Z', 'lastEditedAt': None, 'publishedAt': '2015-04-06T15:25:37Z', 'updatedAt': '2015-04-28T17:23:42Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add support for late Tock entry notifications', 'bodyHTML': '<p>It\\'d be a very nice thing for our Ops team to add support for notifications to be sent out to late Tock entrants automatically as opposed to someone having to manually do this.  There are a few ways we could do this, listed below:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Email notifications via a tool like <del>Mandrill</del> and scheduled jobs through Celery (Mandrill isn\\'t an option anymore)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Possible Slack integration via a bot like <a href=\"https://github.com/18F/angrytock\">angrytock</a> (depends on ATO status and procedure)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Client-side browser notifications, e.g., PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"248106260\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/647\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/647/hovercard\" href=\"https://github.com/18F/tock/pull/647\">#647</a> (thanks, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1775733\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mgwalker\">@mgwalker</a>!)</li>\\n</ul>\\n<p>More ideas and details to come in the future as we have time to work through the user needs of this.</p>', 'url': 'https://github.com/18F/tock/issues/653', 'state': 'OPEN', 'createdAt': '2017-08-19T02:39:49Z', 'lastEditedAt': '2017-09-06T21:00:35Z', 'publishedAt': '2017-08-19T02:39:49Z', 'updatedAt': '2018-08-16T16:46:35Z', 'labels': ['help wanted', 'tech:django', 'tech:javascript'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'OAuth2 error upon logging in via SecureAuth', 'bodyHTML': '<p>When trying to access Tock from a fresh browser session after a deploy, it may result in a redirect error:</p>\\n<pre><code>oauth2: cannot fetch token: 400 Bad Request\\nResponse: {\"error\":\"invalid_grant\",\"error_description\":\"Redirect URI mismatch.\"}\\n</code></pre>\\n<p>It is unclear why this happens, but apparently there is something wonky with the certification and/or route setup with cloud.gov and the hook(s) with SecureAuth.</p>\\n<p>The workaround currently is to just go back to <a href=\"https://tock.18f.gov/\" rel=\"nofollow\">https://tock.18f.gov/</a> after attempting to sign in via SecureAuth and Tock should load fine, but it would be nice to get this resolved so it doesn\\'t happen to begin with.</p>', 'url': 'https://github.com/18F/tock/issues/658', 'state': 'CLOSED', 'createdAt': '2017-08-25T13:28:14Z', 'lastEditedAt': None, 'publishedAt': '2017-08-25T13:28:14Z', 'updatedAt': '2018-04-04T17:20:03Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix borked static asset references', 'bodyHTML': \"<p>While looking into an unrelated issue I noticed several errors show up in the logs while fetching static assets:</p>\\n<pre><code>ERR Not Found: /static/img/uswds/close.svg\\nERR WARNING:django.request:Not Found: /static/img/uswds/close.svg\\nERR Not Found: /tock/static/js/vendor/underscore-min.js\\nERR WARNING:django.request:Not Found: /tock/static/js/vendor/underscore-min.js\\n</code></pre>\\n<p>There might be other related ones, but in any case these references need to be fixed to ensure functionality doesn't break anywhere.</p>\", 'url': 'https://github.com/18F/tock/issues/665', 'state': 'CLOSED', 'createdAt': '2017-09-21T16:28:27Z', 'lastEditedAt': '2017-09-21T16:28:39Z', 'publishedAt': '2017-09-21T16:28:27Z', 'updatedAt': '2018-03-20T12:43:25Z', 'labels': ['code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'UAA Auth Route service is discontinued and needs to be replaced', 'bodyHTML': '<p>Per <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=391313\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/brittag\">@brittag</a>:</p>\\n<blockquote>\\n<p>Maybe helpful for when Tock comes up for ATO, not sure where to put this: it uses the discontinued experimental cloud.gov UAA Auth Route service, which has a known issue (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"213188171\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/cloudfoundry-community/cf-uaa-guard-service/issues/16\" data-hovercard-type=\"issue\" data-hovercard-url=\"/cloudfoundry-community/cf-uaa-guard-service/issues/16/hovercard\" href=\"https://github.com/cloudfoundry-community/cf-uaa-guard-service/issues/16\">cloudfoundry-community/cf-uaa-guard-service#16</a>).</p>\\n</blockquote>\\n<blockquote>\\n<p>Also good to note: we disabled creation of new instances of the service, and if you try to unbind the service, it\\'ll tell you \"action not authorized\" (just ask us to remove it manually when you want it removed).</p>\\n</blockquote>\\n<blockquote>\\n<p>The recommended alternative is to implement <a href=\"https://cloud.gov/docs/apps/leveraging-authentication/\" rel=\"nofollow\">https://cloud.gov/docs/apps/leveraging-authentication/</a> instead.</p>\\n</blockquote>\\n<p>Specifically, it is subject to cookie replay attacks.  We need to find an alternative, and this will be a required fix for ATO compliance (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"251394710\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/652\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/tock/issues/652/hovercard\" href=\"https://github.com/18F/tock/issues/652\">#652</a>).</p>', 'url': 'https://github.com/18F/tock/issues/679', 'state': 'CLOSED', 'createdAt': '2017-10-05T16:08:12Z', 'lastEditedAt': '2017-10-05T16:12:48Z', 'publishedAt': '2017-10-05T16:08:12Z', 'updatedAt': '2018-03-09T19:04:27Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update reports to include FY18-specific reports', 'bodyHTML': \"<p>The reports page in Tock only allows you to pull all information or just a single FY specifically, but there is leakage between the reports. It appears they pass a single <code>after</code> param, so they can pick up reports from after the desired date.</p>\\n<p>There is also a desire to add the user organization to the tables (both html and csv) as an additional datapoint.</p>\\n<p><em>We'll know we're done when</em></p>\\n<ul>\\n<li>FY reports only pull the desired FY</li>\\n<li>user.organization shows in the output table</li>\\n<li>Any related tests are written</li>\\n</ul>\", 'url': 'https://github.com/18F/tock/issues/680', 'state': 'OPEN', 'createdAt': '2017-10-13T14:33:19Z', 'lastEditedAt': '2018-10-26T12:57:13Z', 'publishedAt': '2017-10-13T14:33:19Z', 'updatedAt': '2018-10-26T12:57:27Z', 'labels': ['help wanted', 'tech:django'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Disappearing hours', 'bodyHTML': \"<p>While entering my most recent hours, I scrolled up a couple time to find that my earlier entries had been erased. Oddly, this seemed to even reset a batch of saved hours, and added back in a line that I had deleted. As far as I could tell, it was the stuff that was off-screen that changed, but I can't be sure.</p>\\n<p>I'm sorry that I don't have more information to give, but I quickly submitted my hours in order to try to avoid them disappearing again.</p>\", 'url': 'https://github.com/18F/tock/issues/697', 'state': 'CLOSED', 'createdAt': '2018-01-19T22:24:12Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T22:24:12Z', 'updatedAt': '2018-08-16T17:28:30Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update Django to the latest version', 'bodyHTML': \"<p>Per Django's update docs, we'll need to update to 1.11 before updating to 2.0.x.</p>\", 'url': 'https://github.com/18F/tock/issues/699', 'state': 'CLOSED', 'createdAt': '2018-01-22T15:43:32Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T15:43:32Z', 'updatedAt': '2018-03-19T18:10:57Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix Django Debug Toolbar', 'bodyHTML': '<p>Django Debug Toolbar is incredibly useful for development and debugging, but we cannot effectively use it as something is misconfigured with it.  It appears at least partly to be a static assets issue (which is related to issue (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"259556843\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/665\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/tock/issues/665/hovercard\" href=\"https://github.com/18F/tock/issues/665\">#665</a>), and it may be a Django upgrade issue as well (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"290511093\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/699\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/tock/issues/699/hovercard\" href=\"https://github.com/18F/tock/issues/699\">#699</a>).</p>\\n<p>It\\'d be nice to get this working again to help improve Tock\\'s development workflow!</p>', 'url': 'https://github.com/18F/tock/issues/700', 'state': 'CLOSED', 'createdAt': '2018-01-22T15:50:32Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T15:50:32Z', 'updatedAt': '2018-03-23T00:41:04Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Reference UserData instead of User where appropriate', 'bodyHTML': \"<p>The User model is Django's built-in auth model that's best left alone. We're currently using entries on the User model as our primary relationship between users and other model objects. We should be using UserData instead, which is our own custom model of information related to users.</p>\\n<p>Shifting to UserData will mean a lot of little changes throughout this app, which will have a lot of knock-on effects and require a bunch of updated tests, but it will make ongoing development easier and it should make for fewer table joins in our queries.</p>\", 'url': 'https://github.com/18F/tock/issues/701', 'state': 'OPEN', 'createdAt': '2018-01-22T15:52:53Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T15:52:53Z', 'updatedAt': '2018-08-16T17:14:29Z', 'labels': ['help wanted', 'tech:django'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Improve Docker setup and fix Python debugging', 'bodyHTML': '<p>It\\'d be great if someone could take a look and see if there\\'s any way we can improve our Docker setup with Tock.  While the thought here is just in general (are the files in the right place, are we leveraging container dependencies appropriately, do we have the piece configured optimally, etc.), there is one big piece in particular:  being able to drop into the Python debugger (<code>pdb</code>, or a <code>pdb</code>-replacement like <a href=\"https://pypi.python.org/pypi/pdbpp/0.9.2\" rel=\"nofollow\"><code>pdbpp</code></a>) while running the app, tests, or something else.  That is currently not working for us and it makes development and debugging very difficult.</p>', 'url': 'https://github.com/18F/tock/issues/702', 'state': 'CLOSED', 'createdAt': '2018-01-22T15:57:58Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T15:57:58Z', 'updatedAt': '2018-03-28T16:13:04Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Improve CircleCI setup and leverage build workflows for automated deployments', 'bodyHTML': \"<p>We'd like to see if any other improvements can be made to our CircleCI configuration, so it'd be great if someone/some folks could take a look!</p>\\n<p>In addition, we know we need to leverage build workflows for automated deployments for ATO purposes.  In particular, we are planning on the following:</p>\\n<ul>\\n<li>Continue committing to <code>master</code>, which would trigger a build and deployment directly to the <code>stage</code> space.</li>\\n<li>Add a workflow looking for a specific tag pattern to deploy to the <code>prod</code> space for production releases.</li>\\n</ul>\", 'url': 'https://github.com/18F/tock/issues/703', 'state': 'CLOSED', 'createdAt': '2018-01-22T16:00:04Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T16:00:04Z', 'updatedAt': '2018-03-28T16:09:56Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update all Tock dependencies', 'bodyHTML': '<p>A handful of the Python dependencies in Tock need to be updated to their latest versions.  Some additional testing and verification will be needed to make sure all of the upgrades integrate seamlessly.</p>\\n<p>Updating Django is a separate issue (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"290511093\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/699\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/tock/issues/699/hovercard\" href=\"https://github.com/18F/tock/issues/699\">#699</a>) as that is going to be required for ATO.</p>', 'url': 'https://github.com/18F/tock/issues/704', 'state': 'CLOSED', 'createdAt': '2018-01-22T16:14:16Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T16:14:16Z', 'updatedAt': '2018-04-04T18:04:00Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update USWDS to latest version', 'bodyHTML': \"<p>The USWDS version in Tock is a bit old, it'd be nice to get it fully updated to the latest version.</p>\", 'url': 'https://github.com/18F/tock/issues/705', 'state': 'CLOSED', 'createdAt': '2018-01-22T16:17:18Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T16:17:18Z', 'updatedAt': '2018-03-23T12:25:48Z', 'labels': ['code.gov', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Improve the graphs/visuals in Tock', 'bodyHTML': \"<p>Tock's graphs and visuals in the reports page could use some TLC!  If there's something we can do here in a reasonable amount of time, it would be a big help.</p>\", 'url': 'https://github.com/18F/tock/issues/706', 'state': 'OPEN', 'createdAt': '2018-01-22T16:22:57Z', 'lastEditedAt': None, 'publishedAt': '2018-01-22T16:22:57Z', 'updatedAt': '2018-10-24T19:24:19Z', 'labels': ['code.gov', 'design', 'help wanted', 'theme:ux'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update deploy process to handle expensive migrations', 'bodyHTML': '<p>We ran into this when deploying the latest work from the Jingle Sprint. The migrations are running for each instance type, and we don\\'t want that as migrations should only run once.</p>\\n<h2>Acceptance Criteria</h2>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Push a multi-instance version of Tock to staging and see the migrations only running once.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Migrations only run on the zeroth instance.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Migrations that take a long time (longer than three minutes) are run as tasks and this is documented.</li>\\n</ul>', 'url': 'https://github.com/18F/tock/issues/710', 'state': 'OPEN', 'createdAt': '2018-01-23T21:29:49Z', 'lastEditedAt': None, 'publishedAt': '2018-01-23T21:29:49Z', 'updatedAt': '2018-01-24T17:06:33Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'eRegs team members prefilling incorrectly. ', 'bodyHTML': '<p>eRegs team members <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12564977\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rtwell\">@rtwell</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=171940\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/thebestsophist\">@thebestsophist</a>, and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2626258\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tadhg-ohiggins\">@tadhg-ohiggins</a> all had their Tock timecards prefill as FAITAS Foundation Engagement rather than the correct eRegs Phase 2. To the untrained eye the same error happening the same way three different times seems hopeful. (Though not as hopeful as how few people had a problem at all, for which ALL THE HIGH-FIVES.)</p>', 'url': 'https://github.com/18F/tock/issues/718', 'state': 'CLOSED', 'createdAt': '2018-02-06T03:33:43Z', 'lastEditedAt': None, 'publishedAt': '2018-02-06T03:33:43Z', 'updatedAt': '2018-03-29T23:51:31Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add a logout link', 'bodyHTML': '<p>As mentioned in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"295251074\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/720\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/720/hovercard?comment_id=370448610&amp;comment_type=issue_comment\" href=\"https://github.com/18F/tock/pull/720#issuecomment-370448610\">#720 (comment)</a>:</p>\\n<blockquote>\\n<p>It just occurred to me that we don\\'t have a logout link.  We might want to add one, so that e.g. someone who wants to be super secure can do so, and so that e.g. if two people happen to be at the same computer and need to use tock, they can switch accounts without having to reset their browser cache.</p>\\n</blockquote>', 'url': 'https://github.com/18F/tock/issues/731', 'state': 'CLOSED', 'createdAt': '2018-03-05T15:25:55Z', 'lastEditedAt': None, 'publishedAt': '2018-03-05T15:25:55Z', 'updatedAt': '2018-03-07T17:43:33Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Refactor application settings and documentation', 'bodyHTML': '<p>This issue is able to be worked on in tandem with <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"302829607\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/733\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/tock/issues/733/hovercard\" href=\"https://github.com/18F/tock/issues/733\">#733</a> but with a specific focus on the <code>settings.py</code> files used by the various environments. Parts of this issue can be worked on outside of the scope of the ATO process. Multiple PRs can address this ticket.</p>\\n<p><em>Discovered in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"295251074\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/720\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/720/hovercard\" href=\"https://github.com/18F/tock/pull/720\">#720</a></em></p>\\n<h3>Acceptance Criteria</h3>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Each environment is using the specific <code>settings/*.py</code> file for the correct environment.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a href=\"https://github.com/18F/tock/pull/720#discussion_r171556911\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/720/hovercard\">Removing <code>DEBUG = True</code> from the tests</a>.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Documentation, or automation, around enforcing these changes going forward.</li>\\n</ul>', 'url': 'https://github.com/18F/tock/issues/734', 'state': 'OPEN', 'createdAt': '2018-03-06T19:18:49Z', 'lastEditedAt': '2018-04-08T18:59:50Z', 'publishedAt': '2018-03-06T19:18:49Z', 'updatedAt': '2018-04-08T18:59:50Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': \"Reporting period queries should return 404 when they don't find anything\", 'bodyHTML': '<p>Concerning the <code>test_reports:ReportingPeriodDetailView</code>, this view is raising a <code>DoesNotExist: ReportingPeriod matching query does not exist.</code>, which suggests that, even if the current user is authenticated, we should be catching this and returning a <code>404</code>, instead of propagating the exception.</p>\\n<p><em>Discovered in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"301952635\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/729\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/729/hovercard\" href=\"https://github.com/18F/tock/pull/729\">#729</a></em></p>\\n<h3>Acceptance Criteria</h3>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Fix the DoesNotExist: ReportingPeriod matching query does not exist error raised by test_reports:ReportingPeriodDetailView</li>\\n</ul>', 'url': 'https://github.com/18F/tock/issues/735', 'state': 'CLOSED', 'createdAt': '2018-03-06T19:22:49Z', 'lastEditedAt': None, 'publishedAt': '2018-03-06T19:22:49Z', 'updatedAt': '2018-03-12T18:06:03Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix the `IndexError: list index out of range` at `/utilization/`', 'bodyHTML': '<p>Looks like <code>/utilization/</code> is raising an <code>IndexError: list index out of range exception</code>.</p>\\n<p><em>Discovered in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"301952635\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/729\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/729/hovercard\" href=\"https://github.com/18F/tock/pull/729\">#729</a></em></p>\\n<h3>Acceptance Criteria</h3>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Fix the <code>IndexError: list index out of range</code> at <code>/utilization/</code></li>\\n</ul>', 'url': 'https://github.com/18F/tock/issues/736', 'state': 'CLOSED', 'createdAt': '2018-03-06T19:25:52Z', 'lastEditedAt': None, 'publishedAt': '2018-03-06T19:25:52Z', 'updatedAt': '2018-03-19T19:08:18Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Underscore not loading and potentially unused', 'bodyHTML': \"<p>I noticed that loading tock throws <code>Refused to execute script from 'https://tock.18f.gov/tock/static/js/vendor/underscore-min.js' because its MIME type ('text/html') is not executable, and strict MIME type checking is enabled.</code>. But it's not clear from a quick skim that underscore is actually used. If it <em>is</em> used, we probably don't need to both include it in <code>package.json</code> and vendor the minified source--which we're doing for a few other assets as well.</p>\", 'url': 'https://github.com/18F/tock/issues/760', 'state': 'CLOSED', 'createdAt': '2018-03-19T03:42:09Z', 'lastEditedAt': None, 'publishedAt': '2018-03-19T03:42:09Z', 'updatedAt': '2018-03-20T12:43:25Z', 'labels': ['code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Create a \"Tock is Down\" page', 'bodyHTML': '<p>We should have an \"out of order\" page we can put up if we need to take the app down on short notice.</p>', 'url': 'https://github.com/18F/tock/issues/806', 'state': 'CLOSED', 'createdAt': '2018-05-09T16:51:45Z', 'lastEditedAt': None, 'publishedAt': '2018-05-09T16:51:45Z', 'updatedAt': '2018-10-05T20:20:31Z', 'labels': ['enhancement', 'help wanted', 'tech:django', 'tech:html', 'theme:ux'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '[moderate] Vulnerable Version of jquery.min.js', 'bodyHTML': '<p><strong>Location</strong>:  <code>/tock/static/admin/js/vendor/jquery/jquery.min.js</code></p>\\n<p><strong>Description</strong>:  The library jquery version 2.2.3 has known security issues between 1.12.3 and 3.0.0-beta1</p>\\n<p><strong>Recommendation</strong>:  Upgrade version of jquery.min.js to greater than 3.0.0-beta1</p>\\n<p><strong>References</strong>:</p>\\n<ul>\\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"91385079\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/jquery/jquery/issues/2432\" data-hovercard-type=\"issue\" data-hovercard-url=\"/jquery/jquery/issues/2432/hovercard\" href=\"https://github.com/jquery/jquery/issues/2432\">jquery/jquery#2432</a></li>\\n<li><a href=\"http://blog.jquery.com/2016/01/08/jquery-2-2-and-1-12-released/\" rel=\"nofollow\">http://blog.jquery.com/2016/01/08/jquery-2-2-and-1-12-released/</a></li>\\n<li><a href=\"http://research.insecurelabs.org/jquery/test/\" rel=\"nofollow\">http://research.insecurelabs.org/jquery/test/</a></li>\\n</ul>', 'url': 'https://github.com/18F/tock/issues/811', 'state': 'CLOSED', 'createdAt': '2018-05-21T14:03:47Z', 'lastEditedAt': None, 'publishedAt': '2018-05-21T14:03:47Z', 'updatedAt': '2018-06-28T18:11:24Z', 'labels': ['ATO', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Ensure markdown is safe', 'bodyHTML': '<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"322977987\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/tock/issues/808\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/tock/pull/808/hovercard\" href=\"https://github.com/18F/tock/pull/808\">#808</a> added support for markdown formatting of messages, but did not ensure that the stored messages are safe. Since this happens in the admin, with trusted users, it <em>shouldn\\'t</em> be a problem, but it is possible that someone could inadvertently submit content that breaks layout intent, or, theoretically, creates larger problems (<a href=\"https://code.djangoproject.com/ticket/17837\" rel=\"nofollow\">https://code.djangoproject.com/ticket/17837</a> for example)</p>\\n<p>We could also get a small performance boost by converting and sanitizing on save into a non-editable field, then using that field for output rather than converting every time in the view.</p>', 'url': 'https://github.com/18F/tock/issues/819', 'state': 'CLOSED', 'createdAt': '2018-08-16T16:36:50Z', 'lastEditedAt': None, 'publishedAt': '2018-08-16T16:36:50Z', 'updatedAt': '2018-10-10T14:11:19Z', 'labels': ['help wanted', 'tech:django'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Develop :grateful-tock: bot that recognizes on-time submissions', 'bodyHTML': '<p>We already have angry-tock reporting late submitters, but <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1211146\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pburkholder\">@pburkholder</a> suggested (and the motion quickly carried) that it would be nice to also have a happy tock that recognizes and thanks people who have consistently submitted to Tock on time over X time period.</p>\\n<p>We\\'ll need to figure out X. Peter suggested 26 weeks. I think that may be a bit ambitious and we might want to try a shorter period. We could also consider having award levels or something for larger periods.</p>', 'url': 'https://github.com/18F/tock/issues/824', 'state': 'OPEN', 'createdAt': '2018-09-20T12:40:14Z', 'lastEditedAt': None, 'publishedAt': '2018-09-20T12:40:14Z', 'updatedAt': '2018-09-20T12:40:48Z', 'labels': ['enhancement', 'help wanted', 'tech:django', 'tech:javascript'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix inactive user login redirect loop', 'bodyHTML': '<p>Currently, if someone is not an active user in tock, they get thrown into an nasty redirect loop. We should catch the user-is-not-active case and instead direct them to a simple unauthenticated page that says something like <em>\"you are inactive in Tock, please reach out to the Tock team in the #tock Slack channel for help.\"</em></p>\\n<p><em>We\\'ll know we\\'re done when</em></p>\\n<ul>\\n<li>Inactive users logging in resolve to a helpful page</li>\\n<li>Tests are written</li>\\n</ul>', 'url': 'https://github.com/18F/tock/issues/825', 'state': 'CLOSED', 'createdAt': '2018-09-26T14:49:40Z', 'lastEditedAt': '2018-09-26T14:51:29Z', 'publishedAt': '2018-09-26T14:49:40Z', 'updatedAt': '2018-10-01T17:55:59Z', 'labels': ['bug', 'help wanted', 'tech:django'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'NON_BILLABLE project list is hardcoded', 'bodyHTML': '<p>In <code>tock.hours.views</code> there is a list of <code>NON_BILLABLE_PROJECT_IDS</code> that is used only once in the <code>general_snippets_only_timecard_list</code> view to show the snippets of what people were doing when they tock to a non-billable project.</p>\\n<p>Because this list is hardcoded, when we add a new non-billable project it does not get picked up.</p>\\n<p>Since this list is not used anywhere else, the view could just get a queryset of the non-billable projects, which can be determined by following the <code>accounting_code</code> relationship, which has a <code>billable</code> attribute (see the <code>is_billable</code> method on <code>project</code>).</p>', 'url': 'https://github.com/18F/tock/issues/834', 'state': 'CLOSED', 'createdAt': '2018-10-10T13:25:46Z', 'lastEditedAt': None, 'publishedAt': '2018-10-10T13:25:46Z', 'updatedAt': '2018-10-11T13:06:57Z', 'labels': ['help wanted', 'tech:django'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Chart data does not appear aligned with correct dates', 'bodyHTML': '<p>It appears that the chart data are not aligned with the correct dates. See this example for Project 734.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/32077682/47455844-86b7e680-d798-11e8-9f19-5d7745dd5327.png\"><img src=\"https://user-images.githubusercontent.com/32077682/47455844-86b7e680-d798-11e8-9f19-5d7745dd5327.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Discovered by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2654503\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/edmullen\">@edmullen</a></p>', 'url': 'https://github.com/18F/tock/issues/841', 'state': 'OPEN', 'createdAt': '2018-10-24T19:25:22Z', 'lastEditedAt': None, 'publishedAt': '2018-10-24T19:25:22Z', 'updatedAt': '2018-10-24T19:25:46Z', 'labels': ['bug', 'help wanted', 'theme:ux'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'tock', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'handler400 issues', 'bodyHTML': \"<p>We have a custom 400 error handler defined, but there are a few issues:</p>\\n<ol>\\n<li>We have no 400.html template so it <em>shouldn't</em> work. Calling it would result in a 500 error.</li>\\n<li>We don't have a test that would have uncovered (1). We only found it by accident.</li>\\n</ol>\\n<p><em>We'll know we're done when:</em></p>\\n<ul>\\n<li>Template created</li>\\n<li>Tests written</li>\\n<li>400 errors are handled correctly</li>\\n</ul>\", 'url': 'https://github.com/18F/tock/issues/842', 'state': 'OPEN', 'createdAt': '2018-10-24T19:28:52Z', 'lastEditedAt': None, 'publishedAt': '2018-10-24T19:28:52Z', 'updatedAt': '2018-10-24T19:29:18Z', 'labels': ['help wanted', 'tech:django', 'theme:ux'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'laptop', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Testing of seekrets rulesets using BATS', 'bodyHTML': '<p>In order to ensure that our regex rules are correct, they should be tested, using <a href=\"https://github.com/sstephenson/bats\">BATS</a> and run automatically with Travis.</p>\\n<p>Rulesets for <a href=\"https://github.com/apuigsech/git-seekret\"><code>git-seekrets</code></a> are defined as regex inside a yaml file. These include rule name, the regex for the <code>match</code>, and any acceptable false positives as <code>unmatch</code>.  Existing rulesets that need tests defined are here:<br>\\n<a href=\"https://github.com/18F/laptop/tree/seekret/seekret-rules\">https://github.com/18F/laptop/tree/seekret/seekret-rules</a></p>\\n<p>Depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"181504116\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/75\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/laptop/issues/75/hovercard\" href=\"https://github.com/18F/laptop/issues/75\">#75</a> for easier implementation.</p>\\n<p>If fixing, please use <code>seekret</code> branch so it\\'s merged into PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171458017\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/69\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/laptop/pull/69/hovercard\" href=\"https://github.com/18F/laptop/pull/69\">#69</a></p>\\n<p>More about the rules YAML: <a href=\"https://github.com/apuigsech/seekret/blob/75ab481819b4c1e1794497defea9a9332943295b/README.rst#rules\">https://github.com/apuigsech/seekret/blob/75ab481819b4c1e1794497defea9a9332943295b/README.rst#rules</a></p>\\n<h4>Acceptance Criteria</h4>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Install <code>git seekret</code> in a repeatable way ( should be covered in another story )</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Install <code>BATS</code> in a repeatable way, <a href=\"https://github.com/sstephenson/bats\">readme</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Write <code>BATS</code> tests for each of these:\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Check for <code>git seekret</code> installation.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Check for <code>rulesets</code> enabled.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Check that <code>git seekret</code> is called on a test repository and secrets are detected. (positives)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Check that <code>git seekret</code> is called on a test repository and non-secrets are not detected. (acceptable false positives)</li>\\n</ul>\\n</li>\\n</ul>', 'url': 'https://github.com/18F/laptop/issues/74', 'state': 'CLOSED', 'createdAt': '2016-10-06T19:23:27Z', 'lastEditedAt': '2016-11-14T22:16:45Z', 'publishedAt': '2016-10-06T19:23:27Z', 'updatedAt': '2016-12-09T15:48:23Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'laptop', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Download & enable rulesets during installation of seekrets', 'bodyHTML': '<p>As a new user to <code>git-seekret</code> I want to be able to run one script to install everything I need to start using these hooks to stop committing sensitive information.</p>\\n<p>Implementation:<br>\\nSee TODO items in <a href=\"https://github.com/18F/laptop/blob/seekret/seekrets-install\"><code>seekrets-install</code></a>. Initially, the rules can be downloaded using a reference to the <code>seekret</code> branch of this repo for testing, will need to reference <code>master</code> for merge.<br>\\nAdded bonus points related to enabling rules: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"181493426\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/apuigsech/git-seekret/issues/12\" data-hovercard-type=\"issue\" data-hovercard-url=\"/apuigsech/git-seekret/issues/12/hovercard\" href=\"https://github.com/apuigsech/git-seekret/issues/12\">apuigsech/git-seekret#12</a></p>\\n<p>If fixing, please use <code>seekret</code> branch so it\\'s merged into PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171458017\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/69\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/laptop/pull/69/hovercard\" href=\"https://github.com/18F/laptop/pull/69\">#69</a></p>', 'url': 'https://github.com/18F/laptop/issues/75', 'state': 'CLOSED', 'createdAt': '2016-10-06T19:27:05Z', 'lastEditedAt': '2016-10-06T21:24:24Z', 'publishedAt': '2016-10-06T19:27:05Z', 'updatedAt': '2016-11-14T17:41:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'laptop', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'New seekret ruleset for Mandrill/Mailchimp', 'bodyHTML': '<p>As as developer with access to Mandrill, I want to make sure that I\\'m not accidentally checking in my Mandrill API key.</p>\\n<p>Implementation:<br>\\nBuilding on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"181503346\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/74\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/laptop/issues/74/hovercard\" href=\"https://github.com/18F/laptop/issues/74\">#74</a>, a new set of BATS tests, and rule file which contains any match/unmatch regex should be included.</p>\\n<p>If fixing, please use seekret branch so it\\'s merged into PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"171458017\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/69\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/laptop/pull/69/hovercard\" href=\"https://github.com/18F/laptop/pull/69\">#69</a></p>', 'url': 'https://github.com/18F/laptop/issues/77', 'state': 'CLOSED', 'createdAt': '2016-10-06T19:55:39Z', 'lastEditedAt': '2016-10-06T21:19:24Z', 'publishedAt': '2016-10-06T19:55:39Z', 'updatedAt': '2016-12-12T19:45:31Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'laptop', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Instructions on how to run BATS locally for git-seekrets', 'bodyHTML': '<p>Once <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"181503346\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/74\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/laptop/issues/74/hovercard\" href=\"https://github.com/18F/laptop/issues/74\">#74</a> is addressed, it would be helpful for developers to have instructions on how to setup and run the tests locally.</p>\\n<p>The instructions (and possible additional script logic) should preserve their current rules prior to running the tests locally and should restore their rules after the tests.</p>\\n<p>Extra considerations:<br>\\nMay want to trap the <code>Ctrl-C</code> signal (and maybe other signals) so that if a developer pushes Ctrl-C, it will cleanup before exiting. Example: <code>A clean_up function</code> section in <a href=\"http://linuxcommand.org/wss0160.php\" rel=\"nofollow\">http://linuxcommand.org/wss0160.php</a></p>\\n<h4>Acceptance Criteria</h4>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Documentation for <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"181503346\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/laptop/issues/74\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/laptop/issues/74/hovercard\" href=\"https://github.com/18F/laptop/issues/74\">#74</a></li>\\n</ul>', 'url': 'https://github.com/18F/laptop/issues/78', 'state': 'CLOSED', 'createdAt': '2016-10-07T10:43:37Z', 'lastEditedAt': '2016-11-14T22:17:12Z', 'publishedAt': '2016-10-07T10:43:37Z', 'updatedAt': '2016-11-22T17:32:12Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'jekyll-get', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'make this a gem', 'bodyHTML': '<p>Makes it easier for projects that use this to keep up-to-date. Happy to help if needed.</p>', 'url': 'https://github.com/18F/jekyll-get/issues/8', 'state': 'OPEN', 'createdAt': '2016-01-05T16:47:06Z', 'lastEditedAt': None, 'publishedAt': '2016-01-05T16:47:06Z', 'updatedAt': '2018-07-09T18:09:48Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'How should we handle changes that need to be reflected on the printed cards?', 'bodyHTML': '<p>Question originally asked by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11636908\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jenniferthibault\">@jenniferthibault</a> in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"100187432\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/methods/issues/27\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/methods/issues/27/hovercard\" href=\"https://github.com/18F/methods/issues/27\">#27</a>:</p>\\n<p>suggestions for a good way to make changes on the site &amp; the printed cards, without losing track? Keeping the print cards up to date is definitely important, but it takes ~20 min each time we need to re-export and upload, so minimizing the number of times we do that would be <g-emoji class=\"g-emoji\" alias=\"+1\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f44d.png\"></g-emoji></p>\\n<p>My initial responses (with a few adjustments from the original):</p>\\n<ul>\\n<li>Apply a tag like, say, <code>card copy</code> to any PRs that include language updates that affect the cards.</li>\\n<li>Specify in each PR exactly which methods are affected. The file changes themselves will show it, but this way it may be easier to see when multiple PRs affect the same method. A small language change on one method will usually not be worth re-exporting, but six or seven small changes on the same method might be.</li>\\n<li>Establish a regular update schedule for non-urgent changes to the cards. What\\'s a good frequency?</li>\\n<li>Make sure 18F staff know how to find the INDD files so other designers can address if/when such issues arise.</li>\\n</ul>\\n<p>What do people think? Other ideas? Problems with the above?</p>', 'url': 'https://github.com/18F/methods/issues/32', 'state': 'CLOSED', 'createdAt': '2015-08-11T21:51:47Z', 'lastEditedAt': None, 'publishedAt': '2015-08-11T21:51:47Z', 'updatedAt': '2015-10-16T20:42:21Z', 'labels': ['help wanted', 'print'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Link Errors \"404 Not Found\"', 'bodyHTML': '<p>Behavior: Old URLs are not directing to new URLs \"404 Not Found\"</p>\\n<p>Examples:<br>\\nOLD URL: <a href=\"https://methods.18f.gov/personas/\" rel=\"nofollow\">https://methods.18f.gov/personas/</a><br>\\nNEW URL: <a href=\"https://methods.18f.gov/decide/personas/\" rel=\"nofollow\">https://methods.18f.gov/decide/personas/</a></p>\\n<p>OLD URL: <a href=\"https://methods.18f.gov/feature-dot-voting/\" rel=\"nofollow\">https://methods.18f.gov/feature-dot-voting/</a><br>\\nNEW URL: <a href=\"https://methods.18f.gov/discover/feature-dot-voting/\" rel=\"nofollow\">https://methods.18f.gov/discover/feature-dot-voting/</a></p>\\n<p>Login to <a href=\"https://methods.18f.gov/personas/\" rel=\"nofollow\">https://methods.18f.gov/personas/</a> or <a href=\"https://methods.18f.gov/feature-dot-voting/\" rel=\"nofollow\">https://methods.18f.gov/feature-dot-voting/</a> experience link error</p>\\n<p>Solution: Expect old links to direct to new URLS</p>', 'url': 'https://github.com/18F/methods/issues/112', 'state': 'CLOSED', 'createdAt': '2016-07-25T17:28:23Z', 'lastEditedAt': None, 'publishedAt': '2016-07-25T17:28:23Z', 'updatedAt': '2016-08-26T20:24:54Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Pull-down menus briefly flash open on page load', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9259185/29327385-8daea4b4-81b4-11e7-92b9-765944cef62a.png\"><img src=\"https://user-images.githubusercontent.com/9259185/29327385-8daea4b4-81b4-11e7-92b9-765944cef62a.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/methods/issues/301', 'state': 'CLOSED', 'createdAt': '2017-08-15T17:23:45Z', 'lastEditedAt': None, 'publishedAt': '2017-08-15T17:23:45Z', 'updatedAt': '2018-01-18T18:40:06Z', 'labels': ['bug', 'front end', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Set up GSA recruiter', 'bodyHTML': '<p>Set up the GSA recruiter to be used when wanting to capture folks for user testing <a href=\"https://github.com/GSA/recruiter\">https://github.com/GSA/recruiter</a></p>', 'url': 'https://github.com/18F/methods/issues/313', 'state': 'OPEN', 'createdAt': '2017-09-18T17:26:19Z', 'lastEditedAt': '2017-11-27T21:50:03Z', 'publishedAt': '2017-09-18T17:26:19Z', 'updatedAt': '2017-11-27T21:50:11Z', 'labels': ['front end', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Test minor design mods to see whether users better find individual card links and print button', 'bodyHTML': '<p>This suggestion is based in speculation, rather than data. So proceed (or opt not to) accordingly! It\\'s difficult to tell where users \"bounce,\" since all of the cards are on a single page. However, it seems that users may be having trouble finding individual method-card pages.</p>\\n<p>Cards are accessed by clicking the header  \"Bodystorming\" in the image below  but there is nothing to visually identify the header as a link. (Users must hover in order to see the underscore)<br>\\n<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9259185/30601452-a92172ba-9d27-11e7-9f3a-093231298f74.png\"><img src=\"https://user-images.githubusercontent.com/9259185/30601452-a92172ba-9d27-11e7-9f3a-093231298f74.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<h2>Design tweak to consider / test: add underscore to header by default </h2>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9259185/30601526-d5b53ba4-9d27-11e7-91a9-11513b8bca6b.png\"><img src=\"https://user-images.githubusercontent.com/9259185/30601526-d5b53ba4-9d27-11e7-91a9-11513b8bca6b.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<h2>Also consider changing the color of these blue buttons to white. The hot blue color is hard on the eyes</h2>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9259185/30601592-019768f0-9d28-11e7-91e1-e97c7faa90ca.png\"><img src=\"https://user-images.githubusercontent.com/9259185/30601592-019768f0-9d28-11e7-91e1-e97c7faa90ca.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<h2>White avoids color clashing, and is still 508 compliant </h2>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9259185/30601660-289d6a58-9d28-11e7-84f0-2aed7044369b.png\"><img src=\"https://user-images.githubusercontent.com/9259185/30601660-289d6a58-9d28-11e7-84f0-2aed7044369b.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<h2>Additional thought: consider linking the hover menus to individual card pages, rather than using anchor links </h2>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/9259185/30601737-51f0d304-9d28-11e7-9526-c3a5291a0091.png\"><img src=\"https://user-images.githubusercontent.com/9259185/30601737-51f0d304-9d28-11e7-9526-c3a5291a0091.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/methods/issues/315', 'state': 'CLOSED', 'createdAt': '2017-09-19T15:51:15Z', 'lastEditedAt': None, 'publishedAt': '2017-09-19T15:51:15Z', 'updatedAt': '2018-01-19T21:44:48Z', 'labels': ['from fall 2017 research', 'front end', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update top navigation to link directly to individual methods', 'bodyHTML': '<p>Navigating to an individual method was something to address that came out of our user research.</p>\\n<p>Update the top navigation to link to individual method pages instead of anchor linking down into the page.</p>', 'url': 'https://github.com/18F/methods/issues/329', 'state': 'CLOSED', 'createdAt': '2017-12-04T18:02:26Z', 'lastEditedAt': None, 'publishedAt': '2017-12-04T18:02:26Z', 'updatedAt': '2018-01-19T21:44:17Z', 'labels': ['from fall 2017 research', 'front end', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Make method title look more clickable', 'bodyHTML': '<p>Make method title look more clickable</p>', 'url': 'https://github.com/18F/methods/issues/330', 'state': 'CLOSED', 'createdAt': '2017-12-04T18:05:10Z', 'lastEditedAt': '2018-01-19T19:48:56Z', 'publishedAt': '2017-12-04T18:05:10Z', 'updatedAt': '2018-01-30T15:59:47Z', 'labels': ['from fall 2017 research', 'front end', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Explain/contextualize methods on homepage', 'bodyHTML': '<p>Currently the homepage jumps right into individual methods without giving any context or explanatory content to help guide the user and have a deeper understanding for HCD and how methods can be applied.</p>\\n<h3>Some ideas are</h3>\\n<p><strong>Update the homepage</strong></p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Potentially the homepage would be a simple overview, not a list of all cards?</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Make homepage that could help orient people who are new to the methods on how to start exploring the cards.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Create a visual overview / map to help with wayfinding, to help orient people new to HCD and the method cards.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Incorporate the graphic in <a href=\"https://gsablogs.gsa.gov/gsablog/files/2017/10/HCD-Discovery-Guide-Interagency-v1.2-1.pdf\" rel=\"nofollow\">Matt Fords HCD handbook</a>something like that would help (Could also help address the issue with people not understanding category/phase?)</li>\\n</ul>\\n<p><strong>Connect the Methods to broader HCD guidance</strong></p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Create an 18F research guide that helps orient folks to the basics of HCD, to contextually ground the cards and help folks with how to start.</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F should find language to connect \"what\" HCD is with \"why and how\" it works in government and more specifically, in 18F.</p>\\n</li>\\n</ul>', 'url': 'https://github.com/18F/methods/issues/331', 'state': 'CLOSED', 'createdAt': '2017-12-04T18:08:10Z', 'lastEditedAt': '2018-03-15T19:57:20Z', 'publishedAt': '2017-12-04T18:08:10Z', 'updatedAt': '2018-10-05T13:19:53Z', 'labels': ['content', 'from fall 2017 research', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Explain categories better', 'bodyHTML': '<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Capitalize and refer to categories as proper nouns.</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add a few words of description [for categories]. Took me a while to wrap my head around what this is all about.</p>\\n</li>\\n</ul>', 'url': 'https://github.com/18F/methods/issues/332', 'state': 'OPEN', 'createdAt': '2017-12-04T18:23:58Z', 'lastEditedAt': None, 'publishedAt': '2017-12-04T18:23:58Z', 'updatedAt': '2018-05-03T15:31:34Z', 'labels': ['content', 'from fall 2017 research', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'methods', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Enhance method cards (homepage + new methods)', 'bodyHTML': '<p>During phase 2 of the <a href=\"https://github.com/18F/10X-Users-First\">10x Users First</a> project, we encountered a number of challenges users face when implementing user centered design and even more specifically, when referencing the method cards:</p>\\n<ul>\\n<li>Users like the method cards, but don\\'t know what to start</li>\\n<li>When reading the <code>usability testing</code> card, users assume it applies solely to prototyping (because the copy suggests it\\'s to be used during prototyping)</li>\\n<li>Users lack information they need to effectively conduct problem framing prior to digging into research</li>\\n</ul>\\n<p>As a part of our closing recommendations for phase 2, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=40205199\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lalitha-jonnalagadda\">@lalitha-jonnalagadda</a> and I would suggest making the following updates/changes to help solve the issues outlined above.</p>\\n<ul>\\n<li>Create an explainer that helps users orient themselves upon first arriving at methods.18f.gov. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1449852\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/line47\">@line47</a> outlined some initial ideas for how to potentially go about this in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"279093185\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/methods/issues/331\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/methods/issues/331/hovercard\" href=\"https://github.com/18F/methods/issues/331\">#331</a></li>\\n<li>Clarify the <code>usability testing</code> card so that it no longer suggests that testing is only done while prototyping</li>\\n<li>Add a <code>problem framing</code> card</li>\\n</ul>\\n<p>I should note that this probably belongs in separate issues, but because these are all linked to our recommendations for our 10x project, we thought it would be best to keep this as one issue and let the team resolve/address as they choose.</p>', 'url': 'https://github.com/18F/methods/issues/358', 'state': 'OPEN', 'createdAt': '2018-08-27T22:41:33Z', 'lastEditedAt': None, 'publishedAt': '2018-08-27T22:41:33Z', 'updatedAt': '2018-08-27T22:42:10Z', 'labels': ['content', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'PLEASE read EVERYTHING ARL has done', 'bodyHTML': '<p>tldr version: the legal stuff is <strong>really</strong> complicated.  See <a href=\"https://github.com/openjournals/joss/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/openjournals/joss/issues/179/hovercard\">this dicussion</a> for some of the legal issues involved.  The license agreement you\\'ve put together <strong>does not</strong> address many of the issues.</p>\\n<p><a href=\"http://www.arl.army.mil/www/default.cfm\" rel=\"nofollow\">ARL</a> has been wrestling with the legal issues since October 2015.  They are <em>complex</em>.  You can read some of the issues <a href=\"https://github.com/USArmyResearchLab/ARL-Open-Source-Guidance-and-Instructions/blob/master/LEGAL_ANALYSIS.md\">here</a>, and you can see the guidelines we\\'ve come up with for our own workforce <a href=\"https://github.com/USArmyResearchLab/ARL-Open-Source-Guidance-and-Instructions\">here</a>.  Please read through our material completely.</p>\\n<p>I\\'ve also been given an email address to contact you through, I\\'ll be writing to you directly so you can confirm I\\'m DoD, and so I can confirm who you are. Then we can have a more complete discussion.</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/8', 'state': 'CLOSED', 'createdAt': '2017-02-23T21:51:45Z', 'lastEditedAt': None, 'publishedAt': '2017-02-23T21:51:45Z', 'updatedAt': '2017-02-27T22:37:25Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 11}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'FAQ Updated!', 'bodyHTML': \"<p>We made a substantial update to the FAQ.  There are still some items we'd like to add, but would really appreciate any feedback on issues we might have missed or language that could be improved.  Thanks!</p>\", 'url': 'https://github.com/Code-dot-mil/code.mil/issues/99', 'state': 'CLOSED', 'createdAt': '2017-03-03T14:31:35Z', 'lastEditedAt': None, 'publishedAt': '2017-03-03T14:31:35Z', 'updatedAt': '2018-03-27T09:51:07Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Add featured code projects \"above the fold\" on homepage', 'bodyHTML': '<p>Users visiting the site might want to see some of the neat projects that have been open sourced within the DoD. It would be good to have a snapshot of two or three of these on the homepage, above the fold.</p>\\n<p>(Perhaps a slideshow instead of the static hero element?)</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/140', 'state': 'OPEN', 'createdAt': '2018-01-10T15:06:30Z', 'lastEditedAt': None, 'publishedAt': '2018-01-10T15:06:30Z', 'updatedAt': '2018-10-01T17:55:02Z', 'labels': ['[effort] medium', '[issue-type] content', '[skill-level] beginner', 'code.gov', 'help wanted', 'website'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Design a Code.mil logo', 'bodyHTML': '<p>Work plan</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Identify agency/code that will take final custody of code.mil</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Identify stakeholders that have decision making authority at that agency/code</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> State purpose and audience</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Identify design requirements (color requirements, fonts which the agency prefers)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Propose candidate designs</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Cut designs into vector format, and rasters as needed (including favicons)</li>\\n</ul>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/147', 'state': 'OPEN', 'createdAt': '2018-01-30T15:25:05Z', 'lastEditedAt': '2018-02-05T21:51:33Z', 'publishedAt': '2018-01-30T15:25:05Z', 'updatedAt': '2018-10-01T17:43:45Z', 'labels': ['[effort] medium', '[issue-type] enhancement', '[skill-level] beginner', 'code.gov', 'help wanted', 'website'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Add a press section?', 'bodyHTML': '<p>We might want a page to track press / announcements / releases / etc.</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/160', 'state': 'CLOSED', 'createdAt': '2018-02-13T18:02:31Z', 'lastEditedAt': None, 'publishedAt': '2018-02-13T18:02:31Z', 'updatedAt': '2018-05-29T21:26:48Z', 'labels': ['[issue-type] question', 'help wanted', 'website'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Add \"help wanted\" instructions to site', 'bodyHTML': '<h2>Content</h2>\\n<p>I would like the instructions on \"how to open source\" to include information on how to use the Code.gov \"help wanted\" labels so that GH issues can be displayed on the Code.gov site. Instructions for using these labels can be found on the <a href=\"https://github.com/GSA/code-gov/blob/master/HelpWanted.md\">\"code-gov\" repo</a>.</p>\\n<h2>Page(s) Affected</h2>\\n<p><a href=\"https://www.code.mil/how-to-open-source.html\" rel=\"nofollow\">https://www.code.mil/how-to-open-source.html</a></p>\\n<p>But maybe also <a href=\"https://www.code.mil/frequently-asked-questions.html\" rel=\"nofollow\">https://www.code.mil/frequently-asked-questions.html</a> ?</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/180', 'state': 'OPEN', 'createdAt': '2018-03-19T19:41:24Z', 'lastEditedAt': None, 'publishedAt': '2018-03-19T19:41:24Z', 'updatedAt': '2018-10-09T13:22:46Z', 'labels': ['[effort] small', '[issue-type] content', '[skill-level] beginner', 'code.gov', 'help wanted', 'website'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Project Validation', 'bodyHTML': '<p>We should validate the JSON before pushing any changes that could break or improperly update project info.</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/186', 'state': 'OPEN', 'createdAt': '2018-03-27T00:11:37Z', 'lastEditedAt': None, 'publishedAt': '2018-03-27T00:11:37Z', 'updatedAt': '2018-06-22T20:30:21Z', 'labels': ['[effort] medium', '[issue-type] enhancement', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Missing content on home page ', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=30059011\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jordangov\">@jordangov</a></p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/213', 'state': 'CLOSED', 'createdAt': '2018-06-22T16:54:10Z', 'lastEditedAt': None, 'publishedAt': '2018-06-22T16:54:10Z', 'updatedAt': '2018-06-25T15:57:58Z', 'labels': ['[effort] medium', '[issue-type] bug', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Update Issue and Pull Request templates', 'bodyHTML': '<p>Per conversation with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=30059011\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jordangov\">@jordangov</a>, we should consider updating the Issue and Pull Request templates to include a checklist similar to:</p>\\n<ul>\\n<li><a href=\"https://github.com/deptofdefense/move.mil/blob/master/.github/ISSUE_TEMPLATE.md\">deptofdefense/move.mil\\'s <code>ISSUE_TEMPLATE.md</code></a></li>\\n<li><a href=\"https://github.com/deptofdefense/move.mil/blob/master/.github/PULL_REQUEST_TEMPLATE.md\">deptofdefense/move.mil\\'s <code>PULL_REQUEST_TEMPLATE.md</code></a></li>\\n</ul>\\n<p>We\\'ve found these to be pretty helpful in steering behavior and avoiding low-hanging obstacles to quickly triaging and responding to change requests.</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/221', 'state': 'OPEN', 'createdAt': '2018-06-29T14:45:54Z', 'lastEditedAt': None, 'publishedAt': '2018-06-29T14:45:54Z', 'updatedAt': '2018-10-30T00:47:43Z', 'labels': ['[effort] small', '[issue-type] enhancement', '[skill-level] beginner', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Allow Project Owners to submit projects for code inventory file', 'bodyHTML': '<p>We should consider creating a form on the code.mil website that allows project owners to submit details of their projects for the purposes of generating the <code>code.json</code> inventory file.</p>\\n<p>The steps toward this goal might involve</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> breaking the existing <code>code.json</code> file into project-specific data files (e.g. <code>src/_data/code_json/move-mil.json</code> (or YAML?) (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"339944300\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/Code-dot-mil/code.mil/issues/232\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/Code-dot-mil/code.mil/pull/232/hovercard\" href=\"https://github.com/Code-dot-mil/code.mil/pull/232\">#232</a>)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> add small Jekyll plugin to generate <code>code.json</code> file from data files (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"339944300\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/Code-dot-mil/code.mil/issues/232\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/Code-dot-mil/code.mil/pull/232/hovercard\" href=\"https://github.com/Code-dot-mil/code.mil/pull/232\">#232</a>)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> determine a means of validating individual project data files and the resultant <code>code.json</code> file</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> create the necessary pages on code.mil website to accept these submissions (this one\\'s worth its own issue for sorting out design, implementation, etc.)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> form submission could/should create a pull request on this project\\'s repository for evaluation and inform the user of the PR\\'s URL (on say, a \"thanks!\" page)</li>\\n</ul>\\n<p>Possibly useful Netlify documentation:</p>\\n<ul>\\n<li><a href=\"https://www.netlify.com/docs/form-handling/\" rel=\"nofollow\">https://www.netlify.com/docs/form-handling/</a></li>\\n<li><a href=\"https://www.netlify.com/docs/functions/\" rel=\"nofollow\">https://www.netlify.com/docs/functions/</a></li>\\n</ul>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/231', 'state': 'OPEN', 'createdAt': '2018-07-10T15:23:13Z', 'lastEditedAt': '2018-07-10T18:31:34Z', 'publishedAt': '2018-07-10T15:23:13Z', 'updatedAt': '2018-10-30T00:47:44Z', 'labels': ['[effort] large', '[issue-type] enhancement', '[skill-level] advanced', 'code.gov', 'help wanted', 'website'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Check email link text color', 'bodyHTML': '<p>It\\'s light grey for some reason! <g-emoji class=\"g-emoji\" alias=\"man_shrugging\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f937-2642.png\">\\u200d</g-emoji></p>\\n<p>It should be white.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/27780860/42531278-96eb1904-8451-11e8-8ad9-3dd849b82b62.png\"><img width=\"518\" alt=\"screen shot 2018-07-10 at 2 57 04 pm\" src=\"https://user-images.githubusercontent.com/27780860/42531278-96eb1904-8451-11e8-8ad9-3dd849b82b62.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/234', 'state': 'OPEN', 'createdAt': '2018-07-10T18:57:50Z', 'lastEditedAt': None, 'publishedAt': '2018-07-10T18:57:50Z', 'updatedAt': '2018-10-30T00:47:44Z', 'labels': ['[effort] small', '[issue-type] bug', '[skill-level] beginner', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Footer Email Reference', 'bodyHTML': '<h2>Feature </h2>\\n<p>Increase maintainability of references in footer</p>\\n<h2>Affected Area</h2>\\n<p><a href=\"https://github.com/Code-dot-mil/code.mil/blob/master/src/_data/footer.yml\">footer</a>, lines 58 &amp; 59</p>\\n<h2>Description</h2>\\n<p>\\'href\\' for email uses a liquid reference to the configuration file. However, the associated \\'text\\' is hard-coded.  hard-coding could be replaced with:</p>\\n<pre><code>\\'{{site.email}}\\'\\n</code></pre>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/235', 'state': 'OPEN', 'createdAt': '2018-07-15T14:53:08Z', 'lastEditedAt': None, 'publishedAt': '2018-07-15T14:53:08Z', 'updatedAt': '2018-10-30T00:47:44Z', 'labels': ['[effort] small', '[issue-type] enhancement', '[skill-level] beginner', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Add documentation on how to do good OSS documentation', 'bodyHTML': '<h2>Feature</h2>\\n<p>We would like to have better documentation on how to create good open source software documentation as guidance for Department organizations wishing to open source things. This should include things like relevant sections of a \"contributing\" doc (not just a link to an example), how to write and review PRs, good commit messages, how to write a good GH issue, etc.</p>\\n<h2>Page(s) Affected</h2>\\n<p>This could go on <a href=\"https://www.code.mil/how-to-open-source.html\" rel=\"nofollow\">https://www.code.mil/how-to-open-source.html</a> (\"How to Open Source\"), but it could live on it\\'s own page, linked a couple of places.</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/240', 'state': 'OPEN', 'createdAt': '2018-09-06T14:15:26Z', 'lastEditedAt': None, 'publishedAt': '2018-09-06T14:15:26Z', 'updatedAt': '2018-10-30T00:47:44Z', 'labels': ['[effort] small', '[issue-type] content', '[skill-level] beginner', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Have a user-friendly project inventory', 'bodyHTML': '<h2>Feature</h2>\\n<p>Right now the only way to see projects on Code.mil is to look at the <code>code.json</code> file. I would like to have a user-friendly view of the projects in that inventory for anyone to peruse. The Code.gov team <a href=\"https://code.gov/#!/browse-projects\" rel=\"nofollow\">has something like this</a>, but I\\'m not sure if it is reusable, and we don\\'t necessarily need it to look like that.</p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/241', 'state': 'OPEN', 'createdAt': '2018-10-01T13:27:25Z', 'lastEditedAt': None, 'publishedAt': '2018-10-01T13:27:25Z', 'updatedAt': '2018-10-30T00:47:44Z', 'labels': ['[effort] large', '[issue-type] enhancement', '[skill-level] intermediate', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code.mil', 'repo_owner_name': 'Code.mil', 'repo_owner_email': 'code@dds.mil', 'repo_owner_user_name': 'Code-dot-mil', 'repo_owner_profile_url': 'https://github.com/Code-dot-mil', 'title': 'Add DDS.mil website to inventory', 'bodyHTML': '<h2>Feature</h2>\\n<p>I would like to add the <a href=\"https://github.com/deptofdefense/dds.mil\">DDS.mil website/repo</a> to the code.json inventory file for DoD/Code.mil.</p>\\n<h2>Page(s) Affected</h2>\\n<p><a href=\"https://code.mil/code.json\" rel=\"nofollow\">https://code.mil/code.json</a></p>', 'url': 'https://github.com/Code-dot-mil/code.mil/issues/245', 'state': 'OPEN', 'createdAt': '2018-10-23T17:23:48Z', 'lastEditedAt': None, 'publishedAt': '2018-10-23T17:23:48Z', 'updatedAt': '2018-10-30T00:47:21Z', 'labels': ['[effort] small', '[issue-type] enhancement', '[skill-level] beginner', 'code.gov', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'jpo-ode', 'repo_owner_name': 'US DOT ITS JPO ODE', 'repo_owner_email': 'ariel.gold@dot.gov', 'repo_owner_user_name': 'usdot-jpo-ode', 'repo_owner_profile_url': 'https://github.com/usdot-jpo-ode', 'title': 'TIM to RSU REST Request not returning successful SNMP bindings', 'bodyHTML': '<p>I\\'m trying to send a TIM to the RSU in our office using the TIM REST request with a JSON body.</p>\\n<p>When I use the the \"admin\" for the RSU username and \"password\" for the password it is returning:</p>\\n<p>{SDW={success: true, message: \"Deposit to SDW was successful\"}, 192.168.0.145={success: true, message: \"SNMP deposit successful. RSU IP = 192.168.0.145, Status Code: 0\"}}</p>\\n<p>When v3user is used for the username the response is:</p>\\n<p>{SDW={success: true, message: \"Deposit to SDW was successful\"}, 192.168.0.145={success: false, message: \"SNMP deposit failed for RSU IP 192.168.0.145, error code=5(General variable binding error)\"}}</p>\\n<p>In either case I am not seeing the TIM getting created on the RSU. I am not sure if this could be an issue with my JSON, and I\\'m also not sure which username is correct.</p>\\n<p>Thanks!<br>\\nKim</p>', 'url': 'https://github.com/usdot-jpo-ode/jpo-ode/issues/115', 'state': 'CLOSED', 'createdAt': '2017-06-08T20:37:35Z', 'lastEditedAt': None, 'publishedAt': '2017-06-08T20:37:35Z', 'updatedAt': '2017-06-13T16:10:03Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'jpo-ode', 'repo_owner_name': 'US DOT ITS JPO ODE', 'repo_owner_email': 'ariel.gold@dot.gov', 'repo_owner_user_name': 'usdot-jpo-ode', 'repo_owner_profile_url': 'https://github.com/usdot-jpo-ode', 'title': 'TIM units and conversions', 'bodyHTML': '<p>I\\'ve trying to figure out what units the ODE is expecting from TIMs.</p>\\n<p>For example, the ODE is validating elevation based on meters (-409.5 to 6143.9) while the standard asks for 10 cm units. Doing this conversion before sending the TIM can put the elevation out of bounds.</p>\\n<p>Also the standard specifies lat/longs in .1 microdegrees, should the ODE be responsible for the conversion or should that fall on the user?</p>\\n<p>I\\'ve attached JSON that I\\'ve generated that deposits a TIM to an RSU, the nodeLat and nodeLongs are in .1 microdegrees with deltas that match.</p>\\n<p>Thank you!<br>\\nKim<br>\\n<a href=\"https://github.com/usdot-jpo-ode/jpo-ode/files/1201699/timJson.txt\">timJson.txt</a></p>', 'url': 'https://github.com/usdot-jpo-ode/jpo-ode/issues/147', 'state': 'CLOSED', 'createdAt': '2017-08-04T21:32:43Z', 'lastEditedAt': None, 'publishedAt': '2017-08-04T21:32:43Z', 'updatedAt': '2017-08-29T13:20:03Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'peek-delayed_job', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add support for non-ActiveRecord backends', 'bodyHTML': '<p>Not sure if there\\'s a way to do the queries in a generic way...</p>\\n<p><a href=\"https://github.com/collectiveidea/delayed_job/wiki/Backends\">https://github.com/collectiveidea/delayed_job/wiki/Backends</a></p>', 'url': 'https://github.com/18F/peek-delayed_job/issues/2', 'state': 'OPEN', 'createdAt': '2015-08-24T02:55:28Z', 'lastEditedAt': None, 'publishedAt': '2015-08-24T02:55:28Z', 'updatedAt': '2015-08-24T02:55:28Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'peek-delayed_job', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'adapt for ActiveJob', 'bodyHTML': '<p>Should be able to work in nearly the same way. Not sure if it should be the same gem, or a different one...?</p>\\n<p><a href=\"http://edgeguides.rubyonrails.org/active_job_basics.html\" rel=\"nofollow\">http://edgeguides.rubyonrails.org/active_job_basics.html</a></p>', 'url': 'https://github.com/18F/peek-delayed_job/issues/4', 'state': 'OPEN', 'createdAt': '2016-05-11T18:23:03Z', 'lastEditedAt': None, 'publishedAt': '2016-05-11T18:23:03Z', 'updatedAt': '2016-05-11T18:23:03Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'cf-hello-worlds', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Migrate to cloudfoundry-samples org', 'bodyHTML': '<p>Just discovered <a href=\"https://github.com/cloudfoundry-samples\">https://github.com/cloudfoundry-samples</a>, via <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"142714751\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/cf-hello-worlds/issues/21\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/cf-hello-worlds/pull/21/hovercard?comment_id=204093500&amp;comment_type=issue_comment\" href=\"https://github.com/18F/cf-hello-worlds/pull/21#issuecomment-204093500\">#21 (comment)</a>.</p>', 'url': 'https://github.com/18F/cf-hello-worlds/issues/22', 'state': 'OPEN', 'createdAt': '2016-03-31T19:44:18Z', 'lastEditedAt': None, 'publishedAt': '2016-03-31T19:44:18Z', 'updatedAt': '2017-12-02T17:42:53Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Code.gov Schema Feedback', 'bodyHTML': '<p>At Code.gov we are constantly looking at how to improve our processes and those of our partners. A central part of these improvements in our JSON schema.</p>\\n<p>In the past, we have updated the schema from an initial 1.0.0 release to a 2.0.0 with little feedback. We would like to remedy that by asking for feedback on our future releases starting with version 2.0.1.</p>\\n<p>In this new release, we have added additional optional fields that we feel could benefit our users. We would like feedback on these fields and any other additional you feel should be considered.</p>\\n<p>The new schema can be viewed <a href=\"https://github.com/GSA/code-gov-data/blob/master/schemas/schema-2.0.1-rc.json\">here</a>.</p>\\n<p>We look forward to your ideas!</p>', 'url': 'https://github.com/GSA/code-gov/issues/15', 'state': 'OPEN', 'createdAt': '2018-07-27T18:53:22Z', 'lastEditedAt': None, 'publishedAt': '2018-07-27T18:53:22Z', 'updatedAt': '2018-09-10T19:27:04Z', 'labels': ['feedback', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'cbp-theme', 'repo_owner_name': 'U.S. Customs and Border Protection', 'repo_owner_email': '', 'repo_owner_user_name': 'US-CBP', 'repo_owner_profile_url': 'https://github.com/US-CBP', 'title': 'Dockerfile for contributors', 'bodyHTML': '<p>It would be lovely if someone could contribute a dockerfile so contributors could all have a consistent development environment to work with.</p>\\n', 'url': 'https://github.com/US-CBP/cbp-theme/issues/5', 'state': 'OPEN', 'createdAt': '2016-07-07T15:50:17Z', 'lastEditedAt': '2016-07-13T17:39:28Z', 'publishedAt': '2016-07-07T15:50:17Z', 'updatedAt': '2016-09-23T01:14:06Z', 'labels': ['0 - Backlog', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cbp-theme', 'repo_owner_name': 'U.S. Customs and Border Protection', 'repo_owner_email': '', 'repo_owner_user_name': 'US-CBP', 'repo_owner_profile_url': 'https://github.com/US-CBP', 'title': 'Improve Continuous Integration ', 'bodyHTML': '<p>As a developer, I would like to incorporate security checks, testing, code coverage, static analysis to the continuous integration process so that we can ensure higher quality of code.</p>\\n<p>We currently use Travis CI and want to enhance the build process so we need to research tools to:</p>\\n<ul>\\n<li>automate security vulnerabilities coming from code and dependencies</li>\\n<li>create acceptance tests</li>\\n<li>automate static code analysis</li>\\n</ul>\\n<p>See: <a href=\"https://github.com/integrations\">https://github.com/integrations</a></p>\\n', 'url': 'https://github.com/US-CBP/cbp-theme/issues/14', 'state': 'OPEN', 'createdAt': '2016-07-12T19:00:07Z', 'lastEditedAt': '2016-07-13T15:08:33Z', 'publishedAt': '2016-07-12T19:00:07Z', 'updatedAt': '2016-07-13T15:08:33Z', 'labels': ['1 - Ready', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cbp-theme', 'repo_owner_name': 'U.S. Customs and Border Protection', 'repo_owner_email': '', 'repo_owner_user_name': 'US-CBP', 'repo_owner_profile_url': 'https://github.com/US-CBP', 'title': 'Onboarding Process', 'bodyHTML': '<p>As a new contributor, I would like a simple way to get started with the project so that I can contribute quickly with minimal friction.</p>\\n<ul>\\n<li>Research ways to bring contributors on board with Git, Slack, and other methods to start on the project.  This could be a simple wiki to a chatbot, like this one:</li>\\n</ul>\\n<p><a href=\"https://18f.gsa.gov/2015/12/01/how-we-dramatically-improved-18fs-onboarding-process-in-3-months\" rel=\"nofollow\">18F Onboarding Process Blog</a></p>\\n', 'url': 'https://github.com/US-CBP/cbp-theme/issues/15', 'state': 'CLOSED', 'createdAt': '2016-07-12T19:03:36Z', 'lastEditedAt': '2016-07-13T15:11:25Z', 'publishedAt': '2016-07-12T19:03:36Z', 'updatedAt': '2016-11-30T03:13:48Z', 'labels': ['1 - Ready', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cbp-theme', 'repo_owner_name': 'U.S. Customs and Border Protection', 'repo_owner_email': '', 'repo_owner_user_name': 'US-CBP', 'repo_owner_profile_url': 'https://github.com/US-CBP', 'title': 'Host Kitchen Sink on Github Pages', 'bodyHTML': '<p>As a contributor, I would like to quickly see all the components so that I can quickly experiment, fix and improve the development loop and showcase components to other parties.</p>\\n<p>The current kitchen sink, the page with all the components, is currently hosted under app/kitchensink.  Ideally, we would host it on <a href=\"https://pages.github.com/\">Github Pages</a></p>\\n', 'url': 'https://github.com/US-CBP/cbp-theme/issues/16', 'state': 'CLOSED', 'createdAt': '2016-07-12T19:12:12Z', 'lastEditedAt': '2016-07-13T15:05:07Z', 'publishedAt': '2016-07-12T19:12:12Z', 'updatedAt': '2016-07-13T18:38:21Z', 'labels': ['2 - Working <= 5', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cbp-theme', 'repo_owner_name': 'U.S. Customs and Border Protection', 'repo_owner_email': '', 'repo_owner_user_name': 'US-CBP', 'repo_owner_profile_url': 'https://github.com/US-CBP', 'title': 'Create Open Source Guide', 'bodyHTML': '<p>As a developer, I would like resources that for open source CBP projects, so that we have a shared understanding of best practices and guidelines for creating and maintaining open source projects for CBP.</p>\\n<ul>\\n<li>Use <a href=\"https://pages.18f.gov/open-source-guide/\" rel=\"nofollow\">18F Open Source Guide</a> as a template</li>\\n</ul>', 'url': 'https://github.com/US-CBP/cbp-theme/issues/21', 'state': 'CLOSED', 'createdAt': '2016-07-19T17:39:52Z', 'lastEditedAt': None, 'publishedAt': '2016-07-19T17:39:52Z', 'updatedAt': '2016-10-13T03:31:16Z', 'labels': ['1 - Ready', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'raw_display prepends commas', 'bodyHTML': \"<p>surely there's a <code>join</code> i can use instead eh</p>\", 'url': 'https://github.com/18F/Sendak/issues/2', 'state': 'CLOSED', 'createdAt': '2014-09-29T17:49:27Z', 'lastEditedAt': None, 'publishedAt': '2014-09-29T17:49:27Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['bug', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'list-iam-groups', 'bodyHTML': '<p><a href=\"https://github.com/18F/Sendak/blob/master/bin/js/list-iam-groups.js\">this exists</a>, sort of; verify that it works and Does The Right Thing</p>', 'url': 'https://github.com/18F/Sendak/issues/5', 'state': 'CLOSED', 'createdAt': '2014-10-02T14:19:59Z', 'lastEditedAt': None, 'publishedAt': '2014-10-02T14:19:59Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'list-iam-policies task', 'bodyHTML': '<p><a href=\"https://github.com/18F/Sendak/blob/master/bin/js/list-iam-group-policies.js\"><code>list-iam-group-policies</code></a> probably needs to be renamed <code>list-iam-policies</code> and have a mandatory <code>--group</code> or <code>--user</code> flag. this makes the startup logic considerably more icky</p>', 'url': 'https://github.com/18F/Sendak/issues/6', 'state': 'OPEN', 'createdAt': '2014-10-02T14:25:56Z', 'lastEditedAt': None, 'publishedAt': '2014-10-02T14:25:56Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['help wanted', 'task'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Unit tests', 'bodyHTML': '<p>I absolutely positively refuse to have a milestone that is in any way phrased as \"this is working and safe for consumption\" without unit testing. The first milestone I have here, <a href=\"https://github.com/18F/Sendak/milestones/end-to-end%20sendak%20user%20creation\">user creation</a> is not really advertised as such; however, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a>\\'s <em>\"Milestone 1\"</em> will definitely constitute people looking at, and using, Sendak.</p>\\n<p>I would point out that \"unit tests\" in this case means that all the languages present will have unit tests for the code that lives in Sendak. This means python and js for now (and there are some tiny documents on how to unit test shell if we want to go there; I\\'ll decide that later).</p>', 'url': 'https://github.com/18F/Sendak/issues/10', 'state': 'OPEN', 'createdAt': '2014-10-06T23:44:40Z', 'lastEditedAt': None, 'publishedAt': '2014-10-06T23:44:40Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Datastore update', 'bodyHTML': '<p>Sendak needs to have a persistent database (the term is used loosely) so that users in different places can all access the data therein, and that modifications are available immediately to all users. The suggestions seem to be:</p>\\n<ul>\\n<li>something django something</li>\\n<li>redis or riak</li>\\n<li>mongo</li>\\n<li>postgres</li>\\n</ul>\\n<p>This should replace the ODORM stuff, but ODORM should still be available for testing (and accordingly, any updates to the data model that come from integration to \"the new datastore\" should include relevant updates to ODORM).</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=166734\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jackiekazil\">@jackiekazil</a> and I have a meeting to discuss on 7 Oct.</p>', 'url': 'https://github.com/18F/Sendak/issues/11', 'state': 'CLOSED', 'createdAt': '2014-10-07T00:34:38Z', 'lastEditedAt': None, 'publishedAt': '2014-10-07T00:34:38Z', 'updatedAt': '2014-10-27T13:04:43Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Document API for creating new \"tasks\"', 'bodyHTML': '<p>Ultimately all new tasks that are added to Sendak follow a particular model. <a href=\"https://github.com/18F/Sendak/blob/master/bin/README.md\">This is defined</a> but not in an especially friendly way. This documentation should lay out the design philosophy behind the approach of atomic tasks and dispatching shell commands, and include an example task in python, shell, and node. None of these should be longer than thirty lines and should \"do something\" (the <em>same</em> something) for purposes of illustration.</p>\\n<p>This documentation should comprise the first \"formal documentation\" for Sendak and should live in <code>docs</code> and be markdown. Because we love markdown.</p>\\n<p>NOTE: This is not the formal \"this is how you use Sendak\" documentation. At this point Sendak is very much a \"building the car while you\\'re driving it\" kind of project, and the technical details are much more important and immediately useful than narratives.</p>', 'url': 'https://github.com/18F/Sendak/issues/12', 'state': 'CLOSED', 'createdAt': '2014-10-07T00:54:11Z', 'lastEditedAt': None, 'publishedAt': '2014-10-07T00:54:11Z', 'updatedAt': '2015-02-09T03:42:07Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '\"So you\\'re new to AWS at 18F\" document', 'bodyHTML': '<p>This document should be part of the onboarding process but since Sendak is driving its requirements, it makes sense for it to be here for now. This document, markdown, should enumerate the things a user needs to do from \"just has an iam login\" to \"can actually do a thing\" within our AWS environment.</p>\\n<p>It should be written so that a person who is new to AWS can understand it. It should <em>not</em> include code, use things in backticks, et cetera. It <em>should</em> include images to explain where in the Amazon console these things are (because they are infuriatingly difficult to find).</p>\\n<p>I feel like someone who is better at documentation than Jane should write this.</p>', 'url': 'https://github.com/18F/Sendak/issues/14', 'state': 'CLOSED', 'createdAt': '2014-10-07T01:09:48Z', 'lastEditedAt': None, 'publishedAt': '2014-10-07T01:09:48Z', 'updatedAt': '2015-01-23T18:35:26Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'python shell dispatch library', 'bodyHTML': '<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"44692508\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/Sendak/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/Sendak/issues/7/hovercard\" href=\"https://github.com/18F/Sendak/issues/7\">#7</a>; this should be exactly that, only in the pythons.</p>', 'url': 'https://github.com/18F/Sendak/issues/15', 'state': 'CLOSED', 'createdAt': '2014-10-07T01:11:08Z', 'lastEditedAt': None, 'publishedAt': '2014-10-07T01:11:08Z', 'updatedAt': '2014-12-29T03:17:08Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Requisite policies for M2', 'bodyHTML': '<p>See <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a>\\'s <a href=\"https://github.com/18F/DevOps/blob/master/aws-iam/conf/vpc_restricted_group.template\">previous work</a> on same.</p>', 'url': 'https://github.com/18F/Sendak/issues/16', 'state': 'OPEN', 'createdAt': '2014-10-07T15:53:17Z', 'lastEditedAt': None, 'publishedAt': '2014-10-07T15:53:17Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'The grownup Sendak datastore', 'bodyHTML': '<p>The period of <a href=\"https://github.com/18F/Sendak/blob/master/components/odorm/odorm.js\">odorm</a> being useful has mostly ended. The original purpose of that code was to create something that would allow for persistence, and provide api hooks so that subsequently, it could be forklifted away and a proper datathing could be put in its place.</p>\\n<p>Suggestions so far are:</p>\\n<ul>\\n<li>mongodb</li>\\n<li>riak, redis, etc</li>\\n<li>something django something</li>\\n<li>postgres</li>\\n</ul>\\n<p>these all have pluses and minuses.</p>\\n<p>The API to the store should not break the current datastore api, so the calls:</p>\\n<ul>\\n<li><code>update-object</code></li>\\n<li><code>add-object</code></li>\\n<li><code>del-object</code></li>\\n<li><code>new-object</code></li>\\n<li><code>object-types</code></li>\\n<li><code>get-datastore</code></li>\\n<li><code>write-data</code> (or <code>sync</code> or whichever)</li>\\n</ul>\\n<p>should all be supported in the new backend for Sendak storage.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=166734\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jackiekazil\">@jackiekazil</a> and I are discussing how this will look.</p>', 'url': 'https://github.com/18F/Sendak/issues/20', 'state': 'CLOSED', 'createdAt': '2014-10-07T16:09:34Z', 'lastEditedAt': None, 'publishedAt': '2014-10-07T16:09:34Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'containerised/deployable riak', 'bodyHTML': \"<p>there's a project that has a dockerised riak that might work. but we need to be able to magically deploy a riak somewhere. this might leave us with</p>\\n<ul>\\n<li>sendak-data</li>\\n<li>sendak-bin</li>\\n</ul>\\n<p>as two separate repositories. maybe. have to think on that.</p>\", 'url': 'https://github.com/18F/Sendak/issues/23', 'state': 'CLOSED', 'createdAt': '2014-10-09T19:58:39Z', 'lastEditedAt': None, 'publishedAt': '2014-10-09T19:58:39Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update sendak install doc', 'bodyHTML': \"<p>The README has:</p>\\n<pre><code>On a Mac, this is `brew install awscli`. On Ubuntu, you will want `apt-get install awscli`.\\n</code></pre>\\n<p><code>pip install aws</code> will likely net you a newer version, and is OS-agnostic. But I don't want to blindly update the docs unless @avriette has tested this configuration.</p>\", 'url': 'https://github.com/18F/Sendak/issues/27', 'state': 'CLOSED', 'createdAt': '2014-10-24T16:17:32Z', 'lastEditedAt': None, 'publishedAt': '2014-10-24T16:17:32Z', 'updatedAt': '2014-11-05T03:35:51Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'discuss indexing (Solr) in riak backend vs doing lifting in frontend', 'bodyHTML': '<p>Riak lets us search a couple ways. One is it gives us <a href=\"http://docs.basho.com/riak/latest/dev/using/keyfilters/\" rel=\"nofollow\">key filters</a>, which are okay if your keys are named sensibly. I haven\\'t been doing this because I expect the ontology (or even the data store) to change week-to-week, and we don\\'t have a whole heap of data. The other way to do this is with mapping the data objects with a schema that <a href=\"http://docs.basho.com/riak/latest/dev/using/search/\" rel=\"nofollow\">Solr peruses</a>. This requires, however, coming up with a schema, and maintaining same.</p>\\n<p>The tradeoff is, write a schema, maintain the Solr configuration in Riak, or just have a <code>grep</code>-alike in the Sendak layer that does all this? Given we are talking about, at most, hundreds of keys, it seems harmless to just do it outside the database.</p>', 'url': 'https://github.com/18F/Sendak/issues/32', 'state': 'CLOSED', 'createdAt': '2014-10-29T12:08:27Z', 'lastEditedAt': None, 'publishedAt': '2014-10-29T12:08:27Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add verbosity & logging', 'bodyHTML': '<p>I\\'m really tired of adding/removing <code>console.log</code> lines. I think this is probably going to wind up being <a href=\"https://github.com/nomiddlename/log4js-node\">log4js</a>.</p>', 'url': 'https://github.com/18F/Sendak/issues/33', 'state': 'CLOSED', 'createdAt': '2014-11-03T20:43:22Z', 'lastEditedAt': None, 'publishedAt': '2014-11-03T20:43:22Z', 'updatedAt': '2015-04-18T02:06:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'convert contributed schema to json', 'bodyHTML': '<p>The contributed <a href=\"https://github.com/avriette/rrm\">rrm</a> <a href=\"https://github.com/18F/Sendak/blob/master/contrib/sendak_rrm_schema.json\">schema</a> needs to be converted to json.</p>', 'url': 'https://github.com/18F/Sendak/issues/35', 'state': 'CLOSED', 'createdAt': '2014-11-05T18:59:05Z', 'lastEditedAt': None, 'publishedAt': '2014-11-05T18:59:05Z', 'updatedAt': '2015-01-01T21:51:35Z', 'labels': ['bug', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '--help display concatenating first two fields', 'bodyHTML': '<p>running <code>sendak task-name --help</code> results in concatenated columns, which is hard to read:</p>\\n<pre><code>fetch:sendak-deployable jane$ sendak list-sendak-users --help\\nUsage: \\n    --usernameSpecify an expression to match against username               \\n    --arnSpecify an expression to match against the arn                \\n    --amznidSpecify an expression to match against the amznid             \\n</code></pre>\\n<p>I\\'ve <a href=\"https://github.com/zaach/nopt-usage/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/zaach/nopt-usage/issues/2/hovercard\">opened an issue</a> but there\\'s no traction.</p>', 'url': 'https://github.com/18F/Sendak/issues/36', 'state': 'CLOSED', 'createdAt': '2014-11-08T19:22:29Z', 'lastEditedAt': None, 'publishedAt': '2014-11-08T19:22:29Z', 'updatedAt': '2014-11-22T21:52:28Z', 'labels': ['bug', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'command-line parser abstraction', 'bodyHTML': '<p>There is a ton of code at the top of all the node tasks that is repeated. A simple hash should be created:</p>\\n<pre><code>var parsed = require( \\'sendak-usage\\' ).parse( {\\n  help: {\\n    \\'long-args\\': [ \\'help\\', \\'halp\\' ],\\n    \\'description\\': \\'sets the helpful bit\\',\\n    \\'short-args\\': [ \\'h\\' ],\\n    \\'default\\': false\\n    \\'type\\': [ Boolean ]\\n  }\\n} );\\n</code></pre>\\n<p>this could then be backended on <code>nopt</code> or <code>minimist</code> (per <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4592\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/konklone\">@konklone</a>). But it\\'s equally readable and reduces code duplication and allows forklift changes with minimal code disruption.</p>', 'url': 'https://github.com/18F/Sendak/issues/38', 'state': 'CLOSED', 'createdAt': '2014-11-12T15:27:27Z', 'lastEditedAt': None, 'publishedAt': '2014-11-12T15:27:27Z', 'updatedAt': '2014-11-19T14:12:25Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'basic healthcheck to all tasks', 'bodyHTML': '<p>Right now we get an ugly stack trace if there\\'s no Riak:</p>\\n<pre><code>fetch:sendak jane$ sendak build-node --instance-type m3.medium --ami-id ami-2eee5d46\\nfetching schema for new_object\\nEncountered empty schema, pulling fresh copy\\n\\n/Users/jane/dev/sendak/node_modules/aws-sdk/lib/request.js:32\\n          throw err;\\n                ^\\nTypeError: Cannot call method \\'then\\' of undefined\\n    at /Users/jane/dev/sendak/bin/js/build-node.js:245:39\\n    at Response.&lt;anonymous&gt; (/Users/jane/dev/sendak/bin/js/build-node.js:195:8)\\n    at Request.&lt;anonymous&gt; (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/request.js:350:18)\\n    at Request.callListeners (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/sequential_executor.js:100:18)\\n    at Request.emit (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/sequential_executor.js:77:10)\\n    at Request.emit (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/request.js:604:14)\\n    at Request.transition (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/request.js:21:12)\\n    at AcceptorStateMachine.runTo (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/state_machine.js:14:12)\\n    at /Users/jane/dev/sendak/node_modules/aws-sdk/lib/state_machine.js:26:10\\n    at Request.&lt;anonymous&gt; (/Users/jane/dev/sendak/node_modules/aws-sdk/lib/request.js:22:9)\\nfetch:sendak jane$\\n</code></pre>\\n<p>Since <code>riak-dc</code> has <a href=\"https://github.com/avriette/riak-dc/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/janearc/riak-dc/issues/7/hovercard\">ping</a> now, it should be trivial to include some basic environment sanity checks in each of the (javascript) tasks. For starters:</p>\\n<ul>\\n<li>does my node environment look ok? (what does this mean?)</li>\\n<li>do i have a riak?</li>\\n<li>does amazon trust my credentials? (something like aws iam ping or whatever)</li>\\n</ul>\\n<p>And of course, once this is done, it should be fairly trivial to have a <code>sendak init</code> that sets this stuff up. Frankly it should have it today.</p>', 'url': 'https://github.com/18F/Sendak/issues/43', 'state': 'CLOSED', 'createdAt': '2014-11-22T21:48:14Z', 'lastEditedAt': None, 'publishedAt': '2014-11-22T21:48:14Z', 'updatedAt': '2014-11-29T22:55:20Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'strictures', 'bodyHTML': '<p>I would prefer Sendak used strictures. (<code>\"use strict\";</code>)</p>', 'url': 'https://github.com/18F/Sendak/issues/46', 'state': 'CLOSED', 'createdAt': '2014-11-25T14:00:09Z', 'lastEditedAt': None, 'publishedAt': '2014-11-25T14:00:09Z', 'updatedAt': '2015-01-01T21:50:34Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'check-github-user task', 'bodyHTML': '<p>An issue is open in <a href=\"https://github.com/mikedeboer/node-github/issues/211\" data-hovercard-type=\"issue\" data-hovercard-url=\"/octokit/rest.js/issues/211/hovercard\">node-github</a> in re the api hook \"not working.\"</p>\\n<p>When that\\'s resolved, pull that code into sendak.</p>', 'url': 'https://github.com/18F/Sendak/issues/47', 'state': 'OPEN', 'createdAt': '2014-11-26T13:36:08Z', 'lastEditedAt': None, 'publishedAt': '2014-11-26T13:36:08Z', 'updatedAt': '2015-01-23T19:28:08Z', 'labels': ['help wanted', 'task'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'local, per-user configuration (\"dotfiles\")', 'bodyHTML': \"<p>templates for nodes.</p>\\n<pre><code>{\\n  'sendak-db': { 'instance-type': 'm3.medium', 'ssh-key': 'jane-fetch-aws-root' }\\n}\\n</code></pre>\\n<p>allowing me to say</p>\\n<p><code>sendak build-node --template sendak-db</code></p>\\n<p>it's worth mentioning that this is a step in the right direction of sendakified containers.</p>\", 'url': 'https://github.com/18F/Sendak/issues/51', 'state': 'OPEN', 'createdAt': '2014-11-28T19:29:34Z', 'lastEditedAt': None, 'publishedAt': '2014-11-28T19:29:34Z', 'updatedAt': '2015-01-22T18:01:58Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'newlines. newlines, everywhere.', 'bodyHTML': '<pre><code>fetch:sendak jane$ sendak check-environment --riak --github\\nCheck [github] seems superficially healthy.\\n\\nCheck [riak] seems superficially healthy.\\n\\nchild process exited \\nfetch:sendak jane$ \\n</code></pre>\\n<p>where on earth are these extra newlines coming from?</p>', 'url': 'https://github.com/18F/Sendak/issues/52', 'state': 'CLOSED', 'createdAt': '2014-11-29T22:33:59Z', 'lastEditedAt': None, 'publishedAt': '2014-11-29T22:33:59Z', 'updatedAt': '2015-02-09T03:42:37Z', 'labels': ['bug', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'remove en64/de64 & replace with js', 'bodyHTML': '<p>the en64/de64 thing was just a bad idea. replace with js to leverage sendak-usage among other things.</p>', 'url': 'https://github.com/18F/Sendak/issues/56', 'state': 'CLOSED', 'createdAt': '2014-12-01T16:47:32Z', 'lastEditedAt': None, 'publishedAt': '2014-12-01T16:47:32Z', 'updatedAt': '2014-12-02T17:14:36Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'ping() method should be rrm, not riak', 'bodyHTML': '<p>swap the <code>riak.ping()</code> healthcheck for <code>rrm.ping()</code> (see <a href=\"https://github.com/avriette/rrm/commit/69ddea943beb8a1dbdd37a58bbc011ed316dbbf9\">this commit</a>)</p>', 'url': 'https://github.com/18F/Sendak/issues/59', 'state': 'CLOSED', 'createdAt': '2014-12-03T14:51:57Z', 'lastEditedAt': None, 'publishedAt': '2014-12-03T14:51:57Z', 'updatedAt': '2014-12-09T20:10:33Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'check-environment rm test is not helpful', 'bodyHTML': '<p><code>sendak check-environment --rrm</code> is <a href=\"https://github.com/18F/Sendak/blob/master/bin/js/check-environment.js#L106\">not real useful</a>. basically at the moment it verifies that the library can be used and a cached schema (which actually is <code>{ defined: false }</code>, and not a Real Schema) is returned. the proper way to do this is to do a <code>get_schema()</code> and verify that there is at least one object type. <a href=\"https://github.com/janearc/rrm/blob/master/lib/rrm.js#L274\">there\\'s code inside rrm</a> to strip out the stuff that\\'s not really schema-like, but i would prefer to not expose that through the api.</p>', 'url': 'https://github.com/18F/Sendak/issues/61', 'state': 'OPEN', 'createdAt': '2014-12-29T14:02:33Z', 'lastEditedAt': None, 'publishedAt': '2014-12-29T14:02:33Z', 'updatedAt': '2015-03-18T12:40:10Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Tab completion for sendak commands', 'bodyHTML': \"<p>For someone, somewhere: I have no idea how custom bash tab completion works, but I know it's a life saver for <code>git</code> and <code>gpg</code> and all sorts of things. It would help <code>sendak</code> too.</p>\", 'url': 'https://github.com/18F/Sendak/issues/65', 'state': 'OPEN', 'createdAt': '2014-12-31T03:15:13Z', 'lastEditedAt': None, 'publishedAt': '2014-12-31T03:15:13Z', 'updatedAt': '2015-01-01T23:17:38Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'rm-sendak-user task', 'bodyHTML': '<p>need to be able to remove sendak users</p>', 'url': 'https://github.com/18F/Sendak/issues/75', 'state': 'OPEN', 'createdAt': '2015-01-07T04:29:47Z', 'lastEditedAt': None, 'publishedAt': '2015-01-07T04:29:47Z', 'updatedAt': '2015-02-02T05:08:12Z', 'labels': ['enhancement', 'help wanted', 'task'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'AWS \"Name\" field lexer', 'bodyHTML': '<p>A function to parse the AWS \"name\" field as described by Noah is required because we will be launching instances.</p>', 'url': 'https://github.com/18F/Sendak/issues/85', 'state': 'OPEN', 'createdAt': '2015-01-23T17:36:03Z', 'lastEditedAt': None, 'publishedAt': '2015-01-23T17:36:03Z', 'updatedAt': '2015-02-25T13:12:14Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'Sendak', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'list-sendak-nodes promises', 'bodyHTML': '<p>the (post-plugsuit) <code>list-sendak-nodes</code> task does not properly wait for the promise (rather, the return from rrm) to display data.</p>', 'url': 'https://github.com/18F/Sendak/issues/93', 'state': 'OPEN', 'createdAt': '2015-02-06T18:32:06Z', 'lastEditedAt': None, 'publishedAt': '2015-02-06T18:32:06Z', 'updatedAt': '2015-02-25T13:37:33Z', 'labels': ['bug', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'stylelint-rules', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Feature request: lint order of properties', 'bodyHTML': '<p>Our front end guide specifies that property value pairs must be alphabetically ordered as so:</p>\\n<div class=\"highlight highlight-source-css\"><pre>background: black;\\ncolor: white;\\nmargin: 1px;\\npadding: 2px;</pre></div>\\n<p>It would be cool if stylelint could check this.</p>', 'url': 'https://github.com/18F/stylelint-rules/issues/17', 'state': 'OPEN', 'createdAt': '2016-06-09T00:16:39Z', 'lastEditedAt': None, 'publishedAt': '2016-06-09T00:16:39Z', 'updatedAt': '2016-09-16T16:36:36Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'stylelint-rules', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'The \"ignore\" option is ignored', 'bodyHTML': '<p>I\\'ve got a gulp config that does this:</p>\\n<div class=\"highlight highlight-source-js\"><pre><span class=\"pl-k\">const</span> <span class=\"pl-c1\">stylelint</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">require</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>@18f/stylelint-rules<span class=\"pl-pds\">\\'</span></span>);\\n\\n<span class=\"pl-smi\">gulp</span>.<span class=\"pl-en\">task</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>stylelint<span class=\"pl-pds\">\\'</span></span>, <span class=\"pl-en\">stylelint</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>src/stylesheets/**/*.css<span class=\"pl-pds\">\\'</span></span>, {\\n  ignore<span class=\"pl-k\">:</span> <span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>src/stylesheets/lib/**/*.scss<span class=\"pl-pds\">\\'</span></span>\\n});</pre></div>\\n<p>And none of the files matching the <code>ignore</code> glob are being ignored. I wonder if this has something to do with the note <a href=\"http://stylelint.io/user-guide/configuration/#ignorefiles\" rel=\"nofollow\">in the docs</a> that says:</p>\\n<blockquote>\\n<p>The <code>ignoreFiles</code> property is stripped from extended configs: only the root-level config can ignore files.</p>\\n</blockquote>', 'url': 'https://github.com/18F/stylelint-rules/issues/25', 'state': 'CLOSED', 'createdAt': '2016-08-24T23:15:35Z', 'lastEditedAt': None, 'publishedAt': '2016-08-24T23:15:35Z', 'updatedAt': '2018-08-20T21:20:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cbp-style-guide', 'repo_owner_name': 'U.S. Customs and Border Protection', 'repo_owner_email': '', 'repo_owner_user_name': 'US-CBP', 'repo_owner_profile_url': 'https://github.com/US-CBP', 'title': 'Calibri Font Example Not Showing In Correct Font', 'bodyHTML': '<p>The Calibri Font in the Typography section of the Style Guide is showing a serif font example in a font other than Calibri.</p>\\n<p>What I am seeing in Chrome and Safari on our CBP Style Guide <a href=\"https://us-cbp.github.io/cbp-style-guide/docs/foundation/typography.html\" rel=\"nofollow\">Typography section</a> -<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/11233429/41248367-d4d17e00-6d7e-11e8-9345-dfff78a26b0b.png\"><img src=\"https://user-images.githubusercontent.com/11233429/41248367-d4d17e00-6d7e-11e8-9345-dfff78a26b0b.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Here is what the <a href=\"https://exchangepedia.com/2006/03/calibri-a-new-font-from-windows-vista.html\" rel=\"nofollow\">Calibri font</a> looks like -<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/11233429/41248429-0d9251a6-6d7f-11e8-8de2-2192e9609148.png\"><img src=\"https://user-images.githubusercontent.com/11233429/41248429-0d9251a6-6d7f-11e8-8de2-2192e9609148.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/US-CBP/cbp-style-guide/issues/81', 'state': 'CLOSED', 'createdAt': '2018-06-11T17:57:38Z', 'lastEditedAt': None, 'publishedAt': '2018-06-11T17:57:38Z', 'updatedAt': '2018-08-30T18:24:52Z', 'labels': ['bug', 'design', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: QoS support with global policy', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=41\" rel=\"nofollow\">issue 41</a> created by djfritz on 2014-05-07T15:55:51.000Z:</p>\\n<p>A vm_qos or similar command is needed to wrap quality of service capabilities on interfaces for VMs. Right now the thinking is that we should use \\'tc\\' or a similar infrastructure to add latency and other QoS metrics. The format of vm_qos will match 1:1 with interfaces listed in vm_net.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/41', 'state': 'CLOSED', 'createdAt': '2015-03-12T20:08:28Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T20:08:28Z', 'updatedAt': '2016-07-23T16:46:33Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minicli: Tab completion', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=88\" rel=\"nofollow\">issue 88</a> created by djfritz on 2015-01-29T00:48:27.000Z:</p>\\n<p>Support tab completion in minicli.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/88', 'state': 'CLOSED', 'createdAt': '2015-03-12T20:55:53Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T20:55:53Z', 'updatedAt': '2015-07-10T20:39:08Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: reserved words', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=111\" rel=\"nofollow\">issue 111</a> created by djfritz on 2015-02-04T22:44:42.000Z:</p>\\n<p>Users shouldn\\'t be able to name vms/taps/bridges/... using reserved words. Currently, the only reserved word is \"all\" which is used for wildcards.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/111', 'state': 'CLOSED', 'createdAt': '2015-03-12T21:01:41Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T21:01:41Z', 'updatedAt': '2015-04-04T00:50:33Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'rfbplay: support auto-transcoding with ffmpeg runtime dependency', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=120\" rel=\"nofollow\">issue 120</a> created by djfritz on 2015-02-13T20:49:14.000Z:</p>\\n<p>support a one liner production to transcode an rfb file to mp4 with ffmpeg.</p>\\n<p>Something like:</p>\\n<p>rfbplay -transcode foo.fb out.mp4</p>\\n<p>Which would start the local webserver according to other flags and invoke ffmpeg with something like:</p>\\n<p>ffmpeg -f mjpeg -r 10 -i <a href=\"http://localhost:9004/foo.fb\" rel=\"nofollow\">http://localhost:9004/foo.fb</a> out.mp4</p>\\n<p>Then quit.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/120', 'state': 'CLOSED', 'createdAt': '2015-03-12T21:42:20Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T21:42:20Z', 'updatedAt': '2015-05-11T23:54:46Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'unit tests', 'bodyHTML': '<p>There are glaring omissions in our unit tests. This needs significant investment. Some things cannot be tested well with the available unit test framework in Go, so there is another ticket for runtime testing. For things that can be well tested though, we need a lot of help.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/141', 'state': 'CLOSED', 'createdAt': '2015-03-25T15:34:24Z', 'lastEditedAt': None, 'publishedAt': '2015-03-25T15:34:24Z', 'updatedAt': '2015-07-13T20:53:45Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'runtime test framework', 'bodyHTML': \"<p>A number of components in minimega cannot be tested with Go's unit test framework, in particular interactions with qemu/qmp, etc. We need a runtime test harness to run on a small cluster. The framework can be fairly simple - support some language and minimega scripts for runtime tests, and support some sort of success assertion.</p>\\n<p>Beyond that, we need to write the runtime tests we know we'll need, and scope a development practice in the 'contributing.article' for adding new tests.</p>\\n<p>Good intern project.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/142', 'state': 'CLOSED', 'createdAt': '2015-03-25T15:39:06Z', 'lastEditedAt': None, 'publishedAt': '2015-03-25T15:39:06Z', 'updatedAt': '2015-07-20T16:22:21Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'add vm serial or equivalent API', 'bodyHTML': '<p>This appears to be started in branch serial.</p>\\n<p>We need to support a variable number of legacy-isa and virtio-serial serial ports for each VM.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/180', 'state': 'CLOSED', 'createdAt': '2015-04-17T22:40:15Z', 'lastEditedAt': None, 'publishedAt': '2015-04-17T22:40:15Z', 'updatedAt': '2015-05-28T17:28:48Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'Feature request: vm reset', 'bodyHTML': \"<p>Not sure if this ever got done...or put as a feature request...</p>\\n<p>'vm reset vm-0'<br>\\n-would take vm-0 back to original state from which it was started<br>\\n-essentially grouping 'vm kill vm-0;vm start vm-0'.<br>\\n-would be useful on multiple vm's to be reset at once.  i.e. to put an environment back to a freshly booted environment for training.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/185', 'state': 'CLOSED', 'createdAt': '2015-04-28T18:01:50Z', 'lastEditedAt': None, 'publishedAt': '2015-04-28T18:01:50Z', 'updatedAt': '2015-05-08T18:00:48Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: at least one dangling kvm process on entering VM_ERROR state', 'bodyHTML': \"<p>If you hit the race:</p>\\n<p>vm launch foo noblock<br>\\nvm start foo</p>\\n<p>And get the VM into the error state with the 'qmp not ready' error, you'll notice that qemu for that VM is still running, because vm.start() didn't kill the process after putting it in the error state. Later, vm kill won't attempt to kill it because it's in the error state.</p>\\n<p>At least two things could happen here instead:</p>\\n<ul>\\n<li>Attempt to reissue commands on error VMs that aren't actually dead - like 'vm start'. That would require some more book keeping</li>\\n<li>Always kill VMs when they enter the error state</li>\\n</ul>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/209', 'state': 'CLOSED', 'createdAt': '2015-05-18T17:02:45Z', 'lastEditedAt': None, 'publishedAt': '2015-05-18T17:02:45Z', 'updatedAt': '2015-08-12T20:45:58Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniccc: vm tag hooks', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>\\n<p>Want to start thinking about what capabilities folks want in a <code>vm tag</code> hook into miniccc. What I mean by this is to provide some way to have miniccc set a key/value for the vm it represents on an event (specific file create, memory usage over threshold), or something else entirely. I\\'m not sure what the best approach here is.</p>\\n<p>What I\\'d like to have eventually is some robust, generic, API for setting some event, having miniccc wait for that event to happen, and signal back. For things like \"memory over threshold\", it would be even cooler if we could do things on a scale - \"0-10%: set mem:low, ... 90-100%: set mem:critical\"</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/218', 'state': 'CLOSED', 'createdAt': '2015-05-26T20:57:48Z', 'lastEditedAt': None, 'publishedAt': '2015-05-26T20:57:48Z', 'updatedAt': '2015-09-21T14:48:03Z', 'labels': ['duplicate', 'enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'misc: create \"validMAC(mac string) bool\" for valid/allocated mac addresses', 'bodyHTML': '<p>See <a href=\"https://github.com/google/gopacket/tree/master/macs\">https://github.com/google/gopacket/tree/master/macs</a></p>\\n<p>We need to only auto-generate macs that have valid allocations. Using reserved macs can have interesting results on external tools such as wireshark.</p>\\n<p>Need this soon.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11760828\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jericks-sandia\">@jericks-sandia</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2590210\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/devinc\">@devinc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/231', 'state': 'CLOSED', 'createdAt': '2015-06-08T17:50:04Z', 'lastEditedAt': None, 'publishedAt': '2015-06-08T17:50:04Z', 'updatedAt': '2015-06-23T23:10:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'documentation: write vyatta article', 'bodyHTML': '<p>See summary.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/268', 'state': 'CLOSED', 'createdAt': '2015-07-31T20:50:03Z', 'lastEditedAt': None, 'publishedAt': '2015-07-31T20:50:03Z', 'updatedAt': '2015-08-17T14:41:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: add static configuration support to dnsmasq and vyatta APIs', 'bodyHTML': '<p>See summary. Add support for specifying static IPs, etc. referenced by MAC, VM, etc. on future dnsmasq and already running dnsmasq instances.</p>\\n<p>Example:</p>\\n<pre><code>dnsmasq static vm &lt;vm id&gt; &lt;ipv4 address/subnet&gt;\\n</code></pre>', 'url': 'https://github.com/sandia-minimega/minimega/issues/279', 'state': 'CLOSED', 'createdAt': '2015-08-18T14:19:23Z', 'lastEditedAt': None, 'publishedAt': '2015-08-18T14:19:23Z', 'updatedAt': '2016-06-08T20:10:51Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: rewrite web graph to show full detail', 'bodyHTML': '<p>See summary. The graph view in the web interface should render all endpoints instead of the VLAN view.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/292', 'state': 'CLOSED', 'createdAt': '2015-08-24T15:25:51Z', 'lastEditedAt': None, 'publishedAt': '2015-08-24T15:25:51Z', 'updatedAt': '2016-10-10T17:45:17Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'ron/miniccc: add event/action capabilities', 'bodyHTML': '<p>miniccc should be programmable so that we can respond to events such as \"memory threshold 80%\", and <code>vm tag</code> actions such as \"color node red\".</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/294', 'state': 'CLOSED', 'createdAt': '2015-08-24T15:31:26Z', 'lastEditedAt': None, 'publishedAt': '2015-08-24T15:31:26Z', 'updatedAt': '2016-07-23T16:46:55Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: refactor bridge code', 'bodyHTML': '<p>The bridge code is some of the oldest in the tree and desperately needs a rewrite.</p>\\n<p>This has already begun at: <a href=\"https://github.com/jcrussell/minimega/tree/bridge\">https://github.com/jcrussell/minimega/tree/bridge</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/303', 'state': 'CLOSED', 'createdAt': '2015-09-01T15:41:37Z', 'lastEditedAt': None, 'publishedAt': '2015-09-01T15:41:37Z', 'updatedAt': '2015-09-28T22:30:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: add web components for cc interface', 'bodyHTML': '<p>See summary. We\\'re not entirely sure what all this should include yet. Please discuss.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3037396\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jfktrey\">@jfktrey</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11760828\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jericks-sandia\">@jericks-sandia</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/306', 'state': 'CLOSED', 'createdAt': '2015-09-01T19:24:36Z', 'lastEditedAt': None, 'publishedAt': '2015-09-01T19:24:36Z', 'updatedAt': '2016-06-08T20:11:34Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: mouse/keyboard over cc?', 'bodyHTML': '<p>Wondering how this could be implemented. Thoughts? This would need to support at least linux and windows.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2590210\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/devinc\">@devinc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/308', 'state': 'CLOSED', 'createdAt': '2015-09-01T19:26:29Z', 'lastEditedAt': None, 'publishedAt': '2015-09-01T19:26:29Z', 'updatedAt': '2015-09-21T14:51:12Z', 'labels': ['help wanted', 'question', 'wontfix'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'Update mac address in docs', 'bodyHTML': '<p>When you set mac addresses via minimega, it doesn\\'t warn that the mac address you are trying to use may not be usable by your os driver.</p>\\n<p>It just forces it and you will have no idea why it can\\'t get a dhcp lease. I was using 00:00:00:00:00:01, rookie mistake I know and it wouldn\\'t receive a dhcp lease, changing the mac address fixed it. Recently I was at a hotel and I connected via wifi. I wanted to not pay for wifi again so I tried to spoof the address onto my ethernet adapter, and it would refuse to set. Changing the ending number by one would let it set, but not connect. Lesson learned there are certain addresses where the operating system driver just says no.</p>\\n<p>We don\\'t have to warn users per se, but we should update the docs to use mac addresses that will likely work.<br>\\n\"vm config net 100,00:00:00:00:00:00 101,00:00:00:00:01:00 102,00:00:00:00:02:00\"<br>\\nWill likely not work depending on your os ethernet driver and dns server.</p>\\n<p>\"vm config net bridge0,100,00:11:22:33:44:55\" will likely cause issues too</p>\\n<p>Windows ethernet drivers tends to be more sensitive to their address. From what I read here Locally administered mac addresses start with x2, x6, xA, xE and multicast addresses of x3,x7,xF. So anything in those ranges are generally safe. <a href=\"http://serverfault.com/questions/40712/what-range-of-mac-addresses-can-i-safely-use-for-my-virtual-machines\" rel=\"nofollow\">http://serverfault.com/questions/40712/what-range-of-mac-addresses-can-i-safely-use-for-my-virtual-machines</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/322', 'state': 'CLOSED', 'createdAt': '2015-10-01T18:42:47Z', 'lastEditedAt': None, 'publishedAt': '2015-10-01T18:42:47Z', 'updatedAt': '2015-10-01T21:51:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: vnc port collisions ', 'bodyHTML': '<p>When launching VMs, if a network tap already exists that we want to allocate for a VM, we increment the tap name (mega_tapX) and try again until we find a tap name that isn\\'t in use.</p>\\n<p>We have a similar issue with the VNC port we ask qemu to use. By default we tell qemu to use 5900+. If a port happens to be in use (not uncommon for VNC), then we just mark the VM in the error state and give up. We should instead do something similar to the tap solution.</p>\\n<p>The best solution would be to check if the port is in use first (/proc/net/tcp and friends show this) and decouple the port&lt;-&gt;id map. Another solution would be to have qemu pick the port and then ask qemu what port it used (via qmp, a quick look doesn\\'t look like qemu has a qmp interface for this yet).</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/342', 'state': 'CLOSED', 'createdAt': '2015-10-22T22:00:26Z', 'lastEditedAt': None, 'publishedAt': '2015-10-22T22:00:26Z', 'updatedAt': '2016-08-03T21:13:41Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'container based router', 'bodyHTML': '<p>We need a fully opensource container router image that takes one or more configs for deployment. If we get something solid, we\\'ll tease out an API for it and replace the \\'vyatta\\' API with this.</p>\\n<p>I\\'d like:</p>\\n<ul>\\n<li>routing (ospf, ospf3, bgp, static)</li>\\n<li>dhcp with static ip options</li>\\n<li>optional static ips for all interfaces</li>\\n<li>dns</li>\\n<li>full ipv6 support everywhere</li>\\n<li>RAD/slaac support for v6</li>\\n<li>firewall (just iptables is fine)</li>\\n<li>snmp would be neat to have</li>\\n<li>centralized logging</li>\\n<li>some agent for making changes perhaps instead of a direct configs for all of the tools</li>\\n</ul>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a> thoughts?</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/344', 'state': 'CLOSED', 'createdAt': '2015-10-29T16:04:48Z', 'lastEditedAt': None, 'publishedAt': '2015-10-29T16:04:48Z', 'updatedAt': '2016-07-19T17:12:34Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'doc: update CC tutorial', 'bodyHTML': '<p>The <a href=\"http://minimega.org/articles/tutorials/cc.article\" rel=\"nofollow\">cc tutorial</a> is a bit out of date (e.g. cc is on by default now). Should update article accordingly.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/408', 'state': 'CLOSED', 'createdAt': '2016-01-22T18:34:15Z', 'lastEditedAt': None, 'publishedAt': '2016-01-22T18:34:15Z', 'updatedAt': '2016-03-21T23:04:26Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'web: make namespace-aware', 'bodyHTML': '<p>Should be able to have a dropdown in the page that allows you to select a namespace. Should then only see the hosts and VMs that belong to that namespace.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/474', 'state': 'CLOSED', 'createdAt': '2016-03-25T18:44:01Z', 'lastEditedAt': None, 'publishedAt': '2016-03-25T18:44:01Z', 'updatedAt': '2016-10-10T17:45:06Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'Web ui crashes chrome windows x64', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5001991/15159265/24717b44-16b1-11e6-917e-587cbe2d7b27.PNG\"><img src=\"https://cloud.githubusercontent.com/assets/5001991/15159265/24717b44-16b1-11e6-917e-587cbe2d7b27.PNG\" alt=\"chrome error\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/524', 'state': 'CLOSED', 'createdAt': '2016-05-10T19:14:40Z', 'lastEditedAt': None, 'publishedAt': '2016-05-10T19:14:40Z', 'updatedAt': '2016-10-10T17:44:48Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: `disk partition` API', 'bodyHTML': \"<p>Add API to partition disks. Rewrite disk tests so that we don't shell out to parted.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/534', 'state': 'CLOSED', 'createdAt': '2016-05-13T20:20:23Z', 'lastEditedAt': None, 'publishedAt': '2016-05-13T20:20:23Z', 'updatedAt': '2017-01-19T16:57:26Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: update novnc vendorized code, re-implement tunnel to use new standard', 'bodyHTML': '<p>novnc used to use base64 encoded data over a websocket, now it does some other magic. <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"104964674\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/sandia-minimega/minimega/issues/315\" data-hovercard-type=\"issue\" data-hovercard-url=\"/sandia-minimega/minimega/issues/315/hovercard\" href=\"https://github.com/sandia-minimega/minimega/issues/315\">#315</a> discusses this.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/566', 'state': 'CLOSED', 'createdAt': '2016-06-08T20:18:53Z', 'lastEditedAt': None, 'publishedAt': '2016-06-08T20:18:53Z', 'updatedAt': '2016-09-13T21:16:57Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: `file delete .`', 'bodyHTML': \"<p>What's the canonical way to delete all files? I used <code>file delete .</code> and it deleted everything I wanted but it also deleted the files directory. Then, when I tried to send new files, minimega complains that the files directory does not exist. If the <code>file delete</code> API detects that the directory to delete is the files directory, it should skip it and just delete the contents.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/574', 'state': 'CLOSED', 'createdAt': '2016-06-13T20:29:20Z', 'lastEditedAt': None, 'publishedAt': '2016-06-13T20:29:20Z', 'updatedAt': '2016-10-10T20:51:32Z', 'labels': ['bug', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'protonuke: add IRC client', 'bodyHTML': \"<p>Hey guys, let's hear some chatter out there.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/622', 'state': 'CLOSED', 'createdAt': '2016-08-19T21:35:25Z', 'lastEditedAt': None, 'publishedAt': '2016-08-19T21:35:25Z', 'updatedAt': '2017-09-21T19:45:05Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega/ron/miniccc: change log level from cc', 'bodyHTML': \"<p>It would be convenient to be able to change <code>miniccc</code>'s log level from a <code>cc</code> API.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/705', 'state': 'CLOSED', 'createdAt': '2016-10-19T22:42:10Z', 'lastEditedAt': None, 'publishedAt': '2016-10-19T22:42:10Z', 'updatedAt': '2017-03-17T18:56:24Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minilog: elevate `logSetup`', 'bodyHTML': '<p>We have the same <code>logSetup</code> in almost every executable in the toolset. We should have <code>minilog</code> register the flags and then perform the actions currently in <code>logSetup</code> in <code>minilog.Init</code>.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/754', 'state': 'CLOSED', 'createdAt': '2016-11-11T17:54:48Z', 'lastEditedAt': None, 'publishedAt': '2016-11-11T17:54:48Z', 'updatedAt': '2016-12-22T16:07:29Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: vnc bug', 'bodyHTML': \"<p>It doesn't look like the last command in a recording is being executed.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/759', 'state': 'CLOSED', 'createdAt': '2016-11-14T18:51:33Z', 'lastEditedAt': None, 'publishedAt': '2016-11-14T18:51:33Z', 'updatedAt': '2016-11-30T20:48:21Z', 'labels': ['bug', 'help wanted', 'triage'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: ganglia-like view for host and VM stats', 'bodyHTML': '<p>Let\\'s do something like this:</p>\\n<p><a href=\"https://en.wikipedia.org/wiki/Ganglia_(software)#/media/File:ScalableGridEngineGanglia2.png\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Ganglia_(software)#/media/File:ScalableGridEngineGanglia2.png</a></p>\\n<p>for the host page on miniweb</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/857', 'state': 'CLOSED', 'createdAt': '2017-02-07T18:44:26Z', 'lastEditedAt': None, 'publishedAt': '2017-02-07T18:44:26Z', 'updatedAt': '2018-01-03T21:38:28Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: VM controls', 'bodyHTML': '<p>Add buttons to start/stop/kill/... VMs.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/872', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:32:53Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:32:53Z', 'updatedAt': '2017-09-25T19:57:18Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: upload/download files', 'bodyHTML': '<p>Add functionality to upload/download files to/from the <code>iomeshage</code> directory.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/873', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:33:54Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:33:54Z', 'updatedAt': '2018-01-03T19:53:11Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: world map', 'bodyHTML': '<p>In a previous incarnation, the web interface had a world map that would place VMs according to their tags. It would be nice to revive this.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/874', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:36:03Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:36:03Z', 'updatedAt': '2018-01-03T18:53:00Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: expose hotplug, cdrom APIs', 'bodyHTML': '<p>Similar to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"209217603\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/sandia-minimega/minimega/issues/872\" data-hovercard-type=\"issue\" data-hovercard-url=\"/sandia-minimega/minimega/issues/872/hovercard\" href=\"https://github.com/sandia-minimega/minimega/issues/872\">#872</a>, expose buttons to hotplug USB drives or CDROMs.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/875', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:37:24Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:37:24Z', 'updatedAt': '2018-01-03T18:36:50Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: notes', 'bodyHTML': '<p>Have a tab on the website I can write notes to about an experiment. Some place to store passwords, tell people not to do certain things.<br>\\nList what needs to be done still.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/916', 'state': 'CLOSED', 'createdAt': '2017-05-05T17:09:02Z', 'lastEditedAt': None, 'publishedAt': '2017-05-05T17:09:02Z', 'updatedAt': '2018-01-03T18:43:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'SCIRun', 'repo_owner_name': 'The Scientific Computing and Imaging Institute', 'repo_owner_email': 'cibc-contact@sci.utah.edu', 'repo_owner_user_name': 'SCIInstitute', 'repo_owner_profile_url': 'https://github.com/SCIInstitute', 'title': 'Clean up hard-coded module factory and refactor module creation logic.', 'bodyHTML': '<p>This is a continuation of issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"7165765\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/SCIInstitute/SCIRun/issues/54\" data-hovercard-type=\"issue\" data-hovercard-url=\"/SCIInstitute/SCIRun/issues/54/hovercard\" href=\"https://github.com/SCIInstitute/SCIRun/issues/54\">#54</a>.</p>', 'url': 'https://github.com/SCIInstitute/SCIRun/issues/101', 'state': 'OPEN', 'createdAt': '2012-11-20T16:48:03Z', 'lastEditedAt': None, 'publishedAt': '2012-11-20T16:48:03Z', 'updatedAt': '2017-10-11T17:09:05Z', 'labels': ['Framework', 'MLM Project', 'Modules', 'Priority-Unspecified', 'Refactoring', 'Training', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SCIRun', 'repo_owner_name': 'The Scientific Computing and Imaging Institute', 'repo_owner_email': 'cibc-contact@sci.utah.edu', 'repo_owner_user_name': 'SCIInstitute', 'repo_owner_profile_url': 'https://github.com/SCIInstitute', 'title': 'Move all AlgorithmParameters to use new declaration macros', 'bodyHTML': '<p>They should match port names when possible.</p>', 'url': 'https://github.com/SCIInstitute/SCIRun/issues/415', 'state': 'OPEN', 'createdAt': '2013-10-11T19:22:18Z', 'lastEditedAt': None, 'publishedAt': '2013-10-11T19:22:18Z', 'updatedAt': '2017-10-11T17:09:06Z', 'labels': ['Algorithms', 'Framework', 'Modules', 'Refactoring', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SCIRun', 'repo_owner_name': 'The Scientific Computing and Imaging Institute', 'repo_owner_email': 'cibc-contact@sci.utah.edu', 'repo_owner_user_name': 'SCIInstitute', 'repo_owner_profile_url': 'https://github.com/SCIInstitute', 'title': 'Specify delimiter for parsing entry in CreateMatrix', 'bodyHTML': '<p>Follow-up from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"9105679\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/SCIInstitute/SCIRun/issues/122\" data-hovercard-type=\"issue\" data-hovercard-url=\"/SCIInstitute/SCIRun/issues/122/hovercard\" href=\"https://github.com/SCIInstitute/SCIRun/issues/122\">#122</a>, requested by Josh.</p>', 'url': 'https://github.com/SCIInstitute/SCIRun/issues/706', 'state': 'OPEN', 'createdAt': '2014-11-19T22:00:41Z', 'lastEditedAt': None, 'publishedAt': '2014-11-19T22:00:41Z', 'updatedAt': '2017-10-11T17:09:06Z', 'labels': ['Algorithms', 'GUI', 'Modules', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SCIRun', 'repo_owner_name': 'The Scientific Computing and Imaging Institute', 'repo_owner_email': 'cibc-contact@sci.utah.edu', 'repo_owner_user_name': 'SCIInstitute', 'repo_owner_profile_url': 'https://github.com/SCIInstitute', 'title': 'CreateStandardColorMap improvements, part 1: Add all remaining v4 ColorMaps', 'bodyHTML': '<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"59851793\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/SCIInstitute/SCIRun/issues/898\" data-hovercard-type=\"issue\" data-hovercard-url=\"/SCIInstitute/SCIRun/issues/898/hovercard\" href=\"https://github.com/SCIInstitute/SCIRun/issues/898\">#898</a>. List of v4 colormaps:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Gray</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Old Rainbow</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Lighthue</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Don</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Dark Gray</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Orange Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Green Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Blue Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Pink,White,Blue</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Mixed Rainbow</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Gray2</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Rainbow</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Darkhue</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Blackbody</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> BP Seismic</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Red Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Yellow Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Cyan Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Purple Tint</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Orange,Black,Lime</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Mixed GrayScale</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Gray3</li>\\n</ul>', 'url': 'https://github.com/SCIInstitute/SCIRun/issues/1348', 'state': 'OPEN', 'createdAt': '2016-03-03T17:47:45Z', 'lastEditedAt': None, 'publishedAt': '2016-03-03T17:47:45Z', 'updatedAt': '2018-07-20T21:18:06Z', 'labels': ['Graphics', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'SCIRun', 'repo_owner_name': 'The Scientific Computing and Imaging Institute', 'repo_owner_email': 'cibc-contact@sci.utah.edu', 'repo_owner_user_name': 'SCIInstitute', 'repo_owner_profile_url': 'https://github.com/SCIInstitute', 'title': 'Sphere option: make scalable as percentage of bounding box', 'bodyHTML': '', 'url': 'https://github.com/SCIInstitute/SCIRun/issues/1524', 'state': 'OPEN', 'createdAt': '2016-07-13T21:30:07Z', 'lastEditedAt': None, 'publishedAt': '2016-07-13T21:30:07Z', 'updatedAt': '2017-10-11T17:09:06Z', 'labels': ['GUI', 'Graphics', 'IBBM', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ImagingSIMS', 'repo_owner_name': 'ImagingSIMS', 'repo_owner_email': None, 'repo_owner_user_name': 'ImagingSIMS', 'repo_owner_profile_url': 'https://github.com/ImagingSIMS', 'title': 'Additional spectra types', 'bodyHTML': '<p>ImagingSIMS has suport for Bio-Tof (.xyt, .dat) and J105 (.IonoptikaIA2DspectrV2) spectra files. For those who have knowledge of the file types of other systems and would like to add support for those, let me know and we can get those included.</p>\\n<p>In essence, there is an abstract Spectrum class which each type of spectrum will inherit from (i.e. there are already BioToFSpectrum and J105Spectrum classes). To add support for more, just create a new derived class and make sure to implement the proper functions for loading and saving those spectra, as well as the necessary functions that must be implemented/overriden.</p>', 'url': 'https://github.com/ImagingSIMS/ImagingSIMS/issues/8', 'state': 'OPEN', 'createdAt': '2016-01-04T18:21:52Z', 'lastEditedAt': None, 'publishedAt': '2016-01-04T18:21:52Z', 'updatedAt': '2016-01-04T18:21:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'omega_h', 'repo_owner_name': 'Dan Ibanez', 'repo_owner_email': '', 'repo_owner_user_name': 'ibaned', 'repo_owner_profile_url': 'https://github.com/ibaned', 'title': 'AMR refine with two elements', 'bodyHTML': '<p>Modifying the <code>amr_test.cpp</code> file to:</p>\\n<pre><code>int main(int argc, char** argv) {\\n  auto lib = Omega_h::Library(&amp;argc, &amp;argv);\\n  auto mesh = Omega_h::build_box(lib.world(), OMEGA_H_HYPERCUBE, 1.0, 1.0, 0.0, 2, 1, 0); \\n  auto xfer_opts = Omega_h::TransferOpts();\\n  Omega_h::amr_refine(&amp;mesh, Omega_h::Bytes({1, 0}), xfer_opts);\\n  std::cout &lt;&lt; \"after refine, \" &lt;&lt; mesh.nelems() &lt;&lt; \" elements\\\\n\";\\n  std::cout &lt;&lt; \"elems2verts: \" &lt;&lt; mesh.ask_elem_verts() &lt;&lt; \\'\\\\n\\';\\n  std::cout &lt;&lt; \"coords: \" &lt;&lt; mesh.coords() &lt;&lt; \\'\\\\n\\';\\n}\\n</code></pre>\\n<p>such that there are two elements (rather than one) results in this assertion failing:</p>\\n<pre><code>assertion 0 &lt;= i failed at /ascldap/users/bngranz/src/omega_h/src/Omega_h_array.hpp +61\\n</code></pre>\\n<p>with this stack trace:</p>\\n<pre><code>#0  0x0000003070e32495 in raise () from /lib64/libc.so.6\\n#1  0x0000003070e33c75 in abort () from /lib64/libc.so.6\\n#2  0x00007ffff7aff49e in Omega_h_fail () at omega_h/src/Omega_h_c.cpp:22\\n#3  0x00007ffff7b05f1b in Omega_h::Write&lt;int&gt;::operator[](int) const () at omega_h/src/Omega_h_array.hpp:61\\n#4  0x00007ffff7c79d15 in Omega_h::get_rep2md_order(Omega_h::Mesh*, int, Omega_h::Few&lt;Omega_h::LOs, 4&gt;, Omega_h::Few&lt;Omega_h::LOs, 4&gt;, Omega_h::Few&lt;bool, 4&gt;) () at omega_h/src/Omega_h_array.hpp:129\\n#5  0x00007ffff7d59eba in Omega_h::amr_refine(Omega_h::Mesh*, Omega_h::Bytes, Omega_h::TransferOpts) () at omega_h/src/Omega_h_amr.cpp:28\\n#6  0x000000000040e849 in main () at omega_h/src/amr_test.cpp:10\\n</code></pre>\\n<p>Is this expected until some additional capabilities are included into the amr refine code?</p>\\n<hr>\\n<p>I\\'ve done some initial debugging to see if the inputs to the <code>get_rep2md_order</code> function are correct. Placing the debug output:</p>\\n<pre><code>   std::cout &lt;&lt; \"prod_dim: \" &lt;&lt; prod_dim &lt;&lt; std::endl;\\n    for (Int i = 0; i &lt; mesh-&gt;dim(); ++i) {\\n      std::cout &lt;&lt; \"mods_have_prods[\" &lt;&lt; i &lt;&lt; \"]: \"\\n        &lt;&lt; mods_have_prods[i] &lt;&lt; std::endl;\\n    }   \\n    for (Int i = 0; i &lt; 4; ++i) {\\n      if (! mods2mds[i].exists()) continue;\\n      std::cout &lt;&lt; \"mods2mds[\" &lt;&lt; i &lt;&lt; \"]: \"\\n        &lt;&lt; mods2mds[i] &lt;&lt; std::endl;\\n    }   \\n    for (Int i = 0; i &lt; 4; ++i) {\\n      if (! mods2nprods[i].exists()) continue;\\n      std::cout &lt;&lt; \"mods2nprods[\" &lt;&lt; i &lt;&lt; \"]: \"\\n        &lt;&lt; mods2nprods[i] &lt;&lt; std::endl;\\n    }   \\n</code></pre>\\n<p>after <a href=\"https://github.com/ibaned/omega_h/blob/master/src/Omega_h_amr.cpp#L25\">this</a> line produces the output:</p>\\n<pre><code>prod_dim: 0\\nmods_have_prods[0]: 0\\nmods_have_prods[1]: 1\\nmods2mds[0]: {0, 1, 2, 4}\\nmods2mds[1]: {0, 1, 2, 3}\\nmods2mds[2]: {0}\\nmods2nprods[1]: {1, 1, 1, 1}\\nmods2nprods[2]: {1}\\nprod_dim: 1\\nmods_have_prods[0]: 0\\nmods_have_prods[1]: 1\\nmods2mds[0]: {0, 1, 2, 4}\\nmods2mds[1]: {0, 1, 2, 3}\\nmods2mds[2]: {0}\\nmods2nprods[1]: {2, 2, 2, 2}\\nmods2nprods[2]: {4}\\n</code></pre>\\n<p>seems right to me?</p>', 'url': 'https://github.com/ibaned/omega_h/issues/223', 'state': 'CLOSED', 'createdAt': '2018-04-01T16:03:53Z', 'lastEditedAt': None, 'publishedAt': '2018-04-01T16:03:53Z', 'updatedAt': '2018-04-02T15:15:40Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Bizarre linking issue', 'bodyHTML': '<p>This is more of a \"help_wanted\" kind of question.</p>\\n<p>I am having a linking issue for netcdf with albany. On my workstation I have a systemwide netcdf installation (needed by some other packages, e.g., octave). When I build albany (and trilinos), I load modules for all the required libraries (hdf5, netcdf, yaml...). At the end, my LD_LIBRARY_PATH env variable looks like this (i\\'m using fake path names for brevity):</p>\\n<p><code>LD_LIBRARY_PATH=/modulepath/netcdf/lib;/modulepath/hdf5/lib:/modulepath/openmpi/lib:.../usr/lib64:/usr/lib</code></p>\\n<p>So the system directories are <em>at the end</em>. Good. When I build trilinos, everything is fine, and when I inspect the libraries with <code>ldd libXYZ.so | grep netcdf</code>, I see that the correct one is linked (the one in <code>/modulepath/netcdf/lib</code>). However, when I build albany, the <em>wrong</em> one is picked. This generates a warning</p>\\n<pre><code>/usr/bin/ld: warning: libnetcdf.so.11, needed by\\n /path/to/trilinos/lib/libstk_tools_lib.so.12.13, may conflict with libnetcdf.so.7\\n</code></pre>\\n<p>and, more importantly, the system library does not support parallel correctly. I can verify that the wrong netcdf is linked, since with, say, <code>ldd libalbanySTK.so | grep netcdf</code> I get</p>\\n<pre><code>libnetcdf.so.7 =&gt; /usr/lib64/libnetcdf.so.7 (0x00007f0cc5235000)\\nlibnetcdf.so.11 =&gt; /modulepath/netcdf/lib/libnetcdf.so.11 (0x00007f0cbf75a000)\\n</code></pre>\\n<p>It appears that <em>somewhere</em> in albany, the path <code>/usr/lib64</code> is prepended to <code>ld</code> search path. I looked through the build directory, but I cannot find the place where this happens. Even the <code>build.cmake</code> file for <code>libalbanySTK</code> lists the correct dependency in the <code>albanySTK_EXTERNAL_OBJECTS</code> variable (i.e., it lists <code>/modulepath/netcdf/lib/libnetcdf.so</code>), but then the other one gets linked, when <code>-lnetcdf</code> is found on the link line.</p>\\n<p>I found a workaround by adding the <a href=\"https://cmake.org/cmake/help/v3.3/policy/CMP0060.html\" rel=\"nofollow\">policy</a> <code>cmake_policy(SET CMP0060 NEW)</code> to the main <code>CMakeLists.txt</code>, but I don\\'t want to do that, especially since I am probably the only one with this issue.</p>\\n<p>Has anyone experienced the same problem at some point?</p>', 'url': 'https://github.com/gahansen/Albany/issues/232', 'state': 'CLOSED', 'createdAt': '2017-11-30T23:31:15Z', 'lastEditedAt': '2017-11-30T23:33:15Z', 'publishedAt': '2017-11-30T23:31:15Z', 'updatedAt': '2017-12-01T00:14:35Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Albany User Guide', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971921\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibaned\">@ibaned</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7558465\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/agsalin\">@agsalin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5940580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mperego\">@mperego</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7018124\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ikalash\">@ikalash</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=147948\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jtostie\">@jtostie</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5702945\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bgranzow\">@bgranzow</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3226046\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartgol\">@bartgol</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11995357\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/calleman21\">@calleman21</a></p>\\n<p>Sorry for spamming all of you, but I think this issue is very broad.</p>\\n<p>In the past, and most recently today, I have been asked whether there is an Albany User Guide for people that want to just run Albany, but have no plans to touch the source code.</p>\\n<p>I believe that there is scattered information here and there, and I\\'m reaching out to all of you to ask if you know about it, and to gage the interest to try to bring it together into a single place.</p>\\n<p>Thoughts?</p>', 'url': 'https://github.com/gahansen/Albany/issues/250', 'state': 'OPEN', 'createdAt': '2018-01-19T01:48:41Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T01:48:41Z', 'updatedAt': '2018-01-22T15:49:56Z', 'labels': ['help wanted', 'question', 'user documentation', 'user usability'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Hanging Tempus tests on skybridge-login5 with intel compiler', 'bodyHTML': '<p>Around Feb. 9, 2 Tempus tests began failing in <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> \\'s Skybridge intel build:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlypassed&amp;buildid=67116\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlypassed&amp;buildid=67116</a></p>\\n<p>What is truly bizarre about this problem is when I use the same exact scripts as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> to run the tests, also on skybridge-login5 and run via cronjob, the tests pass:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/index.php?project=Albany&amp;subproject=albany_cluster-toss3_skybridge-login5_serial-intel-release&amp;date=2018-02-19\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/index.php?project=Albany&amp;subproject=albany_cluster-toss3_skybridge-login5_serial-intel-release&amp;date=2018-02-19</a></p>\\n<p>We have made sure that my ~/.bashrc and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a>\\'s ~/.bashrc files are the same.  Anyone have any thoughts?  It would be nice if perhaps someone else could give this build a try and report what happens.</p>', 'url': 'https://github.com/gahansen/Albany/issues/265', 'state': 'CLOSED', 'createdAt': '2018-02-20T16:10:36Z', 'lastEditedAt': None, 'publishedAt': '2018-02-20T16:10:36Z', 'updatedAt': '2018-07-02T03:31:29Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Replacement for MDArray, potential bad memory leak in Shards from MDArray', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971921\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibaned\">@ibaned</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7018124\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ikalash\">@ikalash</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7558465\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/agsalin\">@agsalin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a>  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5940580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mperego\">@mperego</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3226046\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartgol\">@bartgol</a> While chasing a frustrating bug in Schwarz about resetting state arrays, I discovered that MDArrays are shards::Arrays, as defined in Albany_StateInfoStruct.hpp.</p>\\n<p>shards::Arrays overload the operator= with a shallow copy, hence the failure in resetting state variables for Schwarz.</p>\\n<p>There are two problems with this:</p>\\n<ul>\\n<li>There appears to be no way to do a deep copy of an MDArray/shard:Array, which is needed for Schwarz.</li>\\n<li>The shallow copy uses raw pointers. It does not free the old pointer before overwriting it with the new one, hence the memory it was pointing to is lost.</li>\\n</ul>\\n<p>My question is: is it possible to replace the MDArray in Albany_StateInfoStruct.hpp with something else? A Kokkos view perhaps?</p>\\n<p>I could jump through hoops and make this work with MDArrays somehow, but it seems to me that there should be a cleaner solution and also avoid the potential for memory leaks.</p>\\n<p>I\\'m open to suggestions.</p>', 'url': 'https://github.com/gahansen/Albany/issues/268', 'state': 'CLOSED', 'createdAt': '2018-02-28T19:21:22Z', 'lastEditedAt': '2018-02-28T19:42:49Z', 'publishedAt': '2018-02-28T19:21:22Z', 'updatedAt': '2018-03-08T00:13:27Z', 'labels': ['bug', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Albany build broken due to Kokkos::Experimental::Impl not being defined', 'bodyHTML': '<p>It looks like Albany failed to build in the nightlies last night.  I can only see the external CDash, as I am on foreign travel:</p>\\n<p><a href=\"https://my.cdash.org/viewBuildError.php?buildid=1381133\" rel=\"nofollow\">https://my.cdash.org/viewBuildError.php?buildid=1381133</a></p>\\n<p>but I am guessing this happened in the internal tests too.  Here is the error cut/paste here:</p>\\n<pre><code>repos/Albany/src/PHAL_Utilities_Def.hpp:224:39: error: \\'Kokkos::Experimental::Impl\\' has not been declared\\n</code></pre>\\n<p>Can someone please look at what is going on / fix it while I am away?</p>', 'url': 'https://github.com/gahansen/Albany/issues/269', 'state': 'CLOSED', 'createdAt': '2018-03-08T08:08:42Z', 'lastEditedAt': '2018-03-08T08:10:41Z', 'publishedAt': '2018-03-08T08:08:42Z', 'updatedAt': '2018-03-08T16:51:51Z', 'labels': ['build', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Tpetra::Map destructor warning printed for Albany tests', 'bodyHTML': '<p>I noticed that starting this morning, all (I believe) Albany tests have this warning printed:</p>\\n<pre><code>WARNING: Tpetra::Map destructor (~Map()) is being called after Tpetra::finalize() has been called.  This is user error!  This may happen if you create a Tpetra::Map (or RCP or shared_ptr of a Tpetra::Map) at the same scope in main() as Tpetra::finalize().  Don\\'t do that.  Please refer to GitHib Issue #2372.\\n</code></pre>\\n<p>It looks like the warning was added to Tpetra yesterday (see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"304818275\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/2372\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/2372/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/2372\">trilinos/Trilinos#2372</a> ).  We should try to understand what we\\'re doing wrong with the Tpetra::Map destructor.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1564391\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tjfulle\">@tjfulle</a>, would you be willing to look at this, as someone well-acquainted with Tpetra and also working on Albany maintenance?</p>', 'url': 'https://github.com/gahansen/Albany/issues/275', 'state': 'CLOSED', 'createdAt': '2018-03-20T15:48:30Z', 'lastEditedAt': '2018-03-20T15:48:43Z', 'publishedAt': '2018-03-20T15:48:30Z', 'updatedAt': '2018-03-21T20:38:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Issue with LCM Python tests that execute \"./AlbanyT *yaml\" command on some HPC platforms', 'bodyHTML': '<p>In building / running Albany/LCM on the Solo ECN machine, I discovered an issue with the LCM tests that run python scripts with the command \"./AlbanyT *yaml\".  The issue is on some platforms, \"mpirun -np 1 AlbanyT\" or \"mpiexec -np 1 AlbanyT\" is required to run serial executables, with Solo being one of them.  I think this issue may have come up before.  I can modify the scripts to execute the command \"mpirun -np 1 AlbanyT\" except I think then on some platforms there may be an issue with not providing a path to mpirun (or using srun / mpiexec instead of mpirun).  Ideally, we\\'d want to get the path to the mpi command from cmake.  I think <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a> may have encountered this before.</p>\\n<p>Here are the tests that would need to be modified to fix this:</p>\\n<pre><code>    109 - CohesiveElement (Failed)\\n    112 - EquilibriumConcentrationBC (Failed)\\n    113 - HeliumODEs (Failed)\\n    117 - AnisotropicHyperelasticDamage (Failed)\\n    118 - AnisotropicDamage-Bifurcation (Failed)\\n    119 - Gurson (Failed)\\n    120 - Neohookean (Failed)\\n    121 - CrystalPlasticity_MPS (Failed)\\n    131 - MechanicsWithHelium (Failed)\\n    137 - Partition (Failed)\\n    142 - SurfaceElementLocking (Failed)\\n    143 - SurfaceElementOrtiz (Failed)\\n    230 - Schwarz_Cubes (Failed)\\n    231 - Schwarz_Alternating_Quasistatics (Failed)\\n    232 - Schwarz_Alternating_Dynamics_Cubes (Failed)\\n    233 - Schwarz_Alternating_Dynamics_CubesInelastic (Failed)\\n</code></pre>', 'url': 'https://github.com/gahansen/Albany/issues/278', 'state': 'CLOSED', 'createdAt': '2018-03-29T03:28:48Z', 'lastEditedAt': '2018-07-02T22:55:43Z', 'publishedAt': '2018-03-29T03:28:48Z', 'updatedAt': '2018-07-07T00:49:04Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Time Dependent BC that varies in space and time ', 'bodyHTML': \"<p>As discussed at the Albany meeting this morning, there is an interest in adding to Albany a time dependent BC (Dirichlet as well as Neumann) where the BC values are spatially and temporally dependent, and not given by an analytical function.  Albany currently has the following capabilities:</p>\\n<ul>\\n<li>Set a Dirichlet BC from a field in the mesh named dirichlet_field (allowing a spatially-varying BC that is not given by an analytical function).</li>\\n<li>Set a time-dependent BC (Dirichlet, perhaps Neumann too) that is spatially constant on a given nodeset.</li>\\n</ul>\\n<p>The new time dependent BC would combine these two capabilities.  Specifically, we'd need to:</p>\\n<ul>\\n<li>Add the capability to read snapshots defining the BC field into dirichlet_field.  Probably we should not store all the snapshots but a couple at a time to avoid running out of memory.</li>\\n<li>Add the capability to interpolate the time-dependent BC values to times where they are needed, in the case where the time-step is different than the times where the snapshots are stored.  This sort of interpolation is done already in TimeDepBC for scalar-valued (in space) BCs.  This interpolation is what will require at least 2 BC snapshots to be stored at a time.</li>\\n</ul>\\n<p>Any volunteers to help with this task?  The new BC is of interest to the Tsunami work, as well as the RPI folks; perhaps others are interested in this too?</p>\", 'url': 'https://github.com/gahansen/Albany/issues/316', 'state': 'OPEN', 'createdAt': '2018-07-09T16:49:13Z', 'lastEditedAt': None, 'publishedAt': '2018-07-09T16:49:13Z', 'updatedAt': '2018-07-09T19:59:15Z', 'labels': ['Tsunami', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Add a test for the Vx, Vxdot, Vxdotdot, Vp tangent direction functionalities.', 'bodyHTML': \"<p>Currently, these are in the Workset, but are never set to annything other than NULL by the model evaluator. Hence, all the evaluators that are supposed to do something if they are not null, do nothing.</p>\\n<p>We should come up with a test that uses them, even if it is from a modified version of Albany's model evaluator.</p>\", 'url': 'https://github.com/gahansen/Albany/issues/335', 'state': 'OPEN', 'createdAt': '2018-07-19T23:16:53Z', 'lastEditedAt': None, 'publishedAt': '2018-07-19T23:16:53Z', 'updatedAt': '2018-07-19T23:16:53Z', 'labels': ['Testing', 'help wanted', 'infrastructure'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Warning-free Albany build', 'bodyHTML': '<p>I was tracking down a bug, and it ended up being something like <code>a - b;</code> instead of <code>a = b;</code>. So I thought \"well, let\\'s turn on warnings, so I don\\'t waste 1h of my time later on finding these bugs\". And then warningmageddon happened.</p>\\n<p>Albany generates a gazillion of warnings! Unused parameters/typedefs, signed/unsigned comparisons, and initialization order are the major stars of the show, with countless hits.</p>\\n<p>Now, virtually all of these warning are benign, and could be ignored. However, as Albany grows larger and larger, it would be nice (to say the least) to fix those warnings. Besides, the fewer the warnings spit out by the compiler, the easier it is to catch the dangerous ones. I think of this issue as a constant reminder: if we run into one obvious warning, we should clean it up, together with our commits. And possibly not introduce a new one.</p>\\n<p>Note: yes, we can silence warnings, but that\\'s not a very clean solution.</p>', 'url': 'https://github.com/gahansen/Albany/issues/354', 'state': 'OPEN', 'createdAt': '2018-08-14T19:22:22Z', 'lastEditedAt': None, 'publishedAt': '2018-08-14T19:22:22Z', 'updatedAt': '2018-08-15T00:11:35Z', 'labels': ['build', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Numerous test failures in Albany nightlies as of this morning', 'bodyHTML': '<p>There are numerous test failures in Albany as of this morning:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlyfailed&amp;buildid=75093\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlyfailed&amp;buildid=75093</a></p>\\n<p>Most of them seem to be failures when running exodiff for LCM problems, but a few seem to have to do with reading in an Exodus file to restart from, e.g. <a href=\"http://cdash.sandia.gov/CDash-2-3-0/testDetails.php?test=3880312&amp;build=75103\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/testDetails.php?test=3880312&amp;build=75103</a>:</p>\\n<pre><code>p=2: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Variable type counts are inconsistent. See processor 0 output for more details.\\np=3: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Variable type counts are inconsistent. See processor 0 output for more details.\\np=0: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Number of nodeset variables is not consistent on all processors.\\n        Database: th1d_tpetra.exo\\n \\tProcessor 0 count = 3\\n \\tProcessor 1 count = 0\\n \\tProcessor 2 count = 0\\n</code></pre>\\n<p>It looks like there were no non-trivial checkins to Albany master this week, so I think the failures are due to changes in Trilinos.  Anyone want to investigate this?</p>', 'url': 'https://github.com/gahansen/Albany/issues/358', 'state': 'CLOSED', 'createdAt': '2018-08-23T15:57:17Z', 'lastEditedAt': None, 'publishedAt': '2018-08-23T15:57:17Z', 'updatedAt': '2018-09-24T16:59:58Z', 'labels': ['Testing', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Modify alg.i for SurfaceElementLocking to have exodiff compare SURF_S*, SURF_* and SURF_HYDRO_* fields', 'bodyHTML': '<p>In resolving issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"353447168\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/358\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/358/hovercard\" href=\"https://github.com/gahansen/Albany/issues/358\">#358</a> , I had to turn off exodiff comparisons of some of the SURF fields for the SurfaceElementLocking test case, as these fields are no longer generated in the *alg.e file when running algebra, due to a change in the naming of STK fields written to the output exodus file.  If these comparisons are of interest, can someone (preferably the author and one familiar with what algebra is supposed to be doing - tagging <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7317023\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jwfoulk\">@jwfoulk</a> ) look at this with me (or look at it on their own/fix it)?  I think the fix should be very quick.</p>', 'url': 'https://github.com/gahansen/Albany/issues/365', 'state': 'OPEN', 'createdAt': '2018-09-24T16:59:21Z', 'lastEditedAt': None, 'publishedAt': '2018-09-24T16:59:21Z', 'updatedAt': '2018-09-24T16:59:21Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Make headers include all explicit dependencies', 'bodyHTML': '<p>Plenty of headers in Albany (especially in the evaluators folder) miss some includes. For instance, very few evaluators headers include <code>PHAL_Dimension.hpp</code> (directly or indirectly). Things obviously work anyways, since at the time of use, such headers are (directly or indirectly) included. For instance, including <code>PHAL_AlbanyTraits.hpp</code> brings in all the data types and the dimensions tags.</p>\\n<p>While this <em>works</em>, it is also not optimal, at least on 2+1 levels:</p>\\n<ol start=\"0\">\\n<li>it is a bad practice;</li>\\n<li>when faced with a function/class/type I don\\'t fully understand, I sometimes go up the include stack, till I reach the point where it is defined. Relying on some upstream headers being included at the time the current header will be used makes this impossible;</li>\\n<li>If you have a text editor with real-time compilation in the background that highlights compiler errors, you can be submerged by a red-tide of errors, which make navigating the code harder.</li>\\n</ol>\\n<p>While I understand that the effort of fixing this is probably too big for the gain we would get (after all, the code compiles and runs), I would like to ask developers to be aware of this. When adding a new header or modifying an existing one, please spend 3 seconds checking whether each symbol\\'s header is included (directly or indirectly), and add it if missing.</p>\\n<p>P.S: I don\\'t want to get into the discussion of whether indirect inclusion is fine or not (though I am a strong supporter of \"include everything you explicitly use that you cannot forward declare\", rather than \"if the first header you include includes the second one, you don\\'t need the second one\"). What I\\'m <em>strongly encouraging</em> is the idea that including any header from our library in file <code>foo.cpp</code> should <em>not</em>  force the user to include other headers that <code>foo.cpp</code> does not explicitly need. The end user may not even know where the symbol <code>Cell</code> is defined, nor should he/she care.</p>', 'url': 'https://github.com/gahansen/Albany/issues/379', 'state': 'OPEN', 'createdAt': '2018-11-01T15:01:34Z', 'lastEditedAt': '2018-11-01T15:04:59Z', 'publishedAt': '2018-11-01T15:01:34Z', 'updatedAt': '2018-11-01T15:04:59Z', 'labels': ['developer usability', 'help wanted', 'user usability'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Remove or replace all instances of ALBANY_KOKKOS_UNDER_DEVELOPMENT', 'bodyHTML': '<p>This has been discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260676342\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/184\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/184/hovercard\" href=\"https://github.com/gahansen/Albany/issues/184\">#184</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378833321\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/382\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/382/hovercard\" href=\"https://github.com/gahansen/Albany/issues/382\">#382</a>. It would be great to remove it and keep the kokkos kernels but there may be some instances where we would like to keep the legacy implementation. At the very least, my suggestion would be to try to remove it everywhere except where kernels are called and make it a requirement to use the Kokkos data abstractions. Then possibly rename it too <code>ALBANY_USE_KOKKOS_KERNELS</code> or flip it to <code>ALBANY_LEGACY_CODE</code> so that the kokkos kernels are the default.</p>', 'url': 'https://github.com/gahansen/Albany/issues/385', 'state': 'OPEN', 'createdAt': '2018-11-12T19:19:10Z', 'lastEditedAt': None, 'publishedAt': '2018-11-12T19:19:10Z', 'updatedAt': '2018-11-14T18:20:33Z', 'labels': ['Discussion', 'Kokkos', 'developer usability', 'help wanted', 'infrastructure'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'DCS-Slmod', 'repo_owner_name': None, 'repo_owner_email': '', 'repo_owner_user_name': 'mrSkortch', 'repo_owner_profile_url': 'https://github.com/mrSkortch', 'title': 'slmodMetaStats file', 'bodyHTML': '<p>I am adding an slmodMetaStats file. The purpose of this file is to store useful information from session to session that isn\\'t directly related to player statistics. Current I will use it to store the last used MissionStats file so that whenever a new mission is started slmod will open and resave the previous missions stats file. This is so the file is recompiled and becomes more readable.</p>\\n<p>I\\'ve got a few ideas for what could be put in this file and may implement it in the future. Possible \"metaStats\" :</p>\\n<ol>\\n<li>Stats on missions<br>\\na. time a mission of a specific name has been hosted.<br>\\nb. flight hours of players on the mission</li>\\n<li>Stats on a map<br>\\na. Time a map has been played<br>\\nb. Most popular mission</li>\\n<li>Voting stats (conditional on adding vote map/mission functionality)<br>\\na. Map/missions that have been voted to be switched from and how many times.</li>\\n</ol>', 'url': 'https://github.com/mrSkortch/DCS-SLmod/issues/17', 'state': 'CLOSED', 'createdAt': '2018-01-15T10:14:41Z', 'lastEditedAt': None, 'publishedAt': '2018-01-15T10:14:41Z', 'updatedAt': '2018-01-24T00:12:59Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: QoS support with global policy', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=41\" rel=\"nofollow\">issue 41</a> created by djfritz on 2014-05-07T15:55:51.000Z:</p>\\n<p>A vm_qos or similar command is needed to wrap quality of service capabilities on interfaces for VMs. Right now the thinking is that we should use \\'tc\\' or a similar infrastructure to add latency and other QoS metrics. The format of vm_qos will match 1:1 with interfaces listed in vm_net.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/41', 'state': 'CLOSED', 'createdAt': '2015-03-12T20:08:28Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T20:08:28Z', 'updatedAt': '2016-07-23T16:46:33Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minicli: Tab completion', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=88\" rel=\"nofollow\">issue 88</a> created by djfritz on 2015-01-29T00:48:27.000Z:</p>\\n<p>Support tab completion in minicli.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/88', 'state': 'CLOSED', 'createdAt': '2015-03-12T20:55:53Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T20:55:53Z', 'updatedAt': '2015-07-10T20:39:08Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: reserved words', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=111\" rel=\"nofollow\">issue 111</a> created by djfritz on 2015-02-04T22:44:42.000Z:</p>\\n<p>Users shouldn\\'t be able to name vms/taps/bridges/... using reserved words. Currently, the only reserved word is \"all\" which is used for wildcards.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/111', 'state': 'CLOSED', 'createdAt': '2015-03-12T21:01:41Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T21:01:41Z', 'updatedAt': '2015-04-04T00:50:33Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'rfbplay: support auto-transcoding with ffmpeg runtime dependency', 'bodyHTML': '<p>Original <a href=\"https://code.google.com/p/minimega/issues/detail?id=120\" rel=\"nofollow\">issue 120</a> created by djfritz on 2015-02-13T20:49:14.000Z:</p>\\n<p>support a one liner production to transcode an rfb file to mp4 with ffmpeg.</p>\\n<p>Something like:</p>\\n<p>rfbplay -transcode foo.fb out.mp4</p>\\n<p>Which would start the local webserver according to other flags and invoke ffmpeg with something like:</p>\\n<p>ffmpeg -f mjpeg -r 10 -i <a href=\"http://localhost:9004/foo.fb\" rel=\"nofollow\">http://localhost:9004/foo.fb</a> out.mp4</p>\\n<p>Then quit.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/120', 'state': 'CLOSED', 'createdAt': '2015-03-12T21:42:20Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T21:42:20Z', 'updatedAt': '2015-05-11T23:54:46Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'unit tests', 'bodyHTML': '<p>There are glaring omissions in our unit tests. This needs significant investment. Some things cannot be tested well with the available unit test framework in Go, so there is another ticket for runtime testing. For things that can be well tested though, we need a lot of help.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/141', 'state': 'CLOSED', 'createdAt': '2015-03-25T15:34:24Z', 'lastEditedAt': None, 'publishedAt': '2015-03-25T15:34:24Z', 'updatedAt': '2015-07-13T20:53:45Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'runtime test framework', 'bodyHTML': \"<p>A number of components in minimega cannot be tested with Go's unit test framework, in particular interactions with qemu/qmp, etc. We need a runtime test harness to run on a small cluster. The framework can be fairly simple - support some language and minimega scripts for runtime tests, and support some sort of success assertion.</p>\\n<p>Beyond that, we need to write the runtime tests we know we'll need, and scope a development practice in the 'contributing.article' for adding new tests.</p>\\n<p>Good intern project.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/142', 'state': 'CLOSED', 'createdAt': '2015-03-25T15:39:06Z', 'lastEditedAt': None, 'publishedAt': '2015-03-25T15:39:06Z', 'updatedAt': '2015-07-20T16:22:21Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'add vm serial or equivalent API', 'bodyHTML': '<p>This appears to be started in branch serial.</p>\\n<p>We need to support a variable number of legacy-isa and virtio-serial serial ports for each VM.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/180', 'state': 'CLOSED', 'createdAt': '2015-04-17T22:40:15Z', 'lastEditedAt': None, 'publishedAt': '2015-04-17T22:40:15Z', 'updatedAt': '2015-05-28T17:28:48Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'Feature request: vm reset', 'bodyHTML': \"<p>Not sure if this ever got done...or put as a feature request...</p>\\n<p>'vm reset vm-0'<br>\\n-would take vm-0 back to original state from which it was started<br>\\n-essentially grouping 'vm kill vm-0;vm start vm-0'.<br>\\n-would be useful on multiple vm's to be reset at once.  i.e. to put an environment back to a freshly booted environment for training.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/185', 'state': 'CLOSED', 'createdAt': '2015-04-28T18:01:50Z', 'lastEditedAt': None, 'publishedAt': '2015-04-28T18:01:50Z', 'updatedAt': '2015-05-08T18:00:48Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: at least one dangling kvm process on entering VM_ERROR state', 'bodyHTML': \"<p>If you hit the race:</p>\\n<p>vm launch foo noblock<br>\\nvm start foo</p>\\n<p>And get the VM into the error state with the 'qmp not ready' error, you'll notice that qemu for that VM is still running, because vm.start() didn't kill the process after putting it in the error state. Later, vm kill won't attempt to kill it because it's in the error state.</p>\\n<p>At least two things could happen here instead:</p>\\n<ul>\\n<li>Attempt to reissue commands on error VMs that aren't actually dead - like 'vm start'. That would require some more book keeping</li>\\n<li>Always kill VMs when they enter the error state</li>\\n</ul>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/209', 'state': 'CLOSED', 'createdAt': '2015-05-18T17:02:45Z', 'lastEditedAt': None, 'publishedAt': '2015-05-18T17:02:45Z', 'updatedAt': '2015-08-12T20:45:58Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniccc: vm tag hooks', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>\\n<p>Want to start thinking about what capabilities folks want in a <code>vm tag</code> hook into miniccc. What I mean by this is to provide some way to have miniccc set a key/value for the vm it represents on an event (specific file create, memory usage over threshold), or something else entirely. I\\'m not sure what the best approach here is.</p>\\n<p>What I\\'d like to have eventually is some robust, generic, API for setting some event, having miniccc wait for that event to happen, and signal back. For things like \"memory over threshold\", it would be even cooler if we could do things on a scale - \"0-10%: set mem:low, ... 90-100%: set mem:critical\"</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/218', 'state': 'CLOSED', 'createdAt': '2015-05-26T20:57:48Z', 'lastEditedAt': None, 'publishedAt': '2015-05-26T20:57:48Z', 'updatedAt': '2015-09-21T14:48:03Z', 'labels': ['duplicate', 'enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'misc: create \"validMAC(mac string) bool\" for valid/allocated mac addresses', 'bodyHTML': '<p>See <a href=\"https://github.com/google/gopacket/tree/master/macs\">https://github.com/google/gopacket/tree/master/macs</a></p>\\n<p>We need to only auto-generate macs that have valid allocations. Using reserved macs can have interesting results on external tools such as wireshark.</p>\\n<p>Need this soon.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11760828\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jericks-sandia\">@jericks-sandia</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2590210\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/devinc\">@devinc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/231', 'state': 'CLOSED', 'createdAt': '2015-06-08T17:50:04Z', 'lastEditedAt': None, 'publishedAt': '2015-06-08T17:50:04Z', 'updatedAt': '2015-06-23T23:10:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'documentation: write vyatta article', 'bodyHTML': '<p>See summary.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/268', 'state': 'CLOSED', 'createdAt': '2015-07-31T20:50:03Z', 'lastEditedAt': None, 'publishedAt': '2015-07-31T20:50:03Z', 'updatedAt': '2015-08-17T14:41:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: add static configuration support to dnsmasq and vyatta APIs', 'bodyHTML': '<p>See summary. Add support for specifying static IPs, etc. referenced by MAC, VM, etc. on future dnsmasq and already running dnsmasq instances.</p>\\n<p>Example:</p>\\n<pre><code>dnsmasq static vm &lt;vm id&gt; &lt;ipv4 address/subnet&gt;\\n</code></pre>', 'url': 'https://github.com/sandia-minimega/minimega/issues/279', 'state': 'CLOSED', 'createdAt': '2015-08-18T14:19:23Z', 'lastEditedAt': None, 'publishedAt': '2015-08-18T14:19:23Z', 'updatedAt': '2016-06-08T20:10:51Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: rewrite web graph to show full detail', 'bodyHTML': '<p>See summary. The graph view in the web interface should render all endpoints instead of the VLAN view.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/292', 'state': 'CLOSED', 'createdAt': '2015-08-24T15:25:51Z', 'lastEditedAt': None, 'publishedAt': '2015-08-24T15:25:51Z', 'updatedAt': '2016-10-10T17:45:17Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'ron/miniccc: add event/action capabilities', 'bodyHTML': '<p>miniccc should be programmable so that we can respond to events such as \"memory threshold 80%\", and <code>vm tag</code> actions such as \"color node red\".</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/294', 'state': 'CLOSED', 'createdAt': '2015-08-24T15:31:26Z', 'lastEditedAt': None, 'publishedAt': '2015-08-24T15:31:26Z', 'updatedAt': '2016-07-23T16:46:55Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: refactor bridge code', 'bodyHTML': '<p>The bridge code is some of the oldest in the tree and desperately needs a rewrite.</p>\\n<p>This has already begun at: <a href=\"https://github.com/jcrussell/minimega/tree/bridge\">https://github.com/jcrussell/minimega/tree/bridge</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/303', 'state': 'CLOSED', 'createdAt': '2015-09-01T15:41:37Z', 'lastEditedAt': None, 'publishedAt': '2015-09-01T15:41:37Z', 'updatedAt': '2015-09-28T22:30:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: add web components for cc interface', 'bodyHTML': '<p>See summary. We\\'re not entirely sure what all this should include yet. Please discuss.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3037396\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jfktrey\">@jfktrey</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11760828\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jericks-sandia\">@jericks-sandia</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/306', 'state': 'CLOSED', 'createdAt': '2015-09-01T19:24:36Z', 'lastEditedAt': None, 'publishedAt': '2015-09-01T19:24:36Z', 'updatedAt': '2016-06-08T20:11:34Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: mouse/keyboard over cc?', 'bodyHTML': '<p>Wondering how this could be implemented. Thoughts? This would need to support at least linux and windows.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2590210\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/devinc\">@devinc</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/308', 'state': 'CLOSED', 'createdAt': '2015-09-01T19:26:29Z', 'lastEditedAt': None, 'publishedAt': '2015-09-01T19:26:29Z', 'updatedAt': '2015-09-21T14:51:12Z', 'labels': ['help wanted', 'question', 'wontfix'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'Update mac address in docs', 'bodyHTML': '<p>When you set mac addresses via minimega, it doesn\\'t warn that the mac address you are trying to use may not be usable by your os driver.</p>\\n<p>It just forces it and you will have no idea why it can\\'t get a dhcp lease. I was using 00:00:00:00:00:01, rookie mistake I know and it wouldn\\'t receive a dhcp lease, changing the mac address fixed it. Recently I was at a hotel and I connected via wifi. I wanted to not pay for wifi again so I tried to spoof the address onto my ethernet adapter, and it would refuse to set. Changing the ending number by one would let it set, but not connect. Lesson learned there are certain addresses where the operating system driver just says no.</p>\\n<p>We don\\'t have to warn users per se, but we should update the docs to use mac addresses that will likely work.<br>\\n\"vm config net 100,00:00:00:00:00:00 101,00:00:00:00:01:00 102,00:00:00:00:02:00\"<br>\\nWill likely not work depending on your os ethernet driver and dns server.</p>\\n<p>\"vm config net bridge0,100,00:11:22:33:44:55\" will likely cause issues too</p>\\n<p>Windows ethernet drivers tends to be more sensitive to their address. From what I read here Locally administered mac addresses start with x2, x6, xA, xE and multicast addresses of x3,x7,xF. So anything in those ranges are generally safe. <a href=\"http://serverfault.com/questions/40712/what-range-of-mac-addresses-can-i-safely-use-for-my-virtual-machines\" rel=\"nofollow\">http://serverfault.com/questions/40712/what-range-of-mac-addresses-can-i-safely-use-for-my-virtual-machines</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/322', 'state': 'CLOSED', 'createdAt': '2015-10-01T18:42:47Z', 'lastEditedAt': None, 'publishedAt': '2015-10-01T18:42:47Z', 'updatedAt': '2015-10-01T21:51:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: vnc port collisions ', 'bodyHTML': '<p>When launching VMs, if a network tap already exists that we want to allocate for a VM, we increment the tap name (mega_tapX) and try again until we find a tap name that isn\\'t in use.</p>\\n<p>We have a similar issue with the VNC port we ask qemu to use. By default we tell qemu to use 5900+. If a port happens to be in use (not uncommon for VNC), then we just mark the VM in the error state and give up. We should instead do something similar to the tap solution.</p>\\n<p>The best solution would be to check if the port is in use first (/proc/net/tcp and friends show this) and decouple the port&lt;-&gt;id map. Another solution would be to have qemu pick the port and then ask qemu what port it used (via qmp, a quick look doesn\\'t look like qemu has a qmp interface for this yet).</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=831629\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jcrussell\">@jcrussell</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/342', 'state': 'CLOSED', 'createdAt': '2015-10-22T22:00:26Z', 'lastEditedAt': None, 'publishedAt': '2015-10-22T22:00:26Z', 'updatedAt': '2016-08-03T21:13:41Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'container based router', 'bodyHTML': '<p>We need a fully opensource container router image that takes one or more configs for deployment. If we get something solid, we\\'ll tease out an API for it and replace the \\'vyatta\\' API with this.</p>\\n<p>I\\'d like:</p>\\n<ul>\\n<li>routing (ospf, ospf3, bgp, static)</li>\\n<li>dhcp with static ip options</li>\\n<li>optional static ips for all interfaces</li>\\n<li>dns</li>\\n<li>full ipv6 support everywhere</li>\\n<li>RAD/slaac support for v6</li>\\n<li>firewall (just iptables is fine)</li>\\n<li>snmp would be neat to have</li>\\n<li>centralized logging</li>\\n<li>some agent for making changes perhaps instead of a direct configs for all of the tools</li>\\n</ul>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=93811\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/floren\">@floren</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8174328\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bjwrigh\">@bjwrigh</a> thoughts?</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/344', 'state': 'CLOSED', 'createdAt': '2015-10-29T16:04:48Z', 'lastEditedAt': None, 'publishedAt': '2015-10-29T16:04:48Z', 'updatedAt': '2016-07-19T17:12:34Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'doc: update CC tutorial', 'bodyHTML': '<p>The <a href=\"http://minimega.org/articles/tutorials/cc.article\" rel=\"nofollow\">cc tutorial</a> is a bit out of date (e.g. cc is on by default now). Should update article accordingly.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/408', 'state': 'CLOSED', 'createdAt': '2016-01-22T18:34:15Z', 'lastEditedAt': None, 'publishedAt': '2016-01-22T18:34:15Z', 'updatedAt': '2016-03-21T23:04:26Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'web: make namespace-aware', 'bodyHTML': '<p>Should be able to have a dropdown in the page that allows you to select a namespace. Should then only see the hosts and VMs that belong to that namespace.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/474', 'state': 'CLOSED', 'createdAt': '2016-03-25T18:44:01Z', 'lastEditedAt': None, 'publishedAt': '2016-03-25T18:44:01Z', 'updatedAt': '2016-10-10T17:45:06Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'Web ui crashes chrome windows x64', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/5001991/15159265/24717b44-16b1-11e6-917e-587cbe2d7b27.PNG\"><img src=\"https://cloud.githubusercontent.com/assets/5001991/15159265/24717b44-16b1-11e6-917e-587cbe2d7b27.PNG\" alt=\"chrome error\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/524', 'state': 'CLOSED', 'createdAt': '2016-05-10T19:14:40Z', 'lastEditedAt': None, 'publishedAt': '2016-05-10T19:14:40Z', 'updatedAt': '2016-10-10T17:44:48Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: `disk partition` API', 'bodyHTML': \"<p>Add API to partition disks. Rewrite disk tests so that we don't shell out to parted.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/534', 'state': 'CLOSED', 'createdAt': '2016-05-13T20:20:23Z', 'lastEditedAt': None, 'publishedAt': '2016-05-13T20:20:23Z', 'updatedAt': '2017-01-19T16:57:26Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: update novnc vendorized code, re-implement tunnel to use new standard', 'bodyHTML': '<p>novnc used to use base64 encoded data over a websocket, now it does some other magic. <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"104964674\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/sandia-minimega/minimega/issues/315\" data-hovercard-type=\"issue\" data-hovercard-url=\"/sandia-minimega/minimega/issues/315/hovercard\" href=\"https://github.com/sandia-minimega/minimega/issues/315\">#315</a> discusses this.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/566', 'state': 'CLOSED', 'createdAt': '2016-06-08T20:18:53Z', 'lastEditedAt': None, 'publishedAt': '2016-06-08T20:18:53Z', 'updatedAt': '2016-09-13T21:16:57Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: `file delete .`', 'bodyHTML': \"<p>What's the canonical way to delete all files? I used <code>file delete .</code> and it deleted everything I wanted but it also deleted the files directory. Then, when I tried to send new files, minimega complains that the files directory does not exist. If the <code>file delete</code> API detects that the directory to delete is the files directory, it should skip it and just delete the contents.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/574', 'state': 'CLOSED', 'createdAt': '2016-06-13T20:29:20Z', 'lastEditedAt': None, 'publishedAt': '2016-06-13T20:29:20Z', 'updatedAt': '2016-10-10T20:51:32Z', 'labels': ['bug', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'protonuke: add IRC client', 'bodyHTML': \"<p>Hey guys, let's hear some chatter out there.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/622', 'state': 'CLOSED', 'createdAt': '2016-08-19T21:35:25Z', 'lastEditedAt': None, 'publishedAt': '2016-08-19T21:35:25Z', 'updatedAt': '2017-09-21T19:45:05Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega/ron/miniccc: change log level from cc', 'bodyHTML': \"<p>It would be convenient to be able to change <code>miniccc</code>'s log level from a <code>cc</code> API.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/705', 'state': 'CLOSED', 'createdAt': '2016-10-19T22:42:10Z', 'lastEditedAt': None, 'publishedAt': '2016-10-19T22:42:10Z', 'updatedAt': '2017-03-17T18:56:24Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minilog: elevate `logSetup`', 'bodyHTML': '<p>We have the same <code>logSetup</code> in almost every executable in the toolset. We should have <code>minilog</code> register the flags and then perform the actions currently in <code>logSetup</code> in <code>minilog.Init</code>.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/754', 'state': 'CLOSED', 'createdAt': '2016-11-11T17:54:48Z', 'lastEditedAt': None, 'publishedAt': '2016-11-11T17:54:48Z', 'updatedAt': '2016-12-22T16:07:29Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'minimega: vnc bug', 'bodyHTML': \"<p>It doesn't look like the last command in a recording is being executed.</p>\", 'url': 'https://github.com/sandia-minimega/minimega/issues/759', 'state': 'CLOSED', 'createdAt': '2016-11-14T18:51:33Z', 'lastEditedAt': None, 'publishedAt': '2016-11-14T18:51:33Z', 'updatedAt': '2016-11-30T20:48:21Z', 'labels': ['bug', 'help wanted', 'triage'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: ganglia-like view for host and VM stats', 'bodyHTML': '<p>Let\\'s do something like this:</p>\\n<p><a href=\"https://en.wikipedia.org/wiki/Ganglia_(software)#/media/File:ScalableGridEngineGanglia2.png\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Ganglia_(software)#/media/File:ScalableGridEngineGanglia2.png</a></p>\\n<p>for the host page on miniweb</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/857', 'state': 'CLOSED', 'createdAt': '2017-02-07T18:44:26Z', 'lastEditedAt': None, 'publishedAt': '2017-02-07T18:44:26Z', 'updatedAt': '2018-01-03T21:38:28Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: VM controls', 'bodyHTML': '<p>Add buttons to start/stop/kill/... VMs.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/872', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:32:53Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:32:53Z', 'updatedAt': '2017-09-25T19:57:18Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: upload/download files', 'bodyHTML': '<p>Add functionality to upload/download files to/from the <code>iomeshage</code> directory.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/873', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:33:54Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:33:54Z', 'updatedAt': '2018-01-03T19:53:11Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: world map', 'bodyHTML': '<p>In a previous incarnation, the web interface had a world map that would place VMs according to their tags. It would be nice to revive this.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/874', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:36:03Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:36:03Z', 'updatedAt': '2018-01-03T18:53:00Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: expose hotplug, cdrom APIs', 'bodyHTML': '<p>Similar to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"209217603\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/sandia-minimega/minimega/issues/872\" data-hovercard-type=\"issue\" data-hovercard-url=\"/sandia-minimega/minimega/issues/872/hovercard\" href=\"https://github.com/sandia-minimega/minimega/issues/872\">#872</a>, expose buttons to hotplug USB drives or CDROMs.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/875', 'state': 'CLOSED', 'createdAt': '2017-02-21T17:37:24Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T17:37:24Z', 'updatedAt': '2018-01-03T18:36:50Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'minimega', 'repo_owner_name': 'minimega', 'repo_owner_email': '', 'repo_owner_user_name': 'sandia-minimega', 'repo_owner_profile_url': 'https://github.com/sandia-minimega', 'title': 'miniweb: notes', 'bodyHTML': '<p>Have a tab on the website I can write notes to about an experiment. Some place to store passwords, tell people not to do certain things.<br>\\nList what needs to be done still.</p>', 'url': 'https://github.com/sandia-minimega/minimega/issues/916', 'state': 'CLOSED', 'createdAt': '2017-05-05T17:09:02Z', 'lastEditedAt': None, 'publishedAt': '2017-05-05T17:09:02Z', 'updatedAt': '2018-01-03T18:43:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'eavp', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'EAVP JAXB XML optimization', 'bodyHTML': \"<p>I'm starting a discussion about the XML used for our forthcoming JAXB support for the EAVP modeling data structures. I cannot attach an xml file directly and the formatting is messed up for xml when I try to insert it as text or code, so I'll send the list an example of a current BasicMesh with a few properties set and two children, although it is currently not working due to class casting issues from ElementNSImpl to IMeshCategory. One immediate way to clean this up would be to remove the previousTransformation, either from just the JAXB support or from IView entirely, as it is unused.</p>\", 'url': 'https://github.com/eclipse/eavp/issues/45', 'state': 'OPEN', 'createdAt': '2016-04-26T21:58:32Z', 'lastEditedAt': None, 'publishedAt': '2016-04-26T21:58:32Z', 'updatedAt': '2016-05-11T13:59:28Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'eavp', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Commit messages should be sent to the mailing list', 'bodyHTML': \"<p>When a developer commits to any of EAVP's branches, the commit message and list of edited paths should be forwarded to the mailing list at eavp-dev (at) eclipse (dot) org.</p>\", 'url': 'https://github.com/eclipse/eavp/issues/48', 'state': 'CLOSED', 'createdAt': '2016-05-04T15:17:11Z', 'lastEditedAt': None, 'publishedAt': '2016-05-04T15:17:11Z', 'updatedAt': '2016-05-18T15:19:51Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'eavp', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Implement ASCIISTLGeometryImporter in jay/model', 'bodyHTML': '<p>The jay/model branch contains new data structures for managing geometries. All of these data structures are based on an EMF model. This model also contains an IGeometryImporter interface. We need to implement this interface for ASCII-based STL files.</p>\\n<p>You can do this in the branch. The ASCIISTLGeometryImporterImpl.java class is already generated. Pay attention that:<br>\\n1.) You follow the instructions to prevent the operation from being overwritten, namely the comment \"// Ensure that you remove <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15230806\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/generated\">@generated</a> or mark it <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15230806\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/generated\">@generated</a> NOT.\" I prefer that you use <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15230806\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/generated\">@generated</a> NOT<br>\\n2.) You update the model, not the source code, with the default value for the description.<br>\\n3.) You figure out the proper way to fill the fileTypes array, and, preferably, mark it final so that it can\\'t be changed. This should also be done in the model.<br>\\n4.) Break up the import into multiple functions instead of putting all calls into load(). For example, you can have functions like createTriangleFromString() and loadShapes() that are called as part of load().</p>\\n<p>Any changes to the model will require regenerating the model and edit code. You should also generate tests for these bundles using the genmodel, and then implement a test for ASCIISTLGeometryImporterImpl.java.</p>', 'url': 'https://github.com/eclipse/eavp/issues/57', 'state': 'CLOSED', 'createdAt': '2016-06-10T12:58:10Z', 'lastEditedAt': None, 'publishedAt': '2016-06-10T12:58:10Z', 'updatedAt': '2016-08-10T12:59:47Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'eavp', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Need more documentation on IGES', 'bodyHTML': '<p>We will target the IGES format for the geometry editor next, which is described on Wikipedia:</p>\\n<p><a href=\"https://en.wikipedia.org/wiki/IGES\" rel=\"nofollow\">https://en.wikipedia.org/wiki/IGES</a></p>\\n<p>The full specification is here:</p>\\n<p><a href=\"http://diyhpl.us/~bryan/papers2/IGES5-3_forDownload.pdf\" rel=\"nofollow\">http://diyhpl.us/~bryan/papers2/IGES5-3_forDownload.pdf</a></p>\\n<p>This is a very simple format for which we can use Xtext, but we need to understand all the pieces first. Here is the sample from Wikipedia:</p>\\n<pre><code>                                                                        S      1\\n1H,,1H;,4HSLOT,37H$1$DUA2:[IGESLIB.BDRAFT.B2I]SLOT.IGS;,                G      1\\n17HBravo3 BravoDRAFT,31HBravo3-&gt;IGES V3.002 (02-Oct-87),32,38,6,38,15,  G      2\\n4HSLOT,1.,1,4HINCH,8,0.08,13H871006.192927,1.E-06,6.,                   G      3\\n31HD. A. Harrod, Tel. 313/995-6333,24HAPPLICON - Ann Arbor, MI,4,0;     G      4\\n     116       1       0       1       0       0       0       0       1D      1\\n     116       1       5       1       0                               0D      2\\n     116       2       0       1       0       0       0       0       1D      3\\n     116       1       5       1       0                               0D      4\\n     100       3       0       1       0       0       0       0       1D      5\\n     100       1       2       1       0                               0D      6\\n     100       4       0       1       0       0       0       0       1D      7\\n     100       1       2       1       0                               0D      8\\n     110       5       0       1       0       0       0       0       1D      9\\n     110       1       3       1       0                               0D     10\\n     110       6       0       1       0       0       0       0       1D     11\\n     110       1       3       1       0                               0D     12\\n116,0.,0.,0.,0,0,0;                                                    1P      1\\n116,5.,0.,0.,0,0,0;                                                    3P      2\\n100,0.,0.,0.,0.,1.,0.,-1.,0,0;                                         5P      3\\n100,0.,5.,0.,5.,-1.,5.,1.,0,0;                                         7P      4\\n110,0.,-1.,0.,5.,-1.,0.,0,0;                                           9P      5\\n110,0.,1.,0.,5.,1.,0.,0,0;                                            11P      6\\nS      1G      4D     12P      6                                        T      1\\n\\'\\'\\'\\n\\nWhat is each piece of this? For example, in the first part, after 116, 100, or 110, what are the integers? What are the floats after the same numbers at the bottom? Please document all of the pieces of this file so that we can run them through Xtext. \\n\\n</code></pre>', 'url': 'https://github.com/eclipse/eavp/issues/58', 'state': 'OPEN', 'createdAt': '2016-06-10T13:02:38Z', 'lastEditedAt': None, 'publishedAt': '2016-06-10T13:02:38Z', 'updatedAt': '2016-06-22T13:33:42Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'eavp', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'EAVP Xtext plugins contain binary files', 'bodyHTML': \"<p>Jonah Graham pointed out that some binary files that shouldn't have been committed are in the new geometry model bundle for both the EMF model and the Xtext code. He is going to issue a pull request to fix this.</p>\", 'url': 'https://github.com/eclipse/eavp/issues/73', 'state': 'CLOSED', 'createdAt': '2016-07-06T21:18:51Z', 'lastEditedAt': None, 'publishedAt': '2016-07-06T21:18:51Z', 'updatedAt': '2016-07-07T14:23:36Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'eavp', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Adding Extensions in new packages', 'bodyHTML': \"<p>I'm having trouble accessing extension points in a new package. The problem can be reproduced by copying the TabDescriptorProvider from org.eclipse.eavp.viz.service.mesh.properties to a new package, such as org.eclipse.eavp.viz.service.geometry.properties, exporting the new package, and changing the extension point in org.eclipse.ice.client.widgets to point to the new file. Note that there are two extension points pointing to TabDescriptorProvider in the file, the second of which doesn't seem to affect anything. The extension doesn't seem to be picked up and the properties view is blank.</p>\\n<p>By contrast, creating a copy in org.eclipse.eavp.viz.service.geometry.widgets, which already exists, and pointing to it works fine. This makes me think that there's something I need to do to set the package up other than just exporting it, but I can't figure out what.</p>\", 'url': 'https://github.com/eclipse/eavp/issues/123', 'state': 'CLOSED', 'createdAt': '2016-08-23T17:52:28Z', 'lastEditedAt': None, 'publishedAt': '2016-08-23T17:52:28Z', 'updatedAt': '2016-08-23T18:33:32Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Output from analysis tools should be a user friendly format', 'bodyHTML': '<p>The products of the analysis framework should be packaged in an easily usable (e.g. NetCDF / ASCII) / viewable format. (e.g. HTML file).</p>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/21', 'state': 'CLOSED', 'createdAt': '2016-09-15T17:33:30Z', 'lastEditedAt': None, 'publishedAt': '2016-09-15T17:33:30Z', 'updatedAt': '2017-09-13T07:01:24Z', 'labels': ['help wanted', 'priority', 'solution under review', 'sub-ice-shelf'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'develop branch', 'bodyHTML': '<p>I went ahead and created a <code>develop</code> branch and made it the default for this repo.  However, this deserves discussion and buy-in from everyone involved in this repo.  This issue page is meant to allow us to discuss any cons and to make sure everyone knows what changes were made and why.</p>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/39', 'state': 'CLOSED', 'createdAt': '2016-10-27T07:20:12Z', 'lastEditedAt': None, 'publishedAt': '2016-10-27T07:20:12Z', 'updatedAt': '2016-11-01T17:24:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Analysis task for SSH variability', 'bodyHTML': '<p>Our Quarter 1 metric for MPAS Ocean for FY 2018 is the variability of sea-surface height.  This is an issue to remind us that this needs to be completed and reported on by Dec. 15th (exactly 3 weeks from today).</p>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/278', 'state': 'OPEN', 'createdAt': '2017-11-24T16:24:17Z', 'lastEditedAt': '2017-11-26T17:24:53Z', 'publishedAt': '2017-11-24T16:24:17Z', 'updatedAt': '2018-01-14T16:02:31Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Checklist for v0.8.0', 'bodyHTML': '<p>To do:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add support for online MOC</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Break MOC into separate tasks for climatology and time series</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Support comparison with ref in MOC time series</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Make line colors consistent for main, ref, v0 and obs in time series and MHT plots</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Task for MLD and KE comparison with SOSE</p>\\n</li>\\n<li class=\"task-list-item\">\\n<p><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> ...</p>\\n</li>\\n</ul>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/303', 'state': 'CLOSED', 'createdAt': '2018-01-26T18:00:58Z', 'lastEditedAt': '2018-01-26T18:02:32Z', 'publishedAt': '2018-01-26T18:00:58Z', 'updatedAt': '2018-05-03T15:20:21Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Make line colors consistent for main, ref, v0 and obs in time series and MHT plots', 'bodyHTML': '<p>The color choices for the main, reference, v0 and observations on different line plots is not consistent:<br>\\nmain in black, ref in blue (v0 in red, not shown):<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4179064/39585078-3821c9c8-4ef4-11e8-8f81-5461bf2e56be.png\"><img src=\"https://user-images.githubusercontent.com/4179064/39585078-3821c9c8-4ef4-11e8-8f81-5461bf2e56be.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>main in red, ref in black, obs in blue and green:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4179064/39961961-56123de6-5642-11e8-90b8-86d0b8235d32.png\"><img src=\"https://user-images.githubusercontent.com/4179064/39961961-56123de6-5642-11e8-90b8-86d0b8235d32.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>main in black, obs in blue and red, ref in green:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4179064/39961964-657ea72e-5642-11e8-8f78-5fc0a0da297b.png\"><img src=\"https://user-images.githubusercontent.com/4179064/39961964-657ea72e-5642-11e8-8f78-5fc0a0da297b.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>I would propose we always use:</p>\\n<ul>\\n<li>main in black</li>\\n<li>first obs in blue</li>\\n<li>second obs in green</li>\\n<li>third obs in cyan (not currently needed)</li>\\n<li>ref run in red</li>\\n<li>v0 run in purple</li>\\n</ul>\\n<p>If anyone on the team has experience with making lines friendly for the color blind, I would appreciate input.</p>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/351', 'state': 'CLOSED', 'createdAt': '2018-05-03T15:17:54Z', 'lastEditedAt': '2018-05-12T22:13:04Z', 'publishedAt': '2018-05-03T15:17:54Z', 'updatedAt': '2018-05-16T15:25:41Z', 'labels': ['clean up', 'help wanted', 'priority', 'solution under review'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Should we add a hovmoller plot of the AMOC at 26.5?', 'bodyHTML': \"<p>...or do we just want  a line plot so it's easier to compare with obs?</p>\", 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/403', 'state': 'OPEN', 'createdAt': '2018-05-22T20:32:37Z', 'lastEditedAt': None, 'publishedAt': '2018-05-22T20:32:37Z', 'updatedAt': '2018-05-30T22:07:22Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Use of \"refField*\" for both observations and reference runs is confusing', 'bodyHTML': '<p>In analysis subtasks (and subsequently plotting subtasks), it is confusing that the variable <code>refFieldName</code> and <code>refTitleLabel</code> is used for both reference runs and observations. It would seem that it should only be applied to the former, given <code>refConfig</code> is used for configuration options for a reference run.</p>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/424', 'state': 'OPEN', 'createdAt': '2018-06-26T18:45:10Z', 'lastEditedAt': None, 'publishedAt': '2018-06-26T18:45:10Z', 'updatedAt': '2018-11-07T16:47:22Z', 'labels': ['clean up', 'help wanted', 'priority'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'MPAS-Analysis', 'repo_owner_name': 'MPAS-Dev', 'repo_owner_email': '', 'repo_owner_user_name': 'MPAS-Dev', 'repo_owner_profile_url': 'https://github.com/MPAS-Dev', 'title': 'Version 1.1', 'bodyHTML': '<p>Checklist for the release:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Entry point - <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378563007\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/477\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/477/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/477\">#477</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Python 3.7 - <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378593124\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/479\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/479/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/479\">#479</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Remove depricated functions - <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378593437\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/480\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/480/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/480\">#480</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Updates to timeSeriesAntarcticMelt and generating masks <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379575868\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/482\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/482/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/482\">#482</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379585619\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/483\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/483/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/483\">#483</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Fix artifacts in BGC obs plots <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379628590\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/486\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/486/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/486\">#486</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Double check the docs, including authors list, add image for BGC run <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379609258\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/485\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/485/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/485\">#485</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Update version number to 1.1 - <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378563007\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/477\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/477/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/477\">#477</a></li>\\n</ul>\\n<p>Here\\'s a draft release message for v1.1:</p>\\n<p>Highlights include analysis of surface biogeochemistry,  eddy kinetic energy and iceberg concentration as well as enhancement of transect plots.</p>\\n<h3>Major Enhancements</h3>\\n<ul>\\n<li>Lat and lon axes for transect plots <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"342129835\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/437\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/437/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/437\">#437</a></li>\\n<li>Task to plot iceberg concentration <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"308058594\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/320\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/320/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/320\">#320</a></li>\\n<li>Task for surface climatology maps of ocean biogeochemistry fields <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"338018814\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/433\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/433/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/433\">#433</a></li>\\n<li>Transect contour plots <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"346409010\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/450\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/450/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/450\">#450</a></li>\\n<li>Eddy Kinetic Energy (EKE) climatology analysis <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"345027053\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/447\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/447/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/447\">#447</a></li>\\n</ul>\\n<h3>Minor Enhancements</h3>\\n<ul>\\n<li>Added a utility for making an MPAS to Antarctic mapping file <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"344905202\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/446\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/446/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/446\">#446</a></li>\\n<li>Updated the location, depth and seasons for SOSE transects <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"376627079\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/462\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/462/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/462\">#462</a></li>\\n<li>Added climatologyMapBGC to docs <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"377671255\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/471\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/471/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/471\">#471</a></li>\\n<li>Switched to using an entry point for the mpas_analysis package <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378563007\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/477\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/477/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/477\">#477</a></li>\\n<li>Added a subtask for computing region masks on the fly <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379575868\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/482\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/482/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/482\">#482</a></li>\\n<li>Split TimeSeriesAntarcticMelt into multiple subtasks <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379585619\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/483\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/483/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/483\">#483</a></li>\\n</ul>\\n<h3>Minor clean-up</h3>\\n<ul>\\n<li>Disabled HDF5 locking in example job scripts <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"343263677\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/443\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/443/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/443\">#443</a></li>\\n<li>Updated license file <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"344612762\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/444\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/444/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/444\">#444</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"345872586\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/448\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/448/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/448\">#448</a></li>\\n<li>Refactored BGC so it is one task, not one per field <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"347173875\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/453\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/453/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/453\">#453</a></li>\\n<li>Updated the list of public observations <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"354026201\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/456\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/456/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/456\">#456</a></li>\\n<li>Removed depricated inplace arg to xarray ds rename calls <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378593437\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/480\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/480/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/480\">#480</a></li>\\n<li>Clean up documentation <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379609258\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/485\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/485/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/485\">#485</a></li>\\n</ul>\\n<h3>Bug fixes</h3>\\n<ul>\\n<li>Bug fix in climatology anomalyRefYear <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"342884797\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/442\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/442/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/442\">#442</a></li>\\n<li>Bug fix in interpolating transect segments <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"342839675\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/439\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/439/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/439\">#439</a></li>\\n<li>Fixed error reporting on tasks <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"346397030\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/449\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/449/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/449\">#449</a></li>\\n<li>Updated observations XML for EKE <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"349703392\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/454\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/454/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/454\">#454</a></li>\\n<li>Fixed some errors and warnings that come up during CI <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"376949673\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/465\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/465/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/465\">#465</a></li>\\n<li>Fixed Read The Docs and updated to python 3.6  <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"377450595\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/466\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/466/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/466\">#466</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"377453729\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/467\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/467/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/467\">#467</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"377489319\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/469\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/469/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/469\">#469</a></li>\\n<li>Fixed detecting periodic lat/lon descriptors <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378301151\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/475\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/475/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/475\">#475</a></li>\\n<li>Explicitly set colormap type (indexed or continuous) in config options <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378043394\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/473\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/473/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/473\">#473</a></li>\\n<li>Fixed CI under python 2 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378568936\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/478\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/478/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/478\">#478</a></li>\\n<li>Update to CI to python 3.7 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378593124\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/479\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/479/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/479\">#479</a></li>\\n<li>Add periodic image to BGC obs data <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379628590\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/MPAS-Dev/MPAS-Analysis/issues/486\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/MPAS-Dev/MPAS-Analysis/pull/486/hovercard\" href=\"https://github.com/MPAS-Dev/MPAS-Analysis/pull/486\">#486</a></li>\\n</ul>', 'url': 'https://github.com/MPAS-Dev/MPAS-Analysis/issues/481', 'state': 'OPEN', 'createdAt': '2018-11-10T20:59:35Z', 'lastEditedAt': '2018-11-15T20:47:07Z', 'publishedAt': '2018-11-10T20:59:35Z', 'updatedAt': '2018-11-15T20:47:07Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Target Resolution for Linux computers', 'bodyHTML': '<p>This problem has been effecting me for a while, but it\\'s now interfering with one of the last steps on getting the JavaFX branch building. When I try to resolve mars.target on my Linux machines, I get the error message</p>\\n<p>Problems occurred while resolving the target contents<br>\\nAn error occurred while configuring the installed items<br>\\nPreference node \"http:_download.eclipse.org_tools_cdt_releases_8.7\" has been removed.<br>\\nsession context was:(profile=TARGET_DEFINITION:resource:/org.eclipse.ice.target.mars/mars.target, phase=org.eclipse.equinox.internal.p2.engine.phases.Configure, operand=null --&gt; [R]org.eclipse.cdt.feature.group 8.7.0.201506070905, action=org.eclipse.equinox.internal.p2.touchpoint.eclipse.actions.AddRepositoryAction)</p>\\n<p>This happens regardless of where in ICE I try to open the target from or what version of ICE I\\'m using, including the most recent unstable nightly. Once it occurs on a machine, it effects every instance of ICE on it.</p>', 'url': 'https://github.com/eclipse/ice/issues/85', 'state': 'CLOSED', 'createdAt': '2016-01-20T13:56:47Z', 'lastEditedAt': None, 'publishedAt': '2016-01-20T13:56:47Z', 'updatedAt': '2016-01-23T02:11:47Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Client Thread creation refactor', 'bodyHTML': '<p>Currently, the Client\\'s processItem function is creating and running a thread while having no way to synchronize with it. This is causing build failures in ClientTester (part of Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"141008743\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/eclipse/ice/issues/176\" data-hovercard-type=\"issue\" data-hovercard-url=\"/eclipse/ice/issues/176/hovercard\" href=\"https://github.com/eclipse/ice/issues/176\">#176</a> ). Alex and I discussed the problem, and propose that Client be refactored to take a thread creation factory. In real cases, this new factory class will function identically to Client\\'s current code, but it will allow us to inject a fake thread factory which does not actually launch any new threads for use with test classes.</p>\\n<p>Since this plan would modify a core part of ICE\\'s API, we thought it would be best to open an issue for discussion on how to deal with this test failure.</p>', 'url': 'https://github.com/eclipse/ice/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-24T19:00:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-24T19:00:24Z', 'updatedAt': '2016-05-09T02:44:04Z', 'labels': ['build issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'XMLPersistenceProvider queue synchronization', 'bodyHTML': '<p>The XMLPersistenceProvider currently lacks a way to test if it has any unfinished tasks either queued or undergoing processing. This means that there is no way for the test class XMLPersistenceProviderTester to check whether assigned tasks are completed before, for example, trying to read a written file, in turn causing test failures (part of Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"141008743\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/eclipse/ice/issues/176\" data-hovercard-type=\"issue\" data-hovercard-url=\"/eclipse/ice/issues/176/hovercard\" href=\"https://github.com/eclipse/ice/issues/176\">#176</a> ). Creating a Boolean variable and naively setting it to false at the beginning of the provider\\'s run loop if the Queue is empty failed, and so Alex and I decided to open this issue for discussion on how to have the provider correctly alert other classes to its current status.</p>', 'url': 'https://github.com/eclipse/ice/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-24T19:10:27Z', 'lastEditedAt': None, 'publishedAt': '2016-03-24T19:10:27Z', 'updatedAt': '2016-03-24T19:10:27Z', 'labels': ['build issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'ICE download page serving wrong version', 'bodyHTML': \"<p>Today I downloaded ICE binaries from download.eclipse.org/ice/builds/next for both Mac and Windows, and I've noticed several regressions from ICE both as launched from a run configuration and from previous binaries downloaded from the same page on 4/18. This can be seen from the Developer Menu missing EAVP under Framework and a compilation error from org.bouncycastle.openssl not being in the default target platform, among others. I think these might be copies of binaries from ICE master or an earlier version of next.</p>\", 'url': 'https://github.com/eclipse/ice/issues/194', 'state': 'CLOSED', 'createdAt': '2016-04-22T16:48:49Z', 'lastEditedAt': None, 'publishedAt': '2016-04-22T16:48:49Z', 'updatedAt': '2016-05-11T21:48:33Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'ICE build cannot download required plugins', 'bodyHTML': '<p>The ICE build is currently unable to download all of its required maven plugins. Current builds are working only because of pre-downloaded plugins from previous working builds in our .m2 folders. In order to reproduce the bug, delete your computer\\'s .m2 repository (be sure to back it up first), then clone a new version of ICE.</p>\\n<p>I have a partial fix that addresses the problem of the tycho-maven-plugin no longer being available from the Eclipse CBI repository. However, it required me changing to the Tycho 0.26.0-SNAPSHOT build because I couldn\\'t find a stable repo for 0.24.0 and the 0.24.0-SNAPSHOT is giving me an error when I try to use it. You can see it on the Robert/Build-Fix branch. If you get build errors related to the maven-plugin-api, try to clean the project and restart ICE. I\\'m still getting errors for other plug-ins, which I\\'m working on.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6378849\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jayjaybillings\">@jayjaybillings</a> I\\'m assigning this to you just to ask about the feasibility of changing our Tycho version, or if I just need to find a working repo for the 0.24.0 version, as I still intend to keep working on this myself unless I hear otherwise.</p>', 'url': 'https://github.com/eclipse/ice/issues/205', 'state': 'CLOSED', 'createdAt': '2016-05-17T21:36:41Z', 'lastEditedAt': None, 'publishedAt': '2016-05-17T21:36:41Z', 'updatedAt': '2016-05-19T18:47:46Z', 'labels': ['build issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Update ICE to Neon', 'bodyHTML': '', 'url': 'https://github.com/eclipse/ice/issues/222', 'state': 'CLOSED', 'createdAt': '2016-07-07T12:17:20Z', 'lastEditedAt': None, 'publishedAt': '2016-07-07T12:17:20Z', 'updatedAt': '2016-07-12T22:11:31Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Find LAMMPS example', 'bodyHTML': '<p>Identify a LAMPS example for the ADIOS in situ visualization work.</p>', 'url': 'https://github.com/eclipse/ice/issues/267', 'state': 'OPEN', 'createdAt': '2016-09-20T16:20:36Z', 'lastEditedAt': None, 'publishedAt': '2016-09-20T16:20:36Z', 'updatedAt': '2016-10-14T11:58:14Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Test Parallel Job Launch for Oomph installation', 'bodyHTML': '<p>The Oomph installed version of ICE needs to be checked to see if the parallel job launching functionality is working.</p>\\n<p>This can be done by running the Eclipse Installer, changing to Advanced Mode, selecting Eclipse for RCP and RAP Development, and hitting next. On this screen, download the ICE Oomph profile from <a href=\"https://raw.githubusercontent.com/eclipse/ice/master/org.eclipse.ice.aggregator/ICE.setup\" rel=\"nofollow\">https://raw.githubusercontent.com/eclipse/ice/master/org.eclipse.ice.aggregator/ICE.setup</a> and drag and drop it into the list of Eclipse Projects, then select the new ICE option and follow the rest of the prompts.</p>', 'url': 'https://github.com/eclipse/ice/issues/275', 'state': 'OPEN', 'createdAt': '2016-10-19T18:00:41Z', 'lastEditedAt': None, 'publishedAt': '2016-10-19T18:00:41Z', 'updatedAt': '2016-10-19T18:00:41Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'ICE Next blank Workspace Error notifying preference change listener', 'bodyHTML': '<p>Currently for our unstable build, starting a new instance of ICE with a new workspace displays error at startup (see picture). It says \\'Error notifying preference change listener. NullPointerException\\' Here\\'s the log:</p>\\n<pre lang=\"code\"><code>java.lang.NullPointerException\\n        at org.eclipse.mylyn.internal.tasks.ui.TasksUiPlugin$2.propertyChange(TasksUiPlugin.java:296)\\n        at org.eclipse.ui.preferences.ScopedPreferenceStore$3.run(ScopedPreferenceStore.java:350)\\n        at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)\\n        at org.eclipse.ui.preferences.ScopedPreferenceStore.firePropertyChangeEvent(ScopedPreferenceStore.java:346)\\n        at org.eclipse.ui.preferences.ScopedPreferenceStore.setValue(ScopedPreferenceStore.java:658)\\n        at org.eclipse.mylyn.internal.tasks.ui.TasksUiPlugin$TasksUiInitializationJob.hideNonMatchingSubtasks(TasksUiPlugin.java:418)\\n        at org.eclipse.mylyn.internal.tasks.ui.TasksUiPlugin$TasksUiInitializationJob.runInUIThread(TasksUiPlugin.java:406)\\n        at org.eclipse.ui.progress.UIJob$1.run(UIJob.java:97)\\n        at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:37)\\n        at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:182)\\n        at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4033)\\n        at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3700)\\n        at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1133)\\n        at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)\\n        at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1022)\\n        at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)\\n        at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:698)\\n        at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)\\n        at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:610)\\n        at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)\\n        at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:138)\\n        at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\\n        at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)\\n        at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)\\n        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)\\n        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)\\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n        at java.lang.reflect.Method.invoke(Method.java:498)\\n        at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:673)\\n        at org.eclipse.equinox.launcher.Main.basicRun(Main.java:610)\\n        at org.eclipse.equinox.launcher.Main.run(Main.java:1519)\\n</code></pre>\\n<p>This is high priority - issue VIBE currently has is fixed in next. With this fixed we can ship off ICE to them for their VM.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/827531/21024349/2705016c-bd52-11e6-899a-75ee47a48f2a.png\"><img src=\"https://cloud.githubusercontent.com/assets/827531/21024349/2705016c-bd52-11e6-899a-75ee47a48f2a.png\" alt=\"screen shot 2016-12-08 at 2 03 33 pm\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/eclipse/ice/issues/310', 'state': 'OPEN', 'createdAt': '2016-12-08T19:25:05Z', 'lastEditedAt': '2016-12-08T19:25:23Z', 'publishedAt': '2016-12-08T19:25:05Z', 'updatedAt': '2016-12-08T23:02:28Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'On Fedora 25 importing local repository to ICE generated 65 errors', 'bodyHTML': '<p>One of the errors is about incomplete build path (or simply not referencing it properly). This issue could probably be about misconfigured project.</p>', 'url': 'https://github.com/eclipse/ice/issues/319', 'state': 'CLOSED', 'createdAt': '2017-01-25T20:07:29Z', 'lastEditedAt': None, 'publishedAt': '2017-01-25T20:07:29Z', 'updatedAt': '2017-01-26T18:54:52Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Add tutorial for general new users', 'bodyHTML': '<p>All of our current tutorial materials (e.g. for XSEDE), are written from the assumption that the reader will have our tutorial specific version of ICE with all required data files and programs and a pre-populated workspace on one of our USB sticks.</p>\\n<p>We need a more universal tutorial that explains to someone on their own computer and using nothing but generally available resources online how to download ICE, import the repo, download third party programs like VisIt, etc. so that we have somewhere to point people who want to get started with the latest version of ICE instead of whatever we had prepared the last time we did a formal tutorial.</p>', 'url': 'https://github.com/eclipse/ice/issues/320', 'state': 'OPEN', 'createdAt': '2017-01-25T20:38:09Z', 'lastEditedAt': None, 'publishedAt': '2017-01-25T20:38:09Z', 'updatedAt': '2017-01-25T20:38:09Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Proposed updates to Build/Deployment scheme for ICE', 'bodyHTML': '<p>ICE Devs,</p>\\n<p>Will you please tell me what you think about this proposed new build layout for ICE (see picture)? Right now our current build process is murderously monolithic. I feel like breaking it up will let us do two things better:</p>\\n<ol>\\n<li>Work on various parts of the code without fussing with the other parts (no more importing all of ICE to work on a few bundles)</li>\\n<li>Carve up the source tree so that we can create new minimal, headless, and Vaadin-based products without creating an even longer and more complicated build.</li>\\n</ol>\\n<p>Any thoughts?</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6378849/26416717/d94ffb14-4084-11e7-8cf3-5392eb3c575b.jpg\"><img src=\"https://cloud.githubusercontent.com/assets/6378849/26416717/d94ffb14-4084-11e7-8cf3-5392eb3c575b.jpg\" alt=\"ice_proposed_build_20170524\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/eclipse/ice/issues/372', 'state': 'OPEN', 'createdAt': '2017-05-24T17:30:58Z', 'lastEditedAt': None, 'publishedAt': '2017-05-24T17:30:58Z', 'updatedAt': '2017-05-25T18:21:35Z', 'labels': ['enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Checked attribute in \"Discount point  and credits\" radio buttons', 'bodyHTML': '<p>can we give the selected radio button the attribute checked=\"checked\"?<br>\\nRight now element \"discount-zero-a\" always has checked=\"checked\"</p>\\n<p>When I click a different radio button, example: \"discount-three-a\",, then the only element with attribute checked=\"checked\" should be \"discount-three-a\"</p>\\n<p>This would make the browser tests easier to code</p>', 'url': 'https://github.com/cfpb/owning-a-home/issues/125', 'state': 'OPEN', 'createdAt': '2014-09-25T17:44:52Z', 'lastEditedAt': None, 'publishedAt': '2014-09-25T17:44:52Z', 'updatedAt': '2015-05-15T16:30:04Z', 'labels': ['dev', 'enhancement', 'help wanted', 'javascript', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Loan type dropdown on rate checker is too narrow', 'bodyHTML': '<p>In some cases the text in the loan checker is too long for the width of the loan type dropdown:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/704760/5905916/b0728b32-a561-11e4-8fae-c92fa45a7fdf.png\"><img src=\"https://cloud.githubusercontent.com/assets/704760/5905916/b0728b32-a561-11e4-8fae-c92fa45a7fdf.png\" alt=\"screen shot 2015-01-26 at 1 38 52 pm\" style=\"max-width:100%;\"></a></p>\\n<p>Consider making the loan type dropdown double the width of the other dropdowns. There appears to be space:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/704760/5905931/d1fe8c56-a561-11e4-8478-a9971fb6e6c8.png\"><img src=\"https://cloud.githubusercontent.com/assets/704760/5905931/d1fe8c56-a561-11e4-8478-a9971fb6e6c8.png\" alt=\"screen shot 2015-01-26 at 1 45 10 pm\" style=\"max-width:100%;\"></a></p>\\n<p>Or truncate the text in the dropdown with an ellipsis when dropdown is not selected.</p>', 'url': 'https://github.com/cfpb/owning-a-home/issues/316', 'state': 'OPEN', 'createdAt': '2015-01-26T18:47:40Z', 'lastEditedAt': None, 'publishedAt': '2015-01-26T18:47:40Z', 'updatedAt': '2015-05-15T15:04:11Z', 'labels': ['bug', 'dev', 'help wanted'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Install elasticsearch needed in Readme installation instructions?', 'bodyHTML': '<p>Are ElasticSearch installation instructions needed in <a href=\"https://github.com/cfpb/owning-a-home#sheer--ElasticSearch\">https://github.com/cfpb/owning-a-home#sheer--ElasticSearch</a> in order to run OAH? After installation nothing is done with ElasticSearch.</p>', 'url': 'https://github.com/cfpb/owning-a-home/issues/328', 'state': 'OPEN', 'createdAt': '2015-02-05T19:34:01Z', 'lastEditedAt': None, 'publishedAt': '2015-02-05T19:34:01Z', 'updatedAt': '2015-05-15T15:03:18Z', 'labels': ['bug', 'dev', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Overlapping text', 'bodyHTML': '<p>This only seem to happen if it reaches to 10 or more lenders.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/2673022/7616134/4891e50e-f970-11e4-9eee-984075d2dddf.png\"><img src=\"https://cloud.githubusercontent.com/assets/2673022/7616134/4891e50e-f970-11e4-9eee-984075d2dddf.png\" alt=\"screen shot 2015-05-13 at 1 00 18 pm\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/cfpb/owning-a-home/issues/433', 'state': 'CLOSED', 'createdAt': '2015-05-13T17:08:08Z', 'lastEditedAt': None, 'publishedAt': '2015-05-13T17:08:08Z', 'updatedAt': '2016-11-10T17:08:24Z', 'labels': ['bug', 'css', 'dev', 'entry level', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Loan Options print styles', 'bodyHTML': '<p>The <a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/\" rel=\"nofollow\">Loan Options</a> pages could use some print CSS love.</p>\\n<p>Pages in this section include:</p>\\n<ul>\\n<li><a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/\" rel=\"nofollow\">Loan Options landing</a></li>\\n<li><a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/conventional-loans/\" rel=\"nofollow\">Conventional loans</a></li>\\n<li><a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/FHA-loans/\" rel=\"nofollow\">FHA Loans</a></li>\\n<li><a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/special-loan-programs/\" rel=\"nofollow\">Special Loan Programs</a></li>\\n</ul>\\n<p>There are some guidelines for print styles being discussed here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"57642278\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/cfpb/design-manual/issues/281\" data-hovercard-type=\"issue\" data-hovercard-url=\"/cfpb/design-manual/issues/281/hovercard\" href=\"https://github.com/cfpb/design-manual/issues/281\">cfpb/design-manual#281</a></p>', 'url': 'https://github.com/cfpb/owning-a-home/issues/436', 'state': 'CLOSED', 'createdAt': '2015-05-15T16:02:57Z', 'lastEditedAt': None, 'publishedAt': '2015-05-15T16:02:57Z', 'updatedAt': '2016-11-07T16:22:22Z', 'labels': ['css', 'design', 'dev', 'enhancement', 'entry level', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Explore interest rates print styles', 'bodyHTML': '<p>The <a href=\"http://www.consumerfinance.gov/owning-a-home/check-rates/\" rel=\"nofollow\">Explore interest rates </a> page could use some print CSS love.</p>\\n<p>There are some guidelines for print styles being discussed here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"57642278\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/cfpb/design-manual/issues/281\" data-hovercard-type=\"issue\" data-hovercard-url=\"/cfpb/design-manual/issues/281/hovercard\" href=\"https://github.com/cfpb/design-manual/issues/281\">cfpb/design-manual#281</a></p>', 'url': 'https://github.com/cfpb/owning-a-home/issues/437', 'state': 'CLOSED', 'createdAt': '2015-05-15T16:07:57Z', 'lastEditedAt': None, 'publishedAt': '2015-05-15T16:07:57Z', 'updatedAt': '2016-11-07T16:22:37Z', 'labels': ['css', 'design', 'dev', 'enhancement', 'entry level', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Closing checklist webpage', 'bodyHTML': '<p>We currently provide a <a href=\"http://www.consumerfinance.gov/owning-a-home/resources/checklist_mortgage_closing.pdf\" rel=\"nofollow\">Closing Checklist PDF</a> for download.</p>\\n<p>We\\'d like to create a design and functional prototype that converts this PDF into a webpage, which would live at <a href=\"http://www.consumerfinance.gov/owning-a-home/closing-checklist/\" rel=\"nofollow\">http://www.consumerfinance.gov/owning-a-home/closing-checklist/</a> or a similar URL inside the Owning a Home project.</p>\\n<p>Steps for getting this done might be:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Create a page template in Owning a Home and add the PDF content.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Determine which layout styles to use for this page: likely similar to the <a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/\" rel=\"nofollow\">Loan Options page</a> layout, or using <a href=\"https://github.com/cfpb/cf-layout\">Capital Framework</a>.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add checklist/form functionality - likely using <a href=\"https://github.com/cfpb/owning-a-home/pull/434\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/cfpb/owning-a-home/pull/434/hovercard\">React</a>.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add link + callout for users to download the PDF.</li>\\n</ul>', 'url': 'https://github.com/cfpb/owning-a-home/issues/438', 'state': 'OPEN', 'createdAt': '2015-05-15T16:21:41Z', 'lastEditedAt': None, 'publishedAt': '2015-05-15T16:21:41Z', 'updatedAt': '2015-05-15T16:29:00Z', 'labels': ['css', 'design', 'dev', 'enhancement', 'entry level', 'help wanted', 'html', 'javascript'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'owning-a-home', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Budgeting Worksheet webpage', 'bodyHTML': '<p>We\\'ll soon provide a Budgeting Worksheet PDF for users to download and complete in their preparation for shopping for a mortgage.</p>\\n<p>We\\'d like to create a design and functional prototype that converts this PDF into a responsive webpage, which would live at <a href=\"http://www.consumerfinance.gov/owning-a-home/budget-worksheet/\" rel=\"nofollow\">http://www.consumerfinance.gov/owning-a-home/budget-worksheet/</a> or a similar URL inside the Owning a Home project.</p>\\n<p>Steps for getting this done might be:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Create a page template in Owning a Home and add the PDF content.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Determine which layout styles to use for this page: likely similar to the <a href=\"http://www.consumerfinance.gov/owning-a-home/loan-options/\" rel=\"nofollow\">Loan Options page</a> layout, or using <a href=\"https://github.com/cfpb/cf-layout\">Capital Framework</a>.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add checklist/form functionality - likely using <a href=\"https://github.com/cfpb/owning-a-home/pull/434\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/cfpb/owning-a-home/pull/434/hovercard\">React</a>.</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add link + callout for users to download the PDF to other parts of the existing website.</li>\\n</ul>', 'url': 'https://github.com/cfpb/owning-a-home/issues/441', 'state': 'OPEN', 'createdAt': '2015-05-22T17:40:22Z', 'lastEditedAt': None, 'publishedAt': '2015-05-22T17:40:22Z', 'updatedAt': '2015-06-06T17:54:17Z', 'labels': ['css', 'design', 'dev', 'enhancement', 'help wanted', 'html', 'javascript'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Add examples from \"Defining Phases\" to the documentation', 'bodyHTML': '<p>This file: <a href=\"https://github.com/Cantera/cantera/blob/master/doc/sphinx/cti/example-combustion.rst\">https://github.com/Cantera/cantera/blob/master/doc/sphinx/cti/example-combustion.rst</a> is presently blank. Is it left over from an old version of the documentation?</p>\\n<p>As reported on the Google Group: <a href=\"https://groups.google.com/d/msg/cantera-users/h0s-vJ6iELY/RgqsyqGnCQAJ\" rel=\"nofollow\">https://groups.google.com/d/msg/cantera-users/h0s-vJ6iELY/RgqsyqGnCQAJ</a></p>', 'url': 'https://github.com/Cantera/cantera/issues/313', 'state': 'OPEN', 'createdAt': '2015-12-06T15:05:24Z', 'lastEditedAt': None, 'publishedAt': '2015-12-06T15:05:24Z', 'updatedAt': '2018-03-07T15:54:32Z', 'labels': ['documentation', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Adding citation to the chem input file in the data folder', 'bodyHTML': '<p>Using the chemical mechanism file in the system data of Cantera is very convenient. However, it seems that some of the mechanism files are not properly commented with the associated citation. I would suggest adding citation in all of the mechanism files, at least the chemical format mechanism files.</p>', 'url': 'https://github.com/Cantera/cantera/issues/339', 'state': 'OPEN', 'createdAt': '2016-05-13T07:16:11Z', 'lastEditedAt': '2016-05-13T07:16:30Z', 'publishedAt': '2016-05-13T07:16:11Z', 'updatedAt': '2018-03-07T15:54:17Z', 'labels': ['documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Changing the rate in Python does not change the forward rate constant calculation', 'bodyHTML': '<p>Using <a class=\"commit-link\" href=\"https://github.com/Cantera/cantera/commit/7d3ebdd3581c06f6294e4fb64e355007c2ea766e\"><tt>7d3ebdd</tt></a> (from the conda package) on Linux (Ubuntu 16.04), replacing the reaction rate parameters of a reaction does not affect the calculation of the forward rate constants.</p>\\n<pre><code>import cantera as ct\\ncti_str = \"\"\"\\nunits(length=\\'cm\\', time=\\'s\\', quantity=\\'mol\\', act_energy=\\'cal/mol\\')\\nideal_gas(\\n    name=\\'gas\\',\\n    elements=\\'C\\',\\n    species=\\'A B\\',\\n    reactions=\\'all\\',\\n    initial_state=state(temperature=300.0, pressure=OneAtm)\\n)\\n\\nspecies(\\n    name=\\'A\\',\\n    atoms=\\'C:12\\',\\n    thermo=(\\n        NASA(\\n            [300.00, 1000.00],\\n            [2.08692170E+00,  1.33149650E-01, -8.11574520E-05,\\n             2.94092860E-08, -6.51952130E-12, -3.59128140E+04,\\n             2.73552890E+01]\\n        ),\\n        NASA(\\n            [1000.00, 5000.00],\\n            [2.48802010E+01,  7.82500480E-02, -3.15509730E-05,\\n             5.78789000E-09, -3.98279680E-13, -4.31106840E+04,\\n             -9.36552550E+01]\\n        )\\n    ),\\n)\\n\\nspecies(\\n    name=\\'B\\',\\n    atoms=\\'C:12\\',\\n    thermo=(\\n        NASA(\\n            [300.00, 1000.00],\\n            [2.08692170E+00,  1.33149650E-01, -8.11574520E-05,\\n             2.94092860E-08, -6.51952130E-12, -3.59128140E+04,\\n             2.73552890E+01]\\n        ),\\n        NASA(\\n            [1000.00, 5000.00],\\n            [2.48802010E+01,  7.82500480E-02, -3.15509730E-05,\\n             5.78789000E-09, -3.98279680E-13, -4.31106840E+04,\\n             -9.36552550E+01]\\n        )\\n    ),\\n)\\n\\nreaction(\\n    equation=\\'A =&gt; B\\',\\n    kf=Arrhenius(A=52499925000.0, b=1.5, E=40900.0),\\n)\\n\"\"\"\\ngas = ct.Solution(source=cti_str)\\ngas.TP = 1000, 101325\\nprint(gas.reactions()[0].rate(1000))\\nprint(gas.forward_rate_constants)\\n\\ngas.reactions()[0].rate = ct.Arrhenius(A=4.8765e+69, b=0.0e+00, E=5.0E+04)\\nprint(gas.reactions()[0].rate(1000))\\nprint(gas.forward_rate_constants)\\n</code></pre>\\n<p>which has the output</p>\\n<pre><code>1912707.2378390601\\n[ 1912707.23783906]\\n4.847262590622456e+69\\n[ 1912707.23783906]\\n</code></pre>\\n<p>Is there another function I have to call to inform the Solution about the updated rate?</p>', 'url': 'https://github.com/Cantera/cantera/issues/394', 'state': 'CLOSED', 'createdAt': '2016-11-16T22:08:55Z', 'lastEditedAt': None, 'publishedAt': '2016-11-16T22:08:55Z', 'updatedAt': '2018-06-08T10:40:36Z', 'labels': ['Kinetics', 'documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'ck2cti documentation should be converted to Sphinx-style docstrings', 'bodyHTML': \"<p>The documentation in the ck2cti.py script is currently in a custom format that doesn't seem to be read by the Sphinx docs (at least, I couldn't find a page for it). If the docstrings were rewritten to the standard format, the docs could be included online.</p>\", 'url': 'https://github.com/Cantera/cantera/issues/397', 'state': 'OPEN', 'createdAt': '2016-11-21T14:15:57Z', 'lastEditedAt': None, 'publishedAt': '2016-11-21T14:15:57Z', 'updatedAt': '2016-11-21T20:41:31Z', 'labels': ['ck2cti', 'documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Update/Fix the MacPorts Recipe', 'bodyHTML': '<h3>Cantera version</h3>\\n<p>2.3</p>\\n<h3>Operating System</h3>\\n<p>macOS, MacPorts installation option</p>\\n<h3>Python/MATLAB version</h3>\\n<p>N/A</p>\\n<h3>Expected Behavior</h3>\\n<p>Proper installation</p>\\n<h3>Actual Behavior</h3>\\n<p>Failed installation, see <a href=\"https://groups.google.com/d/msg/cantera-users/rPdKLpC2uys/vIk4jDHTCAAJ\" rel=\"nofollow\">https://groups.google.com/d/msg/cantera-users/rPdKLpC2uys/vIk4jDHTCAAJ</a> for a thread with links</p>\\n<p>Also as discussed at KinCodeCon 2017</p>', 'url': 'https://github.com/Cantera/cantera/issues/496', 'state': 'OPEN', 'createdAt': '2018-01-17T21:34:37Z', 'lastEditedAt': None, 'publishedAt': '2018-01-17T21:34:37Z', 'updatedAt': '2018-03-23T01:55:18Z', 'labels': ['OS X', 'compiling', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'RAJA', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'forallN development tasks', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=660149\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/trws\">@trws</a></p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Eliminate Code Gen (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153137267\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/LLNL/RAJA/issues/4\" data-hovercard-type=\"issue\" data-hovercard-url=\"/LLNL/RAJA/issues/4/hovercard\" href=\"https://github.com/LLNL/RAJA/issues/4\">#4</a>)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Intel compiler issues (slowness in compiling, performance issues) (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153139179\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/LLNL/RAJA/issues/5\" data-hovercard-type=\"issue\" data-hovercard-url=\"/LLNL/RAJA/issues/5/hovercard\" href=\"https://github.com/LLNL/RAJA/issues/5\">#5</a>)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Clang OpenMP (backed out in commit <a class=\"commit-link\" href=\"https://github.com/LLNL/RAJA/commit/ceca2c61d46d5c44f298696b405675f25883cd90\"><tt>ceca2c6</tt></a> ??? need to hunt down specific commit?)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> nvcc lambda \"introspection???\" (need to generate a branch for this)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> add static_assert\\'s to help the user out!</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> add sequential tests for CPU nested and CPU nested reduce tests so the forallN machinery gets tested for all configurations (i.e., without OpenMP enabled)</li>\\n</ul>', 'url': 'https://github.com/LLNL/RAJA/issues/3', 'state': 'CLOSED', 'createdAt': '2016-05-04T23:15:51Z', 'lastEditedAt': '2017-03-14T17:22:44Z', 'publishedAt': '2016-05-04T23:15:51Z', 'updatedAt': '2017-03-14T21:40:22Z', 'labels': ['API/usability', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'RAJA', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'Intel compiler issues (slowness in compiling, performance issues)', 'bodyHTML': '<p>Compilation time takes excessively long for Kripke+RAJA.<br>\\nEach data layout that is enabled makes compilation time double.</p>\\n<p>Current code is guarded to only enable 1 data layout when using Intel compiler, see guard in this file:<br>\\n<div class=\"border rounded-1 my-2\">\\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\\n    <p class=\"mb-0 text-bold\">\\n      <a href=\"https://github.com/LLNL/RAJA/blob/22b1eda03a46bcaca2840a36890aef6e4a06ba09/test/Kripke-v1.1/Kripke-v1.1-RAJA/Kripke/Kernel.cpp#L82\">RAJA/test/Kripke-v1.1/Kripke-v1.1-RAJA/Kripke/Kernel.cpp</a>\\n    </p>\\n    <p class=\"mb-0 text-gray-light\">\\n         Line 82\\n      in\\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/LLNL/RAJA/commit/22b1eda03a46bcaca2840a36890aef6e4a06ba09\">22b1eda</a>\\n    </p>\\n    </div>\\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\\n\\n        <tbody><tr class=\"border-0\">\\n          <td id=\"L82\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"82\"></td>\\n          <td id=\"LC82\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> #<span class=\"pl-k\">ifndef</span> RAJA_COMPILER_ICC </td>\\n        </tr>\\n    </tbody></table>\\n  </div>\\n</div>\\n</p>', 'url': 'https://github.com/LLNL/RAJA/issues/5', 'state': 'CLOSED', 'createdAt': '2016-05-04T23:32:01Z', 'lastEditedAt': None, 'publishedAt': '2016-05-04T23:32:01Z', 'updatedAt': '2017-03-14T13:11:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'RAJA', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'Intel compiler 6x OpenMP performance degradation for feature/keasler/BoxSegment', 'bodyHTML': '<p>The LULESH v1.0 application runs 6x slower on the feature/keasler/BoxSegment branch due to an Intel compiler bug.  gcc-4.9.3p runs at the same speed on the develop branch and the feature/keasler/BoxSegment branch.  That said, the Intel compiler produces code that is over 30% faster on the develop branch, so this is not a dis on the Intel compiler.</p>', 'url': 'https://github.com/LLNL/RAJA/issues/6', 'state': 'CLOSED', 'createdAt': '2016-05-04T23:41:10Z', 'lastEditedAt': None, 'publishedAt': '2016-05-04T23:41:10Z', 'updatedAt': '2017-03-13T21:32:54Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Adding USE_PETSC in env_build.xml', 'bodyHTML': \"<p>For the land model, I'm developing a solver that uses PETSc. Presently, after a case is created, I manually modify the Macros file and add PETSc relevant information. I noticed that for CISM there already exists a 'USE_TRILINOS' entry in env_build.xml and am wondering if someone from s/w team could provide help in adding 'USE_PETSC' or suggest alternate workflow.</p>\\n<p>Thanks,<br>\\nGautam</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/41', 'state': 'CLOSED', 'createdAt': '2014-11-12T19:48:25Z', 'lastEditedAt': None, 'publishedAt': '2014-11-12T19:48:25Z', 'updatedAt': '2015-11-20T01:48:32Z', 'labels': ['Land', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Tabs should be eliminated from source files.', 'bodyHTML': \"<p>We have found a mixture of tabs and spaces used for indentation in various source files in ACME. The problem with tabs is that everyone sets their tab stops differently according to their particular practice/preference/religion. This means that a single file can render sensibly in one person's text editor and completely nonsensically on another.</p>\\n<p>The solution is to either pound away on your space bar, or to tell your text editor to expand a tab into a fixed number of spaces. Optimally, we could communicate this aesthetic to people's editors via special files placed in the source tree.</p>\\n<p>More broadly, we should probably attempt to assemble some least-common-denominator form of a style guide for ACME code (possibly in connection with CESM/NCAR if we can agree on simple guidelines) so that we can avoid these issues in the future.</p>\\n<p>But for the moment, this issue exists only to a) bring this to our attention, and b) decide how to eradicate all the existing tabs.</p>\\n<p>NOTE: I don't think we have a proper label for this kind of issue yet. Perhaps we can discuss this as well.</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/132', 'state': 'OPEN', 'createdAt': '2015-03-12T22:06:51Z', 'lastEditedAt': None, 'publishedAt': '2015-03-12T22:06:51Z', 'updatedAt': '2017-09-20T01:12:22Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'COSP does not work with OpenMP on Mira', 'bodyHTML': '<p>In support of the Atmosphere Group I have been trying to find a layout that works with COSP for an ne120 resolution on Mira. My understanding is that this works fine for ne30. However, I have found exactly one pe layout so far that allows this case to work for ne120 (within my current search space):</p>\\n<p>7200 processes, No OpenMP, MAX_TASKS_PER_NODE=4</p>\\n<p>If I turn on threading it dies during the first COSP calculation (during timestep 8), apparently from a memory issue. Moreover, it dies even with as few as 2 threads per process, e.g.</p>\\n<p>7200 processes, 2 threads per task, MAX_TASKS_PER_NODE=8</p>\\n<p>(lots of core files, with error message of the form</p>\\n<blockquote>\\n<p>***FAULT Encountered unhandled signal 0x0000000b (11) (SIGSEGV)<br>\\nGenerated by interrupt..................0x00000008 (Data TLB Miss Exception DEAR=0x0000001f09ab1e80 ESR=0x0000000000800000)<br>\\n)</p>\\n</blockquote>\\n<p>FYI - without COSP, we run with 7200 processes, 16  threads per task, MAX_TASKS_PER_NODE=64.</p>\\n<p>On Titan, I had to increase the thread stack size to 128 MB to get COSP for ne120 to work. I have tried this on Mira, even going as high as 512MB per thread, but it has not worked. (I also tried 384, 192, and the default 96.)</p>\\n<p>I also tried just increasing the number of MPI tasks without using OpenMP e.g.</p>\\n<p>14400 processes, No OpenMP, MAX_TASKS_PER_NODE=8</p>\\n<p>and this dies in CICE initialization, also due to memory issues:</p>\\n<p>in cice log:</p>\\n<blockquote>\\n<p>(shr_strdata_init)  calling shr_dmodel_mapSet for remap<br>\\nin cesm log:<br>\\n0: \"/gpfs/mira-home/worley/ACME/master/ACME/models/csm_share/shr/shr_map_mod.F90\", line 1300: 1525-108 Error encountered while attempting to allocate a data object.  The program will stop.</p>\\n</blockquote>\\n<p>This latter problem appears to be a function solely of the number of ATM MPI processes, not CICE (which I varied) or how many processes are assigned to each node.</p>\\n<p>So, any Mira experts with any advice? About thread stack size? About how to increase the per process memory limits (so that CICE initialization does not fail if I use 14400 process).</p>\\n<p>The current working layout is wasteful and too slow. I am guessing that this is not a COSP bug given that ne30 works fine, just a memory issue?</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/175', 'state': 'CLOSED', 'createdAt': '2015-04-04T14:03:29Z', 'lastEditedAt': None, 'publishedAt': '2015-04-04T14:03:29Z', 'updatedAt': '2015-06-01T16:34:00Z', 'labels': ['Critical', 'Machine Files', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'slow compilation for MPAS-O and MPAS-CICE on Cetus and Mira', 'bodyHTML': '<p>Since this occurs on both Cetus and Mira (today, at least) it may be more than a transient issue ... MPAS-CICE takes 1 hour to compile. Looking at the timestamps of the object files ...</p>\\n<pre><code> ....\\n -rw-r--r-- 1 worley users 2521424 Dec 22 18:04 cice_core_interface.mod\\n -rw-r--r-- 1 worley users  658562 Dec 22 18:56 mpas_cice_cpl_indices.mod\\n -rw-r--r-- 1 worley users  644886 Dec 22 18:56 mpas_cice_mct_vars.mod\\n -rw-r--r-- 1 worley users  252454 Dec 22 18:56 ice_comp_mct.mod\\n</code></pre>\\n<p>most of the time is spent in compiling mpas_cice_cpl_indices.mod . Not sure who is best positioned to look at this, but will assign it to Doug to start with.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/579', 'state': 'CLOSED', 'createdAt': '2015-12-22T19:40:22Z', 'lastEditedAt': None, 'publishedAt': '2015-12-22T19:40:22Z', 'updatedAt': '2017-02-14T22:44:55Z', 'labels': ['Ocean', 'Sea Ice', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'How to do bundle simulations on Mira with post-cime ACME?', 'bodyHTML': '<p>Hello <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7872788\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/worleyph\">@worleyph</a> , <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8323089\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tangq\">@tangq</a> , <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7873429\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jayeshkrishna\">@jayeshkrishna</a> , <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8136848\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/singhbalwinder\">@singhbalwinder</a> , <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604113\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amametjanov\">@amametjanov</a> ,</p>\\n<p>For pre-cime v0.3 model, we used to be able to use a script (such as <a href=\"https://acme-climate.atlassian.net/wiki/display/ATM/bundle.sh\" rel=\"nofollow\">https://acme-climate.atlassian.net/wiki/display/ATM/bundle.sh</a>) to bundle multiple simulations into a large queue.</p>\\n<p>In that example, each simulation sets to use 2048 nodes, and four simulations are bundled as a single queue requesting 8192 nodes. The requested 8192 nodes would be partitioned into four 2048 blocks. The corresponding COBALT_PARTNAME and RUNJOB_BLOCK would be passed to individual $CASE.submit as environmental variables. The simulation would start immediately using the pre-defined partition. Bundled ensemble simulations are encouraged because of advantage for jobs requesting large blocks.</p>\\n<p>When using the same bundle script to do $CASE.submit for the post-cime ACME, it appears that COBALT_PARTNAME and RUNJOB_BLOCK passed from the bundle script are not used. Each embeded job would be submitted as a new queue (and waiting), and the bundle queue would exit after all the embeded jobs are submitted. The bundle script essentially has no effect.</p>\\n<p>What does it take to make the current form of $CASE.submit to be used for bundle simulations? Or instead leave $CASE.submit as is but using a new kind of bundle script?</p>\\n<p>Thanks.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/583', 'state': 'CLOSED', 'createdAt': '2015-12-23T15:55:12Z', 'lastEditedAt': None, 'publishedAt': '2015-12-23T15:55:12Z', 'updatedAt': '2018-04-03T21:47:53Z', 'labels': ['Scripts', 'help wanted'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Job submission with job holding on', 'bodyHTML': '<p>Job submission does not allow submitting multiple jobs at once.</p>\\n<p>in env_run.xml, RESUBMIT operates that it waits for the one in the queue to finish before resubmitting.</p>\\n<p>There is no way I can ask for sending 10 jobs to the queue with one operation and sequentially dependent.</p>\\n<p>Queue:</p>\\n<p>job1<br>\\njob2 if job1 is successful<br>\\njob3 if job2 is successful<br>\\n...</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/654', 'state': 'CLOSED', 'createdAt': '2016-01-27T21:27:45Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T21:27:45Z', 'updatedAt': '2016-12-13T22:28:05Z', 'labels': ['Scripts', 'Utils', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Extend generation of default PE configurations with MAX_TASKS_PER_NODE', 'bodyHTML': '<p>Compset-, grid- and machine-specific PE configurations can be specified in <code>cime/machines-acme/config_pes.xml</code>. Currently supported xml tags (ntasks, nthrds, rootpe) do not include max_tasks_per_node, which is set from machine-specific configurations in <code>cime/machines-acme/config_machines.xml</code>. New compsets such as <code>-compset A_WCYCL2000 -res ne30_oEC</code> require undersubscribing nodes on some machines to avoid running out-of-memory. This can only be done from a case directory now.</p>\\n<p>Default PE configurations need to be extended with <code>max_tasks_per_node</code> for the entire coupled model, or <code>max_tpn_$comp</code> per component. The latter is preferred to undersubscribe specific memory-heavy components such as ATM.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/732', 'state': 'CLOSED', 'createdAt': '2016-02-26T00:54:39Z', 'lastEditedAt': None, 'publishedAt': '2016-02-26T00:54:39Z', 'updatedAt': '2017-01-23T20:31:09Z', 'labels': ['Scripts', 'enhancement', 'help wanted', 'minor'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'A_WCYCL2000 ne120_oRRS15: mapping error (Cori, Mira, and Titan)', 'bodyHTML': '<p>I\\'ve been trying to find feasible PE layouts for</p>\\n<pre><code> -compset A_WCYCL2000 -res ne120_oRRS15\\n</code></pre>\\n<p>on Cori. I started with a small (1024x1, stacked, noHT) layout, which failed. I then tried 2048x1, stacked, noHT), and most recently 3600x1 for atmosphere, coupler, and land (3616x1) with the other components on their own compute nodes using a 2048x1 decomposition. Again this is all noHT:</p>\\n<pre><code> &lt;entry id=\"MAX_TASKS_PER_NODE\"   value=\"32\"  /&gt;\\n</code></pre>\\n<p>I am getting the identical error for all three of these. From cesm.log:</p>\\n<pre><code> 0000: MCT::m_Router::initp_: GSMap indices not increasing...Will correct\\n 0000: m_GlobalSegMap::initp_: non-positive value of ngseg error, stat =0\\n 0000: 000.MCT(MPEU)::die.: from m_GlobalSegMap::initp_()\\n 0000: Rank 0 [Sat Apr 23 19:39:16 2016] [c1-0c1s13n1] application called MPI_Abort(MPI_COMM_WORLD, 2) - process 0\\n 0000: forrtl: error (76): Abort trap signal\\n ...\\n 0000: cesm.exe           0000000002F2670F  m_dropdead_mp_die          87  m_dropdead.F90\\n 0000: cesm.exe           0000000002F258DF  m_die_mp_die2__           165  m_die.F90\\n 0000: cesm.exe           0000000002EA8106  m_globalsegmap_mp        2433  m_GlobalSegMap.F90\\n 0000: cesm.exe           0000000002EF9A08  m_router_mp_initp         364  m_Router.F90\\n 0000: cesm.exe           0000000002EECE6C  m_rearranger_mp_i         153  m_Rearranger.F90\\n 0000: cesm.exe           0000000002EE3FDF  m_sparsematrixplu         522  m_SparseMatrixPlus.F90\\n 0000: cesm.exe           0000000002C52CF3  shr_mct_mod_mp_sh         355  shr_mct_mod.F90\\n 0000: cesm.exe           00000000004B94DD  seq_map_mod_mp_se         191  seq_map_mod.F90\\n 0000: cesm.exe           000000000044BC91  prep_ocn_mod_mp_p         259  prep_ocn_mod.F90\\n 0000: cesm.exe           0000000000411C7A  cesm_comp_mod_mp_        1582  cesm_comp_mod.F90\\n</code></pre>\\n<p>cpl.log ends with</p>\\n<pre><code> (seq_mct_drv) : Initialize each component: atm, lnd, rof, ocn, ice, glc, wav\\n (component_init_cc:mct) : Initialize component atm\\n (component_init_cc:mct) : Initialize component lnd\\n (component_init_cc:mct) : Initialize component rof\\n (component_init_cc:mct) : Initialize component ocn\\n (component_init_cc:mct) : Initialize component ice\\n (component_init_cc:mct) : Initialize component glc\\n (component_init_cc:mct) : Initialize component wav\\n\\n ...\\n\\n (prep_ocn_init) : Initializing mapper_Sa2o\\n (seq_map_init_rcfile)  called for mapper_Sa2o initialization\\n\\n (shr_mct_sMatPInitnc) Initializing SparseMatrixPlus\\n (shr_mct_sMatPInitnc) SmatP mapname /project/projectdirs/acme/inputdata/cpl/gridmaps/ne120np4/map_ne120np4_to_oRRS15to5_patch.160203.nc\\n (shr_mct_sMatPInitnc) SmatP maptype X\\n (shr_mct_sMatReaddnc) reading mapping matrix data decomposed...\\n (shr_mct_sMatReaddnc) * file name                  : /project/projectdirs/acme/inputdata/cpl/gridmaps/ne120np4/map_ne120np4_to_oRRS15to5_patch.160203.nc\\n (shr_mct_sMatReaddnc) * matrix dims src x dst      :     777602 x   5778136\\n (shr_mct_sMatReaddnc) * number of non-zero elements:   92387502\\n (shr_mct_sMatReaddnc) ... done reading file\\n</code></pre>\\n<p>I\\'ll try another increase in compute nodes for the ocean, but if anyone has any other suggestions, I\\'d appreciate it. Note that I (personally) do not have this compset working anyplace yet. On Titan there is a failure in ice or ocean initialization, so earlier than this in the execution.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/864', 'state': 'CLOSED', 'createdAt': '2016-04-24T15:07:39Z', 'lastEditedAt': None, 'publishedAt': '2016-04-24T15:07:39Z', 'updatedAt': '2016-08-30T19:27:46Z', 'labels': ['Coupled Model', 'Coupler', 'Ocean', 'bug', 'compset', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'TIL: threading in MPAS-O requires that MPAS-CICE be built with threading enabled', 'bodyHTML': '<p>Many (most) of my recent experiments looking at threading in the ocean have been with no threading in MPAS-CICE, which apparently is not supported unless MPAS-CICE is still built with threading enabled, so I do not know if threading is broken in MPAS-O or not. I need to repeat my experiments.</p>\\n<p>There is no test currently to prevent a user from specifying threading in the ocean and not in sea ice in env_mach_pes.xml. One simple \"fix\" would be to change the default for BUILD_THREADED in env_build.xml to</p>\\n<pre><code> &lt;entry id=\"BUILD_THREADED\"   value=\"TRUE\"  /&gt;\\n</code></pre>\\n<p>but this will apply even for MPI-only builds across all components. (There is also the issue, already reported as a github issue, that building MPAS-CICE with threading enabled takes hours on Mira and Cetus.) The \"real\" solution in my opinion is not to have MPAS-O use MPAS framework code built according to MPAS-CICE\\'s specifications, but I have not heard anything from the MPAS development group that this is even being considered.</p>\\n<p>I\\'d like to ask the software engineering group to propose a solution. Everything that we discussed in the Performance Group telecon today had downsides, and nothing was the obvious winner.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/915', 'state': 'OPEN', 'createdAt': '2016-06-14T23:15:55Z', 'lastEditedAt': None, 'publishedAt': '2016-06-14T23:15:55Z', 'updatedAt': '2017-05-17T19:57:19Z', 'labels': ['Land Ice', 'Ocean', 'PotentialBug', 'Sea Ice', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 8}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Can the build logic move the timing library to be first?', 'bodyHTML': '<p>Adding instrumentation to MCT is awkward. I have to build a compset, then add timers to MCT, then clean build just MCT, then rebuild. Otherwise, perf_mod is not available when MCT is being built.</p>\\n<p>Just a minor thing, but if we decide to reorder the component builds, to put mpas-o before mpas-cice, or to add a new mpas-infrastructure component before all other mpas components, then moving the timing library build to be first would make my life simpler :-).</p>\\n<p>Rob, please reassign as appropriate.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/916', 'state': 'CLOSED', 'createdAt': '2016-06-16T14:15:56Z', 'lastEditedAt': None, 'publishedAt': '2016-06-16T14:15:56Z', 'updatedAt': '2017-07-04T00:35:50Z', 'labels': ['Scripts', 'Utils', 'help wanted', 'minor', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'scalability issue in I/O for HiRes ocean/ice ', 'bodyHTML': '<p>With the scalability issue in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160917996\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/E3SM-Project/E3SM/issues/917\" data-hovercard-type=\"issue\" data-hovercard-url=\"/E3SM-Project/E3SM/issues/917/hovercard\" href=\"https://github.com/E3SM-Project/E3SM/issues/917\">#917</a> resolved in my sandbox, I am still seeing growth in the initialization time that is interfering with benchmarking the GMPAS compset with resolution oRRS15to5 on Titan. The problem now appears to be primarily in the PIO rearranger (in particular swapm). I\\'ve tried changing the number of PIO tasks (and/or stride) and some of the swapm algorithm parameters, and this helps some, but the cost is still growing with process count at a rate that makes experiments extremely costly.</p>\\n<p>This may simply be what it costs, but I\\'d like other eyes on this as well, to make sure that I am not missing something. I also wonder if the large ngseg associated with the ocean and sea ice are playing a role in the cost here, and perhaps a reordering will help - I\\'ll keep poking at this as well.</p>\\n<p>Example (but not the only relevant timers):</p>\\n<p>32768x1:</p>\\n<pre><code>            o_i:pio_rearrange_read                                      -       55    -     228.791992    10.224689     0.002120         0.000012\\n                o_i:swapm_box_rear_io2comp_int                          -       23    -      75.044983     8.401361     0.001450         0.000005\\n                o_i:swapm_box_rear_io2comp_double                       -       32    -     153.693314    10.223440     0.005986         0.000007\\n</code></pre>\\n<p>32768x2:</p>\\n<pre><code>            o_i:pio_rearrange_read                                      -       55    -     251.960098    11.717317     0.001988         0.000011\\n                o_i:swapm_box_rear_io2comp_int                          -       23    -      80.105286    10.970987     0.001306         0.000005\\n                o_i:swapm_box_rear_io2comp_double                       -       32    -     171.803497    11.716194     0.003911         0.000006\\n</code></pre>\\n<p>65536x1:</p>\\n<pre><code>            o_i:pio_rearrange_read                                      -       55    -     967.347229    71.384605     0.005350         0.000012\\n                o_i:swapm_box_rear_io2comp_int                          -       23    -     334.051361    71.382469     0.004087         0.000005\\n                o_i:swapm_box_rear_io2comp_double                       -       32    -     633.168335    61.295826     0.016546         0.000007\\n</code></pre>\\n<p>65536x2:</p>\\n<pre><code>            o_i:pio_rearrange_read                                      -       55    -     823.766907    40.076656     0.005326         0.000012\\n                o_i:swapm_box_rear_io2comp_int                          -       23    -     266.157593    40.074409     0.003940         0.000005\\n                o_i:swapm_box_rear_io2comp_double                       -       32    -     557.492981    39.186714     0.016216         0.000007\\n</code></pre>\\n<p>131072x1:</p>\\n<pre><code>            o_i:pio_rearrange_read                                  -       55    -    1590.057861   121.147293     0.013219         0.000011\\n                o_i:swapm_box_rear_io2comp_int                      -       23    -     536.446289    87.814972     0.010504         0.000005\\n                o_i:swapm_box_rear_io2comp_double                   -       32    -    1053.389771   121.132515     0.054675         0.000006\\n</code></pre>\\n<p>(Note, \"best case\" has been using 128, 256, or 512 PIO tasks. I also tried disabling MPI_RSEND, so see if that performance bug had returned, and it only slowed performance down a little.)</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/919', 'state': 'CLOSED', 'createdAt': '2016-06-20T18:38:36Z', 'lastEditedAt': None, 'publishedAt': '2016-06-20T18:38:36Z', 'updatedAt': '2016-08-19T03:32:53Z', 'labels': ['Ocean', 'Sea Ice', 'Utils', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'titan ne120L72 run aborted due to file header inconsistent among processes', 'bodyHTML': \"<p>This is an F1850 run, compset equivalent to AV1C-04 for ne120L72 on 5075 nodes.</p>\\n<p>The run was aborted after 11808 steps (123 days) with the following error message</p>\\n<p>pio_support::pio_die:: myrank=          -1 : ERROR: nf_mod.F90:        1508 :<br>\\nFile header is inconsistent among processes<br>\\nImage              PC                Routine            Line        Source<br>\\ncesm.exe           000000000437BD1D  Unknown               Unknown  Unknown<br>\\ncesm.exe           00000000030C4601  pio_support_mp_pi         120  pio_support.F90<br>\\ncesm.exe           00000000030C2965  pio_utils_mp_chec          59  pio_utils.F90<br>\\ncesm.exe           00000000030AC21E  nf_mod_mp_pio_end        1508  nf_mod.F90<br>\\ncesm.exe           000000000238E10D  ice_history_write         476  ice_history_write.F90<br>\\ncesm.exe           0000000002375845  ice_history_mp_ic        2370  ice_history.F90<br>\\ncesm.exe           00000000022D7F5D  ice_comp_mct_mp_i         669  ice_comp_mct.F90<br>\\ncesm.exe           000000000041A1C1  component_mod_mp_        1049  component_mod.F90<br>\\ncesm.exe           00000000004034E1  cesm_comp_mod_mp_        2548  cesm_comp_mod.F90<br>\\ncesm.exe           0000000000417A23  MAIN__                    107  cesm_driver.F90<br>\\ncesm.exe           00000000004012CE  Unknown               Unknown  Unknown<br>\\ncesm.exe           000000000446C011  Unknown               Unknown  Unknown<br>\\ncesm.exe           00000000004011B5  Unknown               Unknown  Unknown</p>\\n<p>A restart run (which was embeded in $CASE.run script) within the single job queue appears to run ok. The restart point was  about 3-days before the failure point.</p>\\n<p>Haven't seen such problem before. What could be the nature of this problem? If does not seem to be any hardware issue. Should we pay some attention to? Thanks.</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/952', 'state': 'CLOSED', 'createdAt': '2016-07-16T15:11:50Z', 'lastEditedAt': None, 'publishedAt': '2016-07-16T15:11:50Z', 'updatedAt': '2017-01-27T18:07:04Z', 'labels': ['Atmosphere', 'Documentation', 'Sea Ice', 'Utils', 'help wanted', 'invalid'], 'is_locked': False, 'total_participants': 8}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'bug in latest mpas-o?', 'bodyHTML': \"<p>Just updated and built a new case:</p>\\n<pre><code>  -compset GMPAS_NYF -res T62_oQU120 \\n</code></pre>\\n<p>on Titan using a 64x1 decomposition (a case that I have built and run before).  This died with</p>\\n<pre><code> task     0 of    64 is running\\n  Reading namelist from file mpas-o_in\\n  Error while reading namelist record cvmix.\\n</code></pre>\\n<p>Comparing an old cvmix namelist (for a case that did work) with the new one (for the failed case), the only difference was the addition of a new namelist variable:</p>\\n<pre><code> config_cvmix_kpp_use_enhanced_diff = .true.\\n</code></pre>\\n<p>Looking at recent updates, this variable was just added to master, but only to the buildnml script. I don't see it in the code at all (e.g. it is not in the cvmix namelist list in mpas_ocn_core_interface.f90).</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/981', 'state': 'CLOSED', 'createdAt': '2016-07-29T18:47:02Z', 'lastEditedAt': None, 'publishedAt': '2016-07-29T18:47:02Z', 'updatedAt': '2016-07-29T18:53:10Z', 'labels': ['Ocean', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': \"New ocean time steps don't support abrupt adjustment from sea ice initial conditions\", 'bodyHTML': '<p>GMPAS_NYF T62_oRRS15to5 is now dying on Titan during I/O for sea ice, it appears:</p>\\n<pre><code> ...\\n  ----- done parsing run-time I/O from streams.cice -----\\n\\n  Setting mpi info: striping_factor=16\\n  Setting mpi info: striping_unit=1048576\\n  pionfwrite_mod::write_nfdarray_double          107   IAM:             0 \\n   start:                         1                        1  count:  \\n                    111118                        1  size : \\n                         1  error:           -39   -872345086           -1\\n</code></pre>\\n<p>I\\'d like someone else to verify this.</p>\\n<p>This is for a PE layout of 16384x1 (stacked).  I changed the PIO stride to 32, and then to 64, and both produced the same error message. Both of these also worked  a couple of weeks ago. What I did change was the timestep sizes in mpas-o, to take advantage of the new optimizations.</p>\\n<p>Assigning to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7873429\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jayeshkrishna\">@jayeshkrishna</a> , since this is in PIO?, but noting to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=334984\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/douglasjacobsen\">@douglasjacobsen</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8173901\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/philipwjones\">@philipwjones</a> , who perhaps can invite someone fro MPAS-CICE development to watch this as well.</p>\\n<p>I\\'ll try other decompositions as well, and also a smaller resolution.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/993', 'state': 'CLOSED', 'createdAt': '2016-08-04T15:32:12Z', 'lastEditedAt': '2016-08-04T19:14:09Z', 'publishedAt': '2016-08-04T15:32:12Z', 'updatedAt': '2017-03-08T14:47:23Z', 'labels': ['Critical', 'Sea Ice', 'Utils', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Titan ne120L72 run failed on writing atm restart files', 'bodyHTML': '<p>This run use intel compiler and it was built after recent fix for PIO link and cmake (issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"169708515\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/E3SM-Project/E3SM/issues/999\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/E3SM-Project/E3SM/pull/999/hovercard\" href=\"https://github.com/E3SM-Project/E3SM/pull/999\">#999</a>):<br>\\nThe run failed at the first point of restart (REST_N=15 days). Both cam.r and cam.rh0 files were partially written. cpl.r has yet to be generated. restart files for other components had been full written.</p>\\n<p>The run script on titan was set to loop once more over aprun if it sees the job was not completed. So there was a repeated run and the 2nd run failed in the same way.</p>\\n<p>The error message at the time of failure below,</p>\\n<p>Overflow when type cast to 4-byte integer.<br>\\nImage              PC                Routine            Line        Source<br>\\ncesm.exe           000000000344DA9D  Unknown               Unknown  Unknown<br>\\ncesm.exe           00000000030EBEE1  pio_support_mp_pi         120  pio_support.F90<br>\\ncesm.exe           00000000030EA245  pio_utils_mp_chec          59  pio_utils.F90<br>\\ncesm.exe           00000000030D3AFE  nf_mod_mp_pio_end        1508  nf_mod.F90<br>\\ncesm.exe           000000000051ED1B  cam_history_mp_h_        4107  cam_history.F90<br>\\ncesm.exe           0000000000518C3C  cam_history_mp_ws        4632  cam_history.F90<br>\\ncesm.exe           0000000000515B69  cam_history_mp_wr        1360  cam_history.F90<br>\\ncesm.exe           000000000054F6E0  cam_restart_mp_ca         250  cam_restart.F90<br>\\ncesm.exe           0000000000508EAA  cam_comp_mp_cam_r         394  cam_comp.F90<br>\\ncesm.exe           00000000004F19C7  atm_comp_mct_mp_a         511  atm_comp_mct.F90<br>\\ncesm.exe           000000000042EC11  component_mod_mp_        1049  component_mod.F90<br>\\ncesm.exe           0000000000418DA8  cesm_comp_mod_mp_        3266  cesm_comp_mod.F90<br>\\ncesm.exe           000000000042C473  MAIN__                    107  cesm_driver.F90<br>\\ncesm.exe           0000000000415D1E  Unknown               Unknown  Unknown</p>\\n<p>To test first using ne30 to see if anything generic in atm component causing the problem.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8136848\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/singhbalwinder\">@singhbalwinder</a> , <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7873429\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jayeshkrishna\">@jayeshkrishna</a> , please also take a look. Since it appears to fail during writing atm restart files, I wonder if there is some thing we missed in the fix for qneg4-restart.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1011', 'state': 'OPEN', 'createdAt': '2016-08-15T14:50:54Z', 'lastEditedAt': '2016-08-15T14:55:34Z', 'publishedAt': '2016-08-15T14:50:54Z', 'updatedAt': '2016-12-10T00:47:55Z', 'labels': ['Atmosphere', 'Critical', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'mabrunke/lnd/varsoil-in-ZD2009 collecting water in urban columns', 'bodyHTML': '<p>When testing mabrunke/lnd/varsoil-in-ZD2009 for do_varsoil = .false., it stops on the third timestep, because the urban columns are gaining water.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8105979\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bishtgautam\">@bishtgautam</a>, is there a vital piece of code in the urban model that I neglected to change?</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1091', 'state': 'CLOSED', 'createdAt': '2016-10-07T17:02:16Z', 'lastEditedAt': None, 'publishedAt': '2016-10-07T17:02:16Z', 'updatedAt': '2016-10-11T20:25:59Z', 'labels': ['Land', 'bug', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'option to build mpas-o without checking that using the correct cvmix', 'bodyHTML': \"<p>Would it be possible to have an option to build ACME with MPAS-O that does not involve checking back with the github repository that have the latest version of cvmix?</p>\\n<p>With the DDoS attack today, I can't build an ACME case on Titan because ./get_cvmix.sh is failing:</p>\\n<pre><code>  ** Using git to acquire cvmix source. **\\n  ******************************************************\\n  ERROR: Build failed to acquire CVMix source. \\n</code></pre>\\n<p>('git pull' is failing as well, with</p>\\n<pre><code> ssh: Could not resolve hostname github.com: Name or service not known\\n</code></pre>\\n<p>)</p>\\n<p>Is it really necessary to check for cvmix every time? We don't require executing 'git pull' every time doing a build.</p>\\n<p>Just curious:  What happens if trying to build without any connectivity? Would this also fail?</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/1111', 'state': 'CLOSED', 'createdAt': '2016-10-21T20:09:31Z', 'lastEditedAt': None, 'publishedAt': '2016-10-21T20:09:31Z', 'updatedAt': '2017-02-28T02:52:40Z', 'labels': ['Ocean', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 10}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Resubmit not happening on SNL redsky and skybridge', 'bodyHTML': '<p>In each $case, the option to run to resubmit to the queue after a successful submission and run is changed by increasing the \"RESUBMIT\" value to &gt; 0 in the env_run.xml file.   In the $case.run file, the parameter $islastjob was being given a value of FALSE from the perl subroutine resubmitCheck() to the perl subroutine ACME/cime/utils/perl15lib/Batch/BatchUtils.pm doResubmit().    The line :<br>\\nif($islastjob eq \\'TRUE\\' &amp;&amp; $resubmit &gt; 0 &amp;&amp; defined $sta_ok)<br>\\nshould be:<br>\\nif($islastjob eq \\'FALSE\\' &amp;&amp; $resubmit &gt; 0 &amp;&amp; defined $sta_ok)<br>\\nThere is a few more steps after this, but at least sbatch is being envoked again.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1129', 'state': 'CLOSED', 'createdAt': '2016-11-07T18:45:02Z', 'lastEditedAt': None, 'publishedAt': '2016-11-07T18:45:02Z', 'updatedAt': '2016-12-13T20:39:19Z', 'labels': ['Atmosphere', 'CIME', 'Machine Files', 'Utils', 'help wanted', 'minor'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Run failed on anvil when using PGI compiler', 'bodyHTML': '<p>Testing ne30_ne30 L72 on anvil with pgi and 90 nodes (PE 3240x1).<br>\\nTried both netcdf and pnetcdf for PIO_TYPENAME. PIO_NUMTASKS=32</p>\\n<p>Segmentation fault during atm initialization. some error message in $CASE.o$JODID file below:</p>\\n<p>[proxy:0:0@b511] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:912): assert (!closed) failed<br>\\n[proxy:0:0@b511] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status<br>\\n[proxy:0:0@b511] main (pm/pmiserv/pmip.c:206): de[proxy:0:1@b512] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:912): assert (!closed) failed</p>\\n<p>In cesm.log, it merely printed for various ranks<br>\\n[b577:mpi_rank_2364][error_sighandler] Caught error: Segmentation fault (signal 11)</p>\\n<p>Any preferred compiler/PIO settings for anvil?<br>\\nSuggestions/comments appreciated.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1130', 'state': 'OPEN', 'createdAt': '2016-11-08T16:13:25Z', 'lastEditedAt': None, 'publishedAt': '2016-11-08T16:13:25Z', 'updatedAt': '2018-10-05T18:52:41Z', 'labels': ['Anvil', 'Atmosphere', 'Critical', 'help wanted'], 'is_locked': False, 'total_participants': 8}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Coupled runs hanging during I/O on Titan', 'bodyHTML': \"<p>This may be an example of the reoccurring issue of certain PIO strides causing problems in ocean I/O. However, I have not been able to work around this yet. (In fact, it may not be OCN at all.)</p>\\n<p>Running</p>\\n<pre><code> -compset ACME_WCYCL2000 -res ne120_oRRS15 \\n</code></pre>\\n<p>on 60,000 cores (43200x1 for ATM, 16384x2 for OCN) using PGI for 1 month with restart writes enabled, the job hangs during the end of the month I/O. It is unclear (to me) where it is hanging. However,</p>\\n<p>a) a 120,000 core job does complete successfully (one month, with restart writes).<br>\\nb) the identical 60,000 core PE layout with restart writes completes successfully when running only one day.</p>\\n<p>It takes 2.5 hours to get the place where the code hangs, and I have already wasted a nontrivial amount of the cli112 allocation trying to determine a workaround for this. I have one more job in the queue - one month run without restart write, just to eliminate one possibility.</p>\\n<p>Comparing output for successfull 120,000 core run and hung 60,000 core run, atm.log for hung jobs stops after</p>\\n<pre><code> ---------------------------------------\\n  WRAPUP: nf_close(            1 )=\\n  ACME_WCYCL2000.ne120_oRRS15_pgi_Router_opt_upd_60K.cam.h0.0001-01.nc\\n     Primary history file\\n     Output at NSTEP     =       2976\\n     Number of time samples on this file =          1\\n     Model Day           =      31.00\\n ---------------------------------------\\n</code></pre>\\n<p>and does not have (from the successfull 120,000 job)</p>\\n<pre><code>  nstep, te     2977   0.33353602001544604E+10   0.33353636089410524E+10   0.37708494014419901E-03   0.98505659048766436E+05\\n  Opened file\\n  ACME_WCYCL2000.ne120_oRRS15_pgi_Router_opt_upd_120K.cam.rs.0001-02-01-00000.nc\\n   to write           31\\n</code></pre>\\n<p>The file</p>\\n<pre><code> ACME_WCYCL2000.ne120_oRRS15_pgi_Router_opt_upd_60K.cam.rs.0001-02-01-00000.nc\\n</code></pre>\\n<p>was created and is nonempty, but I do not know how big it is supposed to be.</p>\\n<p>The PE layout strategies do differ between the 60,000 and 120,000 core layouts. In particular, land is not overlapped with ATM for the 60,000 core run, and uses fewer processes ...</p>\\n<p>I'll try a different PE layout next, maybe. Just an FYI in case someone wants to use the PE layout on</p>\\n<pre><code>  https://acme-climate.atlassian.net/wiki/x/oIHMB \\n</code></pre>\\n<p>for production runs. This appears not to be usable for long runs yet.</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/1141', 'state': 'CLOSED', 'createdAt': '2016-11-13T22:23:34Z', 'lastEditedAt': None, 'publishedAt': '2016-11-13T22:23:34Z', 'updatedAt': '2017-05-13T15:12:11Z', 'labels': ['Critical', 'Titan', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 13}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'HDF5 runtime error on Titan when running GMPAS compset', 'bodyHTML': '<p>This is probably a bug report for Titan, but I wanted to check with the MPAS experts first.</p>\\n<p>I tried running</p>\\n<pre><code> -compset GMPAS-NYF -res T62_oRRS18to6v3 -mach titan -compiler pgi\\n</code></pre>\\n<p>and I always get the error described below (I tried 2048, 4096, and 64000 process decompositions). Note that I can run</p>\\n<pre><code> -compset GMPAS-NYF -res T62_oRRS15to5 -mach titan -compiler pgi\\n</code></pre>\\n<p>jobs with no problem. I can\\'t imagine why the choice of mesh would introduce this error, but thought that I should ask before bothering <a href=\"mailto:help@olcf.ornl.gov\">help@olcf.ornl.gov</a>.</p>\\n<p>Error message:</p>\\n<pre><code> Warning! ***HDF5 library version mismatched error***\\n The HDF5 header files used to compile this application do not match\\n the version used by the HDF5 library to which this application is linked.\\n Data corruption or segmentation faults may occur if the application continues.\\n This can happen when an application was compiled by one version of HDF5 but\\n linked with a different version of static or shared HDF5 library.\\n You should recompile the application or check your shared library related\\n settings such as \\'LD_LIBRARY_PATH\\'.\\n You can, at your own risk, disable this warning by setting the environment\\n variable \\'HDF5_DISABLE_VERSION_CHECK\\' to a value of \\'1\\'.\\n Setting it to 2 or higher will suppress the warning messages totally.\\n Headers are 1.8.16, library is 1.10.0\\n\\n General Information:\\n -------------------\\n                    HDF5 Version: 1.10.0-patch1\\n                   Configured on: Tue Dec  6 14:45:46 CST 2016\\n                   Configured by: ulib@os-172-30-197-139\\n                     Host system: x86_64-unknown-linux-gnu\\n               Uname information: Linux os-172-30-197-139 3.4.63-2.44-default #1 SMP Wed Oct 2 11:18:32 UTC 2013 (d91a619) x86_64 x86_64 x86_64 GNU/Linux\\n                        Byte sex: little-endian\\n              Installation point: /var/tmp/cray-hdf5-1.10.0.1-201612052137.d5c01d2b84e7c-0-root/opt/cray/pe/hdf5-parallel/1.10.0.1/PGI/15.3\\n</code></pre>\\n<p>Does this look familiar? I know that people have beening running this compset on Titan ...</p>\\n<p>Thanks.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1327', 'state': 'CLOSED', 'createdAt': '2017-03-20T02:55:38Z', 'lastEditedAt': None, 'publishedAt': '2017-03-20T02:55:38Z', 'updatedAt': '2017-03-28T14:31:20Z', 'labels': ['Ocean', 'Titan', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 9}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'The FC5L45BGC compset was failed in cori-knl with \"column nbalance error\"', 'bodyHTML': '<p><strong>ACME tag:</strong> v1.0.0-beta.1-130-g7d39622</p>\\n<p><strong>Case created by:</strong>  ./create_newcase --case /global/homes/m/minxu/scratch/F_acmev1_enso_camse_clm45bgc_ne30 -res ne30_ne30 -compset FC5L45BGC -mach cori-knl --compiler intel</p>\\n<p><strong>PES layout:</strong>  2560 x 2 ,  64 MPI tasks per node.</p>\\n<p><strong>Error message:</strong><br>\\n0014:  ERROR in CNBalanceCheckMod.F90 at line 396<br>\\n1863:  column nbalance error =  -3.511888906373967E-006      178098           3<br>\\n0832:  column nbalance error =  -4.293514919911559E-008       78349           3<br>\\n1023:  column nbalance error =  -2.734882737515850E-007       96536           3<br>\\n2369:  column nbalance error =  -1.600117219243727E-006      222936           3<br>\\n2501:  column nbalance error =  -7.471929814815514E-006      233928           3<br>\\n0943:  column nbalance error =  -2.751315590089568E-007       88737           3<br>\\n0943:  Latdeg,Londeg         =    59.9466134666123        93.7563801427842<br>\\n0943:  begnb                 =    2.80072383505868<br>\\n0943:  endnb                 =    2.80073718112814<br>\\n0943:  delta store           =   1.334606945935235E-005<br>\\n0943:  input mass            =   1.307093991055480E-005<br>\\n0943:  output mass           =   2.010211410065240E-012<br>\\n0943:  net flux              =   1.307093790034339E-005<br>\\n0943:  denit                 =   0.000000000000000E+000<br>\\n0943:  n2onit                =   2.010114779247898E-012<br>\\n0943:  no3 leach             =   2.137917904780868E-018<br>\\n0943:  no3 runof             =   0.000000000000000E+000<br>\\n0943:  ndep                  =   1.307093991055480E-005<br>\\n0943:  nfix                  =   0.000000000000000E+000<br>\\n0943:  nsup                  =   0.000000000000000E+000<br>\\n0943:  fire                  =   0.000000000000000E+000<br>\\n0943:  dwt                   =   0.000000000000000E+000<br>\\n0943:  prod                  =   0.000000000000000E+000</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1368', 'state': 'CLOSED', 'createdAt': '2017-04-05T18:46:00Z', 'lastEditedAt': None, 'publishedAt': '2017-04-05T18:46:00Z', 'updatedAt': '2017-08-22T17:35:50Z', 'labels': ['Cori', 'PotentialBug', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'standalone tool for generating performance summaries (a request)', 'bodyHTML': '<p>When a job ends, case_run.py calls get_timing(case, lid) to generate the performance summary based on the case particulars and on the global timing statistics files generated at the end of a run.</p>\\n<p>When a job fails (e.g., runs of out of time), this summary is not generated. However, in the timing/checkpoints subdirectory are typically global statistics files generated as the simulation was running. These can also be used to generate a performance summary up to this point in time.</p>\\n<p>In CIME2 and earlier I could put one of these checkpoint global timing statistics files in the \"right place\" and run the getTiming script and generate a performance summary. Kind of a kludge, but it worked.</p>\\n<p>With CIME5, I don\\'t know how to do this any longer. Perhaps this is simple, but even better would be a tool that was designed just for this, run from the case directory with a pointer to one of these global timing statistics files as an argument.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1443', 'state': 'CLOSED', 'createdAt': '2017-04-22T14:06:57Z', 'lastEditedAt': None, 'publishedAt': '2017-04-22T14:06:57Z', 'updatedAt': '2017-11-14T22:51:45Z', 'labels': ['CIME', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Slow init time in OCN for hires problems (g18to6.T62_oRRS18to6v3.GMPAS-IAF)', 'bodyHTML': '<p>Generic issue, but wanted a place to store notes and we will surely have some code changes to help diagnose/address.</p>\\n<p>I\\'m running on cori-knl, but I understand others have seen similar slow init times. I\\'m still trying to figure out if this is highly dependent on number of total MPI\\'s, number of MPI\\'s for a given component, other settings, etc.  The following is for a G-case where I\\'m giving 150 nodes to OCN and 150 to ICE+CPL.  On each node, using 64 MPI\\'s (pure MPI mode) for a total of 9600 tasks on each of the MPAS components.  I also see even slower init times for coupled hi-res problem that is using similar MPAS setup (afaik), the same number of nodes to each component, but more total nodes in the job -- however, as it fails in restart, I don\\'t have complete timing files.</p>\\n<pre><code>  component       comp_pes    root_pe   tasks  x threads instances (stride) \\n  ---------        ------     -------   ------   ------  ---------  ------  \\n  cpl = cpl        9600        9600     9600   x 1       1      (1     ) \\n  atm = datm       128         19200    128    x 1       1      (1     ) \\n  lnd = slnd       128         19200    128    x 1       1      (1     ) \\n  ice = mpascice   9600        9600     9600   x 1       1      (1     ) \\n  ocn = mpaso      9600        0        9600   x 1       1      (1     ) \\n  rof = drof       128         19200    128    x 1       1      (1     ) \\n  glc = sglc       128         19200    128    x 1       1      (1     ) \\n  wav = swav       128         19200    128    x 1       1      (1     ) \\n  esp = sesp       1           0        1      x 1       1      (1     ) \\n...\\n\\n    Init Time   :    1969.944 seconds \\n    Run Time    :    1397.276 seconds      279.455 seconds/day \\n</code></pre>\\n<p>The timer <code>comp_init_cc_ice</code> reports 1467 which would indicate most of the time in OCN init.<br>\\nAnd <code>o_i:PIO:pio_read_nfdarray_double</code> has 898 seconds from the following file:</p>\\n<p><code>/global/cscratch1/sd/ndk/acme_scratch/cori-knl/g18to6.T62_oRRS18to6v3.GMPAS-IAF.cori-knl_intel.m34-may17.n302t01/run/timing.170519-000252/model_timing.00000</code></p>\\n<p>Assuming the value of <code>pnetcdf</code> is being honored for <code>PIO_TYPENAME</code> that is set in env_run.xml, then it looks like this is the only call that could be causing the time:</p>\\n<pre><code>          ierr=nfmpi_get_vara_all( File%fh,varDesc%varid, &amp;\\n               start, &amp;\\n               count, &amp;\\n               IOBUF,iodesc%Read%n_ElemTYPE, &amp;\\n               iodesc%Read%ElemTYPE)\\n</code></pre>\\n<p>I have some MCT files that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7872788\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/worleyph\">@worleyph</a> has modified to add more timers (though I need to backport that with the incoming MCT 2.0 files).  I have jobs in the Q currently.</p>\\n<p><code>/global/cscratch1/sd/ndk/acme_scratch/cori-knl/g18to6.T62_oRRS18to6v3.GMPAS-IAF.cori-knl_intel.m34-may17.n302t01</code></p>\\n<p>fyi, when I tried to a 32-node hi-res problem, giving OCN 15 nodes and ICE+CPL 15 nodes, I did a top on each compute node while it was in init.  The first 15 nodes are using about 53 GB, while the remaining nodes are using 5GB.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1547', 'state': 'CLOSED', 'createdAt': '2017-05-19T22:47:21Z', 'lastEditedAt': None, 'publishedAt': '2017-05-19T22:47:21Z', 'updatedAt': '2017-07-27T21:37:30Z', 'labels': ['Cori', 'Ocean', 'help wanted'], 'is_locked': False, 'total_participants': 9}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Filenames in cime causing errors on windows filesystem', 'bodyHTML': '<p>Recognizing that as an ACME developer trying to work from a windows platform I represent a minority (perhaps singular) use case, I wonder if it would be possible to alter the filenames for the following four files:<br>\\ncime/src/externals/pio1/tests/testpio/perl5lib/XML/man3/XML::Lite.3<br>\\ncime/src/externals/pio1/tests/testpio/perl5lib/XML/man3/XML::Lite::Element.3<br>\\ncime/src/externals/pio2/examples/basic/perl5lib/XML/man3/XML::Lite.3<br>\\ncime/src/externals/pio2/examples/basic/perl5lib/XML/man3/XML::Lite.3</p>\\n<p>The use of \"::\" in the filename seems to confuse the windows filesystem, and it will not create these files when cloning the repo. These are the only four files in the ACME codebase that cause any problems, and it seems that they are not in such a critical path that renaming would cause problems for the rest of the project.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1553', 'state': 'CLOSED', 'createdAt': '2017-05-23T13:20:26Z', 'lastEditedAt': None, 'publishedAt': '2017-05-23T13:20:26Z', 'updatedAt': '2017-06-08T16:04:26Z', 'labels': ['CIME', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Fail writing restarts on Cori with hires G case', 'bodyHTML': \"<p>Using master as of June 1st.<br>\\nset compset=GMPAS-IAF<br>\\nset mach=cori-knl<br>\\nset res=T62_oRRS18to6v3<br>\\nIt fails with any PE layout I have tried, but mostly it is with 32 OCN nodes, 15 ICE/CPL nodes (using 64 MPI's per node, no openmp). PIO stride is 64.</p>\\n<pre><code>2176:  pio_support::pio_die:: myrank=          -1 : ERROR: nf_mod.F90:        1508 : \\n2176:  NetCDF: One or more variable sizes violate format constraints\\n2176: Image              PC                Routine            Line        Source             \\n2176: acme.exe           0000000001D25838  Unknown               Unknown  Unknown\\n2176: acme.exe           000000000134DA4A  pio_support_mp_pi         120  pio_support.F90\\n2176: acme.exe           000000000134B807  pio_utils_mp_chec          59  pio_utils.F90\\n2176: acme.exe           000000000132E182  nf_mod_mp_pio_end        1508  nf_mod.F90\\n2176: acme.exe           00000000004E7991  seq_rest_mod_mp_s         423  seq_rest_mod.F90\\n2176: acme.exe           0000000000414C3C  cesm_comp_mod_mp_        3577  cesm_comp_mod.F90\\n2176: acme.exe           00000000004275A2  MAIN__                     68  cesm_driver.F90\\n2176: acme.exe           000000000040BB0E  Unknown               Unknown  Unknown\\n2176: acme.exe           0000000001E19DE0  Unknown               Unknown  Unknown\\n2176: acme.exe           000000000040B9F7  Unknown               Unknown  Unknown\\n</code></pre>\\n<p>After a run, the last files touched are:</p>\\n<pre><code>-rw-rw-r--  1 ndk ndk  8216369200 Jun  2 18:31 mpascice.rst.0001-01-02_00000.nc\\n-rw-rw-r--  1 ndk ndk       66936 Jun  2 18:31 ice.log.170602-180412\\n-rw-rw-r--  1 ndk ndk          21 Jun  2 18:31 rpointer.ocn\\n-rw-rw-r--  1 ndk ndk         257 Jun  2 18:31 rpointer.drv\\n-rw-rw-r--  1 ndk ndk       53225 Jun  2 18:31 ocn.log.170602-180412\\n-rw-rw-r--  1 ndk ndk 28630788832 Jun  2 18:31 mpaso.rst.0001-01-02_00000.nc\\n-rw-rw-r--  1 ndk ndk           0 Jun  2 18:31 g18to6.T62_oRRS18to6v3.GMPAS-IAF.cori-knl_intel.m38-jun1.n050t01.restartc.cpl.r.0001-01-02-00000.nc\\n-rw-rw-r--  1 ndk ndk           0 Jun  2 18:31 Restart_forcing_time_stamp\\ndrwxrwxr-x  3 ndk ndk       24576 Jun  2 18:31 ./\\n-rw-rw-r--  1 ndk ndk       51647 Jun  2 18:31 cpl.log.170602-180412\\n-rw-rw-r--  1 ndk ndk      179109 Jun  2 18:32 acme.log.170602-180412\\n</code></pre>\\n<p>I did verify that we are opening the file to write in 64 bit mode.<br>\\nI also verified that a 60to30 G case can write restarts on this machine, with a similar build/launch script.</p>\\n<p>One example case dir: <code>/global/cscratch1/sd/ndk/acme_scratch/cori-knl/g18to6.T62_oRRS18to6v3.GMPAS-IAF.cori-knl_intel.m38-jun1.n050t01.restartb</code></p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/1574', 'state': 'CLOSED', 'createdAt': '2017-06-03T23:10:14Z', 'lastEditedAt': '2017-06-03T23:11:40Z', 'publishedAt': '2017-06-03T23:10:14Z', 'updatedAt': '2018-01-19T21:31:07Z', 'labels': ['Cori', 'Ocean', 'PIO', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': \"Slow-ish Init in ATM for hires run with large number of MPI's on cori-knl\", 'bodyHTML': '<p>It looks like we have solved the issue of long OCN init times, however, now I\\'m seeing that as I add mpi tasks to the ATM, the init time increases more than I was wanting.  If there is anything obvious here, let me know.</p>\\n<p>For a run where I used 1350 nodes, and 86400 MPI tasks the total ATM init time is 2571 seconds.<br>\\nThis is a copy/paste of the top of model.timing.00000 (where ATM and the ioprocs) live.<br>\\nThis is with a PIO stride of 64, so 1 ioproc per node which <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5619181\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mt5555\">@mt5555</a> has been telling me is way too many.  I will try some experiments using larger strides and see what happens.</p>\\n<pre><code>  \"CPL:INIT\"                                                              -        2    -    4073.949219  4061.454346    12.494794         0.000002 \\n    \"CPL:cesm_pre_init2\"                                                  -        1    -      12.449738    12.449738    12.449738         0.000001 \\n    \"cesm_init\"                                                           -        1    -    4061.432617  4061.432617  4061.432617         0.000001 \\n      \"CPL:init_comps\"                                                    -        1    -    3810.102539  3810.102539  3810.102539         0.000001 \\n        \"comp_init_pre_all\"                                               -        1    -       0.083295     0.083295     0.083295         0.000001 \\n        \"comp_init_cc_atm\"                                                -        1    -    2571.797363  2571.797363  2571.797363         0.000001 \\n          \"a_i:PIO:PIO_openfile\"                                          -       61    -     158.213913    13.942003     0.336415         0.000049 \\n          \"a_i:PIO:pio_get_var_1d_double\"                                 -      113    -       5.425022     1.167913     0.022379         0.000090 \\n          \"a_i:phys_grid_init\"                                            -        1    -     133.904907   133.904907   133.904907         0.000001 \\n          \"a_i:get_decomp\"                                                -       39    -    1227.597168  1222.137451     0.000055         0.000031 \\n            \"a_i:get_filemap\"                                             -        5    -       0.093036     0.092973     0.000010         0.000004 \\n            \"a_i:newdecomp\"                                               -        5    -    1227.498535  1222.041626     0.997233         0.000004 \\n*             \"a_i:PIO:PIO_initdecomp_dof\"                                -        6    -    1228.539917  1222.022949     0.997227         0.000005 \\n                \"a_i:PIO:pio_rearrange_create_box\"                        -        6    -    1227.946411  1221.628906     0.987424         0.000005 \\n          \"a_i:PIO:pio_read_darray\"                                       -       39    -     595.134888   584.083130     0.153516         0.000031 \\n            \"a_i:PIO:pio_read_nf\"                                         -       39    -     593.281372   584.037231     0.063636         0.000031 \\n              \"a_i:PIO:pio_read_nfdarray_double\"                          -       39    -     593.261292   584.017578     0.063627         0.000031 \\n            \"a_i:PIO:pio_rearrange_read\"                                  -       39    -       1.829831     0.293735     0.018234         0.000031 \\n              \"a_i:PIO:pio_rearrange_io2comp_double\"                      -       39    -       1.829200     0.293728     0.018227         0.000031 \\n                \"a_i:PIO:swapm_box_rear_io2comp_double\"                   -       39    -       1.785178     0.292382     0.017234         0.000031 \\n          \"a_i:prim_printstate\"                                           -        1    -       0.344330     0.344330     0.344330         0.000001 \\n*           \"a_i:shr_reprosum_int\"                                        -       46    -       0.559446     0.295437     0.000402         0.000037 \\n              \"a_i:repro_sum_loopa\"                                       -       46    -       0.076683     0.076603     0.000001         0.000037 \\n              \"a_i:repro_sum_allr_minmax\"                                 -       46    -       0.338489     0.141277     0.000149         0.000037 \\n              \"a_i:repro_sum_loopb\"                                       -       46    -       0.000116     0.000009     0.000001         0.000037 \\n              \"a_i:repro_sum_allr_i8\"                                     -       46    -       0.060827     0.046707     0.000130         0.000037 \\n          \"a_i:PIO:PIO_createfile\"                                        -        1    -       0.369699     0.369699     0.369699         0.000001 \\n          \"a_i:PIO:pio_write_darray\"                                      -        1    -       1.252447     1.252447     1.252447         0.000001 \\n            \"a_i:PIO:pio_rearrange_write\"                                 -        1    -       0.274641     0.274641     0.274641         0.000001 \\n              \"a_i:PIO:pre_pio_write_nf\"                                  -        1    -       0.406326     0.406326     0.406326         0.000001 \\n                \"a_i:PIO:pio_rearrange_comp2io_int\"                       -        1    -       0.222040     0.222040     0.222040         0.000001 \\n                  \"a_i:PIO:swapm_box_rear_comp2io_int\"                    -        1    -       0.092857     0.092857     0.092857         0.000001 \\n            \"a_i:PIO:pio_write_nf\"                                        -        1    -       0.088327     0.088327     0.088327         0.000001 \\n              \"a_i:PIO:pio_write_nfdarray_int\"                            -        1    -       0.088257     0.088257     0.088257         0.000001 \\n            \"a_i:PIO:post_pio_write_nf\"                                   -        1    -       0.757628     0.757628     0.757628         0.000001 \\n              \"a_i:PIO:allred_add_data_to_buf\"                            -        1    -       0.755920     0.755920     0.755920         0.000001 \\n          \"a_i:PIO:PIO_closefile\"                                         -       37    -       3.712584     2.220797     0.006267         0.000029 \\n          \"a_i:PIO:pio_get_var_0d_text\"                                   -       18    -       0.660133     0.072124     0.024909         0.000014 \\n          \"a_i:PIO:pio_get_var_5d_double\"                                 -       16    -       0.800779     0.085852     0.039741         0.000013 \\n          \"a_i:PIO:pio_get_var_2d_double\"                                 -       33    -       1.209028     0.099566     0.027176         0.000026 \\n          \"a_i:PIO:pio_get_var_0d_double\"                                 -       61    -       1.637957     0.051915     0.022119         0.000049 \\n          \"a_i:PIO:pio_get_vara_1d_double\"                                -       13    -       0.561216     0.197447     0.024395         0.000010 \\n          \"a_i:PIO:pio_get_var_1d_int\"                                    -       26    -       5.091221     1.362160     0.028045         0.000021 \\n          \"a_i:PIO:pio_get_var_3d_int\"                                    -        1    -       0.173343     0.173343     0.173343         0.000001 \\n          \"a_i:PIO:pio_get_var_3d_double\"                                 -        2    -       0.295559     0.162099     0.133460         0.000002 \\n</code></pre>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1578', 'state': 'OPEN', 'createdAt': '2017-06-07T18:00:36Z', 'lastEditedAt': '2017-06-07T18:04:05Z', 'publishedAt': '2017-06-07T18:00:36Z', 'updatedAt': '2018-01-24T19:14:17Z', 'labels': ['Atmosphere', 'Cori', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'what ocean and sea ice initialization files should we be using?', 'bodyHTML': '<p>This question first occurs in issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"230107100\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/E3SM-Project/E3SM/issues/1547\" data-hovercard-type=\"issue\" data-hovercard-url=\"/E3SM-Project/E3SM/issues/1547/hovercard\" href=\"https://github.com/E3SM-Project/E3SM/issues/1547\">#1547</a> (posed by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5684727\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ndkeen\">@ndkeen</a> ) , but wanted to give it its own home. This is a question for the science and coupled groups, but impacts the performance group (among others).</p>\\n<p>The current ocean (and sea ice) iniitalization files for the water cycle compsets are not recognized as pnetcdf files within PIO, and the netcdf file reads used instead take a long time, making initialization very expensive. The ocean group provided new files that do not have this problem, but these files generate warnings (both for G and water cycle compsets) of the form</p>\\n<pre><code> ERROR: Warning: abs(sum(h)-bottomDepth)&gt;2m. Most likely, initial layerThickness does not match bottomDepth.\\n</code></pre>\\n<p>when used with current master.</p>\\n<p>Is there a timeline for updating the water cycle compset definitions to use \"true\" pnetcdf files? And do the warnings about the ocean initial data impact the performance of the model? Would hate to be using data for these runs to optimize they code performance when they are not representative of production runs.</p>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/1580', 'state': 'CLOSED', 'createdAt': '2017-06-09T18:28:17Z', 'lastEditedAt': '2017-06-09T18:29:22Z', 'publishedAt': '2017-06-09T18:28:17Z', 'updatedAt': '2017-10-02T15:06:55Z', 'labels': ['Coupled Model', 'Ocean', 'PIO', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 10}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': 'Integer divide by zero during different stages before 1 day completes, coupled low/high resolution, edison/cori-knl `forrtl: severe (71): integer divide by zero`', 'bodyHTML': \"<p>I've actually seen this integer-divide-by-zero on several other occasions, but wasn't sure it was real.  This is with a coupled high res run with a PE layout I've not tested before.  It uses 2412 MPI's for the LND and 2 threads.</p>\\n<p>This is with a master from Dec 5th.</p>\\n<p><code>/global/cscratch1/sd/ndk/ACME_simulations/2017-master-dec5.hmod419.mdec5.st04.5d.nr.wh0.atune.si.ne120np4_oRRS18to6v3_ICG.cori-knl</code></p>\\n<pre><code>20837: forrtl: severe (71): integer divide by zero\\n20837: Image              PC                Routine            Line        Source             \\n...\\n20837: acme.exe           0000000003B38CB8  pionfget_mod_mp_g         408  pionfget_mod.F90.in\\n20837: acme.exe           00000000028994AC  ncdio_pio_mp_ncd_        1310  ncdio_pio.F90.in\\n20837: acme.exe           0000000002905D96  surfrdmod_mp_surf         120  surfrdMod.F90\\n20837: acme.exe           000000000277F748  clm_initializemod         127  clm_initializeMod.F90\\n20837: acme.exe           0000000002767A82  lnd_comp_mct_mp_l         200  lnd_comp_mct.F90\\n20837: acme.exe           000000000042AECE  component_mod_mp_         231  component_mod.F90\\n20837: acme.exe           0000000000419B47  cime_comp_mod_mp_        1186  cime_comp_mod.F90\\n20837: acme.exe           0000000000427D6F  MAIN__                     92  cime_driver.F90\\n\\ncori05% tail run/lnd.log.171207-190308 \\n (GETFIL): attempting to find local file \\n domain.lnd.ne120np4_oRRS18to6v3.170111.nc\\n (GETFIL): using \\n /global/cscratch1/sd/acmedata/inputdata/share/domains/domain.lnd.ne120np4_oRRS1\\n 8to6v3.170111.nc\\n Opened existing file \\n /global/cscratch1/sd/acmedata/inputdata/share/domains/domain.lnd.ne120np4_oRRS1\\n 8to6v3.170111.nc           0\\n lat/lon grid flag (isgrid2d) is  F\\n ncd_inqvid: variable LANDMASK is not on dataset\\n\\n</code></pre>\\n<p>I see the same error with at least 3 other PE layouts.</p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/1975', 'state': 'OPEN', 'createdAt': '2017-12-08T03:32:35Z', 'lastEditedAt': '2017-12-08T03:33:59Z', 'publishedAt': '2017-12-08T03:32:35Z', 'updatedAt': '2018-02-06T19:17:08Z', 'labels': ['Cori', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': ' SMS_D.ne4_oQU240.A_WCYCL1850S_CMIP6 fails on edison/cori.  `pio_support::pio_die:: myrank=   -1 : ERROR: ionf_mod.F90`', 'bodyHTML': \"<p>On edison, with and without DEBUG, we get a failure trying to run the ne4 version of this test.  It would be nice to have for debugging. This is on next, but we also see the same error with master of several days ago.</p>\\n<p>I also see a failure on cori, but the error is different.  It is an error I've seen before when there is trouble with a netcdf file format. I would need to put print statements in the code to find out which file it is trying to open.  May not be the same error as below.</p>\\n<pre><code> 6:  UrbanInputldomain and input file do not match dims \\n 6:  UrbanInputldomain%ni,ni,=          866       48602\\n 6:  UrbanInputldomain%nj,nj,=            1           1\\n 6:  UrbanInputldomain%ns,ns,=          866       48602\\n 6:  ENDRUN:\\n 6:  ERROR in UrbanParamsType.F90 at line 467                                       \\n 6:                                                                                 \\n 6:                                                                                 \\n 6:                                                                                 \\n 6:                                                                                 \\n 6:                                                                                 \\n 6:                                        \\n 6:  ERROR: Unknown error submitted to shr_abort_abort.\\n 6: Image              PC                Routine            Line        Source             \\n 6: acme.exe           000000001144599D  Unknown               Unknown  Unknown\\n 6: acme.exe           000000000E7F903F  shr_abort_mod_mp_         114  shr_abort_mod.F90\\n 6: acme.exe           000000000E7F8EBC  shr_abort_mod_mp_          61  shr_abort_mod.F90\\n 6: acme.exe           0000000008098E48  abortutils_mp_end          43  abortutils.F90\\n 6: acme.exe           000000000AB83EC9  urbanparamstype_m         467  UrbanParamsType.F90\\n 6: acme.exe           00000000080D5500  clm_initializemod         211  clm_initializeMod.F90\\n 6: acme.exe           00000000080693D8  lnd_comp_mct_mp_l         200  lnd_comp_mct.F90\\n 6: acme.exe           00000000004532C1  component_mod_mp_         231  component_mod.F90\\n 6: acme.exe           000000000041C8A1  cime_comp_mod_mp_        1183  cime_comp_mod.F90\\n 6: acme.exe           0000000000449E2D  MAIN__                     92  cime_driver.F90\\n</code></pre>\\n<p><code>/global/cscratch1/sd/ndk/acme_scratch/edison/n30-mjan19/SMS_D.ne4_oQU240.A_WCYCL1850S_CMIP6.edison_intel.20180119_131652_m0zwzm</code></p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/2043', 'state': 'CLOSED', 'createdAt': '2018-01-20T17:49:48Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T17:49:48Z', 'updatedAt': '2018-06-28T19:59:25Z', 'labels': ['Land', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': \" Fortran runtime error: Index '1' of dimension 1 of array 'skw_zt' outside of expected range with ne16/ne30 F case using GNU DEBUG on edison\", 'bodyHTML': \"<p>On edison, the DEBUG version of the ne30 F case has the following issue. SMS_D_Ln5.ne30_ne30.FC5AV1C-L.edison_gnu</p>\\n<pre><code> 512: At line 938 of file /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/clubb/advance_clubb_core_module.F90At line 938 of file /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/clubb/advance_clubb_core_module.F90\\n 512: Fortran runtime error: \\n 512: Fortran runtime error: Index '1' of dimension 1 of array 'skw_zt' outside of expected range (0:0)Index '1' of dimension 1 of array 'skw_zt' outside of expected range (0:0)\\n 512: \\n 512: \\n 512: Error termination. Backtrace:\\n 512: \\n 512: Error termination. Backtrace:\\n 512: #0  0xde3122 in __advance_clubb_core_module_MOD_advance_clubb_core\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/clubb/advance_clubb_core_module.F90:938\\n 512: #1  0xaa8a44 in __clubb_intr_MOD_clubb_tend_cam\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/cam/clubb_intr.F90:1881\\n 512: #0  0xde3122 in __advance_clubb_core_module_MOD_advance_clubb_core\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/clubb/advance_clubb_core_module.F90:938\\n 512: #2  0x5e3300 in tphysbc\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/cam/physpkg.F90:2462\\n 512: #3  0x5e6e97 in __physpkg_MOD_phys_run1._omp_fn.1\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/cam/physpkg.F90:1029\\n 512: #1  0xaa8a44 in __clubb_intr_MOD_clubb_tend_cam\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/cam/clubb_intr.F90:1881\\n 512: #2  0x5e3300 in tphysbc\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/cam/physpkg.F90:2462\\n 512: #3  0x5e6e97 in __physpkg_MOD_phys_run1._omp_fn.1\\n 512:   at /global/cscratch1/sd/ndk/wacmy/next30-jan19/components/cam/src/physics/cam/physpkg.F90:1029\\n</code></pre>\\n<p>Intel DEBUG did not have a problem.</p>\\n<p><code>/global/cscratch1/sd/ndk/acme_scratch/edison/n30-mjan19/SMS_D_Ln5.ne30_ne30.FC5AV1C-L.edison_gnu.20180120_094625_yw1ibe</code></p>\", 'url': 'https://github.com/E3SM-Project/E3SM/issues/2044', 'state': 'OPEN', 'createdAt': '2018-01-21T17:16:51Z', 'lastEditedAt': None, 'publishedAt': '2018-01-21T17:16:51Z', 'updatedAt': '2018-04-03T21:02:31Z', 'labels': ['Atmosphere', 'Edison', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'E3SM', 'repo_owner_name': 'Energy Exascale Earth System Model Project', 'repo_owner_email': '', 'repo_owner_user_name': 'E3SM-Project', 'repo_owner_profile_url': 'https://github.com/E3SM-Project', 'title': '\"Allocatable array or pointer is not allocated\" in radiation with highres ne120 F case (and coupled cases)', 'bodyHTML': '<p>I was seeing this with run_acme scripts and was finally able to repeat with a create_test:</p>\\n<p><code>SMS_Ld2_D_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_HR.cori-knl_intel.cam-cosplite</code></p>\\n<pre><code>1589: forrtl: severe (153): allocatable array or pointer is not allocated\\n1589: Image              PC                Routine            Line        Source             \\n1589: acme.exe           0000000011D90A0C  Unknown               Unknown  Unknown\\n1589: acme.exe           000000000192FB63  rrtmg_state_mp_rr         236  rrtmg_state.F90\\n1589: acme.exe           0000000000E24215  radiation_mp_radi        1286  radiation.F90\\n1589: acme.exe           0000000000D41FC7  physpkg_mp_tphysb        2673  physpkg.F90\\n1589: acme.exe           0000000000D0E9FA  physpkg_mp_phys_r        1027  physpkg.F90\\n1589: acme.exe           00000000102338E3  Unknown               Unknown  Unknown\\n1589: acme.exe           00000000101EB1C0  Unknown               Unknown  Unknown\\n1589: acme.exe           00000000101EA41A  Unknown               Unknown  Unknown\\n1589: acme.exe           0000000010233C99  Unknown               Unknown  Unknown\\n1589: acme.exe           000000001167A174  Unknown               Unknown  Unknown\\n1589: acme.exe           0000000011F1D519  Unknown               Unknown  Unknown\\n</code></pre>\\n<p><code>/global/cscratch1/sd/ndk/acme_scratch/cori-knl/m67-mar1/SMS_Ld2_D_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_HR.cori-knl_intel.cam-cosplite.20180307_072800_wz9x89/</code></p>\\n<p>I also see the same error with the following, where I was using incorrect compset:<br>\\n<code>SMS_D_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_LRtunedHR</code><br>\\n<code>/global/cscratch1/sd/ndk/acme_scratch/cori-knl/m67-mar1/SMS_D_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_LRtunedHR.cori-knl_intel.20180306_085459_a4y7e0</code></p>\\n<p>This test (without using cosp_lite modifier) also fails, but the error is different:<br>\\n<code>SMS_Ld2_D_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6</code></p>\\n<p>And the following non-DEBUG tests passed (ie did not hit an error):</p>\\n<pre><code>SMS_PS.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_HR.cori-knl_intel.cam-cosplite\\nSMS_PS.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_HR.cori-knl_intel\\nSMS_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_HR.cori-knl_intel.cam-cosplite\\nSMS_PT.ne120np4_oRRS18to6v3_ICG.A_WCYCL1950S_CMIP6_HR.cori-knl_intel\\n</code></pre>', 'url': 'https://github.com/E3SM-Project/E3SM/issues/2131', 'state': 'OPEN', 'createdAt': '2018-03-07T02:29:34Z', 'lastEditedAt': '2018-03-08T00:42:04Z', 'publishedAt': '2018-03-07T02:29:34Z', 'updatedAt': '2018-09-26T21:25:03Z', 'labels': ['Cori', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'parasail', 'repo_owner_name': 'Jeff Daily', 'repo_owner_email': 'jeff.daily@amd.com', 'repo_owner_user_name': 'jeffdaily', 'repo_owner_profile_url': 'https://github.com/jeffdaily', 'title': 'Add meson build system', 'bodyHTML': '<p>Hey <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=904248\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jeffdaily\">@jeffdaily</a><br>\\nMeson is a new meta-buildsystem that generates Ninja files instead of Makefiles. It is much faster, allows for greater portability and has many nice features such as building as part of other projects, enabling address/memory/undefined-behaviour sanitiser and unity builds. Would you be willing to accept a PR to add it?</p>', 'url': 'https://github.com/jeffdaily/parasail/issues/39', 'state': 'CLOSED', 'createdAt': '2017-11-10T10:39:03Z', 'lastEditedAt': None, 'publishedAt': '2017-11-10T10:39:03Z', 'updatedAt': '2017-12-15T18:01:36Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Bizarre linking issue', 'bodyHTML': '<p>This is more of a \"help_wanted\" kind of question.</p>\\n<p>I am having a linking issue for netcdf with albany. On my workstation I have a systemwide netcdf installation (needed by some other packages, e.g., octave). When I build albany (and trilinos), I load modules for all the required libraries (hdf5, netcdf, yaml...). At the end, my LD_LIBRARY_PATH env variable looks like this (i\\'m using fake path names for brevity):</p>\\n<p><code>LD_LIBRARY_PATH=/modulepath/netcdf/lib;/modulepath/hdf5/lib:/modulepath/openmpi/lib:.../usr/lib64:/usr/lib</code></p>\\n<p>So the system directories are <em>at the end</em>. Good. When I build trilinos, everything is fine, and when I inspect the libraries with <code>ldd libXYZ.so | grep netcdf</code>, I see that the correct one is linked (the one in <code>/modulepath/netcdf/lib</code>). However, when I build albany, the <em>wrong</em> one is picked. This generates a warning</p>\\n<pre><code>/usr/bin/ld: warning: libnetcdf.so.11, needed by\\n /path/to/trilinos/lib/libstk_tools_lib.so.12.13, may conflict with libnetcdf.so.7\\n</code></pre>\\n<p>and, more importantly, the system library does not support parallel correctly. I can verify that the wrong netcdf is linked, since with, say, <code>ldd libalbanySTK.so | grep netcdf</code> I get</p>\\n<pre><code>libnetcdf.so.7 =&gt; /usr/lib64/libnetcdf.so.7 (0x00007f0cc5235000)\\nlibnetcdf.so.11 =&gt; /modulepath/netcdf/lib/libnetcdf.so.11 (0x00007f0cbf75a000)\\n</code></pre>\\n<p>It appears that <em>somewhere</em> in albany, the path <code>/usr/lib64</code> is prepended to <code>ld</code> search path. I looked through the build directory, but I cannot find the place where this happens. Even the <code>build.cmake</code> file for <code>libalbanySTK</code> lists the correct dependency in the <code>albanySTK_EXTERNAL_OBJECTS</code> variable (i.e., it lists <code>/modulepath/netcdf/lib/libnetcdf.so</code>), but then the other one gets linked, when <code>-lnetcdf</code> is found on the link line.</p>\\n<p>I found a workaround by adding the <a href=\"https://cmake.org/cmake/help/v3.3/policy/CMP0060.html\" rel=\"nofollow\">policy</a> <code>cmake_policy(SET CMP0060 NEW)</code> to the main <code>CMakeLists.txt</code>, but I don\\'t want to do that, especially since I am probably the only one with this issue.</p>\\n<p>Has anyone experienced the same problem at some point?</p>', 'url': 'https://github.com/gahansen/Albany/issues/232', 'state': 'CLOSED', 'createdAt': '2017-11-30T23:31:15Z', 'lastEditedAt': '2017-11-30T23:33:15Z', 'publishedAt': '2017-11-30T23:31:15Z', 'updatedAt': '2017-12-01T00:14:35Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Albany User Guide', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971921\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibaned\">@ibaned</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7558465\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/agsalin\">@agsalin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5940580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mperego\">@mperego</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7018124\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ikalash\">@ikalash</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=147948\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jtostie\">@jtostie</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5702945\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bgranzow\">@bgranzow</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3226046\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartgol\">@bartgol</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11995357\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/calleman21\">@calleman21</a></p>\\n<p>Sorry for spamming all of you, but I think this issue is very broad.</p>\\n<p>In the past, and most recently today, I have been asked whether there is an Albany User Guide for people that want to just run Albany, but have no plans to touch the source code.</p>\\n<p>I believe that there is scattered information here and there, and I\\'m reaching out to all of you to ask if you know about it, and to gage the interest to try to bring it together into a single place.</p>\\n<p>Thoughts?</p>', 'url': 'https://github.com/gahansen/Albany/issues/250', 'state': 'OPEN', 'createdAt': '2018-01-19T01:48:41Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T01:48:41Z', 'updatedAt': '2018-01-22T15:49:56Z', 'labels': ['help wanted', 'question', 'user documentation', 'user usability'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Hanging Tempus tests on skybridge-login5 with intel compiler', 'bodyHTML': '<p>Around Feb. 9, 2 Tempus tests began failing in <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> \\'s Skybridge intel build:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlypassed&amp;buildid=67116\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlypassed&amp;buildid=67116</a></p>\\n<p>What is truly bizarre about this problem is when I use the same exact scripts as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> to run the tests, also on skybridge-login5 and run via cronjob, the tests pass:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/index.php?project=Albany&amp;subproject=albany_cluster-toss3_skybridge-login5_serial-intel-release&amp;date=2018-02-19\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/index.php?project=Albany&amp;subproject=albany_cluster-toss3_skybridge-login5_serial-intel-release&amp;date=2018-02-19</a></p>\\n<p>We have made sure that my ~/.bashrc and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a>\\'s ~/.bashrc files are the same.  Anyone have any thoughts?  It would be nice if perhaps someone else could give this build a try and report what happens.</p>', 'url': 'https://github.com/gahansen/Albany/issues/265', 'state': 'CLOSED', 'createdAt': '2018-02-20T16:10:36Z', 'lastEditedAt': None, 'publishedAt': '2018-02-20T16:10:36Z', 'updatedAt': '2018-07-02T03:31:29Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Replacement for MDArray, potential bad memory leak in Shards from MDArray', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971921\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibaned\">@ibaned</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7018124\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ikalash\">@ikalash</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7558465\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/agsalin\">@agsalin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a>  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5940580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mperego\">@mperego</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3226046\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartgol\">@bartgol</a> While chasing a frustrating bug in Schwarz about resetting state arrays, I discovered that MDArrays are shards::Arrays, as defined in Albany_StateInfoStruct.hpp.</p>\\n<p>shards::Arrays overload the operator= with a shallow copy, hence the failure in resetting state variables for Schwarz.</p>\\n<p>There are two problems with this:</p>\\n<ul>\\n<li>There appears to be no way to do a deep copy of an MDArray/shard:Array, which is needed for Schwarz.</li>\\n<li>The shallow copy uses raw pointers. It does not free the old pointer before overwriting it with the new one, hence the memory it was pointing to is lost.</li>\\n</ul>\\n<p>My question is: is it possible to replace the MDArray in Albany_StateInfoStruct.hpp with something else? A Kokkos view perhaps?</p>\\n<p>I could jump through hoops and make this work with MDArrays somehow, but it seems to me that there should be a cleaner solution and also avoid the potential for memory leaks.</p>\\n<p>I\\'m open to suggestions.</p>', 'url': 'https://github.com/gahansen/Albany/issues/268', 'state': 'CLOSED', 'createdAt': '2018-02-28T19:21:22Z', 'lastEditedAt': '2018-02-28T19:42:49Z', 'publishedAt': '2018-02-28T19:21:22Z', 'updatedAt': '2018-03-08T00:13:27Z', 'labels': ['bug', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Albany build broken due to Kokkos::Experimental::Impl not being defined', 'bodyHTML': '<p>It looks like Albany failed to build in the nightlies last night.  I can only see the external CDash, as I am on foreign travel:</p>\\n<p><a href=\"https://my.cdash.org/viewBuildError.php?buildid=1381133\" rel=\"nofollow\">https://my.cdash.org/viewBuildError.php?buildid=1381133</a></p>\\n<p>but I am guessing this happened in the internal tests too.  Here is the error cut/paste here:</p>\\n<pre><code>repos/Albany/src/PHAL_Utilities_Def.hpp:224:39: error: \\'Kokkos::Experimental::Impl\\' has not been declared\\n</code></pre>\\n<p>Can someone please look at what is going on / fix it while I am away?</p>', 'url': 'https://github.com/gahansen/Albany/issues/269', 'state': 'CLOSED', 'createdAt': '2018-03-08T08:08:42Z', 'lastEditedAt': '2018-03-08T08:10:41Z', 'publishedAt': '2018-03-08T08:08:42Z', 'updatedAt': '2018-03-08T16:51:51Z', 'labels': ['build', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Tpetra::Map destructor warning printed for Albany tests', 'bodyHTML': '<p>I noticed that starting this morning, all (I believe) Albany tests have this warning printed:</p>\\n<pre><code>WARNING: Tpetra::Map destructor (~Map()) is being called after Tpetra::finalize() has been called.  This is user error!  This may happen if you create a Tpetra::Map (or RCP or shared_ptr of a Tpetra::Map) at the same scope in main() as Tpetra::finalize().  Don\\'t do that.  Please refer to GitHib Issue #2372.\\n</code></pre>\\n<p>It looks like the warning was added to Tpetra yesterday (see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"304818275\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/2372\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/2372/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/2372\">trilinos/Trilinos#2372</a> ).  We should try to understand what we\\'re doing wrong with the Tpetra::Map destructor.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1564391\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tjfulle\">@tjfulle</a>, would you be willing to look at this, as someone well-acquainted with Tpetra and also working on Albany maintenance?</p>', 'url': 'https://github.com/gahansen/Albany/issues/275', 'state': 'CLOSED', 'createdAt': '2018-03-20T15:48:30Z', 'lastEditedAt': '2018-03-20T15:48:43Z', 'publishedAt': '2018-03-20T15:48:30Z', 'updatedAt': '2018-03-21T20:38:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Issue with LCM Python tests that execute \"./AlbanyT *yaml\" command on some HPC platforms', 'bodyHTML': '<p>In building / running Albany/LCM on the Solo ECN machine, I discovered an issue with the LCM tests that run python scripts with the command \"./AlbanyT *yaml\".  The issue is on some platforms, \"mpirun -np 1 AlbanyT\" or \"mpiexec -np 1 AlbanyT\" is required to run serial executables, with Solo being one of them.  I think this issue may have come up before.  I can modify the scripts to execute the command \"mpirun -np 1 AlbanyT\" except I think then on some platforms there may be an issue with not providing a path to mpirun (or using srun / mpiexec instead of mpirun).  Ideally, we\\'d want to get the path to the mpi command from cmake.  I think <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a> may have encountered this before.</p>\\n<p>Here are the tests that would need to be modified to fix this:</p>\\n<pre><code>    109 - CohesiveElement (Failed)\\n    112 - EquilibriumConcentrationBC (Failed)\\n    113 - HeliumODEs (Failed)\\n    117 - AnisotropicHyperelasticDamage (Failed)\\n    118 - AnisotropicDamage-Bifurcation (Failed)\\n    119 - Gurson (Failed)\\n    120 - Neohookean (Failed)\\n    121 - CrystalPlasticity_MPS (Failed)\\n    131 - MechanicsWithHelium (Failed)\\n    137 - Partition (Failed)\\n    142 - SurfaceElementLocking (Failed)\\n    143 - SurfaceElementOrtiz (Failed)\\n    230 - Schwarz_Cubes (Failed)\\n    231 - Schwarz_Alternating_Quasistatics (Failed)\\n    232 - Schwarz_Alternating_Dynamics_Cubes (Failed)\\n    233 - Schwarz_Alternating_Dynamics_CubesInelastic (Failed)\\n</code></pre>', 'url': 'https://github.com/gahansen/Albany/issues/278', 'state': 'CLOSED', 'createdAt': '2018-03-29T03:28:48Z', 'lastEditedAt': '2018-07-02T22:55:43Z', 'publishedAt': '2018-03-29T03:28:48Z', 'updatedAt': '2018-07-07T00:49:04Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Time Dependent BC that varies in space and time ', 'bodyHTML': \"<p>As discussed at the Albany meeting this morning, there is an interest in adding to Albany a time dependent BC (Dirichlet as well as Neumann) where the BC values are spatially and temporally dependent, and not given by an analytical function.  Albany currently has the following capabilities:</p>\\n<ul>\\n<li>Set a Dirichlet BC from a field in the mesh named dirichlet_field (allowing a spatially-varying BC that is not given by an analytical function).</li>\\n<li>Set a time-dependent BC (Dirichlet, perhaps Neumann too) that is spatially constant on a given nodeset.</li>\\n</ul>\\n<p>The new time dependent BC would combine these two capabilities.  Specifically, we'd need to:</p>\\n<ul>\\n<li>Add the capability to read snapshots defining the BC field into dirichlet_field.  Probably we should not store all the snapshots but a couple at a time to avoid running out of memory.</li>\\n<li>Add the capability to interpolate the time-dependent BC values to times where they are needed, in the case where the time-step is different than the times where the snapshots are stored.  This sort of interpolation is done already in TimeDepBC for scalar-valued (in space) BCs.  This interpolation is what will require at least 2 BC snapshots to be stored at a time.</li>\\n</ul>\\n<p>Any volunteers to help with this task?  The new BC is of interest to the Tsunami work, as well as the RPI folks; perhaps others are interested in this too?</p>\", 'url': 'https://github.com/gahansen/Albany/issues/316', 'state': 'OPEN', 'createdAt': '2018-07-09T16:49:13Z', 'lastEditedAt': None, 'publishedAt': '2018-07-09T16:49:13Z', 'updatedAt': '2018-07-09T19:59:15Z', 'labels': ['Tsunami', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Add a test for the Vx, Vxdot, Vxdotdot, Vp tangent direction functionalities.', 'bodyHTML': \"<p>Currently, these are in the Workset, but are never set to annything other than NULL by the model evaluator. Hence, all the evaluators that are supposed to do something if they are not null, do nothing.</p>\\n<p>We should come up with a test that uses them, even if it is from a modified version of Albany's model evaluator.</p>\", 'url': 'https://github.com/gahansen/Albany/issues/335', 'state': 'OPEN', 'createdAt': '2018-07-19T23:16:53Z', 'lastEditedAt': None, 'publishedAt': '2018-07-19T23:16:53Z', 'updatedAt': '2018-07-19T23:16:53Z', 'labels': ['Testing', 'help wanted', 'infrastructure'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Warning-free Albany build', 'bodyHTML': '<p>I was tracking down a bug, and it ended up being something like <code>a - b;</code> instead of <code>a = b;</code>. So I thought \"well, let\\'s turn on warnings, so I don\\'t waste 1h of my time later on finding these bugs\". And then warningmageddon happened.</p>\\n<p>Albany generates a gazillion of warnings! Unused parameters/typedefs, signed/unsigned comparisons, and initialization order are the major stars of the show, with countless hits.</p>\\n<p>Now, virtually all of these warning are benign, and could be ignored. However, as Albany grows larger and larger, it would be nice (to say the least) to fix those warnings. Besides, the fewer the warnings spit out by the compiler, the easier it is to catch the dangerous ones. I think of this issue as a constant reminder: if we run into one obvious warning, we should clean it up, together with our commits. And possibly not introduce a new one.</p>\\n<p>Note: yes, we can silence warnings, but that\\'s not a very clean solution.</p>', 'url': 'https://github.com/gahansen/Albany/issues/354', 'state': 'OPEN', 'createdAt': '2018-08-14T19:22:22Z', 'lastEditedAt': None, 'publishedAt': '2018-08-14T19:22:22Z', 'updatedAt': '2018-08-15T00:11:35Z', 'labels': ['build', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Numerous test failures in Albany nightlies as of this morning', 'bodyHTML': '<p>There are numerous test failures in Albany as of this morning:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlyfailed&amp;buildid=75093\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlyfailed&amp;buildid=75093</a></p>\\n<p>Most of them seem to be failures when running exodiff for LCM problems, but a few seem to have to do with reading in an Exodus file to restart from, e.g. <a href=\"http://cdash.sandia.gov/CDash-2-3-0/testDetails.php?test=3880312&amp;build=75103\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/testDetails.php?test=3880312&amp;build=75103</a>:</p>\\n<pre><code>p=2: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Variable type counts are inconsistent. See processor 0 output for more details.\\np=3: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Variable type counts are inconsistent. See processor 0 output for more details.\\np=0: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Number of nodeset variables is not consistent on all processors.\\n        Database: th1d_tpetra.exo\\n \\tProcessor 0 count = 3\\n \\tProcessor 1 count = 0\\n \\tProcessor 2 count = 0\\n</code></pre>\\n<p>It looks like there were no non-trivial checkins to Albany master this week, so I think the failures are due to changes in Trilinos.  Anyone want to investigate this?</p>', 'url': 'https://github.com/gahansen/Albany/issues/358', 'state': 'CLOSED', 'createdAt': '2018-08-23T15:57:17Z', 'lastEditedAt': None, 'publishedAt': '2018-08-23T15:57:17Z', 'updatedAt': '2018-09-24T16:59:58Z', 'labels': ['Testing', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Modify alg.i for SurfaceElementLocking to have exodiff compare SURF_S*, SURF_* and SURF_HYDRO_* fields', 'bodyHTML': '<p>In resolving issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"353447168\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/358\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/358/hovercard\" href=\"https://github.com/gahansen/Albany/issues/358\">#358</a> , I had to turn off exodiff comparisons of some of the SURF fields for the SurfaceElementLocking test case, as these fields are no longer generated in the *alg.e file when running algebra, due to a change in the naming of STK fields written to the output exodus file.  If these comparisons are of interest, can someone (preferably the author and one familiar with what algebra is supposed to be doing - tagging <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7317023\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jwfoulk\">@jwfoulk</a> ) look at this with me (or look at it on their own/fix it)?  I think the fix should be very quick.</p>', 'url': 'https://github.com/gahansen/Albany/issues/365', 'state': 'OPEN', 'createdAt': '2018-09-24T16:59:21Z', 'lastEditedAt': None, 'publishedAt': '2018-09-24T16:59:21Z', 'updatedAt': '2018-09-24T16:59:21Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Make headers include all explicit dependencies', 'bodyHTML': '<p>Plenty of headers in Albany (especially in the evaluators folder) miss some includes. For instance, very few evaluators headers include <code>PHAL_Dimension.hpp</code> (directly or indirectly). Things obviously work anyways, since at the time of use, such headers are (directly or indirectly) included. For instance, including <code>PHAL_AlbanyTraits.hpp</code> brings in all the data types and the dimensions tags.</p>\\n<p>While this <em>works</em>, it is also not optimal, at least on 2+1 levels:</p>\\n<ol start=\"0\">\\n<li>it is a bad practice;</li>\\n<li>when faced with a function/class/type I don\\'t fully understand, I sometimes go up the include stack, till I reach the point where it is defined. Relying on some upstream headers being included at the time the current header will be used makes this impossible;</li>\\n<li>If you have a text editor with real-time compilation in the background that highlights compiler errors, you can be submerged by a red-tide of errors, which make navigating the code harder.</li>\\n</ol>\\n<p>While I understand that the effort of fixing this is probably too big for the gain we would get (after all, the code compiles and runs), I would like to ask developers to be aware of this. When adding a new header or modifying an existing one, please spend 3 seconds checking whether each symbol\\'s header is included (directly or indirectly), and add it if missing.</p>\\n<p>P.S: I don\\'t want to get into the discussion of whether indirect inclusion is fine or not (though I am a strong supporter of \"include everything you explicitly use that you cannot forward declare\", rather than \"if the first header you include includes the second one, you don\\'t need the second one\"). What I\\'m <em>strongly encouraging</em> is the idea that including any header from our library in file <code>foo.cpp</code> should <em>not</em>  force the user to include other headers that <code>foo.cpp</code> does not explicitly need. The end user may not even know where the symbol <code>Cell</code> is defined, nor should he/she care.</p>', 'url': 'https://github.com/gahansen/Albany/issues/379', 'state': 'OPEN', 'createdAt': '2018-11-01T15:01:34Z', 'lastEditedAt': '2018-11-01T15:04:59Z', 'publishedAt': '2018-11-01T15:01:34Z', 'updatedAt': '2018-11-01T15:04:59Z', 'labels': ['developer usability', 'help wanted', 'user usability'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Remove or replace all instances of ALBANY_KOKKOS_UNDER_DEVELOPMENT', 'bodyHTML': '<p>This has been discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260676342\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/184\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/184/hovercard\" href=\"https://github.com/gahansen/Albany/issues/184\">#184</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378833321\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/382\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/382/hovercard\" href=\"https://github.com/gahansen/Albany/issues/382\">#382</a>. It would be great to remove it and keep the kokkos kernels but there may be some instances where we would like to keep the legacy implementation. At the very least, my suggestion would be to try to remove it everywhere except where kernels are called and make it a requirement to use the Kokkos data abstractions. Then possibly rename it too <code>ALBANY_USE_KOKKOS_KERNELS</code> or flip it to <code>ALBANY_LEGACY_CODE</code> so that the kokkos kernels are the default.</p>', 'url': 'https://github.com/gahansen/Albany/issues/385', 'state': 'OPEN', 'createdAt': '2018-11-12T19:19:10Z', 'lastEditedAt': None, 'publishedAt': '2018-11-12T19:19:10Z', 'updatedAt': '2018-11-14T18:20:33Z', 'labels': ['Discussion', 'Kokkos', 'developer usability', 'help wanted', 'infrastructure'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'Add version-dependent dependencies to Spack packager documentation', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=97253\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mathstuf\">@mathstuf</a> :<br>\\nOn Tue, Mar 08, 2016 at 14:27:50 -0500, Elizabeth Fischer wrote:</p>\\n<blockquote>\\n<p>Not sure if Spack can do this, I didn\\'t find anything in the docs that says<br>\\nit can...</p>\\n<p>Suppose I have library B, which depends on A.  Different versions of B<br>\\nrequire specific versions of A.  For example:</p>\\n<pre><code>B@1.0 requires A@1.1:1.3\\nB@2.0 requires A@1.5:\\n</code></pre>\\n<p>How would I write a package.py file encoding this version-dependent<br>\\ndependency information?  The normal way these things are written, the<br>\\ndepends_on() statement  is written before the B\\'s version number is known.</p>\\n</blockquote>\\n<p>Would:</p>\\n<pre><code>depends_on(\\'A@1.1:1.3\\', when=\\'@1.0\\')\\ndepends_on(\\'A@1.5:\\', when=\\'@2.0\\')\\n</code></pre>\\n<p>not work?</p>', 'url': 'https://github.com/spack/spack/issues/510', 'state': 'OPEN', 'createdAt': '2016-03-08T19:53:51Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T19:53:51Z', 'updatedAt': '2017-11-22T06:32:56Z', 'labels': ['documentation', 'good first issue', 'help wanted', 'up-for-grabs'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'boost: auto-detect and disable ~/user-config.jam', 'bodyHTML': \"<p>I was trying to build Boost via Spack on a system where I previously had created a file <code>~/user-config.jam</code>. This file overrides Spack's configuration options for Boost, leading to a build failure. (The build failure is somewhat hard to detect since it doesn't mention this file, the symptoms are just that the build options that Boost reports are slightly different than what they should be.)</p>\\n<p>Spack should detect the presence of that file, and should either abort with an error, or should temporarily disable it.</p>\", 'url': 'https://github.com/spack/spack/issues/888', 'state': 'OPEN', 'createdAt': '2016-05-03T17:52:04Z', 'lastEditedAt': None, 'publishedAt': '2016-05-03T17:52:04Z', 'updatedAt': '2017-11-22T07:17:23Z', 'labels': ['build-error', 'good first issue', 'help wanted', 'up-for-grabs'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'Mixed Toolchains documentation out-of-date', 'bodyHTML': '<p>The documentation in the section titled</p>\\n<p><a href=\"http://spack.readthedocs.io/en/latest/getting_started.html#mixed-toolchains\" rel=\"nofollow\">Mixed Toolchains</a></p>\\n<p>refers in step 4 to the old location for the compilers.yaml file, and shows an example in the old format for an entry in that file.</p>', 'url': 'https://github.com/spack/spack/issues/2651', 'state': 'OPEN', 'createdAt': '2016-12-20T22:52:14Z', 'lastEditedAt': None, 'publishedAt': '2016-12-20T22:52:14Z', 'updatedAt': '2017-11-22T13:14:07Z', 'labels': ['documentation', 'help wanted', 'up-for-grabs'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'Questions about extend(..., ignore=...)?', 'bodyHTML': \"<ol>\\n<li>\\n<p>The docs should make it clear that <code>ignore=</code> takes regular expressions, not glob wildcard expressions (unless we want to do the latter).</p>\\n</li>\\n<li>\\n<p>How do I ignore more than one thing?  kwargs cannot be repeated.  Would I do this?</p>\\n</li>\\n</ol>\\n<pre><code>extends('python', ignore=('a', 'b'))\\n</code></pre>\", 'url': 'https://github.com/spack/spack/issues/2753', 'state': 'OPEN', 'createdAt': '2017-01-05T18:21:10Z', 'lastEditedAt': None, 'publishedAt': '2017-01-05T18:21:10Z', 'updatedAt': '2017-11-22T13:35:55Z', 'labels': ['documentation', 'good first issue', 'help wanted', 'ready', 'up-for-grabs'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'is it possible to add dependency on -lm [or equivalent] in spack package dependencies?', 'bodyHTML': '<p>Some compilers do not link with -lm [or equivalent] by default. And some packaged do not deal with this in their build tools.</p>\\n<p>Does spack provide a mechanism to specify a dependency on -lm or equivalent library?</p>\\n<p>[for eg: gcc on fedora 27 requires -lm. And one should not use -lm with intel compilers - as intel provides -limf - which intel compilers link with by default]</p>\\n<p>The issue arises with \\'plasma\\' package.</p>\\n<pre><code>     11033 /usr/lib64/ccache/gcc -fopenmp -fPIC -o test/test test/test_zunmlq.o test/test_zsymm.o test/test_zgetri.o test/test_zpotrs.o test/test_zpotri.o test/test_zlansy.o test/test_zlacpy.o test/test_zgeqrf.o test/test_zgelqs.o test/test_dzamax.o test/test_zgetri_aux.o test/test_zpotrf.o test/test_zsyr2k.o test/test_zgesv.o test/test_ztrtri.o test/test_zsyrk.o test/test_zposv.o test/test_zlange.o test/test_zher2k.o test/test_ztrmm.o test/test_zlantr.o test/test_ztradd.o test/test_zhemm.o test/test_zgemm.o test/test_ztrsm.o test/test_zgeadd.o test/test_zherk.o test/test_zlauum.o test/test_zgels.o test/test_zcposv.o test/test_zgetrs.o test/test_zlag2c.o test/test_zgbtrf.o test/test_zpbsv.o test/test_zgbsv.o test/test_zgeqrs.o test/test_zpbtrf.o test/test_zlascl.o test/test_zlaswp.o test/test_zgetrf.o test/test_zlaset.o test/test_clag2z.o test/test_zgelqf.o test/test_zunmqr.o test/test_zlanhe.o test/test_zcgesv.o test/test.o test/test_sormlq.o test/test_dormlq.o test/test_cunmlq.o test/test_ssymm.o test/test_dsymm.o test/test_csymm.o test/test_cgetri.o test/test_dgetri.o test/test_sgetri.o test/test_spotrs.o test/test_dpotrs.o test/test_cpotrs.o test/test_cpotri.o test/test_dpotri.o test/test_spotri.o test/test_slansy.o test/test_dlansy.o test/test_clansy.o test/test_slacpy.o test/test_dlacpy.o test/test_clacpy.o test/test_sgeqrf.o test/test_dgeqrf.o test/test_cgeqrf.o test/test_sgelqs.o test/test_dgelqs.o test/test_cgelqs.o test/test_samax.o test/test_damax.o test/test_scamax.o test/test_cgetri_aux.o test/test_dgetri_aux.o test/test_sgetri_aux.o test/test_spotrf.o test/test_dpotrf.o test/test_cpotrf.o test/test_csyr2k.o test/test_dsyr2k.o test/test_ssyr2k.o test/test_sgesv.o test/test_dgesv.o test/test_cgesv.o test/test_ctrtri.o test/test_dtrtri.o test/test_strtri.o test/test_ssyrk.o test/test_dsyrk.o test/test_csyrk.o test/test_sposv.o test/test_dposv.o test/test_cposv.o test/test_slange.o test/test_dlange.o test/test_clange.o test/test_cher2k.o test/test_ctrmm.o test/test_dtrmm.o test/test_strmm.o test/test_slantr.o test/test_dlantr.o test/test_clantr.o test/test_stradd.o test/test_dtradd.o test/test_ctradd.o test/test_chemm.o test/test_sgemm.o test/test_dgemm.o test/test_cgemm.o test/test_ctrsm.o test/test_dtrsm.o test/test_strsm.o test/test_sgeadd.o test/test_dgeadd.o test/test_cgeadd.o test/test_cherk.o test/test_clauum.o test/test_dlauum.o test/test_slauum.o test/test_sgels.o test/test_dgels.o test/test_cgels.o test/test_dsposv.o test/test_sgetrs.o test/test_dgetrs.o test/test_cgetrs.o test/test_dlag2s.o test/test_sgbtrf.o test/test_dgbtrf.o test/test_cgbtrf.o test/test_spbsv.o test/test_dpbsv.o test/test_cpbsv.o test/test_sgbsv.o test/test_dgbsv.o test/test_cgbsv.o test/test_sgeqrs.o test/test_dgeqrs.o test/test_cgeqrs.o test/test_spbtrf.o test/test_dpbtrf.o test/test_cpbtrf.o test/test_slascl.o test/test_dlascl.o test/test_clascl.o test/test_slaswp.o test/test_dlaswp.o test/test_claswp.o test/test_sgetrf.o test/test_dgetrf.o test/test_cgetrf.o test/test_slaset.o test/test_dlaset.o test/test_claset.o test/test_slag2d.o test/test_sgelqf.o test/test_dgelqf.o test/test_cgelqf.o test/test_sormqr.o test/test_dormqr.o test/test_cunmqr.o test/test_clanhe.o test/test_dsgesv.o -Llib -lplasma -lcoreblas -L/home/balay/git-repo/github/spack/opt/spack/linux-fedora27-x86_64/gcc-7/openblas-0.2.20-swt4jmol62yynopza2oxu5ofl44dc5xt/lib -lopenblas\\n  &gt;&gt; 11034 /usr/bin/ld: test/test_zsymm.o: undefined reference to symbol \\'cabs@@GLIBC_2.2.5\\'\\n  &gt;&gt; 11035 //usr/lib64/libm.so.6: error adding symbols: DSO missing from command line\\n  &gt;&gt; 11036 collect2: error: ld returned 1 exit status\\n\\n</code></pre>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5333079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/luszczek\">@luszczek</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=299842\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tgamblin\">@tgamblin</a></p>', 'url': 'https://github.com/spack/spack/issues/6046', 'state': 'OPEN', 'createdAt': '2017-10-30T21:24:06Z', 'lastEditedAt': None, 'publishedAt': '2017-10-30T21:24:06Z', 'updatedAt': '2017-10-31T15:19:32Z', 'labels': ['help wanted', 'xSDK'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'Using Spack in containerized environments cleanup examples', 'bodyHTML': '<p>This is a documentation feature request: To facilitate optimal use in containerized environments, it would be helpful to have an example of using spack with (say) a docker ubuntu image, including recommendations of how to maximally clean up after package installs to minimize space usage. This is implicit in the current documentation, but a specific section with examples would establish best practices.</p>', 'url': 'https://github.com/spack/spack/issues/7186', 'state': 'OPEN', 'createdAt': '2018-02-05T16:44:31Z', 'lastEditedAt': None, 'publishedAt': '2018-02-05T16:44:31Z', 'updatedAt': '2018-03-01T18:42:47Z', 'labels': ['documentation', 'good first issue', 'help wanted', 'up-for-grabs'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'Documentation clarification: `directory_layout` vs `install_path_scheme`', 'bodyHTML': '<p>Hello,</p>\\n<p>In the documentation (<a href=\"https://spack.readthedocs.io/en/latest/config_yaml.html\" rel=\"nofollow\">https://spack.readthedocs.io/en/latest/config_yaml.html</a>), both <code>directory_layout</code> and <code>install_path_scheme</code> appear but as far as I can tell only the latter is actually used in the source code.</p>\\n<p>As <code>directory_layout</code> is part of the default <code>config.yaml</code> file, my guess is that it might be a leftover from a name change.</p>\\n<p>Can someone clarify this?</p>\\n<p>Best regards,<br>\\nRmi</p>', 'url': 'https://github.com/spack/spack/issues/9349', 'state': 'OPEN', 'createdAt': '2018-09-26T08:07:02Z', 'lastEditedAt': None, 'publishedAt': '2018-09-26T08:07:02Z', 'updatedAt': '2018-10-01T20:36:05Z', 'labels': ['documentation', 'help wanted', 'up-for-grabs'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'spack', 'repo_owner_name': 'Spack', 'repo_owner_email': '', 'repo_owner_user_name': 'spack', 'repo_owner_profile_url': 'https://github.com/spack', 'title': 'Julia package needs updated dependencies', 'bodyHTML': '<p>See: <a href=\"https://github.com/JuliaLang/julia#required-build-tools-and-external-libraries\">https://github.com/JuliaLang/julia#required-build-tools-and-external-libraries</a></p>', 'url': 'https://github.com/spack/spack/issues/9581', 'state': 'OPEN', 'createdAt': '2018-10-18T19:21:51Z', 'lastEditedAt': None, 'publishedAt': '2018-10-18T19:21:51Z', 'updatedAt': '2018-10-29T15:03:44Z', 'labels': ['good first issue', 'help wanted', 'new-version'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'kokkos', 'repo_owner_name': 'Kokkos', 'repo_owner_email': 'crtrott@sandia.gov', 'repo_owner_user_name': 'kokkos', 'repo_owner_profile_url': 'https://github.com/kokkos', 'title': 'View of view initialization', 'bodyHTML': '<p>Before I dive too deeply into this question, is there a plan to make views of views a standard (non-experimental) feature?</p>\\n<h2>If so, my question involves a view of views:</h2>\\n<p>Kokkos::View&lt; Kokkos::View&lt; double*** &gt; ** &gt; B(\"B\", nt, nbr); // num threads x num block rows</p>\\n<h2></h2>\\n<p>The outer view dimensions are set above (memory space agnostic). I would now like to set the sizes of the inner views (those that are of `double***\\'). I would like to be able to initialize those inner views\\'  sizes without the need for a host mirror (this could be a very large data structure and potentially having a copy that lives both on host and device is not ideal).</p>\\n<p>In using a regular for loop to initialize the inner views:</p>\\n<p>for (int_t i = 0; i &lt; B.dimension_1(); ++i) {<br>\\nB(0, i) = Kokkos::View&lt;double***&gt; (\"B\", 2, h_m(i), h_m(i));<br>\\n}</p>\\n<p>I run into the following error:</p>\\n<p>terminate called after throwing an instance of \\'std::runtime_error\\'</p>\\n<h2>what():  Kokkos::CudaSpace::access_error attempt to execute Cuda function from non-Cuda space</h2>\\n<p>How do I go about allocating the memory for these inner views when they live in a non-host memory space?<br>\\nhost mirror? UVM space? Is there a cleaner way?</p>', 'url': 'https://github.com/kokkos/kokkos/issues/102', 'state': 'CLOSED', 'createdAt': '2015-10-06T04:51:58Z', 'lastEditedAt': None, 'publishedAt': '2015-10-06T04:51:58Z', 'updatedAt': '2016-03-16T18:56:24Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'kokkos', 'repo_owner_name': 'Kokkos', 'repo_owner_email': 'crtrott@sandia.gov', 'repo_owner_user_name': 'kokkos', 'repo_owner_profile_url': 'https://github.com/kokkos', 'title': '0d View usage', 'bodyHTML': '<p>I am having difficulty using 0d views (specifically with cuda). 2 small examples below to show what is happening.</p>\\n<h2>1. Copying const view back to host</h2>\\n<div class=\"highlight highlight-source-c++\"><pre>    View &lt;<span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span>&gt; a; <span class=\"pl-c\"><span class=\"pl-c\">//</span> read only variable on device</span>\\n    {\\n      View &lt;<span class=\"pl-k\">int</span>&gt; <span class=\"pl-c1\">b</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>b<span class=\"pl-pds\">\"</span></span>); <span class=\"pl-c\"><span class=\"pl-c\">//</span> not const, set by some function</span>\\n      <span class=\"pl-c\"><span class=\"pl-c\">//</span> b is set to some value</span>\\n      ...\\n      a = b; <span class=\"pl-c\"><span class=\"pl-c\">//</span> set a = b</span>\\n    } <span class=\"pl-c\"><span class=\"pl-c\">//</span> b now out of scope</span>\\n    <span class=\"pl-k\">int</span> c = <span class=\"pl-c1\">0</span>; <span class=\"pl-c\"><span class=\"pl-c\">//</span> get value of a host-side</span>\\n    <span class=\"pl-en\">deep_copy</span>(c, a); <span class=\"pl-c\"><span class=\"pl-c\">//</span> this line fails with: \"error: no instance of overloaded function \"deep_copy\" matches the argument list ...\"</span></pre></div>\\n<hr>\\n<h2>2. atomics</h2>\\n<div class=\"highlight highlight-source-c++\"><pre>    View &lt;<span class=\"pl-k\">int</span>, MemoryTraits&lt;Atomic&gt; &gt; <span class=\"pl-en\">a</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>a<span class=\"pl-pds\">\"</span></span>); \\n    <span class=\"pl-en\">parallel_for</span>(N, ... \\n    {\\n      a += <span class=\"pl-c1\">1</span>; <span class=\"pl-c\"><span class=\"pl-c\">//</span> this line fails: \"no operator \"+=\" matches these operands ... \"</span>\\n    });</pre></div>\\n<hr>\\n<p>2 is less of an issue b/c one can use <code>Kokkos::atomic_add(&amp;a(), 1)</code> ? I have not verified that using this gives the desired results, but it does not throw a compile error.</p>\\n<p>If there is a resource to help with this that I am unaware of, that would be good to know of as well.</p>', 'url': 'https://github.com/kokkos/kokkos/issues/188', 'state': 'CLOSED', 'createdAt': '2016-02-12T01:04:16Z', 'lastEditedAt': None, 'publishedAt': '2016-02-12T01:04:16Z', 'updatedAt': '2016-03-02T20:17:36Z', 'labels': ['InDevelop', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'kokkos', 'repo_owner_name': 'Kokkos', 'repo_owner_email': 'crtrott@sandia.gov', 'repo_owner_user_name': 'kokkos', 'repo_owner_profile_url': 'https://github.com/kokkos', 'title': 'View initialization when class member ', 'bodyHTML': '<p>I\\'m experiencing a similar issue to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"279215008\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/kokkos/kokkos/issues/1254\" data-hovercard-type=\"issue\" data-hovercard-url=\"/kokkos/kokkos/issues/1254/hovercard\" href=\"https://github.com/kokkos/kokkos/issues/1254\">#1254</a>, but I can\\'t seem to fix the issue with the advice given.</p>\\n<p>I have a class that has three <code>Kokkos::View</code>s as class members (no nested <code>View</code>s):</p>\\n<pre><code>typedef Kokkos::HostSpace MemorySpace;\\ntypedef Kokkos::OpenMP AccExecSpace;\\ntypedef Kokkos::OpenMP ExecutionSpace;\\n\\nKokkos::View&lt;Kokkos::vector&lt;double&gt;***, MemorySpace&gt; pdf_;\\nKokkos::View&lt;lbm::NodeStatus***, MemorySpace&gt; node_status_;\\nKokkos::View&lt;Kokkos::vector&lt;double&gt;***, MemorySpace&gt; node_solid_and_velocity_;\\n</code></pre>\\n<p>I\\'m compiling for OpenMP, but get the following runtime error:</p>\\n<blockquote>\\n<p>terminate called after throwing an instance of \\'std::runtime_error\\'<br>\\nwhat():  Constructing View and initializing data with uninitialized execution space<br>\\nTraceback functionality not available</p>\\n</blockquote>\\n<p>In the class constructor, I\\'m using the default constructor for the <code>View</code> members in the initializer list:</p>\\n<pre><code>Lattice(...)\\n    : ...\\n      pdf_(),\\n      node_status_(),\\n      node_solid_and_velocity_(),\\n      ...\\n</code></pre>\\n<p>Then I resize and initialize them in a separate function:</p>\\n<pre><code>  Kokkos::resize(pdf_, nodes_x_, nodes_y_, nodes_z_);\\n  Kokkos::resize(node_status_, nodes_x_, nodes_y_, nodes_z_);\\n  Kokkos::resize(node_solid_and_velocity_, nodes_x_, nodes_y_, nodes_z_);\\n\\n  \\n  // Set initial node status to active fluid\\n  Kokkos::parallel_for(\"init_node_status\",\\n                       Kokkos::RangePolicy&lt;AccExecSpace&gt;(0, nodes_x_ * nodes_y_ * nodes_z_),\\n                       KOKKOS_LAMBDA(const lbm::LatUint&amp; index) {\\n                         const lbm::LatUint z_index = index / (nodes_x_ * nodes_y_);\\n                         const lbm::LatUint y_index = (index % (nodes_x_ * nodes_y_)) / nodes_x_;\\n                         const lbm::LatUint x_index = (index % (nodes_x_ * nodes_y_)) % nodes_x_;\\n                         node_status_(x_index, y_index, z_index) = lbm::NodeStatus::ACTIVE_FLUID;\\n                       });\\n\\n  // Allocate memory for discrete velocities in pdf_\\n  Kokkos::parallel_for(\"init_pdfs\",\\n\\t\\t       Kokkos::RangePolicy&lt;ExecutionSpace&gt;(0, nodes_x_ * nodes_y_ * nodes_z_),\\n\\t\\t       KOKKOS_LAMBDA(const lbm::LatUint&amp; index) {\\n                         const lbm::LatUint z_index = index / (nodes_x_ * nodes_y_);\\n                         const lbm::LatUint y_index = (index % (nodes_x_ * nodes_y_)) / nodes_x_;\\n                         const lbm::LatUint x_index = (index % (nodes_x_ * nodes_y_)) % nodes_x_;\\n\\t\\t\\t pdf_(x_index, y_index, z_index) = Kokkos::vector&lt;double&gt;(27, 0.0);\\n\\t\\t       });\\n</code></pre>\\n<p>Based on my understanding, this should work--<code>Kokkos::OpenMP</code> execution space should have access to <code>Kokkos::HostSpace</code> memory space. Am I missing something obvious about why the execution space is uninitialized? Sorry to bother you with simple implementation questions...</p>', 'url': 'https://github.com/kokkos/kokkos/issues/1486', 'state': 'CLOSED', 'createdAt': '2018-03-22T19:22:41Z', 'lastEditedAt': None, 'publishedAt': '2018-03-22T19:22:41Z', 'updatedAt': '2018-04-19T15:17:24Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'kokkos', 'repo_owner_name': 'Kokkos', 'repo_owner_email': 'crtrott@sandia.gov', 'repo_owner_user_name': 'kokkos', 'repo_owner_profile_url': 'https://github.com/kokkos', 'title': 'App Info Request from Users', 'bodyHTML': '<p>We are trying to put together a list of Kokkos usage in applications, libraries and maybe training with some basic information. We are planning to have both a non-public list and a public list (which ideally would be identical). Besides helping us to justify our existence we also would like to use it to point prospective users to other Kokkos users who might have already done something similar.</p>\\n<p>If you are willing to provide some information you can post that either here or send an email to me directly at <a href=\"mailto:crtrott@sandia.gov\">crtrott@sandia.gov</a>.</p>\\n<p>The information we like to get would be this:</p>\\n<p>Project Name: Name of the application or library etc.<br>\\nArea: What type of code is this (e.g. PIC in Plasma Physics, High Mach CFD)<br>\\nInstitution: Who works on this / owns the code.<br>\\nWebsite: app website if one exists<br>\\nStatus: Production; Porting; Evaluation; Training/Education (see below)<br>\\nUses KokkosKernels: Does it make direct or indirect use of KokkosKernels<br>\\nContact Name:<br>\\nContact Email:<br>\\nCan we make non-contact info public: (i.e. can we put the above info minus contact information on a public wiki)<br>\\nCan we make contact info public: (i.e. can we put the contact name and maybe email on a public wiki)</p>\\n<p>Status:</p>\\n<ul>\\n<li>Production (i.e. runs science/engineering problems)</li>\\n<li>Porting (app decided to use Kokkos and is working on porting, but not yet ready for actual runs)</li>\\n<li>Evaluation (looking at using Kokkos but no firm decision to do so)</li>\\n<li>Training/Education (for example Kokkos use in University classes for parallel programming)</li>\\n</ul>\\n<p>Thanks for your help<br>\\nChristian</p>', 'url': 'https://github.com/kokkos/kokkos/issues/1604', 'state': 'OPEN', 'createdAt': '2018-05-02T20:59:42Z', 'lastEditedAt': None, 'publishedAt': '2018-05-02T20:59:42Z', 'updatedAt': '2018-11-14T19:46:55Z', 'labels': ['Documentation', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'kokkos', 'repo_owner_name': 'Kokkos', 'repo_owner_email': 'crtrott@sandia.gov', 'repo_owner_user_name': 'kokkos', 'repo_owner_profile_url': 'https://github.com/kokkos', 'title': ' error: size_t does not name a type', 'bodyHTML': '<p>I got such an issue when I compile with my own files.<br>\\nWould you please tell me how to fix it?</p>\\n<pre lang=\"nvcc_wrapper\" data-meta=\"- *warning* you have set multiple optimization flags (-std=c++1* or --std=c++1*), only the first is used because nvcc can only accept a single std setting\"><code>In file included from /usr/local/cuda-9.0/include/builtin_types.h:59:0,\\n                 from /usr/local/cuda-9.0/include/crt/host_runtime.h:48,\\n                 from /tmp/tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:5,\\n                 from tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:1:\\n/usr/local/cuda-9.0/include/driver_types.h:856:5: error: size_t does not name a type\\n     size_t  pitch;    /**&lt; Pitch of allocated memory in bytes */\\n     ^\\n/usr/local/cuda-9.0/include/driver_types.h:857:5: error: size_t does not name a type\\n     size_t  xsize;    /**&lt; Logical width of allocation in elements */\\n     ^\\n/usr/local/cuda-9.0/include/driver_types.h:858:5: error: size_t does not name a type\\n     size_t  ysize;    /**&lt; Logical height of allocation in elements */\\n     ^\\n\\nIn file included from /tmp/tmpxft_000027bd_00000000-2_poisson.fatbin.c:2:0,\\n                 from /tmp/tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:6,\\n                 from tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:1:\\n/usr/local/cuda-9.0/include/fatBinaryCtl.h:87:62: error: size_t has not been declared\\n                                                  void* *elf, size_t *esize);\\n                                                              ^\\nIn file included from tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:1:0:\\n/tmp/tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c: In function void __nv_cudaEntityRegisterCallback(void**):\\n/tmp/tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:9:83: error: __nv_dummy_param_ref was not declared in this scope\\n nv_cudaEntityRegisterCallback(void **__T0){__nv_dummy_param_ref(__T0);__nv_save\\n                                                                     ^\\nIn file included from tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:1:0:\\n/tmp/tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c: In function void __sti____cudaRegisterAll():\\n/tmp/tmpxft_000027bd_00000000-5_poisson.cudafe1.stub.c:10:96: error: __cudaRegisterBinary was not declared in this scope\\n __cudaRegisterAll(void){__cudaRegisterBinary(__nv_cudaEntityRegisterCallback);}``\\n</code></pre>', 'url': 'https://github.com/kokkos/kokkos/issues/1657', 'state': 'CLOSED', 'createdAt': '2018-06-02T09:18:31Z', 'lastEditedAt': None, 'publishedAt': '2018-06-02T09:18:31Z', 'updatedAt': '2018-06-08T06:51:23Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'LBANN', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'saving and loading weights', 'bodyHTML': '<p>I need a subset of CR capability as my workflow does not require the states of random number generators, input layers, or data readers. What I need is to save weights at the end of training, and load them into a new model.</p>\\n<p>Currently, I am using lbann2 to train a model and copy the weights of some of the layers to the corresponding ones in another model. Currently, the first model has to run whenever I want to run the second one.</p>\\n<p>However, I wish to keep these weights and reuse them in multiple experiments to try various types of second models instead of repeatedly rerunning the first model.</p>\\n<p>Unless we already have such as capability, can it be easily integrated into lbann2?</p>', 'url': 'https://github.com/LLNL/lbann/issues/225', 'state': 'CLOSED', 'createdAt': '2018-02-16T22:54:33Z', 'lastEditedAt': None, 'publishedAt': '2018-02-16T22:54:33Z', 'updatedAt': '2018-05-11T16:28:49Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'LBANN', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'segfaults or hang in weight::set_values()', 'bodyHTML': \"<p>Trying to use lbann2 on surface, and getting segfaults for hang in weight::set_values(), especially at the line El::Copy(values, *m_values). Both 'values' and 'm_values' are AbsDistMat of El::Device::GPU type. They also seem to have the equal sizes.</p>\\n<p>This is used to be working some time ago when Dylan finished refactoring check pointing  but not anymore.<br>\\nDuring that time, those 'm_values', and 'values' were CPU matrices, and 'm_values' was explicitly copied to a buffer on GPU after El::Copy(). The current code base no longer has the lines for explicit copying as the matrices are already on GPU.</p>\", 'url': 'https://github.com/LLNL/lbann/issues/432', 'state': 'CLOSED', 'createdAt': '2018-06-14T21:33:20Z', 'lastEditedAt': '2018-06-15T17:56:02Z', 'publishedAt': '2018-06-14T21:33:20Z', 'updatedAt': '2018-07-11T16:21:17Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'marfs', 'repo_owner_name': 'MarFS', 'repo_owner_email': 'marfs-on-github@lanl.gov', 'repo_owner_user_name': 'mar-file-system', 'repo_owner_profile_url': 'https://github.com/mar-file-system', 'title': \"Figure out if it's possible to run OrangeFS strictly in user space\", 'bodyHTML': \"<p>We need to be able to run OrangeFS servers and clients on HPC system compute nodes without needing to be root or needing to have files in root-owned space be edited. That is, we cannot rely on having to edit or place files in /etc, /lib, /bin, /sbin, /opt, etc.</p>\\n<p>Talk to David Bonnie (formerly worked on OrangeFS) or Boyd Wilson. Find out if it's possible to run the client and server without ever needing root intervention.</p>\", 'url': 'https://github.com/mar-file-system/marfs/issues/107', 'state': 'CLOSED', 'createdAt': '2016-03-03T20:45:20Z', 'lastEditedAt': None, 'publishedAt': '2016-03-03T20:45:20Z', 'updatedAt': '2016-03-07T23:45:11Z', 'labels': ['help wanted', 'prio_hi'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'marfs', 'repo_owner_name': 'MarFS', 'repo_owner_email': 'marfs-on-github@lanl.gov', 'repo_owner_user_name': 'mar-file-system', 'repo_owner_profile_url': 'https://github.com/mar-file-system', 'title': 'clean-up:  always build with DAL/MDAL', 'bodyHTML': '<p>Once upon a time this was experimental.   Would anyone ever need to build without it?</p>\\n<p>There is a DAL for object interactions (though it may have little if any testing, compared with the non-DAL code-paths, which default to object-semantics).  Remove all the #ifdef cruft for non-DAL/MDAL builds.  Remove build-options for MDAL/DAL.</p>', 'url': 'https://github.com/mar-file-system/marfs/issues/198', 'state': 'OPEN', 'createdAt': '2017-07-28T14:13:39Z', 'lastEditedAt': None, 'publishedAt': '2017-07-28T14:13:39Z', 'updatedAt': '2017-07-28T14:42:17Z', 'labels': ['help wanted', 'prio_lo'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'becquerel', 'repo_owner_name': 'Applied Nuclear Physics - LBNL', 'repo_owner_email': '', 'repo_owner_user_name': 'lbl-anp', 'repo_owner_profile_url': 'https://github.com/lbl-anp', 'title': 'More example spectra', 'bodyHTML': \"<p>Once we start working on actual analysis modules, it will become important to have a variety of spectra for testing. Let's brainstorm our needs here, and we can all contribute spectra as we have a chance.</p>\\n<h3>File types (for parsers that haven't been written yet):</h3>\\n<ul>\\n<li>*.CHN</li>\\n<li>*.N42</li>\\n</ul>\\n<h3>Detector types:</h3>\\n<ul>\\n<li>NaI</li>\\n<li>CdZnTe</li>\\n<li>CsI</li>\\n</ul>\\n<h3>Use cases / sources:</h3>\\n<ul>\\n<li>check sources for calibrations</li>\\n<li>environmental samples for gamma counting</li>\\n<li>Th, U ores</li>\\n<li>neutron activation spectra with lots of peaks</li>\\n</ul>\", 'url': 'https://github.com/lbl-anp/becquerel/issues/20', 'state': 'OPEN', 'createdAt': '2017-02-21T19:18:16Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T19:18:16Z', 'updatedAt': '2018-02-13T21:07:48Z', 'labels': ['discuss', 'doc', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'becquerel', 'repo_owner_name': 'Applied Nuclear Physics - LBNL', 'repo_owner_email': '', 'repo_owner_user_name': 'lbl-anp', 'repo_owner_profile_url': 'https://github.com/lbl-anp', 'title': '`Spectrum` rebinning', 'bodyHTML': \"<ul>\\n<li>Rebinning according to an input bin edges vector</li>\\n<li><code>rebin_like(spec)</code> to use the binning from another spectrum</li>\\n</ul>\\n<p>Please expand on this, I'm not very familiar with rebinning methods or needs.</p>\", 'url': 'https://github.com/lbl-anp/becquerel/issues/29', 'state': 'OPEN', 'createdAt': '2017-03-08T21:55:09Z', 'lastEditedAt': None, 'publishedAt': '2017-03-08T21:55:09Z', 'updatedAt': '2018-08-21T16:59:33Z', 'labels': ['core', 'help wanted', 'new feature', 'priority'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'becquerel', 'repo_owner_name': 'Applied Nuclear Physics - LBNL', 'repo_owner_email': '', 'repo_owner_user_name': 'lbl-anp', 'repo_owner_profile_url': 'https://github.com/lbl-anp', 'title': 'Add description and topics', 'bodyHTML': '<p>Becquerel doesn\\'t have a short description (on the github header or in the readme) or any topics listed. I propose the following (mostly from <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1197880\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/markbandstra\">@markbandstra</a>):</p>\\n<blockquote>\\n<p>Becquerel is a Python package for analyzing nuclear spectroscopic measurements. The core functionalities are reading and writing different spectrum file types, fitting spectral features, performing detector calibrations, and interpreting measurement results. It will include tools for plotting radiation spectra and fits of different spectral features, as well as convenient access to tabulated nuclear data. It relies heavily on the standard scientific Python stack of numpy, scipy, matplotlib, and pandas. It is intended to be general-purpose enough that it can be useful to anyone from an undergraduate taking a laboratory course to the advanced researcher.</p>\\n</blockquote>\\n<p>Regarding topics:</p>\\n<ul>\\n<li><code>nuclear-physics</code></li>\\n<li><code>spectroscopy</code></li>\\n<li><code>gamma-ray</code></li>\\n<li>???</li>\\n</ul>\\n<p>Thoughts?</p>', 'url': 'https://github.com/lbl-anp/becquerel/issues/85', 'state': 'CLOSED', 'createdAt': '2018-02-10T00:10:36Z', 'lastEditedAt': None, 'publishedAt': '2018-02-10T00:10:36Z', 'updatedAt': '2018-04-09T17:54:48Z', 'labels': ['doc', 'enhancement', 'help wanted', 'priority'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'becquerel', 'repo_owner_name': 'Applied Nuclear Physics - LBNL', 'repo_owner_email': '', 'repo_owner_user_name': 'lbl-anp', 'repo_owner_profile_url': 'https://github.com/lbl-anp', 'title': 'Overview notebook', 'bodyHTML': '', 'url': 'https://github.com/lbl-anp/becquerel/issues/94', 'state': 'OPEN', 'createdAt': '2018-03-27T20:09:51Z', 'lastEditedAt': None, 'publishedAt': '2018-03-27T20:09:51Z', 'updatedAt': '2018-07-10T22:58:58Z', 'labels': ['enhancement', 'help wanted', 'priority'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'becquerel', 'repo_owner_name': 'Applied Nuclear Physics - LBNL', 'repo_owner_email': '', 'repo_owner_user_name': 'lbl-anp', 'repo_owner_profile_url': 'https://github.com/lbl-anp', 'title': 'Importlib __spec__/__package__ issue', 'bodyHTML': '<p>In <code>py36</code> we get the following warning:</p>\\n<div class=\"highlight highlight-source-shell\"><pre>anaconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can<span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>t resolve package from __spec__ or __package__, falling back on __name__ and __path__</span></pre></div>\\n<p>I\\'m not sure where this is coming from. Maybe this could help?</p>\\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"335107842\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/pytest-dev/pytest/issues/3613\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/pytest-dev/pytest/pull/3613/hovercard\" href=\"https://github.com/pytest-dev/pytest/pull/3613\">pytest-dev/pytest#3613</a></p>', 'url': 'https://github.com/lbl-anp/becquerel/issues/150', 'state': 'OPEN', 'createdAt': '2018-10-11T02:27:49Z', 'lastEditedAt': None, 'publishedAt': '2018-10-11T02:27:49Z', 'updatedAt': '2018-10-11T03:44:14Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'sw4', 'repo_owner_name': 'Computational Infrastructure for Geodynamics', 'repo_owner_email': 'help@geodynamics.org', 'repo_owner_user_name': 'geodynamics', 'repo_owner_profile_url': 'https://github.com/geodynamics', 'title': 'Restart issue: \"readSACheader: ERROR\" in Artie\\'s h200 run', 'bodyHTML': '<p>Artie ran a 4 node h200 case on Cori, interrupted with scancel after 1 hour, then got this error on restart.</p>\\n<p>Have not been able to reproduce it, but seems feasible if the checkpoint was written but some time series was not completely written.</p>\\n<p>Solution is to use the previous checkpoint, and make sure the time series has a backup file with \".bak\" suffix, see 6f17b3. If restart is required, then user must verify:</p>\\n<ul>\\n<li>That the last checkpoint and time series files were all successfully written and self-consistent. Things to check include file sizes, timestamps, and number of files.</li>\\n<li>Or if that isn\\'t true, then use the previous checkpoint, and copy the .bak time series files to current file names</li>\\n</ul>\\n<p>Then the files should we setup consistently for restart.</p>', 'url': 'https://github.com/geodynamics/sw4/issues/31', 'state': 'OPEN', 'createdAt': '2018-05-29T15:55:04Z', 'lastEditedAt': None, 'publishedAt': '2018-05-29T15:55:04Z', 'updatedAt': '2018-05-29T15:55:55Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'sw4', 'repo_owner_name': 'Computational Infrastructure for Geodynamics', 'repo_owner_email': 'help@geodynamics.org', 'repo_owner_user_name': 'geodynamics', 'repo_owner_profile_url': 'https://github.com/geodynamics', 'title': 'Restart issue: SW4 goes unstable after restart', 'bodyHTML': '<p>Running a variation of Artie\\'s h200 case using <a class=\"commit-link\" href=\"https://github.com/geodynamics/sw4/commit/81660fd6ae981917310ee7ac91c8e48893881b85\"><tt>81660fd</tt></a>, restarting after 400 steps.</p>\\n<p>The last few values of the SAC time series S_21_33.x (converted to ASCII) are:<br>\\n0.003225613    0.003254564    0.003282511    0.003309429    0.003335175<br>\\n0.003359453</p>\\n<p>After restart, the values blow up:<br>\\n0.003225613    0.003254564    0.003282511    0.003309429    0.003335175<br>\\n0.003359453    0.003381787    0.003401527    0.003417878    0.003429959<br>\\n0.003436868    0.003437738    0.003431762    0.003418196    0.003396356<br>\\n0.003365627    0.003325499    0.003275638    0.003215958    0.003146686<br>\\n0.003068366    0.002981824    0.002888080    0.002788229    0.002683327<br>\\n0.002574296    0.002461846    0.002346443    0.002228298    0.002107401<br>\\n0.001983573    0.001856566    0.001726207    0.001592199    0.001452178<br>\\n0.001299709    0.001148364    0.001138667    0.001557166    0.001530237<br>\\n-0.005422587    -0.03075354    -0.04054660      0.1985338       1.112271<br>\\n1.848502      -4.267780      -31.23071      -67.54460       35.99760<br>\\n658.0487       1865.012       1155.168      -9537.353      -37899.54<br>\\n-55165.64       71240.69       556485.5       1252116.       510922.0<br>\\n-5563330.  -1.920454e+07  -2.630546e+07   2.436709e+07   2.062913e+08<br>\\n4.752133e+08   3.576061e+08  -1.256604e+09  -5.289029e+09  -9.355941e+09</p>', 'url': 'https://github.com/geodynamics/sw4/issues/32', 'state': 'CLOSED', 'createdAt': '2018-05-29T16:06:22Z', 'lastEditedAt': None, 'publishedAt': '2018-05-29T16:06:22Z', 'updatedAt': '2018-06-03T22:34:54Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'sw4', 'repo_owner_name': 'Computational Infrastructure for Geodynamics', 'repo_owner_email': 'help@geodynamics.org', 'repo_owner_user_name': 'geodynamics', 'repo_owner_profile_url': 'https://github.com/geodynamics', 'title': \"Restart issue: time series files don't match on restart\", 'bodyHTML': '<p>Using <a class=\"commit-link\" href=\"https://github.com/geodynamics/sw4/commit/81660fd6ae981917310ee7ac91c8e48893881b85\"><tt>81660fd</tt></a>, running a version of examples/meshrefine/loh1-slow-mr-order4.in but with restart.</p>\\n<p>One test that works fine (usgs ascii, sac binary) on restart is here:<br>\\nperformance/scec/LOH.1-h400-check.in</p>\\n<p>I tried a bunch of other tests beyond Artie\\'s mini Hayward, including ones with mesh refinement, attenuation (3 mech, 1 mech).</p>\\n<p>One I tried with and w/o MR is this one:</p>\\n<ul>\\n<li>examples/meshrefine/loh1-slow-mr-order4.in</li>\\n</ul>\\n<p>If I comment out the refinement line, then everything is correct on restart and matches the baseline.</p>', 'url': 'https://github.com/geodynamics/sw4/issues/33', 'state': 'CLOSED', 'createdAt': '2018-05-30T19:48:17Z', 'lastEditedAt': None, 'publishedAt': '2018-05-30T19:48:17Z', 'updatedAt': '2018-06-03T22:33:23Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Adding the C-library test cases', 'bodyHTML': \"<p>We should have a set of test cases in the C-interface-tests that match the application api tests.  Probably don't need them all but having a set of them running against the C-interface vs the C++ interface would test that, especially if we are going to be using that pretty regularly for python, java, and other bindings, and other applications.</p>\", 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/9', 'state': 'CLOSED', 'createdAt': '2017-10-27T00:15:00Z', 'lastEditedAt': None, 'publishedAt': '2017-10-27T00:15:00Z', 'updatedAt': '2018-01-26T15:50:59Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Finish adding doxygen comments to C-shared API', 'bodyHTML': '<p>Many of the functions in the C-shared api are currently lacking doxygen comments and descriptions.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/51', 'state': 'CLOSED', 'createdAt': '2017-12-18T00:21:28Z', 'lastEditedAt': None, 'publishedAt': '2017-12-18T00:21:28Z', 'updatedAt': '2018-02-16T18:02:23Z', 'labels': ['Documentation', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Improve HELICS support for Matlab on Windows', 'bodyHTML': '<p>We need to be able to produce a binary file that can be used with the windows version of Matlab, in addition to support for a Linux Version. and getting this working on Macs would be advisable as well.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/95', 'state': 'CLOSED', 'createdAt': '2018-01-20T01:04:33Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:04:33Z', 'updatedAt': '2018-03-13T18:02:43Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Need a way to regularly test multimachine configurations', 'bodyHTML': '<p>Not sure what this looks like but somewhere we need to have regular automated test runs with multiple machines using the different communication protocols in different configurations.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/98', 'state': 'OPEN', 'createdAt': '2018-01-20T01:09:21Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:09:21Z', 'updatedAt': '2018-09-27T11:51:17Z', 'labels': ['On Hold', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Example using combination federate in C++ and another in C', 'bodyHTML': '<p>We need an example system using the combination federate for both the C++ application Api and another similar example using the C API.  It might make sense to replicate this example in all supported languages,  Matlab, python, and Java.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/99', 'state': 'CLOSED', 'createdAt': '2018-01-20T01:13:31Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:13:31Z', 'updatedAt': '2018-04-12T15:58:52Z', 'labels': ['Examples', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test cases running with erroneous inputs and invalid sequences', 'bodyHTML': '<p>We need a series of test cases that stress the error handling paths in HELICS<br>\\nincluding invalid input, odd timings and timeouts.</p>\\n<p>Anyone want to help break HELICS and fix it?</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/100', 'state': 'CLOSED', 'createdAt': '2018-01-20T01:24:13Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:24:13Z', 'updatedAt': '2018-04-11T04:54:36Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test suite for python', 'bodyHTML': '<p>We will need a test suite in python that executes all functions in the shared library.    The C library tests make sure that the function calls actually do what they are supposed to.  The python test suite needs to ensure those functions got translated correctly.  So it can be a subset of the shared library tests, but if we want to fully support it we need the tests running.   And it should be run regularly (daily?)</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/188', 'state': 'CLOSED', 'createdAt': '2018-02-28T14:28:45Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T14:28:45Z', 'updatedAt': '2018-04-15T05:02:19Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test Suite for Matlab', 'bodyHTML': \"<p>We will need a test suite in Matlab that executes all functions in the shared library interface to Matlab.    The C library tests make sure that the function calls actually do what they are supposed to.  The python test suite needs to ensure those functions got translated correctly.  So it can be a subset of the shared library tests, but if we want to fully support it we need the tests running.   And it should be run regularly (daily?) In the case of Matlab, it probably isn't going to be run on Travis but potentially at one of our local CI test systems.</p>\", 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/189', 'state': 'CLOSED', 'createdAt': '2018-02-28T14:30:40Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T14:30:40Z', 'updatedAt': '2018-07-06T22:39:28Z', 'labels': ['Interfaces', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test Suite for Java', 'bodyHTML': '<p>We will need a test suite in Java that executes all functions in the shared library.    The C library tests make sure that the function calls actually do what they are supposed to.  The python test suite needs to ensure those functions got translated correctly.  So it can be a subset of the shared library tests, but if we want to fully support it we need the tests running.   And it should be run regularly (daily?)</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/190', 'state': 'CLOSED', 'createdAt': '2018-02-28T14:31:30Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T14:31:30Z', 'updatedAt': '2018-04-15T05:02:05Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'potential race condition when using filter functions', 'bodyHTML': '<p>There is a potential race conditions when specifying defined filter functions.  I suspect this may be one root cause of the sporadic failures in the Travis test cases.</p>\\n<p>I have made some progress on this in the thread_safety_update branch but this will not be in place for the 1.0 release.</p>\\n<pre><code>/home/travis/build/GMLC-TDC/HELICS-src/tests/helics/shared_library/FilterTests_cpp.cpp(204): Entering test case \"_9\"\\n6: unknown location(0): fatal error: in \"filter_tests_cpp/message_filter_function2/_9\": memory access violation at address: 0x00000090: no mapping at fault address\\n6: /home/travis/build/GMLC-TDC/HELICS-src/tests/helics/shared_library/FilterTests_cpp.cpp(264): last checkpoint\\n6: Failure occurred in a following context:\\n6:     core_type = tcp_2; \\n6: Test is aborted\\n</code></pre>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/246', 'state': 'CLOSED', 'createdAt': '2018-04-11T05:57:02Z', 'lastEditedAt': None, 'publishedAt': '2018-04-11T05:57:02Z', 'updatedAt': '2018-04-22T21:40:49Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Core dump in python tests', 'bodyHTML': '<p>One of the python tests is failing occasionally with a core dump.  We need to figure out the reason.<br>\\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1813121\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kdheepak\">@kdheepak</a>  does this ever happen on your system? and if so anychance you can provide some more insight into the exact locations of the error?</p>\\n<pre><code>../tests/python_helics/test_message_filter.py::test_message_filter_registration PASSED [ 33%]\\n../tests/python_helics/test_message_filter.py::test_message_filter_function /home/travis/.travis/job_stages: line 57: 12445 Aborted                 (core dumped) python3 -m pytest -v ../tests/python_helics\\n</code></pre>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/277', 'state': 'CLOSED', 'createdAt': '2018-04-23T18:54:56Z', 'lastEditedAt': None, 'publishedAt': '2018-04-23T18:54:56Z', 'updatedAt': '2018-05-13T12:54:18Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Mac binary distribution', 'bodyHTML': '<p>This should use the CPack stuff in cmake that is already setup<br>\\nprobably using the <a href=\"https://cmake.org/cmake/help/latest/module/CPackDMG.html\" rel=\"nofollow\">DragNDrop</a> generator.</p>\\n<p>guessing a few generator specific fields will need to be added</p>\\n<p>though there might be some new generators as well if we were ok requiring a new cmake for the mac builds which isn\\'t out of the question.</p>\\n<p>This might be simple enough that it could be done and included with the 1.3 release.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/379', 'state': 'CLOSED', 'createdAt': '2018-06-30T00:00:18Z', 'lastEditedAt': None, 'publishedAt': '2018-06-30T00:00:18Z', 'updatedAt': '2018-07-25T15:49:25Z', 'labels': ['Installation/build', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ADIOS2', 'repo_owner_name': 'ADIOS', 'repo_owner_email': None, 'repo_owner_user_name': 'ornladios', 'repo_owner_profile_url': 'https://github.com/ornladios', 'title': 'Add updated User Guide documentation', 'bodyHTML': '', 'url': 'https://github.com/ornladios/ADIOS2/issues/440', 'state': 'OPEN', 'createdAt': '2018-02-13T16:37:42Z', 'lastEditedAt': None, 'publishedAt': '2018-02-13T16:37:42Z', 'updatedAt': '2018-02-15T18:07:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'ADIOS2', 'repo_owner_name': 'ADIOS', 'repo_owner_email': None, 'repo_owner_user_name': 'ornladios', 'repo_owner_profile_url': 'https://github.com/ornladios', 'title': 'Compile error on CompressSZ', 'bodyHTML': \"<p>I don't understand why this is not compiling. Ubuntu 16.10 VM, gcc 6.2.0, latest master, SZ is ON:</p>\\n<p>[ 27%] Building CXX object source/adios2/CMakeFiles/adios2.dir/operator/compress/CompressSZ.cpp.o<br>\\n/home/adios/work/ADIOS2/source/adios2/operator/compress/CompressSZ.cpp: In member function virtual std::size_t adios2::core::compress::CompressSZ::Decompress(const void*, std::size_t, void*, const Dims&amp;, std::__cxx11::string, const Params&amp;) const:<br>\\n/home/adios/work/ADIOS2/source/adios2/operator/compress/CompressSZ.cpp:369:51: error: GetTotalSize was not declared in this scope<br>\\nsize_t dataSizeBytes = GetTotalSize(dimensions) * typeSizeBytes;<br>\\n^<br>\\n/home/adios/work/ADIOS2/source/adios2/operator/compress/CompressSZ.cpp:369:51: note: suggested alternative:<br>\\nIn file included from /home/adios/work/ADIOS2/source/adios2/helper/adiosFunctions.h:16:0,<br>\\nfrom /home/adios/work/ADIOS2/source/adios2/operator/compress/CompressSZ.cpp:19:<br>\\n/home/adios/work/ADIOS2/source/adios2/helper/adiosMath.h:30:8: note:   adios2::helper::GetTotalSize<br>\\nsize_t GetTotalSize(const Dims &amp;dimensions) noexcept;<br>\\n^~~~~~~~~~~~<br>\\nsource/adios2/CMakeFiles/adios2.dir/build.make:1214: recipe for target 'source/adios2/CMakeFiles/adios2.dir/operator/compress/CompressSZ.cpp.o' failed<br>\\nmake[2]: *** [source/adios2/CMakeFiles/adios2.dir/operator/compress/CompressSZ.cpp.o] Error 1</p>\", 'url': 'https://github.com/ornladios/ADIOS2/issues/705', 'state': 'CLOSED', 'createdAt': '2018-07-08T17:29:38Z', 'lastEditedAt': None, 'publishedAt': '2018-07-08T17:29:38Z', 'updatedAt': '2018-07-31T12:45:03Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ADIOS2', 'repo_owner_name': 'ADIOS', 'repo_owner_email': None, 'repo_owner_user_name': 'ornladios', 'repo_owner_profile_url': 'https://github.com/ornladios', 'title': 'add mgard support under adios2 thirdparty', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=320135\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/chuckatkins\">@chuckatkins</a> this is just to formalize mgard support inside adios2. Thanks!</p>', 'url': 'https://github.com/ornladios/ADIOS2/issues/781', 'state': 'OPEN', 'createdAt': '2018-08-06T18:17:24Z', 'lastEditedAt': None, 'publishedAt': '2018-08-06T18:17:24Z', 'updatedAt': '2018-08-06T18:17:24Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ADIOS2', 'repo_owner_name': 'ADIOS', 'repo_owner_email': None, 'repo_owner_user_name': 'ornladios', 'repo_owner_profile_url': 'https://github.com/ornladios', 'title': 'DataMan Bidirectional IP Address Assignment', 'bodyHTML': \"<p>Currently DataMan only takes in the IP Address of the reader, or where the data is being sent to. It would be helpful for the other direction to be possible to. That readers could get the data by only knowing where the writer is.</p>\\n<p>Here's an example of where this would be useful:</p>\\n<p>I am trying to send data from one cluster to another cluster. A more straightforward way to do this would have a reader on loginNodeA receive the data from computeNodeA_{0,1,...,N}. The reader from loginNodeA would then send the data to loginNodeB and then loginNodeB would send the data to computeNodeB_{0,1,...,M}</p>\\n<p>In this case it would be extremely cumbersome to determine the M ip addresses needed. Instead DataMan should only need to know the address of what is sending the data, and the receivers can gather the data they need.</p>\\n<p>This also has a problem with the fact that the ports increase. Eg: If I run <code>mpirun -n 5 someDataManWriter</code> and tell DataMan to run on port 200, then this will create 5 copies of <code>someDataManWriter</code> who send on ports 20{0..4}. One for each instance of <code>someDataManWriter</code>.</p>\", 'url': 'https://github.com/ornladios/ADIOS2/issues/806', 'state': 'OPEN', 'createdAt': '2018-08-20T20:02:09Z', 'lastEditedAt': None, 'publishedAt': '2018-08-20T20:02:09Z', 'updatedAt': '2018-08-22T12:20:10Z', 'labels': ['enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ADIOS2', 'repo_owner_name': 'ADIOS', 'repo_owner_email': None, 'repo_owner_user_name': 'ornladios', 'repo_owner_profile_url': 'https://github.com/ornladios', 'title': 'Brusselator SST performance issue', 'bodyHTML': '<p>Analysis code using SST is much slower with this example than to read from files. Same issue on VM and on Titan.</p>\\n<pre><code>$ mpirun -n 16 ./simulation/Brusselator bru.bp 32 32 32 100 1\\n$ time mpirun -n 4 ./analysis/norm_calc bru.bp a.bp 0\\n</code></pre>\\n<pre><code>VM: \\n           BP     SST/FFS     SST/BP\\n         0.7s        14s         19s\\n</code></pre>\\n<p>Titan, with 256^3, 100 steps, 64 writers + 64 readers:<br>\\nFile based: a few minutes<br>\\nSST based: does not finish within an hour. Also steps are slowing down visibly.</p>', 'url': 'https://github.com/ornladios/ADIOS2/issues/842', 'state': 'OPEN', 'createdAt': '2018-09-07T14:44:06Z', 'lastEditedAt': None, 'publishedAt': '2018-09-07T14:44:06Z', 'updatedAt': '2018-09-07T15:28:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Add examples from \"Defining Phases\" to the documentation', 'bodyHTML': '<p>This file: <a href=\"https://github.com/Cantera/cantera/blob/master/doc/sphinx/cti/example-combustion.rst\">https://github.com/Cantera/cantera/blob/master/doc/sphinx/cti/example-combustion.rst</a> is presently blank. Is it left over from an old version of the documentation?</p>\\n<p>As reported on the Google Group: <a href=\"https://groups.google.com/d/msg/cantera-users/h0s-vJ6iELY/RgqsyqGnCQAJ\" rel=\"nofollow\">https://groups.google.com/d/msg/cantera-users/h0s-vJ6iELY/RgqsyqGnCQAJ</a></p>', 'url': 'https://github.com/Cantera/cantera/issues/313', 'state': 'OPEN', 'createdAt': '2015-12-06T15:05:24Z', 'lastEditedAt': None, 'publishedAt': '2015-12-06T15:05:24Z', 'updatedAt': '2018-03-07T15:54:32Z', 'labels': ['documentation', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Adding citation to the chem input file in the data folder', 'bodyHTML': '<p>Using the chemical mechanism file in the system data of Cantera is very convenient. However, it seems that some of the mechanism files are not properly commented with the associated citation. I would suggest adding citation in all of the mechanism files, at least the chemical format mechanism files.</p>', 'url': 'https://github.com/Cantera/cantera/issues/339', 'state': 'OPEN', 'createdAt': '2016-05-13T07:16:11Z', 'lastEditedAt': '2016-05-13T07:16:30Z', 'publishedAt': '2016-05-13T07:16:11Z', 'updatedAt': '2018-03-07T15:54:17Z', 'labels': ['documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Changing the rate in Python does not change the forward rate constant calculation', 'bodyHTML': '<p>Using <a class=\"commit-link\" href=\"https://github.com/Cantera/cantera/commit/7d3ebdd3581c06f6294e4fb64e355007c2ea766e\"><tt>7d3ebdd</tt></a> (from the conda package) on Linux (Ubuntu 16.04), replacing the reaction rate parameters of a reaction does not affect the calculation of the forward rate constants.</p>\\n<pre><code>import cantera as ct\\ncti_str = \"\"\"\\nunits(length=\\'cm\\', time=\\'s\\', quantity=\\'mol\\', act_energy=\\'cal/mol\\')\\nideal_gas(\\n    name=\\'gas\\',\\n    elements=\\'C\\',\\n    species=\\'A B\\',\\n    reactions=\\'all\\',\\n    initial_state=state(temperature=300.0, pressure=OneAtm)\\n)\\n\\nspecies(\\n    name=\\'A\\',\\n    atoms=\\'C:12\\',\\n    thermo=(\\n        NASA(\\n            [300.00, 1000.00],\\n            [2.08692170E+00,  1.33149650E-01, -8.11574520E-05,\\n             2.94092860E-08, -6.51952130E-12, -3.59128140E+04,\\n             2.73552890E+01]\\n        ),\\n        NASA(\\n            [1000.00, 5000.00],\\n            [2.48802010E+01,  7.82500480E-02, -3.15509730E-05,\\n             5.78789000E-09, -3.98279680E-13, -4.31106840E+04,\\n             -9.36552550E+01]\\n        )\\n    ),\\n)\\n\\nspecies(\\n    name=\\'B\\',\\n    atoms=\\'C:12\\',\\n    thermo=(\\n        NASA(\\n            [300.00, 1000.00],\\n            [2.08692170E+00,  1.33149650E-01, -8.11574520E-05,\\n             2.94092860E-08, -6.51952130E-12, -3.59128140E+04,\\n             2.73552890E+01]\\n        ),\\n        NASA(\\n            [1000.00, 5000.00],\\n            [2.48802010E+01,  7.82500480E-02, -3.15509730E-05,\\n             5.78789000E-09, -3.98279680E-13, -4.31106840E+04,\\n             -9.36552550E+01]\\n        )\\n    ),\\n)\\n\\nreaction(\\n    equation=\\'A =&gt; B\\',\\n    kf=Arrhenius(A=52499925000.0, b=1.5, E=40900.0),\\n)\\n\"\"\"\\ngas = ct.Solution(source=cti_str)\\ngas.TP = 1000, 101325\\nprint(gas.reactions()[0].rate(1000))\\nprint(gas.forward_rate_constants)\\n\\ngas.reactions()[0].rate = ct.Arrhenius(A=4.8765e+69, b=0.0e+00, E=5.0E+04)\\nprint(gas.reactions()[0].rate(1000))\\nprint(gas.forward_rate_constants)\\n</code></pre>\\n<p>which has the output</p>\\n<pre><code>1912707.2378390601\\n[ 1912707.23783906]\\n4.847262590622456e+69\\n[ 1912707.23783906]\\n</code></pre>\\n<p>Is there another function I have to call to inform the Solution about the updated rate?</p>', 'url': 'https://github.com/Cantera/cantera/issues/394', 'state': 'CLOSED', 'createdAt': '2016-11-16T22:08:55Z', 'lastEditedAt': None, 'publishedAt': '2016-11-16T22:08:55Z', 'updatedAt': '2018-06-08T10:40:36Z', 'labels': ['Kinetics', 'documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'ck2cti documentation should be converted to Sphinx-style docstrings', 'bodyHTML': \"<p>The documentation in the ck2cti.py script is currently in a custom format that doesn't seem to be read by the Sphinx docs (at least, I couldn't find a page for it). If the docstrings were rewritten to the standard format, the docs could be included online.</p>\", 'url': 'https://github.com/Cantera/cantera/issues/397', 'state': 'OPEN', 'createdAt': '2016-11-21T14:15:57Z', 'lastEditedAt': None, 'publishedAt': '2016-11-21T14:15:57Z', 'updatedAt': '2016-11-21T20:41:31Z', 'labels': ['ck2cti', 'documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Update/Fix the MacPorts Recipe', 'bodyHTML': '<h3>Cantera version</h3>\\n<p>2.3</p>\\n<h3>Operating System</h3>\\n<p>macOS, MacPorts installation option</p>\\n<h3>Python/MATLAB version</h3>\\n<p>N/A</p>\\n<h3>Expected Behavior</h3>\\n<p>Proper installation</p>\\n<h3>Actual Behavior</h3>\\n<p>Failed installation, see <a href=\"https://groups.google.com/d/msg/cantera-users/rPdKLpC2uys/vIk4jDHTCAAJ\" rel=\"nofollow\">https://groups.google.com/d/msg/cantera-users/rPdKLpC2uys/vIk4jDHTCAAJ</a> for a thread with links</p>\\n<p>Also as discussed at KinCodeCon 2017</p>', 'url': 'https://github.com/Cantera/cantera/issues/496', 'state': 'OPEN', 'createdAt': '2018-01-17T21:34:37Z', 'lastEditedAt': None, 'publishedAt': '2018-01-17T21:34:37Z', 'updatedAt': '2018-03-23T01:55:18Z', 'labels': ['OS X', 'compiling', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'flecsi', 'repo_owner_name': 'Los Alamos Ristra project', 'repo_owner_email': '', 'repo_owner_user_name': 'laristra', 'repo_owner_profile_url': 'https://github.com/laristra', 'title': 'ParMetis in third_party', 'bodyHTML': '<p>Are we going to use ParMetis for distributed graph partition for the mesh? If so, can you add ParMetis in the third_party repo? Or should this be an issue the flecsi-third-party repo?</p>', 'url': 'https://github.com/laristra/flecsi/issues/43', 'state': 'CLOSED', 'createdAt': '2016-04-13T19:50:16Z', 'lastEditedAt': None, 'publishedAt': '2016-04-13T19:50:16Z', 'updatedAt': '2016-04-19T14:50:23Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flecsi', 'repo_owner_name': 'Los Alamos Ristra project', 'repo_owner_email': '', 'repo_owner_user_name': 'laristra', 'repo_owner_profile_url': 'https://github.com/laristra', 'title': 'Redistribute partitioned mesh', 'bodyHTML': '<p>Pending on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"154518562\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/laristra/flecsi/issues/66\" data-hovercard-type=\"issue\" data-hovercard-url=\"/laristra/flecsi/issues/66/hovercard\" href=\"https://github.com/laristra/flecsi/issues/66\">#66</a> , redistribute partitioned mesh (both topology and fields) according to the output of ParMetis.</p>\\n<p><strong>Help needed: what exactly should a distributed mesh look a like?</strong></p>', 'url': 'https://github.com/laristra/flecsi/issues/68', 'state': 'CLOSED', 'createdAt': '2016-05-12T15:58:33Z', 'lastEditedAt': '2016-07-24T13:10:18Z', 'publishedAt': '2016-05-12T15:58:33Z', 'updatedAt': '2018-10-30T16:54:16Z', 'labels': ['enhancement', 'help wanted', 'in progress'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'flecsi', 'repo_owner_name': 'Los Alamos Ristra project', 'repo_owner_email': '', 'repo_owner_user_name': 'laristra', 'repo_owner_profile_url': 'https://github.com/laristra', 'title': 'Create official DockerHub account', 'bodyHTML': '<p>Once <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"155840141\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/laristra/flecsi/issues/79\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/laristra/flecsi/pull/79/hovercard\" href=\"https://github.com/laristra/flecsi/pull/79\">#79</a> is closed, create an official account on hub.docker.com for distribution of Docker images.</p>', 'url': 'https://github.com/laristra/flecsi/issues/84', 'state': 'CLOSED', 'createdAt': '2016-05-24T12:25:15Z', 'lastEditedAt': None, 'publishedAt': '2016-05-24T12:25:15Z', 'updatedAt': '2016-05-24T15:45:41Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flecsi', 'repo_owner_name': 'Los Alamos Ristra project', 'repo_owner_email': '', 'repo_owner_user_name': 'laristra', 'repo_owner_profile_url': 'https://github.com/laristra', 'title': '#define task in task.h', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1047961\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/spad12\">@spad12</a></p>\\n<p>Is there a reason what you #define task to nothingness in task.h in commit <a href=\"https://github.com/losalamos/flecsi/commit/4a2a59b9b9e3518c46a3130901b866fccbff6796\">4a2a59b?</a></p>', 'url': 'https://github.com/laristra/flecsi/issues/86', 'state': 'CLOSED', 'createdAt': '2016-06-02T23:24:19Z', 'lastEditedAt': None, 'publishedAt': '2016-06-02T23:24:19Z', 'updatedAt': '2018-10-30T16:56:43Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Add examples from \"Defining Phases\" to the documentation', 'bodyHTML': '<p>This file: <a href=\"https://github.com/Cantera/cantera/blob/master/doc/sphinx/cti/example-combustion.rst\">https://github.com/Cantera/cantera/blob/master/doc/sphinx/cti/example-combustion.rst</a> is presently blank. Is it left over from an old version of the documentation?</p>\\n<p>As reported on the Google Group: <a href=\"https://groups.google.com/d/msg/cantera-users/h0s-vJ6iELY/RgqsyqGnCQAJ\" rel=\"nofollow\">https://groups.google.com/d/msg/cantera-users/h0s-vJ6iELY/RgqsyqGnCQAJ</a></p>', 'url': 'https://github.com/Cantera/cantera/issues/313', 'state': 'OPEN', 'createdAt': '2015-12-06T15:05:24Z', 'lastEditedAt': None, 'publishedAt': '2015-12-06T15:05:24Z', 'updatedAt': '2018-03-07T15:54:32Z', 'labels': ['documentation', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Adding citation to the chem input file in the data folder', 'bodyHTML': '<p>Using the chemical mechanism file in the system data of Cantera is very convenient. However, it seems that some of the mechanism files are not properly commented with the associated citation. I would suggest adding citation in all of the mechanism files, at least the chemical format mechanism files.</p>', 'url': 'https://github.com/Cantera/cantera/issues/339', 'state': 'OPEN', 'createdAt': '2016-05-13T07:16:11Z', 'lastEditedAt': '2016-05-13T07:16:30Z', 'publishedAt': '2016-05-13T07:16:11Z', 'updatedAt': '2018-03-07T15:54:17Z', 'labels': ['documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Changing the rate in Python does not change the forward rate constant calculation', 'bodyHTML': '<p>Using <a class=\"commit-link\" href=\"https://github.com/Cantera/cantera/commit/7d3ebdd3581c06f6294e4fb64e355007c2ea766e\"><tt>7d3ebdd</tt></a> (from the conda package) on Linux (Ubuntu 16.04), replacing the reaction rate parameters of a reaction does not affect the calculation of the forward rate constants.</p>\\n<pre><code>import cantera as ct\\ncti_str = \"\"\"\\nunits(length=\\'cm\\', time=\\'s\\', quantity=\\'mol\\', act_energy=\\'cal/mol\\')\\nideal_gas(\\n    name=\\'gas\\',\\n    elements=\\'C\\',\\n    species=\\'A B\\',\\n    reactions=\\'all\\',\\n    initial_state=state(temperature=300.0, pressure=OneAtm)\\n)\\n\\nspecies(\\n    name=\\'A\\',\\n    atoms=\\'C:12\\',\\n    thermo=(\\n        NASA(\\n            [300.00, 1000.00],\\n            [2.08692170E+00,  1.33149650E-01, -8.11574520E-05,\\n             2.94092860E-08, -6.51952130E-12, -3.59128140E+04,\\n             2.73552890E+01]\\n        ),\\n        NASA(\\n            [1000.00, 5000.00],\\n            [2.48802010E+01,  7.82500480E-02, -3.15509730E-05,\\n             5.78789000E-09, -3.98279680E-13, -4.31106840E+04,\\n             -9.36552550E+01]\\n        )\\n    ),\\n)\\n\\nspecies(\\n    name=\\'B\\',\\n    atoms=\\'C:12\\',\\n    thermo=(\\n        NASA(\\n            [300.00, 1000.00],\\n            [2.08692170E+00,  1.33149650E-01, -8.11574520E-05,\\n             2.94092860E-08, -6.51952130E-12, -3.59128140E+04,\\n             2.73552890E+01]\\n        ),\\n        NASA(\\n            [1000.00, 5000.00],\\n            [2.48802010E+01,  7.82500480E-02, -3.15509730E-05,\\n             5.78789000E-09, -3.98279680E-13, -4.31106840E+04,\\n             -9.36552550E+01]\\n        )\\n    ),\\n)\\n\\nreaction(\\n    equation=\\'A =&gt; B\\',\\n    kf=Arrhenius(A=52499925000.0, b=1.5, E=40900.0),\\n)\\n\"\"\"\\ngas = ct.Solution(source=cti_str)\\ngas.TP = 1000, 101325\\nprint(gas.reactions()[0].rate(1000))\\nprint(gas.forward_rate_constants)\\n\\ngas.reactions()[0].rate = ct.Arrhenius(A=4.8765e+69, b=0.0e+00, E=5.0E+04)\\nprint(gas.reactions()[0].rate(1000))\\nprint(gas.forward_rate_constants)\\n</code></pre>\\n<p>which has the output</p>\\n<pre><code>1912707.2378390601\\n[ 1912707.23783906]\\n4.847262590622456e+69\\n[ 1912707.23783906]\\n</code></pre>\\n<p>Is there another function I have to call to inform the Solution about the updated rate?</p>', 'url': 'https://github.com/Cantera/cantera/issues/394', 'state': 'CLOSED', 'createdAt': '2016-11-16T22:08:55Z', 'lastEditedAt': None, 'publishedAt': '2016-11-16T22:08:55Z', 'updatedAt': '2018-06-08T10:40:36Z', 'labels': ['Kinetics', 'documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'ck2cti documentation should be converted to Sphinx-style docstrings', 'bodyHTML': \"<p>The documentation in the ck2cti.py script is currently in a custom format that doesn't seem to be read by the Sphinx docs (at least, I couldn't find a page for it). If the docstrings were rewritten to the standard format, the docs could be included online.</p>\", 'url': 'https://github.com/Cantera/cantera/issues/397', 'state': 'OPEN', 'createdAt': '2016-11-21T14:15:57Z', 'lastEditedAt': None, 'publishedAt': '2016-11-21T14:15:57Z', 'updatedAt': '2016-11-21T20:41:31Z', 'labels': ['ck2cti', 'documentation', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cantera', 'repo_owner_name': 'Cantera', 'repo_owner_email': '', 'repo_owner_user_name': 'Cantera', 'repo_owner_profile_url': 'https://github.com/Cantera', 'title': 'Update/Fix the MacPorts Recipe', 'bodyHTML': '<h3>Cantera version</h3>\\n<p>2.3</p>\\n<h3>Operating System</h3>\\n<p>macOS, MacPorts installation option</p>\\n<h3>Python/MATLAB version</h3>\\n<p>N/A</p>\\n<h3>Expected Behavior</h3>\\n<p>Proper installation</p>\\n<h3>Actual Behavior</h3>\\n<p>Failed installation, see <a href=\"https://groups.google.com/d/msg/cantera-users/rPdKLpC2uys/vIk4jDHTCAAJ\" rel=\"nofollow\">https://groups.google.com/d/msg/cantera-users/rPdKLpC2uys/vIk4jDHTCAAJ</a> for a thread with links</p>\\n<p>Also as discussed at KinCodeCon 2017</p>', 'url': 'https://github.com/Cantera/cantera/issues/496', 'state': 'OPEN', 'createdAt': '2018-01-17T21:34:37Z', 'lastEditedAt': None, 'publishedAt': '2018-01-17T21:34:37Z', 'updatedAt': '2018-03-23T01:55:18Z', 'labels': ['OS X', 'compiling', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'libvmi', 'repo_owner_name': 'libvmi', 'repo_owner_email': '', 'repo_owner_user_name': 'libvmi', 'repo_owner_profile_url': 'https://github.com/libvmi', 'title': 'Windows initializtion errors result in eprocess_list_search() accessing wrong memory', 'bodyHTML': '<p>From time to time libvmi initializes with \"LibVMI Suggestion: set [...] in libvmi.conf for faster startup.\" messages but it does not return an error. However, in these cases the <code>eprocess_list_search()</code> function uses a wrong memory location to traverse a list that results in long loops that eventually end up in a SEGFAULT accessing invalid memory:</p>\\n<p><a href=\"https://github.com/libvmi/libvmi/blob/master/libvmi/os/windows/process.c#L299\">https://github.com/libvmi/libvmi/blob/master/libvmi/os/windows/process.c#L299</a></p>\\n<p>I couldn\\'t figure out what causes this behavior, but the problem always occurs together with the above \"Suggestion\" messages. Seems like all three checks are triggered in kdbg.c:</p>\\n<p><a href=\"https://github.com/libvmi/libvmi/blob/master/libvmi/os/windows/kdbg.c#L1289\">https://github.com/libvmi/libvmi/blob/master/libvmi/os/windows/kdbg.c#L1289</a></p>\\n<p>Testing with Windows 7 x32 and x64.</p>', 'url': 'https://github.com/libvmi/libvmi/issues/442', 'state': 'OPEN', 'createdAt': '2017-01-26T14:03:31Z', 'lastEditedAt': None, 'publishedAt': '2017-01-26T14:03:31Z', 'updatedAt': '2018-04-20T08:35:05Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'libvmi', 'repo_owner_name': 'libvmi', 'repo_owner_email': '', 'repo_owner_user_name': 'libvmi', 'repo_owner_profile_url': 'https://github.com/libvmi', 'title': 'pyvmi extension compilation errors on Debian Jessie', 'bodyHTML': '<p>Hi !</p>\\n<p>I tried to compile and install <code>pyvmi</code> on a Debian Jessie docker image and it failed with the following errors:</p>\\n<pre><code>running build\\nrunning build_ext\\nbuilding \\'pyvmi\\' extension\\ncreating build\\ncreating build/temp.linux-x86_64-2.7\\nx86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include -I/usr/include/python2.7 -c pyvmi.c -o build/temp.linux-x86_64-2.7/pyvmi.o -I/usr/include/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/include \\npyvmi.c: In function \\'pyvmi_init\\':\\npyvmi.c:181:9: warning: format \\'%u\\' expects argument of type \\'unsigned int\\', but argument 4 has type \\'uint64_t\\' [-Wformat=]\\n         char *domidstring = malloc(snprintf(NULL, 0, \"domid-%u\", domid)+1);\\n         ^\\npyvmi.c:181:9: warning: format \\'%u\\' expects argument of type \\'unsigned int\\', but argument 4 has type \\'uint64_t\\' [-Wformat=]\\npyvmi.c:182:9: warning: format \\'%u\\' expects argument of type \\'unsigned int\\', but argument 3 has type \\'uint64_t\\' [-Wformat=]\\n         sprintf(domidstring, \"domid-%u\", domid);\\n         ^\\npyvmi.c: In function \\'pyvmi_get_vcpureg\\':\\npyvmi.c:1311:13: error: incompatible types when assigning to type \\'registers_t\\' from type \\'int\\'\\n         reg = RAX;\\n             ^\\npyvmi.c:1315:13: error: incompatible types when assigning to type \\'registers_t\\' from type \\'int\\'\\n         reg = RBX;\\n             ^\\npyvmi.c:1319:13: error: incompatible types when assigning to type \\'registers_t\\' from type \\'int\\'\\n         reg = RCX;\\n             ^\\n...\\n...\\n...\\npyvmi.c:1612:24: error: incompatible type for argument 3 of \\'vmi_get_vcpureg\\'\\n     if (VMI_FAILURE == vmi_get_vcpureg(vmi(self), &amp;value, reg, vcpu)) {\\n                        ^\\nIn file included from pyvmi.c:31:0:\\n/usr/include/libvmi/libvmi.h:1901:10: note: expected \\'reg_t\\' but argument is of type \\'registers_t\\'\\n status_t vmi_get_vcpureg(\\n          ^\\npyvmi.c: In function \\'pyvmi_v2pcache_flush\\':\\npyvmi.c:1905:5: error: too few arguments to function \\'vmi_v2pcache_flush\\'\\n     vmi_v2pcache_flush(vmi(self));\\n     ^\\nIn file included from pyvmi.c:31:0:\\n/usr/include/libvmi/libvmi.h:1990:6: note: declared here\\n void vmi_v2pcache_flush(\\n      ^\\nerror: command \\'x86_64-linux-gnu-gcc\\' failed with exit status 1\\n</code></pre>\\n<p>Basically it\\'s the same error everywhere:</p>\\n<pre><code>pyvmi.c:1311:13: error: incompatible types when assigning to type \\'registers_t\\' from type \\'int\\'\\n         reg = RAX;\\n</code></pre>\\n<p>I don\\'t have this issue on Fedora, which has <code>gcc 5.3.1</code>, compared to Jessie <code>gcc 4.9.2</code><br>\\nI created a Dockerfile for you to reproduce the issue:</p>\\n<div class=\"highlight highlight-source-dockerfile\"><pre><span class=\"pl-k\">FROM</span> debian:jessie\\n\\n<span class=\"pl-k\">RUN</span> apt-get update &amp;&amp; apt-get install -y git gcc python python-dev pkg-config build-essential \\\\\\n        libtool automake check libglib2.0-dev libvirt-dev bison flex\\n\\n<span class=\"pl-k\">RUN</span> git clone https://github.com/libvmi/libvmi\\n<span class=\"pl-k\">WORKDIR</span> libvmi\\n<span class=\"pl-k\">RUN</span> ./autogen.sh &amp;&amp; ./configure --prefix=/usr &amp;&amp; make -j4 &amp;&amp; make install\\n<span class=\"pl-k\">RUN</span> cd tools/pyvmi &amp;&amp; python setup.py build</pre></div>\\n<p>Could you fix the <code>pyvmi</code> extension to make it compilable on Debian Jessie ?</p>\\n<p>Thanks !</p>', 'url': 'https://github.com/libvmi/libvmi/issues/456', 'state': 'CLOSED', 'createdAt': '2017-02-15T14:51:42Z', 'lastEditedAt': None, 'publishedAt': '2017-02-15T14:51:42Z', 'updatedAt': '2018-03-18T20:16:43Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'libvmi', 'repo_owner_name': 'libvmi', 'repo_owner_email': '', 'repo_owner_user_name': 'libvmi', 'repo_owner_profile_url': 'https://github.com/libvmi', 'title': 'memory limitation of win-guid ? ', 'bodyHTML': '<p>I have build a win7 guest VM with 4GB  memory. When I used win-guid to get kernel information, there was nothing printed on my console. I used strace command and found it exited with 1. But when I changed the memory to 2GB,  it worked well. So I wonder if there is a limitation of guest memory when I use win-guid example.</p>', 'url': 'https://github.com/libvmi/libvmi/issues/463', 'state': 'OPEN', 'createdAt': '2017-03-18T06:28:39Z', 'lastEditedAt': None, 'publishedAt': '2017-03-18T06:28:39Z', 'updatedAt': '2017-04-21T19:21:09Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'libvmi', 'repo_owner_name': 'libvmi', 'repo_owner_email': '', 'repo_owner_user_name': 'libvmi', 'repo_owner_profile_url': 'https://github.com/libvmi', 'title': 'API Documentation issue for vmi_v2pcache_flush', 'bodyHTML': '<p>Hi !</p>\\n<p>I think there is a little error in the API documentation of the function <code>vmi_v2pcache_flush</code>:</p>\\n<div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">void</span> <span class=\"pl-en\">vmi_v2pcache_flush</span> (<span class=\"pl-c1\">vmi_instance_t</span> vmi)</pre></div>\\n<p>However, the function implementation in <a href=\"https://github.com/libvmi/libvmi/blob/master/libvmi/cache.c#L729\">cache.c</a> is not the same:</p>\\n<div class=\"highlight highlight-source-c\"><pre><span class=\"pl-k\">void</span>\\n<span class=\"pl-en\">vmi_v2pcache_flush</span>(\\n    <span class=\"pl-c1\">vmi_instance_t</span> vmi,\\n    <span class=\"pl-c1\">addr_t</span> dtb)\\n{\\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">v2p_cache_flush</span>(vmi, dtb);\\n}</pre></div>\\n<p>It takes a <code>dtb</code> as second parameter.</p>', 'url': 'https://github.com/libvmi/libvmi/issues/466', 'state': 'OPEN', 'createdAt': '2017-03-28T13:34:09Z', 'lastEditedAt': '2017-03-28T13:34:53Z', 'publishedAt': '2017-03-28T13:34:09Z', 'updatedAt': '2017-07-28T18:56:02Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'libvmi', 'repo_owner_name': 'libvmi', 'repo_owner_email': '', 'repo_owner_user_name': 'libvmi', 'repo_owner_profile_url': 'https://github.com/libvmi', 'title': 'Enable-shm-snapshot error', 'bodyHTML': '<p>Cause of changing flags attribute in vmi_instance to init_flags, make fails with ./configure --disable-xen --enable-shm-snapshot.</p>', 'url': 'https://github.com/libvmi/libvmi/issues/481', 'state': 'CLOSED', 'createdAt': '2017-05-23T05:01:08Z', 'lastEditedAt': None, 'publishedAt': '2017-05-23T05:01:08Z', 'updatedAt': '2017-08-18T18:17:03Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Bizarre linking issue', 'bodyHTML': '<p>This is more of a \"help_wanted\" kind of question.</p>\\n<p>I am having a linking issue for netcdf with albany. On my workstation I have a systemwide netcdf installation (needed by some other packages, e.g., octave). When I build albany (and trilinos), I load modules for all the required libraries (hdf5, netcdf, yaml...). At the end, my LD_LIBRARY_PATH env variable looks like this (i\\'m using fake path names for brevity):</p>\\n<p><code>LD_LIBRARY_PATH=/modulepath/netcdf/lib;/modulepath/hdf5/lib:/modulepath/openmpi/lib:.../usr/lib64:/usr/lib</code></p>\\n<p>So the system directories are <em>at the end</em>. Good. When I build trilinos, everything is fine, and when I inspect the libraries with <code>ldd libXYZ.so | grep netcdf</code>, I see that the correct one is linked (the one in <code>/modulepath/netcdf/lib</code>). However, when I build albany, the <em>wrong</em> one is picked. This generates a warning</p>\\n<pre><code>/usr/bin/ld: warning: libnetcdf.so.11, needed by\\n /path/to/trilinos/lib/libstk_tools_lib.so.12.13, may conflict with libnetcdf.so.7\\n</code></pre>\\n<p>and, more importantly, the system library does not support parallel correctly. I can verify that the wrong netcdf is linked, since with, say, <code>ldd libalbanySTK.so | grep netcdf</code> I get</p>\\n<pre><code>libnetcdf.so.7 =&gt; /usr/lib64/libnetcdf.so.7 (0x00007f0cc5235000)\\nlibnetcdf.so.11 =&gt; /modulepath/netcdf/lib/libnetcdf.so.11 (0x00007f0cbf75a000)\\n</code></pre>\\n<p>It appears that <em>somewhere</em> in albany, the path <code>/usr/lib64</code> is prepended to <code>ld</code> search path. I looked through the build directory, but I cannot find the place where this happens. Even the <code>build.cmake</code> file for <code>libalbanySTK</code> lists the correct dependency in the <code>albanySTK_EXTERNAL_OBJECTS</code> variable (i.e., it lists <code>/modulepath/netcdf/lib/libnetcdf.so</code>), but then the other one gets linked, when <code>-lnetcdf</code> is found on the link line.</p>\\n<p>I found a workaround by adding the <a href=\"https://cmake.org/cmake/help/v3.3/policy/CMP0060.html\" rel=\"nofollow\">policy</a> <code>cmake_policy(SET CMP0060 NEW)</code> to the main <code>CMakeLists.txt</code>, but I don\\'t want to do that, especially since I am probably the only one with this issue.</p>\\n<p>Has anyone experienced the same problem at some point?</p>', 'url': 'https://github.com/gahansen/Albany/issues/232', 'state': 'CLOSED', 'createdAt': '2017-11-30T23:31:15Z', 'lastEditedAt': '2017-11-30T23:33:15Z', 'publishedAt': '2017-11-30T23:31:15Z', 'updatedAt': '2017-12-01T00:14:35Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Albany User Guide', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971921\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibaned\">@ibaned</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7558465\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/agsalin\">@agsalin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5940580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mperego\">@mperego</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7018124\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ikalash\">@ikalash</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=147948\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jtostie\">@jtostie</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5702945\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bgranzow\">@bgranzow</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3226046\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartgol\">@bartgol</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=11995357\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/calleman21\">@calleman21</a></p>\\n<p>Sorry for spamming all of you, but I think this issue is very broad.</p>\\n<p>In the past, and most recently today, I have been asked whether there is an Albany User Guide for people that want to just run Albany, but have no plans to touch the source code.</p>\\n<p>I believe that there is scattered information here and there, and I\\'m reaching out to all of you to ask if you know about it, and to gage the interest to try to bring it together into a single place.</p>\\n<p>Thoughts?</p>', 'url': 'https://github.com/gahansen/Albany/issues/250', 'state': 'OPEN', 'createdAt': '2018-01-19T01:48:41Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T01:48:41Z', 'updatedAt': '2018-01-22T15:49:56Z', 'labels': ['help wanted', 'question', 'user documentation', 'user usability'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Hanging Tempus tests on skybridge-login5 with intel compiler', 'bodyHTML': '<p>Around Feb. 9, 2 Tempus tests began failing in <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> \\'s Skybridge intel build:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlypassed&amp;buildid=67116\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlypassed&amp;buildid=67116</a></p>\\n<p>What is truly bizarre about this problem is when I use the same exact scripts as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> to run the tests, also on skybridge-login5 and run via cronjob, the tests pass:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/index.php?project=Albany&amp;subproject=albany_cluster-toss3_skybridge-login5_serial-intel-release&amp;date=2018-02-19\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/index.php?project=Albany&amp;subproject=albany_cluster-toss3_skybridge-login5_serial-intel-release&amp;date=2018-02-19</a></p>\\n<p>We have made sure that my ~/.bashrc and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a>\\'s ~/.bashrc files are the same.  Anyone have any thoughts?  It would be nice if perhaps someone else could give this build a try and report what happens.</p>', 'url': 'https://github.com/gahansen/Albany/issues/265', 'state': 'CLOSED', 'createdAt': '2018-02-20T16:10:36Z', 'lastEditedAt': None, 'publishedAt': '2018-02-20T16:10:36Z', 'updatedAt': '2018-07-02T03:31:29Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Replacement for MDArray, potential bad memory leak in Shards from MDArray', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=971921\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ibaned\">@ibaned</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7018124\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ikalash\">@ikalash</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7558465\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/agsalin\">@agsalin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a>  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5940580\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mperego\">@mperego</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3226046\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartgol\">@bartgol</a> While chasing a frustrating bug in Schwarz about resetting state arrays, I discovered that MDArrays are shards::Arrays, as defined in Albany_StateInfoStruct.hpp.</p>\\n<p>shards::Arrays overload the operator= with a shallow copy, hence the failure in resetting state variables for Schwarz.</p>\\n<p>There are two problems with this:</p>\\n<ul>\\n<li>There appears to be no way to do a deep copy of an MDArray/shard:Array, which is needed for Schwarz.</li>\\n<li>The shallow copy uses raw pointers. It does not free the old pointer before overwriting it with the new one, hence the memory it was pointing to is lost.</li>\\n</ul>\\n<p>My question is: is it possible to replace the MDArray in Albany_StateInfoStruct.hpp with something else? A Kokkos view perhaps?</p>\\n<p>I could jump through hoops and make this work with MDArrays somehow, but it seems to me that there should be a cleaner solution and also avoid the potential for memory leaks.</p>\\n<p>I\\'m open to suggestions.</p>', 'url': 'https://github.com/gahansen/Albany/issues/268', 'state': 'CLOSED', 'createdAt': '2018-02-28T19:21:22Z', 'lastEditedAt': '2018-02-28T19:42:49Z', 'publishedAt': '2018-02-28T19:21:22Z', 'updatedAt': '2018-03-08T00:13:27Z', 'labels': ['bug', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Albany build broken due to Kokkos::Experimental::Impl not being defined', 'bodyHTML': '<p>It looks like Albany failed to build in the nightlies last night.  I can only see the external CDash, as I am on foreign travel:</p>\\n<p><a href=\"https://my.cdash.org/viewBuildError.php?buildid=1381133\" rel=\"nofollow\">https://my.cdash.org/viewBuildError.php?buildid=1381133</a></p>\\n<p>but I am guessing this happened in the internal tests too.  Here is the error cut/paste here:</p>\\n<pre><code>repos/Albany/src/PHAL_Utilities_Def.hpp:224:39: error: \\'Kokkos::Experimental::Impl\\' has not been declared\\n</code></pre>\\n<p>Can someone please look at what is going on / fix it while I am away?</p>', 'url': 'https://github.com/gahansen/Albany/issues/269', 'state': 'CLOSED', 'createdAt': '2018-03-08T08:08:42Z', 'lastEditedAt': '2018-03-08T08:10:41Z', 'publishedAt': '2018-03-08T08:08:42Z', 'updatedAt': '2018-03-08T16:51:51Z', 'labels': ['build', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Tpetra::Map destructor warning printed for Albany tests', 'bodyHTML': '<p>I noticed that starting this morning, all (I believe) Albany tests have this warning printed:</p>\\n<pre><code>WARNING: Tpetra::Map destructor (~Map()) is being called after Tpetra::finalize() has been called.  This is user error!  This may happen if you create a Tpetra::Map (or RCP or shared_ptr of a Tpetra::Map) at the same scope in main() as Tpetra::finalize().  Don\\'t do that.  Please refer to GitHib Issue #2372.\\n</code></pre>\\n<p>It looks like the warning was added to Tpetra yesterday (see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"304818275\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/2372\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/2372/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/2372\">trilinos/Trilinos#2372</a> ).  We should try to understand what we\\'re doing wrong with the Tpetra::Map destructor.  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1564391\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tjfulle\">@tjfulle</a>, would you be willing to look at this, as someone well-acquainted with Tpetra and also working on Albany maintenance?</p>', 'url': 'https://github.com/gahansen/Albany/issues/275', 'state': 'CLOSED', 'createdAt': '2018-03-20T15:48:30Z', 'lastEditedAt': '2018-03-20T15:48:43Z', 'publishedAt': '2018-03-20T15:48:30Z', 'updatedAt': '2018-03-21T20:38:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Issue with LCM Python tests that execute \"./AlbanyT *yaml\" command on some HPC platforms', 'bodyHTML': '<p>In building / running Albany/LCM on the Solo ECN machine, I discovered an issue with the LCM tests that run python scripts with the command \"./AlbanyT *yaml\".  The issue is on some platforms, \"mpirun -np 1 AlbanyT\" or \"mpiexec -np 1 AlbanyT\" is required to run serial executables, with Solo being one of them.  I think this issue may have come up before.  I can modify the scripts to execute the command \"mpirun -np 1 AlbanyT\" except I think then on some platforms there may be an issue with not providing a path to mpirun (or using srun / mpiexec instead of mpirun).  Ideally, we\\'d want to get the path to the mpi command from cmake.  I think <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5393804\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gahansen\">@gahansen</a> may have encountered this before.</p>\\n<p>Here are the tests that would need to be modified to fix this:</p>\\n<pre><code>    109 - CohesiveElement (Failed)\\n    112 - EquilibriumConcentrationBC (Failed)\\n    113 - HeliumODEs (Failed)\\n    117 - AnisotropicHyperelasticDamage (Failed)\\n    118 - AnisotropicDamage-Bifurcation (Failed)\\n    119 - Gurson (Failed)\\n    120 - Neohookean (Failed)\\n    121 - CrystalPlasticity_MPS (Failed)\\n    131 - MechanicsWithHelium (Failed)\\n    137 - Partition (Failed)\\n    142 - SurfaceElementLocking (Failed)\\n    143 - SurfaceElementOrtiz (Failed)\\n    230 - Schwarz_Cubes (Failed)\\n    231 - Schwarz_Alternating_Quasistatics (Failed)\\n    232 - Schwarz_Alternating_Dynamics_Cubes (Failed)\\n    233 - Schwarz_Alternating_Dynamics_CubesInelastic (Failed)\\n</code></pre>', 'url': 'https://github.com/gahansen/Albany/issues/278', 'state': 'CLOSED', 'createdAt': '2018-03-29T03:28:48Z', 'lastEditedAt': '2018-07-02T22:55:43Z', 'publishedAt': '2018-03-29T03:28:48Z', 'updatedAt': '2018-07-07T00:49:04Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Time Dependent BC that varies in space and time ', 'bodyHTML': \"<p>As discussed at the Albany meeting this morning, there is an interest in adding to Albany a time dependent BC (Dirichlet as well as Neumann) where the BC values are spatially and temporally dependent, and not given by an analytical function.  Albany currently has the following capabilities:</p>\\n<ul>\\n<li>Set a Dirichlet BC from a field in the mesh named dirichlet_field (allowing a spatially-varying BC that is not given by an analytical function).</li>\\n<li>Set a time-dependent BC (Dirichlet, perhaps Neumann too) that is spatially constant on a given nodeset.</li>\\n</ul>\\n<p>The new time dependent BC would combine these two capabilities.  Specifically, we'd need to:</p>\\n<ul>\\n<li>Add the capability to read snapshots defining the BC field into dirichlet_field.  Probably we should not store all the snapshots but a couple at a time to avoid running out of memory.</li>\\n<li>Add the capability to interpolate the time-dependent BC values to times where they are needed, in the case where the time-step is different than the times where the snapshots are stored.  This sort of interpolation is done already in TimeDepBC for scalar-valued (in space) BCs.  This interpolation is what will require at least 2 BC snapshots to be stored at a time.</li>\\n</ul>\\n<p>Any volunteers to help with this task?  The new BC is of interest to the Tsunami work, as well as the RPI folks; perhaps others are interested in this too?</p>\", 'url': 'https://github.com/gahansen/Albany/issues/316', 'state': 'OPEN', 'createdAt': '2018-07-09T16:49:13Z', 'lastEditedAt': None, 'publishedAt': '2018-07-09T16:49:13Z', 'updatedAt': '2018-07-09T19:59:15Z', 'labels': ['Tsunami', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Add a test for the Vx, Vxdot, Vxdotdot, Vp tangent direction functionalities.', 'bodyHTML': \"<p>Currently, these are in the Workset, but are never set to annything other than NULL by the model evaluator. Hence, all the evaluators that are supposed to do something if they are not null, do nothing.</p>\\n<p>We should come up with a test that uses them, even if it is from a modified version of Albany's model evaluator.</p>\", 'url': 'https://github.com/gahansen/Albany/issues/335', 'state': 'OPEN', 'createdAt': '2018-07-19T23:16:53Z', 'lastEditedAt': None, 'publishedAt': '2018-07-19T23:16:53Z', 'updatedAt': '2018-07-19T23:16:53Z', 'labels': ['Testing', 'help wanted', 'infrastructure'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Warning-free Albany build', 'bodyHTML': '<p>I was tracking down a bug, and it ended up being something like <code>a - b;</code> instead of <code>a = b;</code>. So I thought \"well, let\\'s turn on warnings, so I don\\'t waste 1h of my time later on finding these bugs\". And then warningmageddon happened.</p>\\n<p>Albany generates a gazillion of warnings! Unused parameters/typedefs, signed/unsigned comparisons, and initialization order are the major stars of the show, with countless hits.</p>\\n<p>Now, virtually all of these warning are benign, and could be ignored. However, as Albany grows larger and larger, it would be nice (to say the least) to fix those warnings. Besides, the fewer the warnings spit out by the compiler, the easier it is to catch the dangerous ones. I think of this issue as a constant reminder: if we run into one obvious warning, we should clean it up, together with our commits. And possibly not introduce a new one.</p>\\n<p>Note: yes, we can silence warnings, but that\\'s not a very clean solution.</p>', 'url': 'https://github.com/gahansen/Albany/issues/354', 'state': 'OPEN', 'createdAt': '2018-08-14T19:22:22Z', 'lastEditedAt': None, 'publishedAt': '2018-08-14T19:22:22Z', 'updatedAt': '2018-08-15T00:11:35Z', 'labels': ['build', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Numerous test failures in Albany nightlies as of this morning', 'bodyHTML': '<p>There are numerous test failures in Albany as of this morning:</p>\\n<p><a href=\"http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlyfailed&amp;buildid=75093\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/viewTest.php?onlyfailed&amp;buildid=75093</a></p>\\n<p>Most of them seem to be failures when running exodiff for LCM problems, but a few seem to have to do with reading in an Exodus file to restart from, e.g. <a href=\"http://cdash.sandia.gov/CDash-2-3-0/testDetails.php?test=3880312&amp;build=75103\" rel=\"nofollow\">http://cdash.sandia.gov/CDash-2-3-0/testDetails.php?test=3880312&amp;build=75103</a>:</p>\\n<pre><code>p=2: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Variable type counts are inconsistent. See processor 0 output for more details.\\np=3: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Variable type counts are inconsistent. See processor 0 output for more details.\\np=0: *** Caught standard std::exception of type \\'std::runtime_error\\' :\\n ERROR: Number of nodeset variables is not consistent on all processors.\\n        Database: th1d_tpetra.exo\\n \\tProcessor 0 count = 3\\n \\tProcessor 1 count = 0\\n \\tProcessor 2 count = 0\\n</code></pre>\\n<p>It looks like there were no non-trivial checkins to Albany master this week, so I think the failures are due to changes in Trilinos.  Anyone want to investigate this?</p>', 'url': 'https://github.com/gahansen/Albany/issues/358', 'state': 'CLOSED', 'createdAt': '2018-08-23T15:57:17Z', 'lastEditedAt': None, 'publishedAt': '2018-08-23T15:57:17Z', 'updatedAt': '2018-09-24T16:59:58Z', 'labels': ['Testing', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Modify alg.i for SurfaceElementLocking to have exodiff compare SURF_S*, SURF_* and SURF_HYDRO_* fields', 'bodyHTML': '<p>In resolving issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"353447168\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/358\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/358/hovercard\" href=\"https://github.com/gahansen/Albany/issues/358\">#358</a> , I had to turn off exodiff comparisons of some of the SURF fields for the SurfaceElementLocking test case, as these fields are no longer generated in the *alg.e file when running algebra, due to a change in the naming of STK fields written to the output exodus file.  If these comparisons are of interest, can someone (preferably the author and one familiar with what algebra is supposed to be doing - tagging <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7120001\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lxmota\">@lxmota</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7317023\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jwfoulk\">@jwfoulk</a> ) look at this with me (or look at it on their own/fix it)?  I think the fix should be very quick.</p>', 'url': 'https://github.com/gahansen/Albany/issues/365', 'state': 'OPEN', 'createdAt': '2018-09-24T16:59:21Z', 'lastEditedAt': None, 'publishedAt': '2018-09-24T16:59:21Z', 'updatedAt': '2018-09-24T16:59:21Z', 'labels': ['LCM', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Make headers include all explicit dependencies', 'bodyHTML': '<p>Plenty of headers in Albany (especially in the evaluators folder) miss some includes. For instance, very few evaluators headers include <code>PHAL_Dimension.hpp</code> (directly or indirectly). Things obviously work anyways, since at the time of use, such headers are (directly or indirectly) included. For instance, including <code>PHAL_AlbanyTraits.hpp</code> brings in all the data types and the dimensions tags.</p>\\n<p>While this <em>works</em>, it is also not optimal, at least on 2+1 levels:</p>\\n<ol start=\"0\">\\n<li>it is a bad practice;</li>\\n<li>when faced with a function/class/type I don\\'t fully understand, I sometimes go up the include stack, till I reach the point where it is defined. Relying on some upstream headers being included at the time the current header will be used makes this impossible;</li>\\n<li>If you have a text editor with real-time compilation in the background that highlights compiler errors, you can be submerged by a red-tide of errors, which make navigating the code harder.</li>\\n</ol>\\n<p>While I understand that the effort of fixing this is probably too big for the gain we would get (after all, the code compiles and runs), I would like to ask developers to be aware of this. When adding a new header or modifying an existing one, please spend 3 seconds checking whether each symbol\\'s header is included (directly or indirectly), and add it if missing.</p>\\n<p>P.S: I don\\'t want to get into the discussion of whether indirect inclusion is fine or not (though I am a strong supporter of \"include everything you explicitly use that you cannot forward declare\", rather than \"if the first header you include includes the second one, you don\\'t need the second one\"). What I\\'m <em>strongly encouraging</em> is the idea that including any header from our library in file <code>foo.cpp</code> should <em>not</em>  force the user to include other headers that <code>foo.cpp</code> does not explicitly need. The end user may not even know where the symbol <code>Cell</code> is defined, nor should he/she care.</p>', 'url': 'https://github.com/gahansen/Albany/issues/379', 'state': 'OPEN', 'createdAt': '2018-11-01T15:01:34Z', 'lastEditedAt': '2018-11-01T15:04:59Z', 'publishedAt': '2018-11-01T15:01:34Z', 'updatedAt': '2018-11-01T15:04:59Z', 'labels': ['developer usability', 'help wanted', 'user usability'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Albany', 'repo_owner_name': 'Glen Hansen', 'repo_owner_email': 'gahanse@sandia.gov', 'repo_owner_user_name': 'gahansen', 'repo_owner_profile_url': 'https://github.com/gahansen', 'title': 'Remove or replace all instances of ALBANY_KOKKOS_UNDER_DEVELOPMENT', 'bodyHTML': '<p>This has been discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"260676342\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/184\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/184/hovercard\" href=\"https://github.com/gahansen/Albany/issues/184\">#184</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378833321\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/gahansen/Albany/issues/382\" data-hovercard-type=\"issue\" data-hovercard-url=\"/gahansen/Albany/issues/382/hovercard\" href=\"https://github.com/gahansen/Albany/issues/382\">#382</a>. It would be great to remove it and keep the kokkos kernels but there may be some instances where we would like to keep the legacy implementation. At the very least, my suggestion would be to try to remove it everywhere except where kernels are called and make it a requirement to use the Kokkos data abstractions. Then possibly rename it too <code>ALBANY_USE_KOKKOS_KERNELS</code> or flip it to <code>ALBANY_LEGACY_CODE</code> so that the kokkos kernels are the default.</p>', 'url': 'https://github.com/gahansen/Albany/issues/385', 'state': 'OPEN', 'createdAt': '2018-11-12T19:19:10Z', 'lastEditedAt': None, 'publishedAt': '2018-11-12T19:19:10Z', 'updatedAt': '2018-11-14T18:20:33Z', 'labels': ['Discussion', 'Kokkos', 'developer usability', 'help wanted', 'infrastructure'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'SHAD', 'repo_owner_name': 'Pacific Northwest National Laboratory', 'repo_owner_email': 'dev-central@pnnl.gov', 'repo_owner_user_name': 'pnnl', 'repo_owner_profile_url': 'https://github.com/pnnl', 'title': 'Refactor GetGlobalID into AbstractDataStructure', 'bodyHTML': '<p>The method GetGlobalID is implemented over and over in all our data structures.  It should be refactored into the AbstractDataStructure.</p>', 'url': 'https://github.com/pnnl/SHAD/issues/23', 'state': 'OPEN', 'createdAt': '2018-03-26T21:42:16Z', 'lastEditedAt': '2018-08-22T15:13:32Z', 'publishedAt': '2018-03-26T21:42:16Z', 'updatedAt': '2018-08-22T15:13:32Z', 'labels': ['enhancement', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SHAD', 'repo_owner_name': 'Pacific Northwest National Laboratory', 'repo_owner_email': 'dev-central@pnnl.gov', 'repo_owner_user_name': 'pnnl', 'repo_owner_profile_url': 'https://github.com/pnnl', 'title': 'Implement thread-safe random number generators in utils', 'bodyHTML': '', 'url': 'https://github.com/pnnl/SHAD/issues/24', 'state': 'OPEN', 'createdAt': '2018-03-26T23:24:30Z', 'lastEditedAt': None, 'publishedAt': '2018-03-26T23:24:30Z', 'updatedAt': '2018-03-29T23:23:14Z', 'labels': ['enhancement', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'raja', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'forallN development tasks', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=660149\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/trws\">@trws</a></p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Eliminate Code Gen (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153137267\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/LLNL/RAJA/issues/4\" data-hovercard-type=\"issue\" data-hovercard-url=\"/LLNL/RAJA/issues/4/hovercard\" href=\"https://github.com/LLNL/RAJA/issues/4\">#4</a>)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Intel compiler issues (slowness in compiling, performance issues) (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"153139179\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/LLNL/RAJA/issues/5\" data-hovercard-type=\"issue\" data-hovercard-url=\"/LLNL/RAJA/issues/5/hovercard\" href=\"https://github.com/LLNL/RAJA/issues/5\">#5</a>)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Clang OpenMP (backed out in commit <a class=\"commit-link\" href=\"https://github.com/LLNL/RAJA/commit/ceca2c61d46d5c44f298696b405675f25883cd90\"><tt>ceca2c6</tt></a> ??? need to hunt down specific commit?)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> nvcc lambda \"introspection???\" (need to generate a branch for this)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> add static_assert\\'s to help the user out!</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> add sequential tests for CPU nested and CPU nested reduce tests so the forallN machinery gets tested for all configurations (i.e., without OpenMP enabled)</li>\\n</ul>', 'url': 'https://github.com/LLNL/RAJA/issues/3', 'state': 'CLOSED', 'createdAt': '2016-05-04T23:15:51Z', 'lastEditedAt': '2017-03-14T17:22:44Z', 'publishedAt': '2016-05-04T23:15:51Z', 'updatedAt': '2017-03-14T21:40:22Z', 'labels': ['API/usability', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'raja', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'Intel compiler issues (slowness in compiling, performance issues)', 'bodyHTML': '<p>Compilation time takes excessively long for Kripke+RAJA.<br>\\nEach data layout that is enabled makes compilation time double.</p>\\n<p>Current code is guarded to only enable 1 data layout when using Intel compiler, see guard in this file:<br>\\n<div class=\"border rounded-1 my-2\">\\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\\n    <p class=\"mb-0 text-bold\">\\n      <a href=\"https://github.com/LLNL/RAJA/blob/22b1eda03a46bcaca2840a36890aef6e4a06ba09/test/Kripke-v1.1/Kripke-v1.1-RAJA/Kripke/Kernel.cpp#L82\">RAJA/test/Kripke-v1.1/Kripke-v1.1-RAJA/Kripke/Kernel.cpp</a>\\n    </p>\\n    <p class=\"mb-0 text-gray-light\">\\n         Line 82\\n      in\\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/LLNL/RAJA/commit/22b1eda03a46bcaca2840a36890aef6e4a06ba09\">22b1eda</a>\\n    </p>\\n    </div>\\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\\n\\n        <tbody><tr class=\"border-0\">\\n          <td id=\"L82\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"82\"></td>\\n          <td id=\"LC82\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> #<span class=\"pl-k\">ifndef</span> RAJA_COMPILER_ICC </td>\\n        </tr>\\n    </tbody></table>\\n  </div>\\n</div>\\n</p>', 'url': 'https://github.com/LLNL/RAJA/issues/5', 'state': 'CLOSED', 'createdAt': '2016-05-04T23:32:01Z', 'lastEditedAt': None, 'publishedAt': '2016-05-04T23:32:01Z', 'updatedAt': '2017-03-14T13:11:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'raja', 'repo_owner_name': 'Lawrence Livermore National Laboratory', 'repo_owner_email': 'github-admin@llnl.gov', 'repo_owner_user_name': 'LLNL', 'repo_owner_profile_url': 'https://github.com/LLNL', 'title': 'Intel compiler 6x OpenMP performance degradation for feature/keasler/BoxSegment', 'bodyHTML': '<p>The LULESH v1.0 application runs 6x slower on the feature/keasler/BoxSegment branch due to an Intel compiler bug.  gcc-4.9.3p runs at the same speed on the develop branch and the feature/keasler/BoxSegment branch.  That said, the Intel compiler produces code that is over 30% faster on the develop branch, so this is not a dis on the Intel compiler.</p>', 'url': 'https://github.com/LLNL/RAJA/issues/6', 'state': 'CLOSED', 'createdAt': '2016-05-04T23:41:10Z', 'lastEditedAt': None, 'publishedAt': '2016-05-04T23:41:10Z', 'updatedAt': '2017-03-13T21:32:54Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'OpenStudio-workflow-gem', 'repo_owner_name': 'National Renewable Energy Laboratory', 'repo_owner_email': '', 'repo_owner_user_name': 'NREL', 'repo_owner_profile_url': 'https://github.com/NREL', 'title': 'Push to master', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2235296\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/brianlball\">@brianlball</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1907354\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nllong\">@nllong</a> We need to get a very solidly working &amp; tested commit from develop onto master so we can point the AMIs to the master-workflow gem branch. Unless we want to fix each AMI to a specific commit. Either way, I\\'d like to get master a little lot more up to date. Suggestions?</p>', 'url': 'https://github.com/NREL/OpenStudio-workflow-gem/issues/29', 'state': 'OPEN', 'createdAt': '2015-11-25T01:28:20Z', 'lastEditedAt': None, 'publishedAt': '2015-11-25T01:28:20Z', 'updatedAt': '2016-04-14T22:48:09Z', 'labels': ['help wanted', 'in progress', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'ARL-Open-Source-Guidance-and-Instructions', 'repo_owner_name': 'US Army Research Laboratory', 'repo_owner_email': '', 'repo_owner_user_name': 'USArmyResearchLab', 'repo_owner_profile_url': 'https://github.com/USArmyResearchLab', 'title': 'Do ARL forms need to be ADA compliant?', 'bodyHTML': \"<p>ARL uses PDF forms because they are the Army standard.  However, I don't know if they comply with the Americans with Disabilities Act.  Is it possible to create PDF forms that comply with the act?</p>\", 'url': 'https://github.com/USArmyResearchLab/ARL-Open-Source-Guidance-and-Instructions/issues/12', 'state': 'OPEN', 'createdAt': '2017-03-01T22:11:59Z', 'lastEditedAt': None, 'publishedAt': '2017-03-01T22:11:59Z', 'updatedAt': '2017-03-07T20:12:08Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'SolarPILOT', 'repo_owner_name': 'National Renewable Energy Laboratory', 'repo_owner_email': '', 'repo_owner_user_name': 'NREL', 'repo_owner_profile_url': 'https://github.com/NREL', 'title': 'Linux control focus', 'bodyHTML': '<p>When running on linux machines (Ubuntu 14.04, 16.04, Mint), SolarPILOT UI input controls stop working after switching between pages. The control can still accept text entry or dropdown selection, but does not display the change until switching back and forth between pages or forcing redraw by maximizing the window.</p>\\n<p>I have confirmed this issue using native builds and distributions.</p>', 'url': 'https://github.com/NREL/SolarPILOT/issues/4', 'state': 'CLOSED', 'createdAt': '2018-02-23T16:25:14Z', 'lastEditedAt': '2018-03-01T19:41:13Z', 'publishedAt': '2018-02-23T16:25:14Z', 'updatedAt': '2018-03-21T06:47:13Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SolarPILOT', 'repo_owner_name': 'National Renewable Energy Laboratory', 'repo_owner_email': '', 'repo_owner_user_name': 'NREL', 'repo_owner_profile_url': 'https://github.com/NREL', 'title': 'Better interaction with heliostat field plot', 'bodyHTML': '<p>Develop methods for mouse interaction with plotted heliostats. Display ID, data, dimensions, etc. Allow selection and addition/removal of heliostats from the layout.</p>\\n<p>See <a href=\"https://github.com/NREL/SolarPILOT/tree/feature-plot-interact\">https://github.com/NREL/SolarPILOT/tree/feature-plot-interact</a></p>', 'url': 'https://github.com/NREL/SolarPILOT/issues/7', 'state': 'CLOSED', 'createdAt': '2018-03-09T17:54:48Z', 'lastEditedAt': '2018-03-09T17:57:21Z', 'publishedAt': '2018-03-09T17:54:48Z', 'updatedAt': '2018-03-13T04:21:31Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'API: improve flux handle message counter interface', 'bodyHTML': '<p>Currently we have</p>\\n<pre><code>// handle.h\\ntypedef struct {\\n    int request_tx;\\n    int request_rx;\\n    int response_tx;\\n    int response_rx;\\n    int event_tx;\\n    int event_rx;\\n    int keepalive_tx;\\n    int keepalive_rx;\\n} flux_msgcounters_t;\\n\\n/* Get/clear handle message counters.\\n */\\nvoid flux_get_msgcounters (flux_t h, flux_msgcounters_t *mcs);\\nvoid flux_clr_msgcounters (flux_t h);\\n</code></pre>\\n<p>A better interface might be something like:</p>\\n<pre><code>enum { FLUX_MC_TX=1, FLUX_MC_RX=2 };\\n\\nint  flux_get_msgcount (flux_t h, int dirmask, int typemask);\\nvoid flux_clr_msgcount (flux_t h, int dirmask, int typemask);\\n</code></pre>\\n<p>Where the counters(s) selected depend on dirmask and typemask.  <code>flux_get_msgcount()</code>  would return the sum of all selected counters, and <code>flux_clr_msgcount()</code> would clear all selected counters.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/183', 'state': 'OPEN', 'createdAt': '2015-05-07T22:15:53Z', 'lastEditedAt': None, 'publishedAt': '2015-05-07T22:15:53Z', 'updatedAt': '2018-07-10T16:24:55Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'switch to inttypes.h printf macros for portability', 'bodyHTML': '<p>Visit all of the printf-style statements within flux-core and replace any appearance of the non portable conversion specifications with their portable macro equivalent as defined in inttypes.h.</p>\\n<p>Also update RFC 7 to include guidance on coding for portability.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/394', 'state': 'CLOSED', 'createdAt': '2015-09-04T23:25:28Z', 'lastEditedAt': None, 'publishedAt': '2015-09-04T23:25:28Z', 'updatedAt': '2017-01-06T22:15:27Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'PMI script/replay', 'bodyHTML': '<p>As we begin nominally supporting more MPI bootstrap implementations, it might be interesting to have functionality to capture a PMI (and other) \"trace\" or script during a MPI launch, and allow the in tree <code>pmi-client</code> to \"replay\" the bootstrap session based on a script checked into the tests area of the repository.</p>\\n<p>It might not be feasible to completely automate the trace capture (I\\'m thinking a <code>flux trace start</code>, <code>flux trace stop</code> would be awesome, but I can\\'t imagine how we\\'d capture everything), but perhaps a somewhat automated capture plus some manual setup would allow us to greatly extend our automated testing without installing all the world\\'s MPI (and other) libraries in the test instances.</p>\\n<p>Another benefit of this kind of capability would be an ability to capture traces that reproduce some specific bug seen elsewhere, allowing perhaps easier local debugging.</p>\\n<p>I suppose this might work outside of PMI only, but the libpmi interface seems like perhaps a tractable starting point.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/599', 'state': 'OPEN', 'createdAt': '2016-03-10T00:03:34Z', 'lastEditedAt': None, 'publishedAt': '2016-03-10T00:03:34Z', 'updatedAt': '2016-03-10T00:03:34Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'live module cascading failures', 'bodyHTML': \"<p>If a broker slows down for a while then returns to normal responsiveness, the following may happen (test by sending SIGSTOP to a broker, then SIGCONT):</p>\\n<pre><code>$ ./flux start -s64 \\n$ kill -STOP 37817\\n$ flux-start: 1 (pid 37817) Stopped (signal)\\n</code></pre>\\n<p>The broker's TBON parent may mark it 'failed', and its children may reparent.  This is normal.</p>\\n<pre><code>[1460150810.190432] live.crit[0]: transitioning 1 from OK to SLOW\\n[1460150814.190372] live.crit[0]: transitioning 1 from SLOW to FAIL\\n[1460150814.193420] broker.crit[3]: reparent ipc:///tmp/flux-37789-FbuCX8/0/req (new)\\n[1460150814.196075] broker.crit[4]: reparent ipc:///tmp/flux-37789-FbuCX8/0/req (new)\\n</code></pre>\\n<p>When the broker becomes responsive, it may decide its TBON children have failed.  This is wrong.</p>\\n<pre><code>$ kill -CONT 37817\\nflux-start: 1 (pid 37817) Continued\\njimbo /home/garlick/proj/flux-core/src/cmd &gt; [1460150826.819672] live.crit[1]: transitioning 3 from OK to SLOW\\n[1460150826.819703] live.crit[1]: transitioning 4 from OK to SLOW\\n[1460150826.820033] live.crit[1]: transitioning 4 from SLOW to FAIL\\n[1460150826.819672] live.crit[1]: transitioning 3 from OK to SLOW\\n[1460150826.820007] live.crit[1]: transitioning 3 from SLOW to FAIL\\n</code></pre>\\n<p>This triggers <em>their</em> children to reparent:</p>\\n<pre><code>[1460150826.826241] broker.crit[8]: reparent ipc:///tmp/flux-37789-FbuCX8/0/req (new)\\n[1460150826.827488] broker.crit[9]: reparent ipc:///tmp/flux-37789-FbuCX8/0/req (new)\\n[1460150826.828682] broker.crit[10]: reparent ipc:///tmp/flux-37789-FbuCX8/0/req (new)\\n[1460150826.829373] broker.crit[7]: reparent ipc:///tmp/flux-37789-FbuCX8/0/req (new)\\n[1460150828.189251] live.crit[0]: transitioning 1 from FAIL to OK\\n</code></pre>\\n<p>Further, the second set of failed nodes remain that way.</p>\\n<pre><code>$ flux up\\nok:     [0-2,5-63]\\nslow:   \\nfail:   [3-4]\\nunknown:\\n</code></pre>\", 'url': 'https://github.com/flux-framework/flux-core/issues/638', 'state': 'CLOSED', 'createdAt': '2016-04-08T21:41:59Z', 'lastEditedAt': None, 'publishedAt': '2016-04-08T21:41:59Z', 'updatedAt': '2017-03-14T22:49:30Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'update embedded libev version', 'bodyHTML': '<p>As noted in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"160017880\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/flux-framework/flux-core/issues/694\" data-hovercard-type=\"issue\" data-hovercard-url=\"/flux-framework/flux-core/issues/694/hovercard\" href=\"https://github.com/flux-framework/flux-core/issues/694\">#694</a>, clang 3.5.0 has some problems compiling our embedded libev 4.19.<br>\\nIt appears to be fixed upstream.</p>\\n<p>Verify that the latest tagged release includes the fix and update our embedded version.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/717', 'state': 'CLOSED', 'createdAt': '2016-07-06T19:33:06Z', 'lastEditedAt': None, 'publishedAt': '2016-07-06T19:33:06Z', 'updatedAt': '2017-01-10T22:03:16Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'flux(1) disables system manual pages if MANPATH is unset', 'bodyHTML': '<p>The man(1) command searches a default list of directories for pages, or if MANPATH env var is set, <em>only</em> the directories in MANPATH.</p>\\n<p>The flux(1) command driver prepends flux manual page directories to MANPATH environment variable so that \"Flux help\" and man(1) can find the correct manual pages for the \"current\" instance.  This works OK as long as MANPATH already includes the system search path.  However, if MANPATH is not set, flux(1) effectively disables the system manual pages.</p>\\n<p>flux(1) should check if MANPATH is set, and if not, determine the system search path by calling out to manpath(1) if available, and append that to the Flux paths.  Any stderr from manpath(1) should be sent to /dev/null.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/745', 'state': 'CLOSED', 'createdAt': '2016-08-09T16:25:04Z', 'lastEditedAt': None, 'publishedAt': '2016-08-09T16:25:04Z', 'updatedAt': '2016-10-26T16:08:14Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'load infiniband topology into KVS at instance bootstrap', 'bodyHTML': '<p>As discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"170542496\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/flux-framework/flux-core/issues/750\" data-hovercard-type=\"issue\" data-hovercard-url=\"/flux-framework/flux-core/issues/750/hovercard\" href=\"https://github.com/flux-framework/flux-core/issues/750\">#750</a> it may be useful to pull IB network topology into the KVS at instance bootstrap using a strategy similar to the <code>resource-hwloc</code> module.  IB topology/routing can form the basis for future topology-aware scheduling efforts.</p>\\n<p>A <code>resource-ibtopo</code> (or similar) comms module would request the topology from the IB Subnet Manager (SM) or an intermediary and store the result under a key such as <code>resource.ibtopo</code>.  The data representation is TBD; hwloc uses XML, so that would be acceptable.</p>\\n<p>A Flux command patterned after <code>flux-hwloc</code> could be added that can reload or query the toplogy.</p>\\n<p>The IB routing is not entirely static, since links can go up and down and the SM will adapt accordingly, so for extra credit, the module could track these changes and update the KVS;  users (scheduler?) could then <code>kvs_watch</code> for changes.</p>\\n<p>In the future different modules for different networks or access methods could be added.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/753', 'state': 'OPEN', 'createdAt': '2016-08-11T16:44:32Z', 'lastEditedAt': None, 'publishedAt': '2016-08-11T16:44:32Z', 'updatedAt': '2016-08-12T02:24:09Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': \"flux-topo:46: attempt to index field 'conf' (a nil value)\", 'bodyHTML': \"<p>When the live module is not loaded (as is now the default), the <code>flux-topo</code> utility doesn't work, because it obtains the topology from the KVS, the result of a reduction that occurs each time the topology changes.</p>\\n<p>Since the topology is static when that KVS value is unavailable, the topology should probably be calculated on rank 0 and written to the KVS or elsewhere so <code>flux-topo</code> can work.   Alternatively, it could simply handle the error more gracefully.</p>\", 'url': 'https://github.com/flux-framework/flux-core/issues/763', 'state': 'CLOSED', 'createdAt': '2016-08-12T17:20:58Z', 'lastEditedAt': None, 'publishedAt': '2016-08-12T17:20:58Z', 'updatedAt': '2017-01-19T17:51:56Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'Update Organization Metadata', 'bodyHTML': '<p>It would be great to update the organization metadatadata, specifically, I\\'m thinking:</p>\\n<ul>\\n<li>Organization Logo, presumably: <a href=\"http://flux-framework.github.io/img/logo-2x.png\" rel=\"nofollow\">http://flux-framework.github.io/img/logo-2x.png</a></li>\\n<li>Organization Website: <a href=\"http://flux-framework.github.io\" rel=\"nofollow\">http://flux-framework.github.io</a></li>\\n<li>Email list: If any?</li>\\n</ul>\\n<p>Cheers,</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/815', 'state': 'OPEN', 'createdAt': '2016-09-22T17:26:39Z', 'lastEditedAt': None, 'publishedAt': '2016-09-22T17:26:39Z', 'updatedAt': '2016-12-31T00:52:55Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'idea: flux getattr broker-pid?', 'bodyHTML': \"<p>I know this is kind of silly, but it would be convenient to have the broker PID in a broker attribute. There is already a pidfile, but to find it you have to use something like</p>\\n<pre><code>pid=$(cat $(flux getattr scratch-directory)/$(flux getattr rank)/broker.pid)\\n</code></pre>\\n<p>where for debugging it would be nice to be able to do things like</p>\\n<pre><code>cat /proc/$(flux getattr broker-pid)/status\\n</code></pre>\\n<p>Since we already do have the pidfile though, I wasn't sure if the convenience of the attribute would outweigh the duplication, so I didn't go ahead and implement something, but thought I'd ask for feedback first.</p>\", 'url': 'https://github.com/flux-framework/flux-core/issues/839', 'state': 'CLOSED', 'createdAt': '2016-10-07T20:55:41Z', 'lastEditedAt': None, 'publishedAt': '2016-10-07T20:55:41Z', 'updatedAt': '2017-01-18T00:31:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'flux submit man page out of date', 'bodyHTML': '<p>New options have been added to src/bindings/lua/wreck.lua that are missing from the flux-submit man page.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/890', 'state': 'CLOSED', 'createdAt': '2016-11-02T16:32:57Z', 'lastEditedAt': None, 'publishedAt': '2016-11-02T16:32:57Z', 'updatedAt': '2017-01-11T02:33:56Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'flux_reactor_run documentation', 'bodyHTML': '<p>Not 100% sure this is an issue in the core, but it\\'s at least sufficiently odd to document it.</p>\\n<p>ATS backend uses the flux python bindings thusly:</p>\\n<div class=\"highlight highlight-source-python\"><pre>response <span class=\"pl-k\">=</span> flux.rpc_send(<span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>job.submit<span class=\"pl-pds\">\\'</span></span>, jobspec)</pre></div>\\n<p>Internally that turns into something spiritually equivalent to:</p>\\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">&lt;</span>create <span class=\"pl-c1\">RPC</span> <span class=\"pl-k\">with</span> <span class=\"pl-c1\">NULL</span> flags <span class=\"pl-k\">and</span> topic<span class=\"pl-k\">&gt;</span>\\nflux_rpc_get(rpc, payload)</pre></div>\\n<p>I started getting an exception thrown that mapped down to an EAGAIN somehow, note that rpc_get is documented to only let that happen when NONBLOCK is set, which it was not.  The python code has been reworked to retry on an EAGAIN from flux_rpc_get, that version now gets a segfault in messages.c attempting to dereference a null iobuf inside the get retry.</p>\\n<p>Anyone have any thoughts on how this could happen? It shouldn\\'t be resource exhaustion as it\\'s been happening on the submission of the <em>third</em> job to the system.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/899', 'state': 'CLOSED', 'createdAt': '2016-11-10T17:12:49Z', 'lastEditedAt': None, 'publishedAt': '2016-11-10T17:12:49Z', 'updatedAt': '2017-02-01T15:42:29Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'Jobspec parser implementation', 'bodyHTML': '<p>This is a concrete issue for implementation of a canonical jobspec parser and data representation as discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"102654066\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/flux-framework/flux-core/issues/354\" data-hovercard-type=\"issue\" data-hovercard-url=\"/flux-framework/flux-core/issues/354/hovercard\" href=\"https://github.com/flux-framework/flux-core/issues/354\">#354</a>.  The experiments I put together working toward this have been uploaded to <a href=\"https://github.com/trws/jobspec-experiments\">https://github.com/trws/jobspec-experiments</a> in case they may be helpful including a python-based parser that can canonicalize and visualize a slightly kinder (or at least denser) jobspec yaml format, the bones of a start on a C++-based parser and representation on boost::graph, and a go-based parser test that\\'s surprisingly clean at least to injest and verify the structured data on the way in.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/983', 'state': 'OPEN', 'createdAt': '2017-02-21T19:44:08Z', 'lastEditedAt': None, 'publishedAt': '2017-02-21T19:44:08Z', 'updatedAt': '2017-02-21T19:44:08Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'flux + spack + autotools = pain', 'bodyHTML': '<p>This section of configure.ac:</p>\\n<pre><code>AC_CONFIG_LINKS([ \\\\\\n  t/fluxometer.lua:t/fluxometer.lua \\\\\\n])\\n</code></pre>\\n<p>Produces a link of t/fluxometer.lua to t/fluxometer.lua for some reason.  This is causing problems in the spack installer where it manifests as a make error transitioning too many links, since it just loops back on itself.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/1118', 'state': 'OPEN', 'createdAt': '2017-07-21T20:32:41Z', 'lastEditedAt': None, 'publishedAt': '2017-07-21T20:32:41Z', 'updatedAt': '2017-10-19T16:53:20Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'travis-ci: builds have become very slowwwww...', 'bodyHTML': '<p>... in fact, so slow that, when dependencies have to be built (i.e. when pushing to a new branch for the first time), a large percentage of the builds do not finish before the ~50min overall travis-ci timeout.</p>\\n<p>e.g. see a build from one my branches <a href=\"https://travis-ci.org/grondo/flux-core/builds/261085425\" rel=\"nofollow\">here</a></p>\\n<p>I seem to remember these builds taking on the order of ~24min in the past, and normal builds using the cache took ~8min, whereas now they take ~20min on average.</p>\\n<p>I don\\'t know if the issue has arisen after Travis-CI switched to containers based on trusty instead of precise, or if it has something to do with a switch to GCE, or if they tweaked the config of their containers.<br>\\nThere is an <a href=\"https://github.com/travis-ci/travis-ci/issues/8162\" data-hovercard-type=\"issue\" data-hovercard-url=\"/travis-ci/travis-ci/issues/8162/hovercard\">open issue</a> that claims trusty builds are slower, but unfortunately not much activity so far.</p>\\n<p>To mitigate the timeouts, which cause build failures, there are probably multiple things to try:</p>\\n<ul>\\n<li>Since we moved to a new version of the OS, see if some of the dependencies we\\'re building using <code>src/test/travis-dep-builder.sh</code> can instead be provided by apt packages. If we could at least get a version of MPI from a package that would have a big impact (MPI build seems to be one of the larger time sinks in building up the dependency cache)</li>\\n<li>add <code>-j2</code> to all make invocations (this caused strange errors on precise builds, and I\\'m not sure how many vcpu the travis-ci containers actually have anyway)</li>\\n<li>Upload built dependencies to an S3 bucket or other publicly accessible uri so we can build once and use the products from multiple branches</li>\\n<li>I think travis allows docker to run inside their containers. We could upload a docker image pre-installed with all dependencies and docker run <code>make distcheck</code>.</li>\\n</ul>', 'url': 'https://github.com/flux-framework/flux-core/issues/1141', 'state': 'CLOSED', 'createdAt': '2017-08-04T21:19:05Z', 'lastEditedAt': None, 'publishedAt': '2017-08-04T21:19:05Z', 'updatedAt': '2017-08-29T21:08:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'add custom gcc __attribute__  for pack/unpack function profile', 'bodyHTML': '<p>The gcc printf attribute is quite useful for discovering misuse of its format/varargs interface.  A similar attribute for jansson\\'s pack/unpack functions would be mighty useful for flux, as we keep bumping into  bool vs int for <code>b</code> unpacking, missing comma causing const string concatenation of adjacent format and key args, etc..</p>\\n<p>Last time I checked, it looked like <a href=\"http://starynkevitch.net/basile/gcc-melt/\" rel=\"nofollow\">MELT</a> was the way to implement a new attribute.  This seems to no longer be the case.  More research needed to see what the current method is.  One possibility is:</p>\\n<p><a href=\"http://gcc-python-plugin.readthedocs.io/en/latest/attributes.html\" rel=\"nofollow\">http://gcc-python-plugin.readthedocs.io/en/latest/attributes.html</a></p>', 'url': 'https://github.com/flux-framework/flux-core/issues/1526', 'state': 'OPEN', 'createdAt': '2018-05-17T14:27:40Z', 'lastEditedAt': None, 'publishedAt': '2018-05-17T14:27:40Z', 'updatedAt': '2018-07-06T18:12:06Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'flux-core', 'repo_owner_name': 'flux-framework', 'repo_owner_email': '', 'repo_owner_user_name': 'flux-framework', 'repo_owner_profile_url': 'https://github.com/flux-framework', 'title': 'test: need pmix client test coverage', 'bodyHTML': '<p>As noted in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"341189118\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/flux-framework/flux-core/issues/1580\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/flux-framework/flux-core/pull/1580/hovercard\" href=\"https://github.com/flux-framework/flux-core/pull/1580\">#1580</a>, the pmix client code in<code>src/common/libpmi/pmix_client.c</code> has no test coverage.</p>\\n<p>This is the manual test of LSF launching Flux that I ran on LLNL\\'s sierra system:</p>\\n<pre><code># Get a 4-node allocation with a shell\\n$ bsub -Is -nnodes 4 -G guests /usr/bin/bash\\n\\n# Then from the shell run\\n$ jsrun -a 128 -c ALL_CPUS -g ALL_GPUS --bind=none -n 1 \\\\\\n   $HOME/flux-core/src/cmd/flux start flux getattr size\\n</code></pre>\\n<p>The pmix project includes some test code that implements a pmix server using the projects server API.  See:</p>\\n<p><a href=\"https://github.com/pmix/pmix/tree/master/test\">https://github.com/pmix/pmix/tree/master/test</a></p>\\n<p>See also in flux-core, <code>src/common/libpmix/test/simple.c</code> for an example of a standalone test that implements both client and server over a socketpair.  A socketpair is probably not viable for pmix, but a single test executable that implements a server (in one thread?) and exercises the client code in the main thread may be feasible.</p>', 'url': 'https://github.com/flux-framework/flux-core/issues/1583', 'state': 'CLOSED', 'createdAt': '2018-07-16T23:43:30Z', 'lastEditedAt': None, 'publishedAt': '2018-07-16T23:43:30Z', 'updatedAt': '2018-11-01T23:08:40Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'pydm', 'repo_owner_name': 'SLAC Lab', 'repo_owner_email': \"bvan@slacXstanfordXedu | tr 'X' '.'\", 'repo_owner_user_name': 'slaclab', 'repo_owner_profile_url': 'https://github.com/slaclab', 'title': 'Add menu option to list all PVs used on a display.', 'bodyHTML': '<p>Add a menu option that lists all the PVs used on a display, in some way that can be copied to the clipboard (perhaps a new window pops up with a read-only QTextEdit widget).</p>', 'url': 'https://github.com/slaclab/pydm/issues/22', 'state': 'CLOSED', 'createdAt': '2017-03-27T23:22:57Z', 'lastEditedAt': None, 'publishedAt': '2017-03-27T23:22:57Z', 'updatedAt': '2017-12-19T02:54:37Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'pydm', 'repo_owner_name': 'SLAC Lab', 'repo_owner_email': \"bvan@slacXstanfordXedu | tr 'X' '.'\", 'repo_owner_user_name': 'slaclab', 'repo_owner_profile_url': 'https://github.com/slaclab', 'title': 'Increase/Decrease/Restore Font Size', 'bodyHTML': '<p>Increase and Decrease not always resize the widgets fonts.<br>\\nAlso implement Restore on CTRL+0. <img class=\"emoji\" title=\":feelsgood:\" alt=\":feelsgood:\" src=\"https://assets-cdn.github.com/images/icons/emoji/feelsgood.png\" height=\"20\" width=\"20\" align=\"absmiddle\"></p>', 'url': 'https://github.com/slaclab/pydm/issues/157', 'state': 'OPEN', 'createdAt': '2017-10-27T00:02:48Z', 'lastEditedAt': None, 'publishedAt': '2017-10-27T00:02:48Z', 'updatedAt': '2017-12-06T22:28:59Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'pydm', 'repo_owner_name': 'SLAC Lab', 'repo_owner_email': \"bvan@slacXstanfordXedu | tr 'X' '.'\", 'repo_owner_user_name': 'slaclab', 'repo_owner_profile_url': 'https://github.com/slaclab', 'title': 'Widgets being destroyed twice', 'bodyHTML': '<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"278251326\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/slaclab/pydm/issues/175\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/slaclab/pydm/pull/175/hovercard\" href=\"https://github.com/slaclab/pydm/pull/175\">#175</a> for more details.</p>', 'url': 'https://github.com/slaclab/pydm/issues/177', 'state': 'OPEN', 'createdAt': '2017-12-01T00:15:58Z', 'lastEditedAt': None, 'publishedAt': '2017-12-01T00:15:58Z', 'updatedAt': '2018-06-05T18:55:45Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'pydm', 'repo_owner_name': 'SLAC Lab', 'repo_owner_email': \"bvan@slacXstanfordXedu | tr 'X' '.'\", 'repo_owner_user_name': 'slaclab', 'repo_owner_profile_url': 'https://github.com/slaclab', 'title': 'CamViewer needs some love', 'bodyHTML': '<p>CamViewer needs some code cleanup and updates.<br>\\nWe need to avoid rewriting the code from ImageView in order to get a CamViewer app.</p>', 'url': 'https://github.com/slaclab/pydm/issues/299', 'state': 'OPEN', 'createdAt': '2018-04-26T20:54:56Z', 'lastEditedAt': None, 'publishedAt': '2018-04-26T20:54:56Z', 'updatedAt': '2018-05-21T18:39:04Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'chgl', 'repo_owner_name': 'Pacific Northwest National Laboratory', 'repo_owner_email': 'dev-central@pnnl.gov', 'repo_owner_user_name': 'pnnl', 'repo_owner_profile_url': 'https://github.com/pnnl', 'title': 'Implement a Domain-Specific-Language with a REPL for CHGL', 'bodyHTML': '<p>As Chapel currently lacks its own REPL, and since CHGL only needs to keep track of a much smaller subset of operations that a full on Chapel REPL would, I\\'m thinking that I can create a DSL that the user can invoke to easily process their data. Such a REPL could be build via <code>make</code> and its potential usage can be seen below...</p>\\n<pre><code>CHGL&gt; graph = load(\"dataset.txt\")\\nCHGL&gt; vDegDist = vertexDegreeDistribution(graph)\\nCHGL&gt; eDegDist = edgeDegreeDistribution(graph)\\nCHGL&gt; graph2 = makeGraph(numVertices(graph), numEdges(graph))\\nCHGL&gt; generateChungLu(graph2, vDegDist, eDegDist)\\nCHGL&gt; plot(graph2)\\n</code></pre>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=405198\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/marcinz\">@marcinz</a> In case you wanted to see this for yourself.</p>', 'url': 'https://github.com/pnnl/chgl/issues/20', 'state': 'OPEN', 'createdAt': '2018-10-14T13:34:35Z', 'lastEditedAt': None, 'publishedAt': '2018-10-14T13:34:35Z', 'updatedAt': '2018-10-19T06:31:03Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NJOY21', 'repo_owner_name': 'NJOY', 'repo_owner_email': 'njoy@lanl.gov', 'repo_owner_user_name': 'njoy', 'repo_owner_profile_url': 'https://github.com/njoy', 'title': 'Need to have way of reporting version of NJOY', 'bodyHTML': '<p>Some will need to know exactly what version of NJOY21 is being used. This could be accomplished with a <code>--version</code> option on the command line. This should return a traditional version number (e.g., 1.2.7) as well as the output of the \"signature\". This signature needs to be generated when configured and added to the code that is compiled.</p>\\n<p>The version number could be advanced as follows:</p>\\n<ul>\\n<li>Major number always stays at <code>1</code> (we don\\'t have permission for anything else)</li>\\n<li>Minor number updated when new capabilities are included (e.g., resonance reconstruction)</li>\\n<li>Sub number updated at every merge into master</li>\\n</ul>', 'url': 'https://github.com/njoy/NJOY21/issues/76', 'state': 'CLOSED', 'createdAt': '2018-09-04T08:39:18Z', 'lastEditedAt': None, 'publishedAt': '2018-09-04T08:39:18Z', 'updatedAt': '2018-10-25T17:37:13Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Parallelize domain scanning', 'bodyHTML': '<p>Doing this all in serial is a big waste, especially since the requests are hitting different domains. Parallelizing the tasks won\\'t increase load on any scanned site, but will drastically speed up completion time.</p>\\n<p><a href=\"https://docs.python.org/3/library/asyncio-dev.html\" rel=\"nofollow\">https://docs.python.org/3/library/asyncio-dev.html</a></p>', 'url': 'https://github.com/18F/domain-scan/issues/16', 'state': 'CLOSED', 'createdAt': '2015-05-29T16:04:03Z', 'lastEditedAt': None, 'publishedAt': '2015-05-29T16:04:03Z', 'updatedAt': '2015-06-14T02:13:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Suggestion: Split up the Dockerfile', 'bodyHTML': '<p>Just took a look at the Dockerfile for the first time, and was surprised to see how much is in there. I guess it\\'s because the various tools being used all have different dependencies?</p>\\n<p>Having multiple languages in a single Dockerfile is an antipattern (IMHO), and I think the setup for each scanner could be a lot simpler if you isolated each tool to its own Dockerfile. These could then be run independently, or via a <code>domain-scan</code> Dockerfile that calls out to <code>docker run &lt;scanner&gt;</code> and then stitches the results together.</p>\\n<p>I got this idea from the architecture of <a href=\"https://github.com/codeclimate/codeclimate\">the Code Climate CLI</a>, so you could look there for inspiration if you\\'re interested in pursuing this.</p>', 'url': 'https://github.com/18F/domain-scan/issues/66', 'state': 'CLOSED', 'createdAt': '2016-06-02T14:25:39Z', 'lastEditedAt': None, 'publishedAt': '2016-06-02T14:25:39Z', 'updatedAt': '2017-11-20T02:56:20Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'A recursive web crawler to gather domains', 'bodyHTML': '<p><strong>Note</strong>: this is a potentially big task, that should be broken into smaller tasks/stages. But also, there is value to starting with a naive, simple crawler and leveling it up in stages.</p>\\n<p>Either baked into domain-scan, or finding/making a separate tool that does this. We could also potentially use <a href=\"http://commoncrawl.org\" rel=\"nofollow\">Common Crawl</a> data.</p>\\n<p>But the basic need is to gather domains through web crawling, as this is a fertile source for hostnames that do not appear in Censys.io. For .gov, both Censys and the LOC\\'s web crawl (the End of Term Archive) each had ~50% of unique domains not found through any other public method. The LOC crawl data, performed in late 2016, is getting more stale by the month, and also won\\'t be helpful for non-USG sources.</p>', 'url': 'https://github.com/18F/domain-scan/issues/118', 'state': 'OPEN', 'createdAt': '2017-04-03T03:35:29Z', 'lastEditedAt': '2017-11-24T20:00:26Z', 'publishedAt': '2017-04-03T03:35:29Z', 'updatedAt': '2017-11-24T20:01:15Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Build scripts for remote compilation of dependencies for domain-scan.zip', 'bodyHTML': \"<p>The <code>lambda/remote_build.sh</code> script has the commands I use to build the domain-scan Lambda environment, but it's not repeatable, and rebuilds require me to copy/paste manual subsets of the instructions.</p>\\n<p>This is going to become more of a burden over time, as any updates to dependencies will require a rebuild to capture these changes (and <code>pshtt</code> itself is likely to keep rapidly improving in very relevant ways), followed by a re-upload to Lambda.</p>\", 'url': 'https://github.com/18F/domain-scan/issues/162', 'state': 'CLOSED', 'createdAt': '2017-11-19T21:59:33Z', 'lastEditedAt': None, 'publishedAt': '2017-11-19T21:59:33Z', 'updatedAt': '2018-03-20T17:17:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Allow mixing of Lambda and non-Lambda scanners', 'bodyHTML': \"<p>Not all scanners are designed for Lambda use, but it's nice to be able to employ them for the ones that do. If a scanner doesn't support Lambda, it'd be great to just assume local scans for that scanner.</p>\\n<p>Perhaps scanners can opt-in or -out of registering as Lambda-compatible, so that the orchestrator can override the CLI flag for scanners which aren't registered that way.</p>\", 'url': 'https://github.com/18F/domain-scan/issues/163', 'state': 'CLOSED', 'createdAt': '2017-11-20T00:36:42Z', 'lastEditedAt': None, 'publishedAt': '2017-11-20T00:36:42Z', 'updatedAt': '2017-12-02T00:09:27Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Output a meta CSV file, remove --meta flag', 'bodyHTML': \"<p>Instead of adding a --meta flag and cluttering up the resulting scan data, it's likely better to output a meta CSV file for each scan, with the local/Lambda error and timing information for each one. This could be output by default, rather than needing an opt-in with <code>--meta</code>.</p>\\n<p>This would need multiple meta CSV files, one per scanner, or some other way to represent the data. You could also imagine a meta.csv that merges the metadata of all scans, which might be the most convenient to do analysis of overall scan durations and reliability issues.</p>\", 'url': 'https://github.com/18F/domain-scan/issues/164', 'state': 'OPEN', 'createdAt': '2017-11-20T02:45:08Z', 'lastEditedAt': None, 'publishedAt': '2017-11-20T02:45:08Z', 'updatedAt': '2017-11-24T20:01:15Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Allow scanners to specify default Lambda timeout and memory size', 'bodyHTML': '<p>And have it drive the Lambda function create process.</p>\\n<p>Depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"276690926\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/domain-scan/issues/171\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/domain-scan/issues/171/hovercard\" href=\"https://github.com/18F/domain-scan/issues/171\">#171</a>.</p>', 'url': 'https://github.com/18F/domain-scan/issues/169', 'state': 'OPEN', 'createdAt': '2017-11-24T18:32:31Z', 'lastEditedAt': '2017-11-24T20:00:48Z', 'publishedAt': '2017-11-24T18:32:31Z', 'updatedAt': '2018-03-20T17:20:58Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Config file for persistent options', 'bodyHTML': \"<p>I think we're at the stage where want to define configuration in a <code>$HOME/.domain-scan</code> file or something like that, both for general options and for scanner-specific and Lambda-specific and gatherer-specific options. There are too many options!</p>\", 'url': 'https://github.com/18F/domain-scan/issues/170', 'state': 'OPEN', 'createdAt': '2017-11-24T19:35:49Z', 'lastEditedAt': None, 'publishedAt': '2017-11-24T19:35:49Z', 'updatedAt': '2018-03-20T17:20:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Move Lambda deploy scripts to Python', 'bodyHTML': '<p>The <code>lambda/deploy</code> script is reasonable, but we\\'d benefit a lot from having it in Python rather than a standalone bash script, so that it could get more sophisticated, import scanner code, and allow the scanners to set things like timeouts, memory size, etc.</p>\\n<p>Also a note:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Include facility to specify one or more tags for created Lambda functions.</li>\\n</ul>', 'url': 'https://github.com/18F/domain-scan/issues/171', 'state': 'OPEN', 'createdAt': '2017-11-24T19:55:55Z', 'lastEditedAt': None, 'publishedAt': '2017-11-24T19:55:55Z', 'updatedAt': '2018-03-20T17:20:36Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Target Resolution for Linux computers', 'bodyHTML': '<p>This problem has been effecting me for a while, but it\\'s now interfering with one of the last steps on getting the JavaFX branch building. When I try to resolve mars.target on my Linux machines, I get the error message</p>\\n<p>Problems occurred while resolving the target contents<br>\\nAn error occurred while configuring the installed items<br>\\nPreference node \"http:_download.eclipse.org_tools_cdt_releases_8.7\" has been removed.<br>\\nsession context was:(profile=TARGET_DEFINITION:resource:/org.eclipse.ice.target.mars/mars.target, phase=org.eclipse.equinox.internal.p2.engine.phases.Configure, operand=null --&gt; [R]org.eclipse.cdt.feature.group 8.7.0.201506070905, action=org.eclipse.equinox.internal.p2.touchpoint.eclipse.actions.AddRepositoryAction)</p>\\n<p>This happens regardless of where in ICE I try to open the target from or what version of ICE I\\'m using, including the most recent unstable nightly. Once it occurs on a machine, it effects every instance of ICE on it.</p>', 'url': 'https://github.com/eclipse/ice/issues/85', 'state': 'CLOSED', 'createdAt': '2016-01-20T13:56:47Z', 'lastEditedAt': None, 'publishedAt': '2016-01-20T13:56:47Z', 'updatedAt': '2016-01-23T02:11:47Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Client Thread creation refactor', 'bodyHTML': '<p>Currently, the Client\\'s processItem function is creating and running a thread while having no way to synchronize with it. This is causing build failures in ClientTester (part of Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"141008743\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/eclipse/ice/issues/176\" data-hovercard-type=\"issue\" data-hovercard-url=\"/eclipse/ice/issues/176/hovercard\" href=\"https://github.com/eclipse/ice/issues/176\">#176</a> ). Alex and I discussed the problem, and propose that Client be refactored to take a thread creation factory. In real cases, this new factory class will function identically to Client\\'s current code, but it will allow us to inject a fake thread factory which does not actually launch any new threads for use with test classes.</p>\\n<p>Since this plan would modify a core part of ICE\\'s API, we thought it would be best to open an issue for discussion on how to deal with this test failure.</p>', 'url': 'https://github.com/eclipse/ice/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-24T19:00:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-24T19:00:24Z', 'updatedAt': '2016-05-09T02:44:04Z', 'labels': ['build issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'XMLPersistenceProvider queue synchronization', 'bodyHTML': '<p>The XMLPersistenceProvider currently lacks a way to test if it has any unfinished tasks either queued or undergoing processing. This means that there is no way for the test class XMLPersistenceProviderTester to check whether assigned tasks are completed before, for example, trying to read a written file, in turn causing test failures (part of Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"141008743\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/eclipse/ice/issues/176\" data-hovercard-type=\"issue\" data-hovercard-url=\"/eclipse/ice/issues/176/hovercard\" href=\"https://github.com/eclipse/ice/issues/176\">#176</a> ). Creating a Boolean variable and naively setting it to false at the beginning of the provider\\'s run loop if the Queue is empty failed, and so Alex and I decided to open this issue for discussion on how to have the provider correctly alert other classes to its current status.</p>', 'url': 'https://github.com/eclipse/ice/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-24T19:10:27Z', 'lastEditedAt': None, 'publishedAt': '2016-03-24T19:10:27Z', 'updatedAt': '2016-03-24T19:10:27Z', 'labels': ['build issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'ICE download page serving wrong version', 'bodyHTML': \"<p>Today I downloaded ICE binaries from download.eclipse.org/ice/builds/next for both Mac and Windows, and I've noticed several regressions from ICE both as launched from a run configuration and from previous binaries downloaded from the same page on 4/18. This can be seen from the Developer Menu missing EAVP under Framework and a compilation error from org.bouncycastle.openssl not being in the default target platform, among others. I think these might be copies of binaries from ICE master or an earlier version of next.</p>\", 'url': 'https://github.com/eclipse/ice/issues/194', 'state': 'CLOSED', 'createdAt': '2016-04-22T16:48:49Z', 'lastEditedAt': None, 'publishedAt': '2016-04-22T16:48:49Z', 'updatedAt': '2016-05-11T21:48:33Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'ICE build cannot download required plugins', 'bodyHTML': '<p>The ICE build is currently unable to download all of its required maven plugins. Current builds are working only because of pre-downloaded plugins from previous working builds in our .m2 folders. In order to reproduce the bug, delete your computer\\'s .m2 repository (be sure to back it up first), then clone a new version of ICE.</p>\\n<p>I have a partial fix that addresses the problem of the tycho-maven-plugin no longer being available from the Eclipse CBI repository. However, it required me changing to the Tycho 0.26.0-SNAPSHOT build because I couldn\\'t find a stable repo for 0.24.0 and the 0.24.0-SNAPSHOT is giving me an error when I try to use it. You can see it on the Robert/Build-Fix branch. If you get build errors related to the maven-plugin-api, try to clean the project and restart ICE. I\\'m still getting errors for other plug-ins, which I\\'m working on.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6378849\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jayjaybillings\">@jayjaybillings</a> I\\'m assigning this to you just to ask about the feasibility of changing our Tycho version, or if I just need to find a working repo for the 0.24.0 version, as I still intend to keep working on this myself unless I hear otherwise.</p>', 'url': 'https://github.com/eclipse/ice/issues/205', 'state': 'CLOSED', 'createdAt': '2016-05-17T21:36:41Z', 'lastEditedAt': None, 'publishedAt': '2016-05-17T21:36:41Z', 'updatedAt': '2016-05-19T18:47:46Z', 'labels': ['build issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Update ICE to Neon', 'bodyHTML': '', 'url': 'https://github.com/eclipse/ice/issues/222', 'state': 'CLOSED', 'createdAt': '2016-07-07T12:17:20Z', 'lastEditedAt': None, 'publishedAt': '2016-07-07T12:17:20Z', 'updatedAt': '2016-07-12T22:11:31Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Find LAMMPS example', 'bodyHTML': '<p>Identify a LAMPS example for the ADIOS in situ visualization work.</p>', 'url': 'https://github.com/eclipse/ice/issues/267', 'state': 'OPEN', 'createdAt': '2016-09-20T16:20:36Z', 'lastEditedAt': None, 'publishedAt': '2016-09-20T16:20:36Z', 'updatedAt': '2016-10-14T11:58:14Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Test Parallel Job Launch for Oomph installation', 'bodyHTML': '<p>The Oomph installed version of ICE needs to be checked to see if the parallel job launching functionality is working.</p>\\n<p>This can be done by running the Eclipse Installer, changing to Advanced Mode, selecting Eclipse for RCP and RAP Development, and hitting next. On this screen, download the ICE Oomph profile from <a href=\"https://raw.githubusercontent.com/eclipse/ice/master/org.eclipse.ice.aggregator/ICE.setup\" rel=\"nofollow\">https://raw.githubusercontent.com/eclipse/ice/master/org.eclipse.ice.aggregator/ICE.setup</a> and drag and drop it into the list of Eclipse Projects, then select the new ICE option and follow the rest of the prompts.</p>', 'url': 'https://github.com/eclipse/ice/issues/275', 'state': 'OPEN', 'createdAt': '2016-10-19T18:00:41Z', 'lastEditedAt': None, 'publishedAt': '2016-10-19T18:00:41Z', 'updatedAt': '2016-10-19T18:00:41Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'ICE Next blank Workspace Error notifying preference change listener', 'bodyHTML': '<p>Currently for our unstable build, starting a new instance of ICE with a new workspace displays error at startup (see picture). It says \\'Error notifying preference change listener. NullPointerException\\' Here\\'s the log:</p>\\n<pre lang=\"code\"><code>java.lang.NullPointerException\\n        at org.eclipse.mylyn.internal.tasks.ui.TasksUiPlugin$2.propertyChange(TasksUiPlugin.java:296)\\n        at org.eclipse.ui.preferences.ScopedPreferenceStore$3.run(ScopedPreferenceStore.java:350)\\n        at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)\\n        at org.eclipse.ui.preferences.ScopedPreferenceStore.firePropertyChangeEvent(ScopedPreferenceStore.java:346)\\n        at org.eclipse.ui.preferences.ScopedPreferenceStore.setValue(ScopedPreferenceStore.java:658)\\n        at org.eclipse.mylyn.internal.tasks.ui.TasksUiPlugin$TasksUiInitializationJob.hideNonMatchingSubtasks(TasksUiPlugin.java:418)\\n        at org.eclipse.mylyn.internal.tasks.ui.TasksUiPlugin$TasksUiInitializationJob.runInUIThread(TasksUiPlugin.java:406)\\n        at org.eclipse.ui.progress.UIJob$1.run(UIJob.java:97)\\n        at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:37)\\n        at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:182)\\n        at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4033)\\n        at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3700)\\n        at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1133)\\n        at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)\\n        at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1022)\\n        at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)\\n        at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:698)\\n        at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)\\n        at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:610)\\n        at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)\\n        at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:138)\\n        at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\\n        at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)\\n        at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)\\n        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)\\n        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)\\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n        at java.lang.reflect.Method.invoke(Method.java:498)\\n        at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:673)\\n        at org.eclipse.equinox.launcher.Main.basicRun(Main.java:610)\\n        at org.eclipse.equinox.launcher.Main.run(Main.java:1519)\\n</code></pre>\\n<p>This is high priority - issue VIBE currently has is fixed in next. With this fixed we can ship off ICE to them for their VM.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/827531/21024349/2705016c-bd52-11e6-899a-75ee47a48f2a.png\"><img src=\"https://cloud.githubusercontent.com/assets/827531/21024349/2705016c-bd52-11e6-899a-75ee47a48f2a.png\" alt=\"screen shot 2016-12-08 at 2 03 33 pm\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/eclipse/ice/issues/310', 'state': 'OPEN', 'createdAt': '2016-12-08T19:25:05Z', 'lastEditedAt': '2016-12-08T19:25:23Z', 'publishedAt': '2016-12-08T19:25:05Z', 'updatedAt': '2016-12-08T23:02:28Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'On Fedora 25 importing local repository to ICE generated 65 errors', 'bodyHTML': '<p>One of the errors is about incomplete build path (or simply not referencing it properly). This issue could probably be about misconfigured project.</p>', 'url': 'https://github.com/eclipse/ice/issues/319', 'state': 'CLOSED', 'createdAt': '2017-01-25T20:07:29Z', 'lastEditedAt': None, 'publishedAt': '2017-01-25T20:07:29Z', 'updatedAt': '2017-01-26T18:54:52Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Add tutorial for general new users', 'bodyHTML': '<p>All of our current tutorial materials (e.g. for XSEDE), are written from the assumption that the reader will have our tutorial specific version of ICE with all required data files and programs and a pre-populated workspace on one of our USB sticks.</p>\\n<p>We need a more universal tutorial that explains to someone on their own computer and using nothing but generally available resources online how to download ICE, import the repo, download third party programs like VisIt, etc. so that we have somewhere to point people who want to get started with the latest version of ICE instead of whatever we had prepared the last time we did a formal tutorial.</p>', 'url': 'https://github.com/eclipse/ice/issues/320', 'state': 'OPEN', 'createdAt': '2017-01-25T20:38:09Z', 'lastEditedAt': None, 'publishedAt': '2017-01-25T20:38:09Z', 'updatedAt': '2017-01-25T20:38:09Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'ice', 'repo_owner_name': 'Eclipse Foundation', 'repo_owner_email': 'emo@eclipse.org', 'repo_owner_user_name': 'eclipse', 'repo_owner_profile_url': 'https://github.com/eclipse', 'title': 'Proposed updates to Build/Deployment scheme for ICE', 'bodyHTML': '<p>ICE Devs,</p>\\n<p>Will you please tell me what you think about this proposed new build layout for ICE (see picture)? Right now our current build process is murderously monolithic. I feel like breaking it up will let us do two things better:</p>\\n<ol>\\n<li>Work on various parts of the code without fussing with the other parts (no more importing all of ICE to work on a few bundles)</li>\\n<li>Carve up the source tree so that we can create new minimal, headless, and Vaadin-based products without creating an even longer and more complicated build.</li>\\n</ol>\\n<p>Any thoughts?</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6378849/26416717/d94ffb14-4084-11e7-8cf3-5392eb3c575b.jpg\"><img src=\"https://cloud.githubusercontent.com/assets/6378849/26416717/d94ffb14-4084-11e7-8cf3-5392eb3c575b.jpg\" alt=\"ice_proposed_build_20170524\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/eclipse/ice/issues/372', 'state': 'OPEN', 'createdAt': '2017-05-24T17:30:58Z', 'lastEditedAt': None, 'publishedAt': '2017-05-24T17:30:58Z', 'updatedAt': '2017-05-25T18:21:35Z', 'labels': ['enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dyninst', 'repo_owner_name': 'Dyninst Project', 'repo_owner_email': 'dyninst-api@cs.wisc.edu', 'repo_owner_user_name': 'dyninst', 'repo_owner_profile_url': 'https://github.com/dyninst', 'title': 'Cross platform mutatee support', 'bodyHTML': \"<p>Dyninst doesn't have support for mutating binaries that will not run on the current host. For example, a 32 bit x86 host can't rewrite an x86_64 binary. However, we do have support for rewriting x86 binaries on an x86_64 host.</p>\\n<p>To my knowledge, we also don't support cross platform mutatees between Intel and ARM platforms, which could be a nice feature.</p>\", 'url': 'https://github.com/dyninst/dyninst/issues/103', 'state': 'OPEN', 'createdAt': '2016-06-22T18:08:51Z', 'lastEditedAt': None, 'publishedAt': '2016-06-22T18:08:51Z', 'updatedAt': '2017-02-09T18:57:32Z', 'labels': ['enhancement', 'help wanted', 'wontfix'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dyninst', 'repo_owner_name': 'Dyninst Project', 'repo_owner_email': 'dyninst-api@cs.wisc.edu', 'repo_owner_user_name': 'dyninst', 'repo_owner_profile_url': 'https://github.com/dyninst', 'title': 'Merge and fix Windows rewriter', 'bodyHTML': '<p>From Bill:</p>\\n<p>The fork at <a href=\"https://github.com/ea/dyninst\">https://github.com/ea/dyninst</a> contains significant steps towards completion of the Windows binary rewriter. It is missing some key elements, however; its handling of relocation fixup is IIRC incomplete, and it produces binaries that do not execute cleanly.</p>\\n<p>This issue should be closed and replaced with specific bugs once that fork is merged back to a dyninst/dyninst topic branch and we have evaluated where things stand after another year+ of work on Windows parsing and relocation handling on the analysis side of things.</p>', 'url': 'https://github.com/dyninst/dyninst/issues/120', 'state': 'OPEN', 'createdAt': '2016-07-13T17:13:12Z', 'lastEditedAt': '2016-07-13T18:55:07Z', 'publishedAt': '2016-07-13T17:13:12Z', 'updatedAt': '2018-11-05T17:43:42Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'dyninst', 'repo_owner_name': 'Dyninst Project', 'repo_owner_email': 'dyninst-api@cs.wisc.edu', 'repo_owner_user_name': 'dyninst', 'repo_owner_profile_url': 'https://github.com/dyninst', 'title': 'Semantics for LineNoTuple changed in 9.3', 'bodyHTML': \"<p>An unintended change with the best of intentions that nonetheless produced incompatible code: prior to 9.3, LineNoTuple/Statement contained public members first and second referring to a file and line number. In 9.3, they still contain public members first and second inherited from the new AddressRange, where those members now refer to the low and high boundaries of the statement's range.</p>\\n<p>My current plan:</p>\\n<ul>\\n<li>LineNoTuple has been deprecated for many years (at least unofficially). It should be removed as a Statement alias.</li>\\n<li>The manual should reflect this change.</li>\\n<li>Statements should hide AddressRange details and require an explicit range accessor in order to use the range's pair nature. This will ensure that users do not accidentally use the first/second members thinking that they retain their old semantics.</li>\\n</ul>\\n<p>Thoughts?</p>\", 'url': 'https://github.com/dyninst/dyninst/issues/312', 'state': 'OPEN', 'createdAt': '2017-01-18T18:43:18Z', 'lastEditedAt': None, 'publishedAt': '2017-01-18T18:43:18Z', 'updatedAt': '2017-02-09T19:01:09Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dyninst', 'repo_owner_name': 'Dyninst Project', 'repo_owner_email': 'dyninst-api@cs.wisc.edu', 'repo_owner_user_name': 'dyninst', 'repo_owner_profile_url': 'https://github.com/dyninst', 'title': 'Make Dyninst .sos self-contained', 'bodyHTML': \"<p>Dyninst's shared library targets have a fair number of dependencies, both internal and external. At a minimum, users should not need to worry about .so conflicts between our external dependencies and their project's use of those dependencies. Therefore, we should ensure we link against static/PIC versions of the following:</p>\\n<ul>\\n<li>libelf</li>\\n<li>libdwarf/libdw</li>\\n<li>boost libs (thread, system, etc)</li>\\n<li>libiberty</li>\\n<li>threaddb</li>\\n</ul>\\n<p>Pthreads is, I think, okay to link shared, as are the standard C/C++ libs.</p>\", 'url': 'https://github.com/dyninst/dyninst/issues/354', 'state': 'OPEN', 'createdAt': '2017-03-20T16:15:05Z', 'lastEditedAt': None, 'publishedAt': '2017-03-20T16:15:05Z', 'updatedAt': '2018-04-10T19:07:46Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'dyninst', 'repo_owner_name': 'Dyninst Project', 'repo_owner_email': 'dyninst-api@cs.wisc.edu', 'repo_owner_user_name': 'dyninst', 'repo_owner_profile_url': 'https://github.com/dyninst', 'title': 'failure processing linux-vdso64.so.1 image', 'bodyHTML': '<p>Seen on ppc64 on Fedora 26</p>\\n<p>The attached test fails.  One possibility is an attempt is made to get an image for linux-vdso64.so.1:<br>\\n[sysv.C:279-U] - Found library /root/396/call-ifunc.x at 0<br>\\n[sysv.C:279-U] - Found library /lib64/ld64.so.1 at 7fffb04f0000<br>\\n[sysv.C:281-U] - Creating new library object for /lib64/ld64.so.1<br>\\n[sysv.C:279-U] - Found library linux-vdso64.so.1 at 7fffb04d0000<br>\\n[sysv.C:281-U] - Creating new library object for linux-vdso64.so.1<br>\\n[sysv.C:307-U] - Didn\\'t find old library /usr/lib64/ld-2.25.so at 7fffb04f0000, unloading</p>\\n<p>and subsequently stat is called and of course doesn\\'t find it:<br>\\n(gdb) fra<br>\\n#0  MappedFile::check_path (this=0x1028e910, filename=\"linux-vdso64.so.1\")<br>\\nat /usr/src/debug/dyninst-9.3.2/dyninst-9.3.2/common/src/MappedFile.C:226<br>\\n226       if (0 != stat(filename.c_str(), &amp;statbuf)) {</p>\\n<p>Looking at the same test on x8664, linux-vdso64.so.1, also in the dynamic library list, is not handled<br>\\n<a href=\"https://github.com/dyninst/dyninst/files/1352818/396.zip\">396.zip</a></p>', 'url': 'https://github.com/dyninst/dyninst/issues/406', 'state': 'OPEN', 'createdAt': '2017-10-03T15:29:46Z', 'lastEditedAt': None, 'publishedAt': '2017-10-03T15:29:46Z', 'updatedAt': '2018-04-10T19:09:06Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Can read-only images on NFS be supported?', 'bodyHTML': '<p>Investigate.</p>\\n<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"231441676\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/hpc/charliecloud/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/hpc/charliecloud/issues/7/hovercard\" href=\"https://github.com/hpc/charliecloud/issues/7\">#7</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"231441957\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/hpc/charliecloud/issues/8\" data-hovercard-type=\"issue\" data-hovercard-url=\"/hpc/charliecloud/issues/8/hovercard\" href=\"https://github.com/hpc/charliecloud/issues/8\">#8</a>.</p>', 'url': 'https://github.com/hpc/charliecloud/issues/9', 'state': 'OPEN', 'createdAt': '2017-05-25T19:57:02Z', 'lastEditedAt': None, 'publishedAt': '2017-05-25T19:57:02Z', 'updatedAt': '2018-10-04T23:17:50Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Specify minimum Docker version', 'bodyHTML': '<p>User bug report:</p>\\n<blockquote>\\n<p>I am trying to set up Charliecloud on my old CentOS6 box, so, I am building with the SETUID. That builds (provided I set CFLAGS to -std=c99 as gcc 4.4.* does not have c11).</p>\\n<p>After a few stumbles, I seem to have hit a roadblock with Docker only being available in version 1.7.1 via the EPEL repository, which is lacking the --build-arg flag.</p>\\n<p>The newer versions through the yum using the docker.com repo seem to be pulling the CentOS7 packages, and there does not seem to be a CentOS6 directory at <a href=\"https://download.docker.com/linux/centos/\" rel=\"nofollow\">https://download.docker.com/linux/centos/</a> for manual download.</p>\\n</blockquote>\\n<blockquote>\\n<p>It may be worth it to update the Charliecloud docs in that respect so people don\\'t try to install Docker/ChC on CentOS6.</p>\\n</blockquote>\\n<p>A key part of this is that we\\'ve never specified what the minimum Docker version is. Clearly it is greater than 1.7.1, but what is it?</p>\\n<p>1.7.1 <a href=\"https://github.com/moby/moby/issues/14365\" data-hovercard-type=\"issue\" data-hovercard-url=\"/moby/moby/issues/14365/hovercard\">appears to be</a> the last version of Docker that supports CentOS 6.</p>', 'url': 'https://github.com/hpc/charliecloud/issues/29', 'state': 'CLOSED', 'createdAt': '2017-10-02T15:44:54Z', 'lastEditedAt': None, 'publishedAt': '2017-10-02T15:44:54Z', 'updatedAt': '2017-11-17T21:40:43Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Pull from Docker Hub without Docker installed?', 'bodyHTML': '<p>I heard a rumor that one can pull an image from Docker Hub directly with REST calls, without needing Docker installed. Investigate.</p>', 'url': 'https://github.com/hpc/charliecloud/issues/41', 'state': 'OPEN', 'createdAt': '2017-10-25T15:22:38Z', 'lastEditedAt': None, 'publishedAt': '2017-10-25T15:22:38Z', 'updatedAt': '2018-08-31T19:27:18Z', 'labels': ['enhancement', 'help wanted', 'key issue'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Entering a container via a symlink to it fails', 'bodyHTML': '<p>Here\\'s the working command:</p>\\n<pre><code>$ ch-run /home/olifre/containers/ubu_ch/ubuntu_16.04 -- /bin/bash\\n</code></pre>\\n<p>Now, I do:</p>\\n<pre><code>$ mkdir -p /home/olifre/containers/demo/\\n$ cd /home/olifre/containers/demo/\\n$ ln -s /home/olifre/containers/ubu_ch/ubuntu_16.04/ .\\n$ ch-run /home/olifre/containers/demo/ubuntu_16.04  -- /bin/bash\\nch-run: can\\'t re-mount image read-only (is it on NFS?): No such file or directory\\n</code></pre>\\n<p>Since symlinks might be pretty common (they are often seen with existing CVMFS containers, e.g. symlinks like \"latest\" pointing to the actual daily build) it would be nice if this worked (maybe <code>readlink</code> is sufficient to resolve it?).</p>', 'url': 'https://github.com/hpc/charliecloud/issues/50', 'state': 'CLOSED', 'createdAt': '2017-10-27T16:31:33Z', 'lastEditedAt': None, 'publishedAt': '2017-10-27T16:31:33Z', 'updatedAt': '2017-10-30T16:09:08Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Friendlier error message if user has too many supplementary groups', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=166759\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/olifre\">@olifre</a> suggests in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"268959887\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/hpc/charliecloud/issues/47\" data-hovercard-type=\"issue\" data-hovercard-url=\"/hpc/charliecloud/issues/47/hovercard\" href=\"https://github.com/hpc/charliecloud/issues/47\">#47</a>:</p>\\n<blockquote>\\n<p>Maybe in addition, it would be nice to add an extra call to getgroups(0, supp_gids) to check whether the limit would be exceeded and produce an easier to grasp error message ;-).</p>\\n</blockquote>\\n<p>I think we might not need a second call and could just check for <code>EINVAL</code>?</p>', 'url': 'https://github.com/hpc/charliecloud/issues/52', 'state': 'CLOSED', 'createdAt': '2017-10-27T16:41:58Z', 'lastEditedAt': None, 'publishedAt': '2017-10-27T16:41:58Z', 'updatedAt': '2017-10-30T19:11:56Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Spark tests have race conditions', 'bodyHTML': \"<p>The Spark tests contain a number of race conditions where we start up processes in the background, wait a bit, and check once for expected output in the logs. If the output isn't present, we fail the test even if the expected output appeared later.</p>\\n<p>This often cause spurious Travis failures that can be resolved by simply re-running the job (and re-running the race).</p>\\n<p>Proposed solution: Put the output checks in a loop with a timeout.</p>\", 'url': 'https://github.com/hpc/charliecloud/issues/54', 'state': 'OPEN', 'createdAt': '2017-10-27T20:15:48Z', 'lastEditedAt': None, 'publishedAt': '2017-10-27T20:15:48Z', 'updatedAt': '2017-10-27T20:15:48Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Tutorial example lacks \"hello\" directory ?', 'bodyHTML': '<p>Minor nitpick:</p>\\n<p><a href=\"https://hpc.github.io/charliecloud/tutorial.html#share-image-and-other-standard-docker-stuff\" rel=\"nofollow\">https://hpc.github.io/charliecloud/tutorial.html#share-image-and-other-standard-docker-stuff</a></p>\\n<p>When I run the hello example run using Docker as shown:<br>\\nsudo docker run -it hello /bin/bash</p>\\n<p>And then \"ls /\" I see a \"hello\" directory:</p>\\n<p>root@28368f1cb44e:/# ls<br>\\nbin   dev  hello  lib\\t media\\topt   root  sbin  sys  usr<br>\\nboot  etc  home   lib64  mnt\\tproc  run   srv   tmp  var</p>\\n<p>The example in the Tutorial doesn\\'t have this directory.</p>\\n<p>Q</p>', 'url': 'https://github.com/hpc/charliecloud/issues/70', 'state': 'CLOSED', 'createdAt': '2017-11-01T19:06:41Z', 'lastEditedAt': None, 'publishedAt': '2017-11-01T19:06:41Z', 'updatedAt': '2018-04-06T22:51:15Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'ch-run (--version|--help) cannot be called as privileged user', 'bodyHTML': \"<p>This seems to be a design feature, but a bit non-intuitive in the case charliecloud is installed on the host and a privileged user wants to check e.g. the installed version.</p>\\n<p>In real life, I hit this when trying to implement charliecloud support in HTCondor.<br>\\nHTCondor's daemons usually run privileged, and it needs some way to check whether charliecloud is set up correctly, and advertise the version (so job submitters can e.g. request to only run on nodes with version 0.xy).<br>\\nThis fails, since calling <code>ch-run --version</code> fails when run as root.</p>\\n<p>So in short:<br>\\nIt would be best if arguments which will not lead to actual container execution (<code>--help</code>, <code>--version</code>) would also work for privileged users.</p>\", 'url': 'https://github.com/hpc/charliecloud/issues/71', 'state': 'CLOSED', 'createdAt': '2017-11-05T21:44:07Z', 'lastEditedAt': None, 'publishedAt': '2017-11-05T21:44:07Z', 'updatedAt': '2017-11-07T23:10:16Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'add man pages', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=166759\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/olifre\">@olifre</a> in PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"269350291\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/hpc/charliecloud/issues/59\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/hpc/charliecloud/pull/59/hovercard\" href=\"https://github.com/hpc/charliecloud/pull/59\">#59</a>:</p>\\n<blockquote>\\n<p>Which approach would you take:</p>\\n<ol>\\n<li>Automatic generation with help2man ( <a href=\"https://www.gnu.org/software/help2man/\" rel=\"nofollow\">https://www.gnu.org/software/help2man/</a> ), which essentially works by calling the binaries with --help and --version adding some nice formatting,</li>\\n<li>hand-written full-fledged manpages (which may as well be based on help2manoutput to have a starting point, but need more love, e.g. example calls, maybe some FAQ etc., and manual adaptation for any newly added option)?</li>\\n</ol>\\n</blockquote>\\n<p>I think my preference would be for option 2, since I feel the <code>--help</code> output should be pretty concise (less than a screen) and hand-written man pages would let us say a bit more about the various nuances and trade-offs.</p>\\n<p>It would be nice if there were tests to verify that the same options were described in <code>--help</code> and the man page, and also frankly the code itself. But I don\\'t think it\\'s worth holding things up over that.</p>\\n<p>Do man pages need to be build before installing?</p>', 'url': 'https://github.com/hpc/charliecloud/issues/82', 'state': 'CLOSED', 'createdAt': '2017-11-13T21:29:29Z', 'lastEditedAt': None, 'publishedAt': '2017-11-13T21:29:29Z', 'updatedAt': '2018-02-14T20:40:24Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'Prebuilt binaries', 'bodyHTML': \"<p>Hi, I am interested in trying out charliecloud (specifically only <code>ch-run</code> as an unprivileged chroot alternative) and was wondering if signed, prebuilt binaries are available? I looked at the GitHub Releases and didn't see any, and couldn't find references in the docs.</p>\\n<p>Thanks</p>\", 'url': 'https://github.com/hpc/charliecloud/issues/100', 'state': 'OPEN', 'createdAt': '2018-01-25T23:13:08Z', 'lastEditedAt': None, 'publishedAt': '2018-01-25T23:13:08Z', 'updatedAt': '2018-01-26T19:08:38Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': \"some tests fail if allocated nodes don't have the same number of threads\", 'bodyHTML': \"<p>For example, if SLURM gives you two 1:4:2 nodes (sockets:cores:threads):</p>\\n<pre><code>$ echo $SLURM_JOB_CPUS_PER_NODE\\n8(x2)\\n</code></pre>\\n<p>but if you get a 1:4:2 node (8 cores) and a 2:10:2 (40 cores), you get:</p>\\n<pre><code>$ echo $SLURM_JOB_CPUS_PER_NODE\\n40,8\\n</code></pre>\\n<p>which <code>common.bash</code> doesn't know how to parse, at roughly line 83.</p>\", 'url': 'https://github.com/hpc/charliecloud/issues/107', 'state': 'OPEN', 'createdAt': '2018-02-06T20:58:00Z', 'lastEditedAt': None, 'publishedAt': '2018-02-06T20:58:00Z', 'updatedAt': '2018-02-06T20:58:00Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'make clean should delete leftover packaging stuff', 'bodyHTML': '<p>I have a bunch of files under <code>packaging/debian</code> that seem to be build products. I haven\\'t checked the corresponding Red Hat stuff.</p>\\n<p>It would be nice if <code>make clean</code> deleted this stuff, since I keep bumping into it while searching for unrelated things.</p>\\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=166759\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/olifre\">@olifre</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4672577\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/wiene\">@wiene</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12544\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lnussbaum\">@lnussbaum</a> \\xa0is this a trivial change for any of you?</p>', 'url': 'https://github.com/hpc/charliecloud/issues/113', 'state': 'OPEN', 'createdAt': '2018-02-14T23:10:12Z', 'lastEditedAt': None, 'publishedAt': '2018-02-14T23:10:12Z', 'updatedAt': '2018-03-09T00:24:37Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'charliecloud', 'repo_owner_name': 'high performance computing', 'repo_owner_email': 'github-hpc@lanl.gov', 'repo_owner_user_name': 'hpc', 'repo_owner_profile_url': 'https://github.com/hpc', 'title': 'optimize test overhead', 'bodyHTML': '<p>Currently, even skipped tests take about 0.15 seconds. This adds up; in the \"quick\" scope there are around 125 tests, so of the ~30 seconds total duration, we spend about 19 seconds in overhead.</p>\\n<p>Perhaps a third to half of this might be in <code>common.bash</code>. The way Bats works currently, each test is a new shell and a new sourcing of <code>common.bash</code>. We\\'ve never tried to optimize this file, so maybe there\\'s low hanging fruit.</p>\\n<pre><code>$ time BATS_TMPDIR=/tmp BATS_TEST_DIRNAME=. bash -c \\'. common.bash\\'\\n\\nreal\\t0m0.057s\\nuser\\t0m0.008s\\nsys\\t0m0.012s\\n</code></pre>\\n<p>Without <code>common.bash</code>:</p>\\n<pre><code>$ bats/bin/bats foo.bats | ts -i \\'%M:%.S\\'\\n00:00.023807 1..3\\n00:00.032358 ok 1 foo\\n00:00.035874 ok 2 # skip bar\\n00:00.034289 ok 3 baz\\n</code></pre>\\n<p>With <code>common.bash</code>:</p>\\n<pre><code>$ bats/bin/bats foo.bats | ts -i \\'%M:%.S\\'\\n00:00.075184 1..3\\n00:00.100607 ok 1 foo\\n00:00.110405 ok 2 # skip bar\\n00:00.101603 ok 3 baz\\n</code></pre>\\n<p><code>foo.bats</code>:</p>\\n<pre><code>#load common\\n\\n@test \\'foo\\' {\\n    true\\n}\\n\\n@test \\'bar\\' {\\n    skip\\n}\\n\\n@test \\'baz\\' {\\n    true\\n}\\n\\n</code></pre>', 'url': 'https://github.com/hpc/charliecloud/issues/186', 'state': 'OPEN', 'createdAt': '2018-06-20T23:03:26Z', 'lastEditedAt': None, 'publishedAt': '2018-06-20T23:03:26Z', 'updatedAt': '2018-06-20T23:03:26Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'kcron', 'repo_owner_name': 'Scientific Linux', 'repo_owner_email': '', 'repo_owner_user_name': 'scientificlinux', 'repo_owner_profile_url': 'https://github.com/scientificlinux', 'title': 'Convert RPM Spec file to use CPackRPM', 'bodyHTML': '<p>CMake provides CPackRPM for generating RPMs.  This is preferable to our hard coded Spec file.</p>', 'url': 'https://github.com/scientificlinux/kcron/issues/3', 'state': 'OPEN', 'createdAt': '2018-05-31T14:25:00Z', 'lastEditedAt': None, 'publishedAt': '2018-05-31T14:25:00Z', 'updatedAt': '2018-06-13T19:49:13Z', 'labels': ['good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'kcron', 'repo_owner_name': 'Scientific Linux', 'repo_owner_email': '', 'repo_owner_user_name': 'scientificlinux', 'repo_owner_profile_url': 'https://github.com/scientificlinux', 'title': 'Setup CPackDEB', 'bodyHTML': '<p>CMake provides support for building debian style packages.  It would be nice if we could easily generate those from this source tree.</p>', 'url': 'https://github.com/scientificlinux/kcron/issues/4', 'state': 'OPEN', 'createdAt': '2018-05-31T14:26:50Z', 'lastEditedAt': None, 'publishedAt': '2018-05-31T14:26:50Z', 'updatedAt': '2018-05-31T14:45:19Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'kcron', 'repo_owner_name': 'Scientific Linux', 'repo_owner_email': '', 'repo_owner_user_name': 'scientificlinux', 'repo_owner_profile_url': 'https://github.com/scientificlinux', 'title': 'Utilize libseccomp', 'bodyHTML': \"<p>The existing seccomp stub within the codebase doesn't actually work.</p>\\n<ul>\\n<li>The <code>return</code> command from <code>main()</code> calls <code>exit_group()</code> on linux which is blacklisted by <code>SECCOMP_MODE_STRICT</code></li>\\n<li>The use of <code>capabilities</code> is blacklisted by <code>SECCOMP_MODE_STRICT</code></li>\\n<li>I believe <code>unix socket</code> connections (required for systems running <code>nscd</code>) is also blacklisted by <code>SECCOMP_MODE_STRICT</code></li>\\n<li>LDAP/NIS/etc users probably require IP sockets too (also blacklisted by <code>SECCOMP_MODE_STRICT</code>?)</li>\\n</ul>\\n<p>libseccomp should make this all clean, easy, and whatnot.</p>\", 'url': 'https://github.com/scientificlinux/kcron/issues/5', 'state': 'OPEN', 'createdAt': '2018-05-31T14:31:12Z', 'lastEditedAt': '2018-06-01T18:51:26Z', 'publishedAt': '2018-05-31T14:31:12Z', 'updatedAt': '2018-06-04T15:08:41Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'kcron', 'repo_owner_name': 'Scientific Linux', 'repo_owner_email': '', 'repo_owner_user_name': 'scientificlinux', 'repo_owner_profile_url': 'https://github.com/scientificlinux', 'title': 'Unit tests for all code', 'bodyHTML': '<p>There really should be unit tests for all the <code>C</code> and <code>shell</code> code to validate compatibility.</p>\\n<p>I hear <a href=\"https://cmocka.org/\" rel=\"nofollow\">https://cmocka.org/</a> is a good testing framework, but have no real experience with any existing <code>C</code> frameworks.</p>\\n<p>It looks like <a href=\"https://github.com/sstephenson/bats\">https://github.com/sstephenson/bats</a> is the way to go for testing out <code>shell</code> scripts.</p>\\n<p>Long term plan is to integrate with <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"328160223\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/scientificlinux/kcron/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/scientificlinux/kcron/issues/2/hovercard\" href=\"https://github.com/scientificlinux/kcron/issues/2\">#2</a></p>\\n<p>Open to other ideas!</p>', 'url': 'https://github.com/scientificlinux/kcron/issues/9', 'state': 'OPEN', 'createdAt': '2018-05-31T14:42:34Z', 'lastEditedAt': '2018-05-31T15:27:17Z', 'publishedAt': '2018-05-31T14:42:34Z', 'updatedAt': '2018-05-31T16:48:35Z', 'labels': ['enhancement', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'kcron', 'repo_owner_name': 'Scientific Linux', 'repo_owner_email': '', 'repo_owner_user_name': 'scientificlinux', 'repo_owner_profile_url': 'https://github.com/scientificlinux', 'title': 'Setup TravisCI', 'bodyHTML': '<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"328160223\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/scientificlinux/kcron/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/scientificlinux/kcron/issues/2/hovercard\" href=\"https://github.com/scientificlinux/kcron/issues/2\">#2</a>, <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"328165062\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/scientificlinux/kcron/issues/7\" data-hovercard-type=\"issue\" data-hovercard-url=\"/scientificlinux/kcron/issues/7/hovercard\" href=\"https://github.com/scientificlinux/kcron/issues/7\">#7</a>, and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"328167946\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/scientificlinux/kcron/issues/9\" data-hovercard-type=\"issue\" data-hovercard-url=\"/scientificlinux/kcron/issues/9/hovercard\" href=\"https://github.com/scientificlinux/kcron/issues/9\">#9</a> .</p>\\n<p>Travis is free for Open Source projects.  It would be nice if we could automate multi platform testing.</p>\\n<p>It should also run:</p>\\n<ul>\\n<li>cppcheck</li>\\n<li>flawfinder</li>\\n<li>scan-build</li>\\n</ul>\\n<p>Platforms to check:</p>\\n<ul>\\n<li>fedora</li>\\n<li>sl</li>\\n<li>suse</li>\\n<li>debian</li>\\n<li>ubuntu</li>\\n<li>arch</li>\\n</ul>', 'url': 'https://github.com/scientificlinux/kcron/issues/10', 'state': 'OPEN', 'createdAt': '2018-05-31T14:44:40Z', 'lastEditedAt': '2018-05-31T14:47:57Z', 'publishedAt': '2018-05-31T14:44:40Z', 'updatedAt': '2018-05-31T14:47:57Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'peridigm', 'repo_owner_name': 'Peridigm', 'repo_owner_email': '', 'repo_owner_user_name': 'peridigm', 'repo_owner_profile_url': 'https://github.com/peridigm', 'title': 'Outputting the history file takes forever in my simulation', 'bodyHTML': '<p>Hi there.</p>\\n<p>I have been running some simulations using peridigm on a granular particles field.</p>\\n<pre><code>Number of coordinates per node       =           3\\nNumber of nodes                      =      198860\\nNumber of elements                   =      198860\\nNumber of element blocks             =        6512\\nNumber of nodal point sets           =        6512\\nNumber of element side sets          =           0\\nNumber of time steps = 9300\\n</code></pre>\\n<p>I am tracking down the particles velocities and displacements by the closest PD node to the center of the particle. I use the global variables to write them down to the output history file.</p>\\n<p>The problem here is that most time of the run time is devoted to the outputting part. Below is the run time for a case where I output the history file every 10 time steps (930 total).</p>\\n<pre><code>Wallclock Time (seconds):\\n                                        Min            Max            Ave\\n  Total                               3e+04          3e+04          3e+04\\n  Rebalance                         1.7e+03        1.7e+03        1.7e+03\\n  Output                              4e+03        1.7e+04        4.3e+03\\n  Internal Force                    3.2e+02        3.3e+02        3.3e+02\\n  Initialize Contact Maps             0.001         0.0011         0.0011\\n  Gather/Scatter                    9.9e+03        2.3e+04        2.3e+04\\n  Apply Kinematic B.C.                  2.4             83             27\\n  Apply Initial Conditions             0.26           0.27           0.27\\n  Apply Body Forces                     0.1           0.11           0.11\\n</code></pre>\\n<p>And the following is for a case where I output the history file every other time step (4650 total).</p>\\n<pre><code>Wallclock Time (seconds):\\n                                        Min            Max            Ave\\n  Total                             8.5e+04        8.5e+04        8.5e+04\\n  Rebalance                         1.8e+03        1.8e+03        1.8e+03\\n  Output                            6.4e+03        7.1e+04        7.8e+03\\n  Internal Force                    3.2e+02        3.3e+02        3.3e+02\\n  Initialize Contact Maps             0.001         0.0011         0.0011\\n  Gather/Scatter                    9.9e+03        7.5e+04        7.3e+04\\n  Apply Kinematic B.C.                  2.4             85             27\\n  Apply Initial Conditions             0.26           0.27           0.27\\n  Apply Body Forces                     0.1           0.12           0.11\\n</code></pre>\\n<p>As you can see the total run time is increased from 8 hours to 23 hours!! (As I noticed, the major time which is related to making that .h file is not included here.)</p>\\n<p>I am not sure if Peridigm is optimized in terms of global variables.</p>\\n<p>Is there any way that I can generate the history file similar to the way that the exodus file (.e) is generated? As I have realized, the exodus file is generated by each processors and at the end, they can combined using epu. However, there is only one history file generated by the processor #0.</p>\\n<p>Thanks so much for your time. I look forward to hearing back.</p>\\n<p>Best<br>\\nMasoud Behzadinasab<br>\\nPhD Student in Engineering Mechanics<br>\\nUT Austin</p>', 'url': 'https://github.com/peridigm/peridigm/issues/4', 'state': 'CLOSED', 'createdAt': '2016-02-18T20:00:57Z', 'lastEditedAt': None, 'publishedAt': '2016-02-18T20:00:57Z', 'updatedAt': '2016-02-24T20:44:44Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'LIVVkit', 'repo_owner_name': 'Land Ice Verification and Validation toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'LIVVkit', 'repo_owner_profile_url': 'https://github.com/LIVVkit', 'title': 'Chrome not displaying javascript elements locally', 'bodyHTML': '<p><em>From <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7882693\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jhkennedy\">@jhkennedy</a> on March 31, 2017 16:1</em></p>\\n<p>Chrome, on both my linux and mac, will not display the Javascript elements of the output webpages when viewed on the local file system. However, Firefox and Safari will display everything correctly (have not tested IE).</p>\\n<p>To reproduce, <a href=\"https://github.com/ACME-Climate/LIVV/files/886238/cism206v200.tar.gz\">download this output website (cism206v200.tar.gz)</a>, untar, and see if you can view the elements on <code>cism206v200/index.html</code> with Chrome and Firefox.</p>\\n<p>Interestingly, once the output site is made accessible on the internet, Chrome does display everything correctly. See <a href=\"http://jhkennedy.org/sites/default/files/vv_2017-03-31/index.html\" rel=\"nofollow\">here</a>.</p>\\n<p><em>Copied from original issue: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"218545925\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/E3SM-Project/LIVV/issues/83\" data-hovercard-type=\"issue\" data-hovercard-url=\"/E3SM-Project/LIVV/issues/83/hovercard\" href=\"https://github.com/E3SM-Project/LIVV/issues/83\">E3SM-Project/LIVV#83</a></em></p>', 'url': 'https://github.com/LIVVkit/LIVVkit/issues/9', 'state': 'CLOSED', 'createdAt': '2017-08-23T20:20:54Z', 'lastEditedAt': None, 'publishedAt': '2017-08-23T20:20:54Z', 'updatedAt': '2017-10-25T17:46:54Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SpinWaveGenie', 'repo_owner_name': 'SpinWaveGenie', 'repo_owner_email': None, 'repo_owner_user_name': 'SpinWaveGenie', 'repo_owner_profile_url': 'https://github.com/SpinWaveGenie', 'title': 'Support MS Visual Studio', 'bodyHTML': \"<p>While all of the dependencies are available with Windows, SpinWaveGenie hasn't been built on Windows. The release of Microsoft Visual Studio Community Edition and continuous integration service AppVeyor, it's becoming easier to support open source Windows development. At the same time, differences between the two platforms (for example, filesystem) may require refactoring and the lack of a package management system may limit user interest.</p>\\n<p>The basic steps to follow are:</p>\\n<ol>\\n<li>Build and install MS Visual Studio and third party libraries.</li>\\n<li>Refactor build system to also build on Windows with Visual Studio.</li>\\n<li>Fix compilation errors and warnings</li>\\n<li>Fix failing tests</li>\\n<li>Setup AppVeyor continuous integration system.</li>\\n</ol>\\n<p>Each step should be submitted as one or more pull requests. Documentation should be added to the wiki as along the way, not just at the end.</p>\", 'url': 'https://github.com/SpinWaveGenie/SpinWaveGenie/issues/46', 'state': 'CLOSED', 'createdAt': '2015-05-12T01:52:35Z', 'lastEditedAt': None, 'publishedAt': '2015-05-12T01:52:35Z', 'updatedAt': '2015-06-05T23:20:24Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SpinWaveGenie', 'repo_owner_name': 'SpinWaveGenie', 'repo_owner_email': None, 'repo_owner_user_name': 'SpinWaveGenie', 'repo_owner_profile_url': 'https://github.com/SpinWaveGenie', 'title': 'Research alternatives to thirdpartylibs on windows', 'bodyHTML': '<p>Can we do something better for third party libraries on Windows?</p>\\n<p>useful links:<br>\\n<a href=\"http://www.reddit.com/r/cpp/comments/3d1vjq/is_there_a_c_package_manager_if_not_how_do_you/\" rel=\"nofollow\">http://www.reddit.com/r/cpp/comments/3d1vjq/is_there_a_c_package_manager_if_not_how_do_you/</a><br>\\n<a href=\"https://github.com/ruslo/hunter\">https://github.com/ruslo/hunter</a></p>', 'url': 'https://github.com/SpinWaveGenie/SpinWaveGenie/issues/58', 'state': 'OPEN', 'createdAt': '2015-07-16T01:49:19Z', 'lastEditedAt': None, 'publishedAt': '2015-07-16T01:49:19Z', 'updatedAt': '2016-09-19T20:15:22Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'SpinWaveGenie', 'repo_owner_name': 'SpinWaveGenie', 'repo_owner_email': None, 'repo_owner_user_name': 'SpinWaveGenie', 'repo_owner_profile_url': 'https://github.com/SpinWaveGenie', 'title': 'Conda package', 'bodyHTML': '<p>Currently SpinWaveGenie is installable via the system package manager (yum/dnf on RHEL/Fedora and homebrew on OS X). Both of these can also install the new SpinWaveGenie Python bindings and fulfill my immediate needs for running SpinWaveGenie on both my workstation and on the Analysis cluster.</p>\\n<p>That said, the cross-platform Conda package manager has a significant and growing following in the scientific python community. Specifically in neutron scattering, <a href=\"https://github.com/mcvine/mcvine/pull/119\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/mcvine/mcvine/pull/119/hovercard\">McVine is available as a Conda package</a>, <a href=\"https://github.com/rosswhitfield/javelin\">Javelin</a> is tested in miniconda, and there is a <a href=\"https://github.com/mantidproject/documents/blob/718517d98d42800bd4f2de7bb21901b5f95e182a/Design/Anaconda.md\">design document</a> for distributing Mantid as a conda package.</p>\\n<p>If you are interested in contributing a conda recipe, please contact me and make a pull request.</p>', 'url': 'https://github.com/SpinWaveGenie/SpinWaveGenie/issues/100', 'state': 'OPEN', 'createdAt': '2016-06-08T23:11:26Z', 'lastEditedAt': '2016-06-10T01:59:08Z', 'publishedAt': '2016-06-08T23:11:26Z', 'updatedAt': '2016-06-10T01:59:08Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dice', 'repo_owner_name': 'Digital Image Correlation Engine (DICe)', 'repo_owner_email': '', 'repo_owner_user_name': 'dicengine', 'repo_owner_profile_url': 'https://github.com/dicengine', 'title': 'Example files missing from windows package installer', 'bodyHTML': '<p>The tutorial examples do not get shipped with the package installer for windows.</p>', 'url': 'https://github.com/dicengine/dice/issues/21', 'state': 'CLOSED', 'createdAt': '2016-01-18T17:14:23Z', 'lastEditedAt': None, 'publishedAt': '2016-01-18T17:14:23Z', 'updatedAt': '2016-02-19T19:29:13Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dice', 'repo_owner_name': 'Digital Image Correlation Engine (DICe)', 'repo_owner_email': '', 'repo_owner_user_name': 'dicengine', 'repo_owner_profile_url': 'https://github.com/dicengine', 'title': 'set up a python script to automate output visualization in ParaView', 'bodyHTML': '<p>It would be nice if when the DICe analysis finished, it automatically opened ParaView and displayed the results superimposed over the images without having to do this manually</p>', 'url': 'https://github.com/dicengine/dice/issues/55', 'state': 'OPEN', 'createdAt': '2017-11-27T21:23:10Z', 'lastEditedAt': None, 'publishedAt': '2017-11-27T21:23:10Z', 'updatedAt': '2017-12-20T18:32:24Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'openPMD-viewer', 'repo_owner_name': 'openPMD', 'repo_owner_email': 'a.huebl@hzdr.de', 'repo_owner_user_name': 'openPMD', 'repo_owner_profile_url': 'https://github.com/openPMD', 'title': 'OpenPMDTimeSeries: Unit Systems', 'bodyHTML': '<p>To improve the generality of the viewer without harming its usefulness for a specific domain, we could make the following adjustment regarding unit systems:</p>\\n<p>Per default, the <code>OpenPMDTimeSeries</code> should not convert, rename or exclude records.<br>\\nBut we could set a unit system that is used for reading data and formatting plots in a way such as:</p>\\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> opmd_viewer <span class=\"pl-k\">import</span> OpenPMDTimeSeries\\n<span class=\"pl-k\">import</span> opmd_viewer.unit_systems\\n\\nts <span class=\"pl-k\">=</span> OpenPMDTimeSeries(<span class=\"pl-s\"><span class=\"pl-pds\">\\'</span>...<span class=\"pl-pds\">\\'</span></span>)\\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> change to lambda0 &amp; c based system</span>\\nts.set_unitsystem(unit_systems.LPA(<span class=\"pl-c1\">800.e-9</span>))\\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> change back to SI</span>\\nts.set_unitsystem(unit_systems.SI())\\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> change a plasma system</span>\\nts.set_unitsystem(unit_systems.Plasma(<span class=\"pl-c1\">1.e15</span>))\\n\\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> read or plot data now</span></pre></div>\\n<p>The important thing is that we apply the transformations as we read the raw data together with <code>unitSI</code> multiplications, etc.</p>\\n<h3>What can be Converted</h3>\\n<ul>\\n<li>change record scaling (maybe by reading additional records such as mass of particles)</li>\\n<li>change record naming (e.g., \"momentum/x\" -&gt; \"ux\")</li>\\n<li>change base-unit labels (\"m\" -&gt; \"lamda_0\" or \"m\" -&gt; \"micron\")</li>\\n</ul>\\n<h3>Example Unit Systems (Pre-Defined)</h3>\\n<ul>\\n<li><code>SI()</code>: just forward what we read scaled by <code>unitSI</code></li>\\n<li><code>Microns()</code>: use microns instead of meters for lengths</li>\\n<li><code>LPA(lambda0)</code>: scale length to <code>lambda0</code>, times to <code>lambda0/c</code>, speed to <code>c</code>, ...</li>\\n<li><code>Plasma(omega_pe)</code>: scale time by <code>(2 pi) / omega_pe</code>, speed by <code>c</code>, length by <code>(c * 2 pi) / omega_pe</code>, ...</li>\\n<li><code>Raw()</code>: ignore all scalings including <code>unitSI</code> (for debugging codes)</li>\\n<li><code>CGS()</code>: I am just kidding, cgs units are deprecated and will be removed in future versions of <em>science</em> <g-emoji class=\"g-emoji\" alias=\"smiling_imp\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f608.png\"></g-emoji></li>\\n<li>...</li>\\n</ul>\\n<p>If we document the interface of those classes properly, power users could actually even use their own unit system converters even if we did not implement them (yet).</p>\\n<h3>Re-Naming of Records</h3>\\n<p>During the change of the unit system we can also rename the records since e.g., a momentum in beta gamma (<code>ux</code>) is more readable and known in a specific domain.</p>', 'url': 'https://github.com/openPMD/openPMD-viewer/issues/64', 'state': 'OPEN', 'createdAt': '2016-04-20T21:36:08Z', 'lastEditedAt': '2017-12-11T23:02:08Z', 'publishedAt': '2016-04-20T21:36:08Z', 'updatedAt': '2018-05-24T15:58:23Z', 'labels': ['feature', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'openPMD-viewer', 'repo_owner_name': 'openPMD', 'repo_owner_email': 'a.huebl@hzdr.de', 'repo_owner_user_name': 'openPMD', 'repo_owner_profile_url': 'https://github.com/openPMD', 'title': 'Particle Binning: use actual gridspacing when available', 'bodyHTML': '<p>For all kind of particle binning methods (in space, in momentum, ...) it would be very useful to add shape (assignment) functions so one can remove the aliasing noise in the bins.</p>', 'url': 'https://github.com/openPMD/openPMD-viewer/issues/77', 'state': 'CLOSED', 'createdAt': '2016-04-21T23:23:26Z', 'lastEditedAt': None, 'publishedAt': '2016-04-21T23:23:26Z', 'updatedAt': '2017-07-18T05:21:02Z', 'labels': ['feature', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'openPMD-viewer', 'repo_owner_name': 'openPMD', 'repo_owner_email': 'a.huebl@hzdr.de', 'repo_owner_user_name': 'openPMD', 'repo_owner_profile_url': 'https://github.com/openPMD', 'title': 'Avoiding unnecesary data reading and histogram calculations', 'bodyHTML': \"<p>In the typical work, using the slider interface, operations related to the colorbar do not require reading and processing the data, but only need refreshing the <code>imshow</code> plot. In a particular case of the 2D histograms generated from the particle data, the processing with <code>np.histogram2d</code> can be time consuming, so it would be nice to avoid it.</p>\\n<p>One possible solution would be to add some flag, e.g. 'refresh_data', to the function of the 'Refresh' command,  which would be used to decide if data reading and processing should be done, or the previously data can be re-used.</p>\", 'url': 'https://github.com/openPMD/openPMD-viewer/issues/201', 'state': 'OPEN', 'createdAt': '2018-05-14T13:35:18Z', 'lastEditedAt': None, 'publishedAt': '2018-05-14T13:35:18Z', 'updatedAt': '2018-05-14T13:50:00Z', 'labels': ['good first issue', 'help wanted', 'interactive'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'openPMD-viewer', 'repo_owner_name': 'openPMD', 'repo_owner_email': 'a.huebl@hzdr.de', 'repo_owner_user_name': 'openPMD', 'repo_owner_profile_url': 'https://github.com/openPMD', 'title': 'Add support and continuous integration on Windows', 'bodyHTML': '<p>We could use AppVeyor for CI on Windows...</p>', 'url': 'https://github.com/openPMD/openPMD-viewer/issues/206', 'state': 'OPEN', 'createdAt': '2018-05-18T15:31:46Z', 'lastEditedAt': None, 'publishedAt': '2018-05-18T15:31:46Z', 'updatedAt': '2018-05-19T14:45:09Z', 'labels': ['good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'common', 'repo_owner_name': 'Oak Ridge National Laboratory Quantum Computing Institute', 'repo_owner_email': '', 'repo_owner_user_name': 'ORNL-QCI', 'repo_owner_profile_url': 'https://github.com/ORNL-QCI', 'title': 'Design/Implement Graph Data Structure', 'bodyHTML': '<p>We need a graph data structure - perhaps templated on the vertex type (maybe edge type too) that lets us express various, common, quantum programming graphs (tensor networks, ising parameters, etc...)</p>', 'url': 'https://github.com/ORNL-QCI/common/issues/2', 'state': 'OPEN', 'createdAt': '2017-01-19T20:34:40Z', 'lastEditedAt': None, 'publishedAt': '2017-01-19T20:34:40Z', 'updatedAt': '2017-01-19T20:34:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'mfem', 'repo_owner_name': 'MFEM', 'repo_owner_email': '', 'repo_owner_user_name': 'mfem', 'repo_owner_profile_url': 'https://github.com/mfem', 'title': 'Obtain config.mk in CMAKE builds', 'bodyHTML': \"<p>Would it be possible to install a config.mk file out of a CMAKE build?<br>\\nThe reason is that at present if you build MFEM with CMAKE, you are also forced to build other codes that depend on MFEM (in this case, a library) with CMAKE. I'm not aware of any tool that permits to include and use  XXX.cmake configuration files with a standard makefile.</p>\", 'url': 'https://github.com/mfem/mfem/issues/312', 'state': 'CLOSED', 'createdAt': '2017-10-16T09:20:19Z', 'lastEditedAt': None, 'publishedAt': '2017-10-16T09:20:19Z', 'updatedAt': '2018-11-05T17:36:52Z', 'labels': ['building', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'mfem', 'repo_owner_name': 'MFEM', 'repo_owner_email': '', 'repo_owner_user_name': 'mfem', 'repo_owner_profile_url': 'https://github.com/mfem', 'title': 'Better random number generation in HypreLOBPCG and in general', 'bodyHTML': '<p>The convergence of <code>HypreLOBPCG</code> seems to be severely affected by the initial random vectors which are initialized from a single seed value.</p>\\n<p>It would be great if we can improve on this, maybe by using a more sophisticated random number generator.</p>', 'url': 'https://github.com/mfem/mfem/issues/610', 'state': 'OPEN', 'createdAt': '2018-09-17T22:29:43Z', 'lastEditedAt': None, 'publishedAt': '2018-09-17T22:29:43Z', 'updatedAt': '2018-10-23T15:37:45Z', 'labels': ['enhancement', 'help wanted', 'linalg'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Adding the C-library test cases', 'bodyHTML': \"<p>We should have a set of test cases in the C-interface-tests that match the application api tests.  Probably don't need them all but having a set of them running against the C-interface vs the C++ interface would test that, especially if we are going to be using that pretty regularly for python, java, and other bindings, and other applications.</p>\", 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/9', 'state': 'CLOSED', 'createdAt': '2017-10-27T00:15:00Z', 'lastEditedAt': None, 'publishedAt': '2017-10-27T00:15:00Z', 'updatedAt': '2018-01-26T15:50:59Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Finish adding doxygen comments to C-shared API', 'bodyHTML': '<p>Many of the functions in the C-shared api are currently lacking doxygen comments and descriptions.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/51', 'state': 'CLOSED', 'createdAt': '2017-12-18T00:21:28Z', 'lastEditedAt': None, 'publishedAt': '2017-12-18T00:21:28Z', 'updatedAt': '2018-02-16T18:02:23Z', 'labels': ['Documentation', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Improve HELICS support for Matlab on Windows', 'bodyHTML': '<p>We need to be able to produce a binary file that can be used with the windows version of Matlab, in addition to support for a Linux Version. and getting this working on Macs would be advisable as well.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/95', 'state': 'CLOSED', 'createdAt': '2018-01-20T01:04:33Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:04:33Z', 'updatedAt': '2018-03-13T18:02:43Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Need a way to regularly test multimachine configurations', 'bodyHTML': '<p>Not sure what this looks like but somewhere we need to have regular automated test runs with multiple machines using the different communication protocols in different configurations.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/98', 'state': 'OPEN', 'createdAt': '2018-01-20T01:09:21Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:09:21Z', 'updatedAt': '2018-09-27T11:51:17Z', 'labels': ['On Hold', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Example using combination federate in C++ and another in C', 'bodyHTML': '<p>We need an example system using the combination federate for both the C++ application Api and another similar example using the C API.  It might make sense to replicate this example in all supported languages,  Matlab, python, and Java.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/99', 'state': 'CLOSED', 'createdAt': '2018-01-20T01:13:31Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:13:31Z', 'updatedAt': '2018-04-12T15:58:52Z', 'labels': ['Examples', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test cases running with erroneous inputs and invalid sequences', 'bodyHTML': '<p>We need a series of test cases that stress the error handling paths in HELICS<br>\\nincluding invalid input, odd timings and timeouts.</p>\\n<p>Anyone want to help break HELICS and fix it?</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/100', 'state': 'CLOSED', 'createdAt': '2018-01-20T01:24:13Z', 'lastEditedAt': None, 'publishedAt': '2018-01-20T01:24:13Z', 'updatedAt': '2018-04-11T04:54:36Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test suite for python', 'bodyHTML': '<p>We will need a test suite in python that executes all functions in the shared library.    The C library tests make sure that the function calls actually do what they are supposed to.  The python test suite needs to ensure those functions got translated correctly.  So it can be a subset of the shared library tests, but if we want to fully support it we need the tests running.   And it should be run regularly (daily?)</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/188', 'state': 'CLOSED', 'createdAt': '2018-02-28T14:28:45Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T14:28:45Z', 'updatedAt': '2018-04-15T05:02:19Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test Suite for Matlab', 'bodyHTML': \"<p>We will need a test suite in Matlab that executes all functions in the shared library interface to Matlab.    The C library tests make sure that the function calls actually do what they are supposed to.  The python test suite needs to ensure those functions got translated correctly.  So it can be a subset of the shared library tests, but if we want to fully support it we need the tests running.   And it should be run regularly (daily?) In the case of Matlab, it probably isn't going to be run on Travis but potentially at one of our local CI test systems.</p>\", 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/189', 'state': 'CLOSED', 'createdAt': '2018-02-28T14:30:40Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T14:30:40Z', 'updatedAt': '2018-07-06T22:39:28Z', 'labels': ['Interfaces', 'help wanted', 'testing'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Test Suite for Java', 'bodyHTML': '<p>We will need a test suite in Java that executes all functions in the shared library.    The C library tests make sure that the function calls actually do what they are supposed to.  The python test suite needs to ensure those functions got translated correctly.  So it can be a subset of the shared library tests, but if we want to fully support it we need the tests running.   And it should be run regularly (daily?)</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/190', 'state': 'CLOSED', 'createdAt': '2018-02-28T14:31:30Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T14:31:30Z', 'updatedAt': '2018-04-15T05:02:05Z', 'labels': ['help wanted', 'testing'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'potential race condition when using filter functions', 'bodyHTML': '<p>There is a potential race conditions when specifying defined filter functions.  I suspect this may be one root cause of the sporadic failures in the Travis test cases.</p>\\n<p>I have made some progress on this in the thread_safety_update branch but this will not be in place for the 1.0 release.</p>\\n<pre><code>/home/travis/build/GMLC-TDC/HELICS-src/tests/helics/shared_library/FilterTests_cpp.cpp(204): Entering test case \"_9\"\\n6: unknown location(0): fatal error: in \"filter_tests_cpp/message_filter_function2/_9\": memory access violation at address: 0x00000090: no mapping at fault address\\n6: /home/travis/build/GMLC-TDC/HELICS-src/tests/helics/shared_library/FilterTests_cpp.cpp(264): last checkpoint\\n6: Failure occurred in a following context:\\n6:     core_type = tcp_2; \\n6: Test is aborted\\n</code></pre>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/246', 'state': 'CLOSED', 'createdAt': '2018-04-11T05:57:02Z', 'lastEditedAt': None, 'publishedAt': '2018-04-11T05:57:02Z', 'updatedAt': '2018-04-22T21:40:49Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Core dump in python tests', 'bodyHTML': '<p>One of the python tests is failing occasionally with a core dump.  We need to figure out the reason.<br>\\n<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1813121\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kdheepak\">@kdheepak</a>  does this ever happen on your system? and if so anychance you can provide some more insight into the exact locations of the error?</p>\\n<pre><code>../tests/python_helics/test_message_filter.py::test_message_filter_registration PASSED [ 33%]\\n../tests/python_helics/test_message_filter.py::test_message_filter_function /home/travis/.travis/job_stages: line 57: 12445 Aborted                 (core dumped) python3 -m pytest -v ../tests/python_helics\\n</code></pre>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/277', 'state': 'CLOSED', 'createdAt': '2018-04-23T18:54:56Z', 'lastEditedAt': None, 'publishedAt': '2018-04-23T18:54:56Z', 'updatedAt': '2018-05-13T12:54:18Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'HELICS-src', 'repo_owner_name': 'GMLC-TDC', 'repo_owner_email': 'helicsteam@helics.org', 'repo_owner_user_name': 'GMLC-TDC', 'repo_owner_profile_url': 'https://github.com/GMLC-TDC', 'title': 'Mac binary distribution', 'bodyHTML': '<p>This should use the CPack stuff in cmake that is already setup<br>\\nprobably using the <a href=\"https://cmake.org/cmake/help/latest/module/CPackDMG.html\" rel=\"nofollow\">DragNDrop</a> generator.</p>\\n<p>guessing a few generator specific fields will need to be added</p>\\n<p>though there might be some new generators as well if we were ok requiring a new cmake for the mac builds which isn\\'t out of the question.</p>\\n<p>This might be simple enough that it could be done and included with the 1.3 release.</p>', 'url': 'https://github.com/GMLC-TDC/HELICS-src/issues/379', 'state': 'CLOSED', 'createdAt': '2018-06-30T00:00:18Z', 'lastEditedAt': None, 'publishedAt': '2018-06-30T00:00:18Z', 'updatedAt': '2018-07-25T15:49:25Z', 'labels': ['Installation/build', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'pyEntropy', 'repo_owner_name': 'Nikolay Donets', 'repo_owner_email': 'nd.startup@gmail.com', 'repo_owner_user_name': 'nikdon', 'repo_owner_profile_url': 'https://github.com/nikdon', 'title': 'Entropy for RR intervals', 'bodyHTML': '<p>Hey, I\\'m trying to apply your function to ECG signal and, more specifically, RR intervals.</p>\\n<p>I have an RRis array (<code>rri = array([ 702,  743, 1052, ...,  812,  798,  710])</code>) of length 382, sampled at 1000Hz based on a 5min recording.</p>\\n<p>I\\'ve tried the following:</p>\\n<div class=\"highlight highlight-source-python\"><pre>sample_entropy(rri, <span class=\"pl-c1\">len</span>(rri))</pre></div>\\n<p>But it returns:</p>\\n<div class=\"highlight highlight-source-python\"><pre>__main__:<span class=\"pl-c1\">45</span>: <span class=\"pl-c1\">RuntimeWarning</span>: invalid value encountered <span class=\"pl-k\">in</span> true_divide\\n__main__:<span class=\"pl-c1\">46</span>: <span class=\"pl-c1\">RuntimeWarning</span>: divide by zero encountered <span class=\"pl-k\">in</span> log\\nOut[<span class=\"pl-c1\">11</span>]: \\narray([ <span class=\"pl-c1\">2.9060357</span> ,  <span class=\"pl-c1\">2.63176262</span>,  <span class=\"pl-c1\">2.7080502</span> , <span class=\"pl-c1\">...</span>,         nan,\\n               nan,         nan])</pre></div>\\n<p>Am I doing something wrong? Also, what\\'s a good default for the <code>tolerance</code> parameter of the multiscale entropy? Thanks</p>', 'url': 'https://github.com/nikdon/pyEntropy/issues/1', 'state': 'CLOSED', 'createdAt': '2017-04-24T11:27:11Z', 'lastEditedAt': None, 'publishedAt': '2017-04-24T11:27:11Z', 'updatedAt': '2017-08-02T15:42:00Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Muelu installs various files twice', 'bodyHTML': '<p>When checking for files which are overridden during the installation process, one finds that Muelu contains a few of them</p>\\n<pre><code>$ make install\\n$ sort install_manifest.txt | uniq --count --repeated\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_ClassicNodeAPI_Wrapper.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_TMM.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View_def.hpp\\n      2 /opt/trilinos/private/include/trilinos/KokkosCompat_View.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_AdaptiveSaMLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_config.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_FactoryFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_MLParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ParameterListInterpreter.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_RefMaxwell.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacian.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_ShiftedLaplacianOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/MueLu_TpetraOperator.hpp\\n      2 /opt/trilinos/private/include/trilinos/TeuchosKokkosCompat_config.h\\n      2 /opt/trilinos/private/include/trilinos/Thyra_MueLuPreconditionerFactory.hpp\\n      2 /opt/trilinos/private/include/trilinos/Tpetra_CrsMatrixSolveOp.hpp\\n</code></pre>\\n<p>The reason for this is that the Muelu configuration installs multiple files with the same name in the same directory. It is not clear if the contents are the same, too, or if this actually presents a serious bug.</p>\\n<p>(From <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6428</a>).</p>\\n<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856517\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/muelu/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/muelu/hovercard\" href=\"https://github.com/orgs/trilinos/teams/muelu\">@trilinos/muelu</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/8', 'state': 'OPEN', 'createdAt': '2015-11-19T10:30:26Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T10:30:26Z', 'updatedAt': '2016-03-07T23:12:34Z', 'labels': ['help wanted', 'packages: MueLu'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Reorganize Belos adapters into subpackages', 'bodyHTML': '<p>Belos offers <a href=\"https://github.com/trilinos/Trilinos/tree/master/packages/belos\">a number of adapters</a> for their linear solvers, most notably Epetra and Tpetra. Unfortunately, there is no adapter for Thyra though.  Oh wait, <a href=\"https://github.com/trilinos/Trilinos/blob/master/packages/stratimikos/adapters/belos/src/BelosThyraAdapter.hpp\">there is one</a>! In Stratimikos.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/21', 'state': 'OPEN', 'createdAt': '2015-11-21T11:32:59Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T11:32:59Z', 'updatedAt': '2016-03-07T23:11:02Z', 'labels': ['enhancement', 'help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Teko: SIMPLEPreconditionerFactory_tpetra, Allocation pool destroyed with the following memory leak(s):', 'bodyHTML': '<p>With</p>\\n<pre><code>cmake \\\\\\n  -DTrilinos_ENABLE_Teko:BOOL=ON \\\\\\n  -DTPL_ENABLE_MPI:BOOL=OFF \\\\\\n  -DTrilinos_ENABLE_TESTS:BOOL=ON \\\\\\n  -DTrilinos_ENABLE_EXAMPLES:BOOL=ON \\\\\\n  ../../source-nschloe/\\n</code></pre>\\n<p>I\\'m getting a test failure for <code>SIMPLEPreconditionerFactory_tpetra</code>:</p>\\n<pre><code>2: Test command: /home/nschloe/software/trilinos/build/teko/packages/teko/tests/Teko_testdriver_tpetra.exe\\n2: Test timeout computed to be: 1500\\n2: Teuchos::GlobalMPISession::GlobalMPISession(): started serial run\\n2: Running test \"SIMPLEPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Lumped\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Lumped\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(lumped)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = Diagonal\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = Diagonal\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(diag)\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       SIMPLE Parameters: \\n2:          inv type    = \"\"\\n2:          inv v type  = \"Ifpack2\"\\n2:          inv p type  = \"Ifpack2\"\\n2:          alpha       = 1\\n2:          use mass    = 0\\n2:          vel scaling = AbsRowSum\\n2:       SIMPLE Parameter list: \\n2:       Explicit Velocity Inverse Type = AbsRowSum\\n2:       Inverse Pressure Type = Ifpack2\\n2:       Inverse Velocity Type = Ifpack2\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializePrec(absrowsum)\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"diagonal(diag)\" ... PASSED\\n2:    \"diagonal(block-1)\" ... PASSED\\n2:    \"diagonal(block-2)\" ... PASSED\\n2:    \"result(diag)\" ... PASSED\\n2:    \"result(block-1)\" ... PASSED\\n2:    \"result(block-2)\" ... PASSED\\n2: Test \"SIMPLEPreconditionerFactory_tpetra\" completed ... PASSED (12)\\n2: Running test \"DiagonalPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2: ||Z-Y||/||Z|| = 0\\n2:    \"canApply\" ... PASSED\\n2: Test \"DiagonalPreconditionerFactory_tpetra\" completed ... PASSED (3)\\n2: Running test \"LU2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"LU2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"LSCStablePreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 5.5e-05\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 2.7e-05\\n2:    \"identity\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 1e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.4e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 0\\n2: Teko: LSCPrecFact::buildPO TotalTime = 3.3e-05\\n2:    \"result\" ... PASSED\\n2: Test \"LSCStablePreconditionerFactory_tpetra\" completed ... PASSED (7)\\n2: Running test \"LSCStabilized_tpetra\"\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 2e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 4.9e-05\\n2:    \"diagonal\" ... PASSED\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Gamma Parameter = 0.238035\\n2:       LSC Alpha Parameter = 0.646628\\n2:    Teko: End debug MSG\\n2: Teko: LSC::buildState BuildOpsTime = 0.005435\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000186\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.2e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000284\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.005727\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.005789\\n2:    \"strategy\" ... PASSED\\n2: Test \"LSCStabilized_tpetra\" completed ... PASSED (2)\\n2: Running test \"Jacobi2x2PreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatable\" ... PASSED\\n2:    \"identity\" ... PASSED\\n2:    \"diagonal\" ... PASSED\\n2:    \"result\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46db850,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"Ifpack2\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"Block Jacobi\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46ab208,node=0x46d8380,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: JacobiPrecFact: Building default inverse \"ML\"\\n2: Teko: Inverse \"ML\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 1 \"Amesos\"\\n2: Teko: Inverse \"Amesos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2: Teko: JacobiPrecFact: Building inverse 3 \"Ifpack\"\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"initializeFromParameterList\" ... PASSED\\n2: Test \"Jacobi2x2PreconditionerFactory_tpetra\" completed ... PASSED (8)\\n2: Running test \"BlockJacobiPreconditionerFactory_tpetra\"\\n2:    \"createPrec\" ... PASSED\\n2:    \"initializePrec\" ... PASSED\\n2:    \"uninitializePrec\" ... PASSED\\n2:    \"isCompatible\" ... PASSED\\n2: Test \"BlockJacobiPreconditionerFactory_tpetra\" completed ... PASSED (4)\\n2: Running test \"BlockUpperTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockUpperTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"BlockLowerTriInverseOp_tpetra\"\\n2:    \"apply\" ... PASSED\\n2:    \"alphabeta\" ... PASSED\\n2: Test \"BlockLowerTriInverseOp_tpetra\" completed ... PASSED (2)\\n2: Running test \"tTpetraOperatorWrapper\"\\n2:    \"functionality\" ... PASSED\\n2: Test \"tTpetraOperatorWrapper\" completed ... PASSED (1)\\n2: Running test \"InterlacedTpetra\"\\n2:    \"buildSubMaps_num\" ... PASSED\\n2:    \"buildSubMaps_vec\" ... PASSED\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2: Test \"InterlacedTpetra\" completed ... PASSED (5)\\n2: Running test \"BlockingTpetra\"\\n2:    \"buildMaps\" ... PASSED\\n2:    \"one2many\" ... PASSED\\n2:    \"many2one\" ... PASSED\\n2:    \"buildSubBlock\" ... PASSED\\n2: Test \"BlockingTpetra\" completed ... PASSED (4)\\n2: Running test \"TpetraThyraConverter\"\\n2:    \"blockThyraToTpetra\" ... PASSED\\n2:    \"single_blockThyraToTpetra\" ... PASSED\\n2:    \"blockTpetraToThyra\" ... PASSED\\n2:    \"single_blockTpetraToThyra\" ... PASSED\\n2: Test \"TpetraThyraConverter\" completed ... PASSED (4)\\n2: Running test \"tGraphLaplacian_tpetra\"\\n2:    \"single_array\" ... PASSED\\n2:    \"multi_array\" ... PASSED\\n2: Test \"tGraphLaplacian_tpetra\" completed ... PASSED (2)\\n2: Running test \"tParallelInverse_tpetra\"\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"inverse\" ... PASSED\\n2: Teko: Inverse \"Belos\" is of type strat prec = 0, strat solv = 1, block prec = 0\\n2:    \"stridedInverse\" ... PASSED\\n2: Test \"tParallelInverse_tpetra\" completed ... PASSED (2)\\n2: Running test \"tExplicitOps_tpetra\"\\n2:    \"mult_diagScaleMatProd\" ... PASSED\\n2:    \"mult_diagScaling\" ... PASSED\\n2:    \"add\" ... PASSED\\n2:    \"mult_modScaleMatProd\" ... PASSED\\n2:    \"add_mod\" ... PASSED\\n2: Test \"tExplicitOps_tpetra\" completed ... PASSED (5)\\n2: Running test \"LSCHIntegrationTest_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.000374\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.000207\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 8.8e-05\\n2: Teko: LSC::computeInverses Building inv(BHBtmC)\\n2: Teko: LSC::computeInverses GetInvBHBt = 7.5e-05\\n2: Teko: LSC::buildState BuildInvTime = 0.000387\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.000774\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 3e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.000818\\n2:    \"hScaling\" ... PASSED\\n2: Test \"LSCHIntegrationTest_tpetra\" completed ... PASSED (1)\\n2: Running test \"Lumping_tpetra\"\\n2:    \"lumping\" ... PASSED\\n2:    \"invLumping\" ... PASSED\\n2: Test \"Lumping_tpetra\" completed ... PASSED (2)\\n2: Running test \"AbsRowSum_tpetra\"\\n2:    \"absRowSum\" ... PASSED\\n2:    \"invAbsRowSum\" ... PASSED\\n2: Test \"AbsRowSum_tpetra\" completed ... PASSED (2)\\n2: Running test \"NeumannSeries_tpetra\"\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_simpleOp\" ... PASSED\\n2: Teko: Inverse \"Neumann\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"test_scaledOp\" ... PASSED\\n2: Test \"NeumannSeries_tpetra\" completed ... PASSED (2)\\n2: Running test \"PCDStrategy_tpetra\"\\n2: Teko: Inverse \"Ifpack2\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    \"PCDStrategy\" ... PASSED\\n2: Test \"PCDStrategy_tpetra\" completed ... PASSED (1)\\n2: Running test \"LSCIntegrationTest_tpetra\"\\n2: Teko: LSC::initializeState Build Scaling &lt;mass&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009541\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.022672\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003661\\n2: Teko: LSC::buildState BuildInvTime = 0.026382\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.035986\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.036054\\n2:    \"withmassStable\" ... PASSED\\n2: Teko: LSC::initializeState Build Scaling &lt;F&gt; type \"Diagonal\"\\n2: Teko: LSC::buildState BuildOpsTime = 0.009327\\n2: Teko: LSC::computeInverses Building inv(F)\\n2: Teko: LSC::computeInverses GetInvF = 0.023873\\n2: Teko: LSC::computeInverses Building inv(BQBtmC)\\n2: Teko: LSC::computeInverses GetInvBQBt = 0.003909\\n2: Teko: LSC::buildState BuildInvTime = 0.029108\\n2: Teko: LSCPrecFact::buildPO BuildStateTime = 0.038479\\n2: Teko: LSCPrecFact::buildPO GetInvTime = 4e-06\\n2: Teko: LSCPrecFact::buildPO TotalTime = 0.038548\\n2:    \"nomassStable\" ... PASSED\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x4790b68,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46c67a8,node=0x46524a0,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"Basic Inverse\"\\n2:    Teko: Begin debug MSG\\n2:       LSC Inverse Strategy Parameters: \\n2:          inv type   = \"Amesos\"\\n2:          inv v type = \"Ifpack\"\\n2:          inv p type = \"Ifpack\"\\n2:          bndry rows = 1\\n2:          use ldu    = 1\\n2:          use mass    = 0\\n2:          use w-scaling    = 0\\n2:          assume stable    = 0\\n2:          scale type    = Diagonal\\n2:       LSC  Inverse Strategy Parameter list: \\n2:       Inverse Type = Amesos\\n2:       Inverse Velocity Type = Ifpack\\n2:       Inverse Pressure Type = Ifpack\\n2:       Ignore Boundary Rows = 1\\n2:       Use LDU = 1\\n2:    Teko: End debug MSG\\n2: Teko: Inverse \"Ifpack\" is of type strat prec = 1, strat solv = 0, block prec = 0\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x46be938,node=0x5118a20,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: Teko: Building LSC strategy \"The Cat\"\\n2: LSC Construction failed: Strategy \"The Cat\" could not be constructed\\n2:    Teko: Begin debug MSG\\n2:       Looked up \"NS LSC\"\\n2:       Built Teuchos::RCP&lt;Teko::PreconditionerFactory&gt;{ptr=0x478de38,node=0x46c2c60,strong_count=1,weak_count=0}\\n2:    Teko: End debug MSG\\n2: LSC Construction failed: Strategy \"The Cat\" requires a \"Strategy Settings\" sublist\\n2:    \"plConstruction\" ... PASSED\\n2: Test \"LSCIntegrationTest_tpetra\" completed ... PASSED (3)\\n2: Running test \"tStridedTpetraOperator\"\\n2:    \"numvars_constr\" ... PASSED\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tStridedTpetraOperator\" completed ... PASSED (5)\\n2: Running test \"tBlockedTpetraOperator\"\\n2:    \"vector_constr\" ... PASSED\\n2:    \"reorder(flat reorder)\" ... PASSED\\n2:    \"reorder(composite reorder = 1)\" ... PASSED\\n2:    \"reorder(composite reorder = 2)\" ... PASSED\\n2: Test \"tBlockedTpetraOperator\" completed ... PASSED (4)\\n2: \\n2: Tests Passed: 91, Tests Failed: 0\\n2: (Incidently, you want no failures)\\n2: Error: Allocation pool destroyed with the following memory leak(s):\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x46fde80 + 81208 ]\\n2:    { Aligned Allocator } : \"\" ref_count(2) memory[ 0x4754780 + 81208 ]\\n[...]\\n2: \\n 2/17 Test  #2: Teko_testdriver_tpetra .....................***Exception: SegFault 16.57 sec\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/22', 'state': 'CLOSED', 'createdAt': '2015-11-21T12:45:35Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T12:45:35Z', 'updatedAt': '2017-01-12T18:54:32Z', 'labels': ['Teko', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'duplicate TPL adapters', 'bodyHTML': '<p>In Trilinos, TriBits takes care of some of the TPL integration via the files in</p>\\n<pre><code>cmake/tribits/common_tpls/FindTPL*.cmake\\n</code></pre>\\n<p>Their counterparts in</p>\\n<pre><code>cmake/TPLs/FindTPL*.cmake\\n</code></pre>\\n<p>are redundant and should probably be removed.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/24', 'state': 'OPEN', 'createdAt': '2015-11-21T15:32:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-21T15:32:22Z', 'updatedAt': '2016-03-23T06:14:42Z', 'labels': ['Framework', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Kokkos test', 'bodyHTML': '<p>Kokkos testing in Trilinos does not work. It looks like the cmake does not properly include src directory in Kokkos. The configuration that I use is okay with the old Sandia repo.</p>\\n<p>Kyungjoo</p>\\n<pre><code>cd                                                                                                            \\n/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device         \\n&amp;&amp; /home/software/intel/ics_install/impi/4.1.1.036/intel64/bin/mpiicpc                                        \\n-O3 -g -mavx -opt-report=5 -DMPICH_IGNORE_CXX_SEEK -std=c++11 -O3                                             \\n-DNDEBUG                                                                                                      \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test                                            \\n-I/nfshome/kyukim/Work/lib/trilinos/build/shylu/compton/intel-test/packages/kokkos/example/query_device       \\n-I/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device                                \\n-o CMakeFiles/KokkosExample_query_device.dir/query_device.cpp.o -c                                            \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp                 \\nicpc: remark #10397: optimization reports are generated in *.optrpt                                           \\nfiles in the output location                                                                                  \\n/nfshome/kyukim/Work/lib/trilinos/trunk/packages/kokkos/example/query_device/query_device.cpp(47):            \\ncatastrophic error: cannot open source file \"Kokkos_Macros.hpp\"                                               \\n  #include &lt;Kokkos_Macros.hpp&gt;\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/29', 'state': 'CLOSED', 'createdAt': '2015-11-24T21:17:44Z', 'lastEditedAt': None, 'publishedAt': '2015-11-24T21:17:44Z', 'updatedAt': '2016-03-06T13:29:03Z', 'labels': ['Kokkos', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Anasazi tests fail with checkin script and secondary-stable code enabled', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1860620\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/anasazi/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/anasazi/hovercard\" href=\"https://github.com/orgs/trilinos/teams/anasazi\">@trilinos/anasazi</a><br>\\nI am trying to run the checkin script with secondary-stable code enabled.  The following anasazi tests fail.  All my code changes are in zoltan and zoltan2, so I don\\'t suspect them as the problem.</p>\\n<p>595 - Anasazi_Epetra_ModalSolversTester_MPI_4 (Failed)<br>\\n609 - Anasazi_Epetra_OrthoManagerGenTester_0_MPI_4 (Failed)<br>\\n610 - Anasazi_Epetra_OrthoManagerGenTester_1_MPI_4 (Failed)</p>\\n<p>Error messages for 595:<br>\\nERROR:  V*Q failed.<br>\\northonorm error of applyHouse: 0.308401<br>\\nERROR:  applyHouse failed.<br>\\nerror(VQ - house(V,H,tau): 3.5943e-16</p>\\n<p>Error messages for 609:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.07011</p>\\n<p>Error messages for 610:<br>\\n*** Caught standard std::exception of type \\'std::runtime_error\\' :<br>\\n/home/kddevin/code/Trilinos/packages/anasazi/epetra/test/OrthoManager/cxx_gentest.cpp:261:<br>\\nThrow number = 1<br>\\nThrow test that evaluated to true: err &gt; TOL<br>\\nNew X1 did not meet tolerance: orthog(X1,Y2) == 1.14092</p>\\n<p>My custom config options for these tests are listed below.  Is there some other CMake magic that I need to include (or that could be made the default in the checkin script)?</p>\\n<p>Thanks for your help!</p>\\n<p>-D Trilinos_ENABLE_SECONDARY_STABLE_CODE=ON<br>\\n-D Trilinos_ENABLE_Epetra:BOOL=ON<br>\\n-D Trilinos_ENABLE_Galeri:BOOL=ON<br>\\n-D Trilinos_ENABLE_Pamgen:BOOL=ON<br>\\n-D Zoltan_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_EXAMPLES:BOOL=ON<br>\\n-D Zoltan2_ENABLE_TESTS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Experimental:BOOL=ON<br>\\n-D Zoltan_ENABLE_Scotch:BOOL=ON<br>\\n-D Zoltan2_ENABLE_Scotch:BOOL=ON<br>\\n-D Scotch_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi/lib\"<br>\\n-D Scotch_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/Scotch/scotch_6.0.3/32bit_openmpi//include\"<br>\\n-D Zoltan_ENABLE_ParMETIS:BOOL=ON<br>\\n-D Zoltan2_ENABLE_ParMETIS:BOOL=ON<br>\\n-D ParMETIS_LIBRARY_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D ParMETIS_INCLUDE_DIRS:FILEPATH=\"/home/kddevin/code/ParMETIS/ParMETIS-4.0.3/32bit_openmpi\"<br>\\n-D Teuchos_ENABLE_STACKTRACE=OFF<br>\\n-D MPI_BIN_DIR:PATH=/usr/lib64/openmpi/bin<br>\\n-D TPL_ENABLE_MPI:BOOL=ON<br>\\n-D MPI_EXEC_MAX_NUMPROCS:STRING=12<br>\\n-D TPL_ENABLE_Boost=OFF<br>\\n-D TPL_ENABLE_Netcdf=OFF<br>\\n-D TPL_ENABLE_BoostLib=OFF<br>\\n-D Trilinos_ENABLE_SEACAS:BOOL=OFF<br>\\n-D Trilinos_ENABLE_STK:BOOL=OFF<br>\\n-D DART_TESTING_TIMEOUT:STRING=1300<br>\\n-D Amesos2_ENABLE_KLU2=ON</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/145', 'state': 'CLOSED', 'createdAt': '2016-02-17T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2016-02-17T20:54:51Z', 'updatedAt': '2018-07-03T16:50:45Z', 'labels': ['Anasazi', 'help wanted', 'tests'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Tpetra BCRS: Improve vectorization of small dense linear algebra operations', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856650\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/ifpack2/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/ifpack2/hovercard\" href=\"https://github.com/orgs/trilinos/teams/ifpack2\">@trilinos/ifpack2</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=9490481\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/crtrott\">@crtrott</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6992602\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/kyungjoo-kim\">@kyungjoo-kim</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15895383\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amklinv\">@amklinv</a></p>\\n<p>Tpetra::Experimental::BlockCrsMatrix uses the small dense linear algebra operations currently implemented in Tpetra_Experimental_BlockView.hpp.  These operations take Kokkos::View or LittleVector / LittleBlock.  (Their interfaces are enough alike from the perspective of these operations, that we need only consider Kokkos::View in what follows, without loss of generality.)  For example, Tpetra::Experimental::GEMV (small dense matrix times small dense vector) takes a rank-2 View (the matrix) and two rank-1 Views (input and output vectors).</p>\\n<p>Discussions a couple weeks ago with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8905126\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nmhamster\">@nmhamster</a> suggested that we could get outer loop vectorization by doing the following:</p>\\n<ol>\\n<li>Change the storage layout so that the (i,j) entries of consecutive blocks (or the (i) entries of consecutive vectors) are stored contiguously</li>\\n<li>Linear algebra operations on those small dense blocks would then need to take a whichBlock / whichVector index argument, to tell which block / vector to use</li>\\n</ol>\\n<p>The routines wouldn\\'t change, except that instead of writing A(i,j) or x(k) (for example), we would write A(i,j,whichBlock) or x(k,whichBlock).  We have to rely on Kokkos::View::operator() to inline, but this is a much easier approach than explicit SIMD.</p>\\n<p>This depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138758948\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/177\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/177/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/177\">#177</a> and <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"138761181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/trilinos/Trilinos/issues/179\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trilinos/Trilinos/issues/179/hovercard\" href=\"https://github.com/trilinos/Trilinos/issues/179\">#179</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/180', 'state': 'CLOSED', 'createdAt': '2016-03-06T13:17:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-06T13:17:44Z', 'updatedAt': '2016-06-04T23:50:26Z', 'labels': ['help wanted', 'packages: Ifpack2', 'packages: Tpetra', 'system: manycore'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Belos::LinearProblem should unset itself if preconditioner is set', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15914966\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/hkthorn\">@hkthorn</a> <a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1859621\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/belos/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/belos/hovercard\" href=\"https://github.com/orgs/trilinos/teams/belos\">@trilinos/belos</a></p>\\n<p>See discussion here: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128754406\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\" data-hovercard-type=\"issue\" data-hovercard-url=\"/UK-MAC/TeaLeaf_Trilinos/issues/2/hovercard\" href=\"https://github.com/UK-MAC/TeaLeaf_Trilinos/issues/2\">UK-MAC/TeaLeaf_Trilinos#2</a></p>', 'url': 'https://github.com/trilinos/Trilinos/issues/181', 'state': 'OPEN', 'createdAt': '2016-03-07T02:23:48Z', 'lastEditedAt': None, 'publishedAt': '2016-03-07T02:23:48Z', 'updatedAt': '2016-03-07T02:23:48Z', 'labels': ['help wanted', 'packages: Belos'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': \"Tpetra::MatrixMarket::Reader can't read graphs (pattern only)\", 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856852\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/tpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/tpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/tpetra\">@trilinos/tpetra</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a></p>\\n<p>Moved from Bugzilla Bug 6130: <a href=\"https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130\" rel=\"nofollow\">https://software.sandia.gov/bugzilla/show_bug.cgi?id=6130</a></p>\\n<p>Bug posted by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10200375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/egboman\">@egboman</a> .  Original text:</p>\\n<p>I need to read MatrixMarket files with no values (pattern only) into Tpetra for Zoltan2 testing. Ideally, I would like to get a CrsGraph returned from the Tpetra::MatrixMarket::Reader. I don\\'t see how to do this?</p>\\n<p>A work-around would be for Tpetra::MatrixMarket::Reader to create a CrsMatrix with explicit zeros. Then I could extract the graph from the matrix.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/185', 'state': 'CLOSED', 'createdAt': '2016-03-08T04:51:44Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T04:51:44Z', 'updatedAt': '2017-09-06T20:02:25Z', 'labels': ['enhancement', 'help wanted', 'packages: Tpetra'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'TeuchosCore_ScalarTraits_test_MPI_1 Tests Fail on POWER8 with GCC 4.9.2 and CUDA 7.5', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1959736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/bartlettroscoe\">@bartlettroscoe</a> - I am getting these errors in the Trilinos bring up on POWER8 with GCC 4.9.2 and CUDA 7.5. This is being tested on the <code>white</code> Sandia system. Just want to check in whether these would be expected failures or not?</p>\\n<pre><code>34: Testing: Teuchos::ScalarTraits&lt;float&gt; ...\\n34:  Type chain (ascending) : float -&gt; double\\n34:  Type chain (descending): float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n34:\\n34: Testing: Teuchos::ScalarTraits&lt;double&gt; ...\\n34:  Type chain (ascending) : double\\n34:  Type chain (descending): double -&gt; float\\n34:\\n34:  Testing that squareroot(NaN) == NaN! ...\\n34:  squareroot(nan) = nan == nan : failed\\n34:\\n34:  Testing that squareroot(-NaN) == NaN! ...\\n34:  squareroot(-nan) = -nan == nan : failed\\n34:\\n34:  Testing that squareroot(-1) == NaN! ...\\n34:  squareroot(-1) = nan == nan : failed\\n</code></pre>', 'url': 'https://github.com/trilinos/Trilinos/issues/239', 'state': 'CLOSED', 'createdAt': '2016-03-22T02:36:24Z', 'lastEditedAt': None, 'publishedAt': '2016-03-22T02:36:24Z', 'updatedAt': '2016-03-23T19:44:32Z', 'labels': ['Teuchos', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Remove bracket operator use from discretization tools', 'bodyHTML': '<p>Kokkos implemented a nasty hack to support bracket operator use in Intrepid. Long term we need to eliminate the use of bracket operator from all discretization tools that use Kokkos. Phalanx has acceptance tests that check this behavior for calling Intrepid. Below is the email discussion with Carter:</p>\\n<p>Would be easy to implement but dangerous to use.</p>\\n<p>A subview or any kind of non-contiguous view cannot be linearly indexed<br>\\nand will have silent errors when doing so.</p>\\n<p>In DynRankView:</p>\\n<pre><code>operator[]( int i ) const { return data()[i]; }\\n</code></pre>\\n<p>On 4/6/16, 2:03 PM, \"Pawlowski, Roger P\" <a href=\"mailto:rppawlo@sandia.gov\">rppawlo@sandia.gov</a> wrote:</p>\\n<blockquote>\\n<p>Hi Nathan,</p>\\n<p>It seems that the bracket operator on the DynRankView only works for a<br>\\nrank 1 array.  The use case we have with Intrepid is that if I allocate<br>\\na view with rank greater than 1:</p>\\n<p>DynRankView a(10,2);</p>\\n<p>Then the bracket operator should give me access to all twenty entries in<br>\\nthe array (e.g. a[19] should work). For the DynRankView in Phalanx, I<br>\\njust carried around a second member internally that the bracket operator<br>\\nimplementation used:</p>\\n<p>m_field_oned_view =<br>\\narray_oned_type(m_field_data7.ptr_on_device(),m_field_data7.size(),PHX::ge<br>\\ntSacadoSize(m_field_data7));</p>\\n<p>Can we get something similar to this in the kokkos DynRankView? Long<br>\\nterm I we would like to eliminate bracket operator, but that will take<br>\\nquite a bit of refactoring in intrepid.</p>\\n<p>Roger</p>\\n</blockquote>', 'url': 'https://github.com/trilinos/Trilinos/issues/277', 'state': 'OPEN', 'createdAt': '2016-04-07T15:13:46Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T15:13:46Z', 'updatedAt': '2016-12-02T18:49:12Z', 'labels': ['Intrepid2', 'Panzer', 'Phalanx', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Trilinos', 'repo_owner_name': 'Trilinos', 'repo_owner_email': '', 'repo_owner_user_name': 'trilinos', 'repo_owner_profile_url': 'https://github.com/trilinos', 'title': 'Best way to eliminate warnings', 'bodyHTML': '<p><a class=\"team-mention js-team-mention\" data-error-text=\"Failed to load team members\" data-id=\"1856703\" data-permission-text=\"Team members are private\" data-url=\"/orgs/trilinos/teams/xpetra/members\" data-hovercard-type=\"team\" data-hovercard-url=\"/orgs/trilinos/teams/xpetra/hovercard\" href=\"https://github.com/orgs/trilinos/teams/xpetra\">@trilinos/xpetra</a>  Xpetra has a number of these types of warnings:</p>\\n<pre><code>Xpetra_EpetraIntVector.hpp(385): warning: statement is unreachable\\n\\n385      int dot(const Vector&lt;Scalar,LocalOrdinal,GlobalOrdinal,Node&gt; &amp;a) const { XPETRA_MONITOR(\"EpetraIntVectorT::dot\"); TEUCHOS_TEST_FOR_EXCEPTION(-1, Xpetra::Exceptions::NotImplemented, \"TODO\"); return -1; }\\n</code></pre>\\n<p>It would be great to keep the exception and eliminate the warning, without removing the return value, which would generate another type of warning.  Is this possible, short of implementing the method?</p>\\n<p>Pragmas are not an option it seems, as the option <code>--Wunreachable-code</code> has been a no-op in g++ for a long time;  see this <a href=\"https://gcc.gnu.org/ml/gcc-help/2011-05/msg00360.html\" rel=\"nofollow\">link</a>.</p>', 'url': 'https://github.com/trilinos/Trilinos/issues/722', 'state': 'CLOSED', 'createdAt': '2016-10-20T22:09:44Z', 'lastEditedAt': None, 'publishedAt': '2016-10-20T22:09:44Z', 'updatedAt': '2017-08-03T23:11:00Z', 'labels': ['help wanted', 'packages: Xpetra'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cg-site', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'As a user, I want to be able to search cloud.gov documentation', 'bodyHTML': '<p><a href=\"http://gohugo.io\" rel=\"nofollow\">http://gohugo.io</a> uses a <a href=\"https://www.google.com/cse/\" rel=\"nofollow\">Google Custom Search Engine</a>, which it seems we can\\'t create in our Google Apps account <g-emoji class=\"g-emoji\" alias=\"confused\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f615.png\"></g-emoji></p>', 'url': 'https://github.com/18F/cg-site/issues/24', 'state': 'CLOSED', 'createdAt': '2015-03-20T06:47:47Z', 'lastEditedAt': None, 'publishedAt': '2015-03-20T06:47:47Z', 'updatedAt': '2016-06-07T21:12:01Z', 'labels': ['Navigator', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cg-site', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'As a user of cloud.gov, I want to know about how to set up redirects', 'bodyHTML': '<p>Users of cloud.gov need to know the options for setting up redirects, e.g. handing switching from an old domain to a new one. There are a few options we should talk about:</p>\\n<ul>\\n<li>Setting up a little <a href=\"http://docs.cloudfoundry.org/buildpacks/staticfile/index.html\" rel=\"nofollow\">staticfile</a> app with an nginx config that handles redirection</li>\\n<li>For servers, having multiple routes mapped to the same Cloud Foundry application and doing the redirection in code. <a href=\"https://coderwall.com/p/l1uydg/redirect-to-canonical-host-in-rails-4\" rel=\"nofollow\">Options for Rails</a>.</li>\\n</ul>', 'url': 'https://github.com/18F/cg-site/issues/271', 'state': 'CLOSED', 'createdAt': '2016-06-09T18:15:09Z', 'lastEditedAt': None, 'publishedAt': '2016-06-09T18:15:09Z', 'updatedAt': '2016-11-30T06:20:11Z', 'labels': ['SkyPorter', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'joining-18f', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Give applicants a heads-up about implications of becoming a fed', 'bodyHTML': '<p><strong>User story:</strong><br>\\nAs an applicant who may not have previously worked in government, I want to understand the personal implications of becoming an employee of the federal government (e.g., the Hatch Act, FOIAability of _____, social media considerations, implications for attending or speaking at conferences, etc.) so that I can make an informed decision about whether to accept an employment offer.</p>\\n<p><strong>Current behavior:</strong><br>\\nThe site includes <a href=\"https://pages.18f.gov/joining-18f/conferences-training-travel/\" rel=\"nofollow\">some information about conferences</a>. The site includes no information about legal ramifications of being a federal employee.</p>\\n<p><strong>Desired behavior:</strong><br>\\nSee above. Exact content TBD.</p>\\n<p><strong>Technical notes:</strong><br>\\nN/A</p>\\n<p><strong>Outstanding questions:</strong></p>\\n<ul>\\n<li>What will it say? :)</li>\\n</ul>', 'url': 'https://github.com/18F/joining-18f/issues/68', 'state': 'CLOSED', 'createdAt': '2015-09-29T17:30:19Z', 'lastEditedAt': None, 'publishedAt': '2015-09-29T17:30:19Z', 'updatedAt': '2017-03-14T18:14:07Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'joining-18f', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Rework to use U.S. Web Design Standards assets', 'bodyHTML': '', 'url': 'https://github.com/18F/joining-18f/issues/233', 'state': 'CLOSED', 'createdAt': '2016-01-16T01:08:22Z', 'lastEditedAt': None, 'publishedAt': '2016-01-16T01:08:22Z', 'updatedAt': '2017-03-14T18:39:47Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'joining-18f', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Restore information about roles and teams', 'bodyHTML': '<p>...as distinct from open positions. See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"129688049\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/joining-18f/issues/238\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/joining-18f/issues/238/hovercard\" href=\"https://github.com/18F/joining-18f/issues/238\">#238</a> for earlier conversation.</p>', 'url': 'https://github.com/18F/joining-18f/issues/248', 'state': 'CLOSED', 'createdAt': '2016-03-04T01:14:06Z', 'lastEditedAt': None, 'publishedAt': '2016-03-04T01:14:06Z', 'updatedAt': '2017-03-14T18:42:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'concourse-compliance-testing', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'look into using tool to generate the ZAP pipeline', 'bodyHTML': '<p>Right now, we build the pipeline with ERB, but just realized the Cloud Foundry community has a tool for doing templated YAML:</p>\\n<p><a href=\"https://github.com/cloudfoundry-incubator/spiff\">https://github.com/cloudfoundry-incubator/spiff</a></p>', 'url': 'https://github.com/18F/concourse-compliance-testing/issues/73', 'state': 'OPEN', 'createdAt': '2016-05-07T02:31:07Z', 'lastEditedAt': None, 'publishedAt': '2016-05-07T02:31:07Z', 'updatedAt': '2017-02-02T02:52:50Z', 'labels': ['HighBar', 'enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'concourse-compliance-testing', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'simplify targets configuration', 'bodyHTML': '<p>Ideas:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Only accept a single URL per target</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Convert to YAML instead of JSON</li>\\n</ul>\\n<p><a href=\"https://github.com/18F/concourse-compliance-testing/blob/master/config/targets.json\">https://github.com/18F/concourse-compliance-testing/blob/master/config/targets.json</a></p>', 'url': 'https://github.com/18F/concourse-compliance-testing/issues/119', 'state': 'OPEN', 'createdAt': '2016-10-13T21:38:16Z', 'lastEditedAt': None, 'publishedAt': '2016-10-13T21:38:16Z', 'updatedAt': '2016-10-13T21:38:16Z', 'labels': ['HighBar', 'enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'ffd-microsite', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update report PDF to point to generic filename and setup redirects', 'bodyHTML': '<p><strong>Description</strong></p>\\n<p>Currently, the PDF of the report has a file name that includes the date the report was created and/or updated. This leads to issues in regards to direct links to the PDF around the internet.</p>\\n<p><strong>Ask</strong></p>\\n<p>Update the file name to a generic version and point past links to the report to this new url.</p>\\n<p><strong>To do</strong></p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Change filename to generic version and submit PR</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Merge to staging &gt; production</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Create redirect from <code>https://labs.usa.gov/files/FFD_ResearchReport_0216.pdf</code> and <code>https://labs.usa.gov/files/FFD_ResearchReport_0316.pdf</code> to point to this new generic name.</li>\\n</ul>', 'url': 'https://github.com/18F/ffd-microsite/issues/54', 'state': 'OPEN', 'createdAt': '2016-03-08T16:50:49Z', 'lastEditedAt': None, 'publishedAt': '2016-03-08T16:50:49Z', 'updatedAt': '2016-03-14T17:24:31Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Castro', 'repo_owner_name': 'AMReX-Astro', 'repo_owner_email': '', 'repo_owner_user_name': 'AMReX-Astro', 'repo_owner_profile_url': 'https://github.com/AMReX-Astro', 'title': 'Recommend a new default value of gravity.abs_tol', 'bodyHTML': '<p>The Poisson solve absolute tolerance sets the accuracy of the Poisson solve. Given the value of abs_tol, the error level targeted in the Poisson solve is abs_tol * 4 * pi * G * rho_max, where rho_max is the maximum density on the domain. For Cartesian simulations the default value is 1.e-11, and for non-Cartesian the default value is 1.e-10.</p>\\n<p>At high resolution, and/or for complicated mass distributions, this tolerance can be too tight, and the multigrid solve fails. We should study the effect of the gravity tolerance and possibly recommend a new tolerance. If it is justified, the new tolerance should be looser so that the default value fails in fewer cases. However, we should not make it so loose that the effect noticeably deteriorates the accuracy of our simulations.</p>\\n<p>Issues to study:<br>\\n(1) Differences between Cartesian and cylindrical/spherical problems<br>\\n(2) Performance, both for a single processor and for multiple processors<br>\\n(3) Accuracy -- for a given lower tolerance, how much does the answer change?</p>\\n<p>These should be studied with a well-used problem like DustCollapse, and also one or two more complicated problems like the Evrard collapse and wdmerger.</p>', 'url': 'https://github.com/AMReX-Astro/Castro/issues/202', 'state': 'OPEN', 'createdAt': '2017-09-26T05:13:29Z', 'lastEditedAt': None, 'publishedAt': '2017-09-26T05:13:29Z', 'updatedAt': '2017-10-11T22:34:28Z', 'labels': ['good first issue', 'gravity', 'help wanted', 'study'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Castro', 'repo_owner_name': 'AMReX-Astro', 'repo_owner_email': '', 'repo_owner_user_name': 'AMReX-Astro', 'repo_owner_profile_url': 'https://github.com/AMReX-Astro', 'title': 'QCSML is no longer needed', 'bodyHTML': '<p><code>QCSML</code> in the <code>qaux</code> array is not longer really needed.  We used to pre-compute the edge-centered cs, but now we do that in the Riemann solvers directly.</p>', 'url': 'https://github.com/AMReX-Astro/Castro/issues/221', 'state': 'CLOSED', 'createdAt': '2017-10-12T18:39:43Z', 'lastEditedAt': None, 'publishedAt': '2017-10-12T18:39:43Z', 'updatedAt': '2017-10-16T20:25:51Z', 'labels': ['clean-up', 'good first issue', 'hackathon', 'help wanted', 'hydro'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Castro', 'repo_owner_name': 'AMReX-Astro', 'repo_owner_email': '', 'repo_owner_user_name': 'AMReX-Astro', 'repo_owner_profile_url': 'https://github.com/AMReX-Astro', 'title': 'create T_guess parameter', 'bodyHTML': '<p>When inverting the EOS (e.g., calling with <code>eos_input_re</code>), we need an initial guess for T.  Often we just hardcode a value in the code, but we should have this be a runtime parameter, since different initial guesses make sense for different EOSes.</p>', 'url': 'https://github.com/AMReX-Astro/Castro/issues/321', 'state': 'OPEN', 'createdAt': '2018-04-23T17:26:21Z', 'lastEditedAt': None, 'publishedAt': '2018-04-23T17:26:21Z', 'updatedAt': '2018-08-15T01:30:00Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Castro', 'repo_owner_name': 'AMReX-Astro', 'repo_owner_email': '', 'repo_owner_user_name': 'AMReX-Astro', 'repo_owner_profile_url': 'https://github.com/AMReX-Astro', 'title': 'output where and why the timestep limit is set', 'bodyHTML': '<p>We should have an option to print out where in the domain is the most restrictive timestep and what limiter is the cause (hydro, diffusion, reaction, ...)</p>', 'url': 'https://github.com/AMReX-Astro/Castro/issues/328', 'state': 'OPEN', 'createdAt': '2018-05-08T12:44:53Z', 'lastEditedAt': None, 'publishedAt': '2018-05-08T12:44:53Z', 'updatedAt': '2018-05-08T14:54:43Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Castro', 'repo_owner_name': 'AMReX-Astro', 'repo_owner_email': '', 'repo_owner_user_name': 'AMReX-Astro', 'repo_owner_profile_url': 'https://github.com/AMReX-Astro', 'title': 'add time to write plotfile to job_info', 'bodyHTML': '<p>Currently Maestro stores the time to write the plotfile in the <code>job_info</code>.  We should add this to Castro as well.  This is useful for measuring I/O performance.</p>', 'url': 'https://github.com/AMReX-Astro/Castro/issues/365', 'state': 'OPEN', 'createdAt': '2018-07-11T12:35:52Z', 'lastEditedAt': None, 'publishedAt': '2018-07-11T12:35:52Z', 'updatedAt': '2018-08-15T01:28:31Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'sirepo', 'repo_owner_name': 'RadiaSoft LLC', 'repo_owner_email': 'support@radiasoft.net', 'repo_owner_user_name': 'radiasoft', 'repo_owner_profile_url': 'https://github.com/radiasoft', 'title': 'Problem with long-running calculations on cpu-001', 'bodyHTML': '<p>When I try to import <a href=\"https://github.com/radiasoft/sirepo/blob/master/tests/importer_data/srx.py\">https://github.com/radiasoft/sirepo/blob/master/tests/importer_data/srx.py</a> and perform further calculation on the Beamline tab, the calculations fail after ~2 minutes. The calculation is running within radiasoft/sirepo:alpha Docker image on cpu-001. Here is the part of <code>uwsgi.log</code> log:</p>\\n<pre lang=\"log\"><code>*** Starting uWSGI 2.0.12 (64bit) on [Wed Apr 13 20:58:33 2016] ***\\ncompiled with version: 4.9.2 20150212 (Red Hat 4.9.2-6) on 12 April 2016 22:02:03\\nos: Linux-3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u4 (2016-02-29)\\nnodename: sirepo\\nmachine: x86_64\\nclock source: unix\\npcre jit disabled\\ndetected number of CPU cores: 72\\ncurrent working directory: /vagrant\\nwriting pidfile to /vagrant/uwsgi.pid\\ndetected binary path: /home/vagrant/.pyenv/versions/2.7.10/bin/uwsgi\\nyour processes number limit is 4096\\nyour memory page size is 4096 bytes\\ndetected max file descriptor number: 4096\\nlock engine: pthread robust mutexes\\nthunder lock: disabled (you can enable it with --thunder-lock)\\nuwsgi socket 0 bound to TCP address 0.0.0.0:7000 fd 3\\nPython version: 2.7.10 (default, Mar  3 2016, 17:24:18)  [GCC 4.9.2 20150212 (Red Hat 4.9.2-6)]\\nPython main interpreter initialized at 0x177a620\\npython threads support enabled\\nyour server socket listen backlog is limited to 100 connections\\nyour mercy for graceful operations on workers is 60 seconds\\nmapped 331008 bytes (323 KB) for 10 cores\\n*** Operational MODE: threaded ***\\nWSGI app 0 (mountpoint=\\'\\') ready in 2 seconds on interpreter 0x177a620 pid: 193 (default app)\\n*** uWSGI is running in multiple interpreter mode ***\\nspawned uWSGI master process (pid: 193)\\nspawned uWSGI worker 1 (pid: 198, cores: 10)\\n*** Stats server enabled on /vagrant/uwsgi.sock fd: 11 ***\\n.........................\\n[pid: 198|app: 0|req: 35/35] 10.0.137.37 () {48 vars in 904 bytes} [Wed Apr 13 21:02:50 2016] GET /file-list/srw/WrrpgRmU/mirror?20160407 =&gt; generated 35 bytes in 2 msecs (HTTP/1.1 200) 2 headers in 79 bytes (1 switches on core 8)\\nWed Apr 13 21:04:58 2016 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 331] during POST /run (10.0.137.37)\\nIOError: write error\\n[pid: 198|app: 0|req: 37/36] 10.0.137.37 () {52 vars in 948 bytes} [Wed Apr 13 21:02:51 2016] POST /run =&gt; generated 86803 bytes in 127534 msecs (HTTP/1.1 200) 2 headers in 77 bytes (0 switches on core 4)\\nWed Apr 13 21:07:05 2016 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 331] during POST /run (10.0.137.37)\\nIOError: write error\\n[pid: 198|app: 0|req: 37/37] 10.0.137.37 () {52 vars in 948 bytes} [Wed Apr 13 21:04:51 2016] POST /run =&gt; generated 86803 bytes in 134292 msecs (HTTP/1.1 200) 2 headers in 77 bytes (0 switches on core 6)\\n</code></pre>\\n<p>The same problem is observed on alpha, see <a href=\"http://alpha.sirepo.com/srw#/beamline/s95YvwnI\" rel=\"nofollow\">http://alpha.sirepo.com/srw#/beamline/s95YvwnI</a>.</p>', 'url': 'https://github.com/radiasoft/sirepo/issues/161', 'state': 'CLOSED', 'createdAt': '2016-04-13T21:18:39Z', 'lastEditedAt': None, 'publishedAt': '2016-04-13T21:18:39Z', 'updatedAt': '2016-04-14T12:41:12Z', 'labels': ['1', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'RHEAS', 'repo_owner_name': 'NASA', 'repo_owner_email': 'github@lists.nasa.gov', 'repo_owner_user_name': 'nasa', 'repo_owner_profile_url': 'https://github.com/nasa', 'title': 'Ingestion of vic.soils in rheas database', 'bodyHTML': '<p>Please look into this matter. During buildout the vic.soils data is not getting ingested due to role associated with it, it always come up as, \"the kandread role does not exist\" and then discontinue the vic.soils ingestion into the rheas database. However, when done separately after buildout, the vic.soils data is successfully ingested.</p>', 'url': 'https://github.com/nasa/RHEAS/issues/4', 'state': 'CLOSED', 'createdAt': '2015-12-20T18:11:56Z', 'lastEditedAt': None, 'publishedAt': '2015-12-20T18:11:56Z', 'updatedAt': '2016-02-25T20:29:06Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'RHEAS', 'repo_owner_name': 'NASA', 'repo_owner_email': 'github@lists.nasa.gov', 'repo_owner_user_name': 'nasa', 'repo_owner_profile_url': 'https://github.com/nasa', 'title': 'RHEAS crashes when running forecast', 'bodyHTML': '<p>Error opening \"./tmpUjy52V/vic.state_20140101\".<br>\\nModel run-time error...<br>\\nUnable to open File<br>\\n...now exiting to system...</p>\\n<p>[forecast]<br>\\nmodel: vic<br>\\nstartdate: 2014-1-1<br>\\nenddate: 2014-06-30<br>\\nbasin: /home/oware/data/kecounty.shp<br>\\nname: kenyaFsim1<br>\\nresolution: 0.25<br>\\nensemble size: 10<br>\\nmethod: esp</p>\\n<p>[vic]<br>\\nprecip: chirps<br>\\ntemperature: ncep<br>\\nwind: ncep<br>\\nsave to: db<br>\\nsave: prec, soil_moist, runoff<br>\\ninitialize: off</p>\\n<h1>save state: /home/kandread/servir</h1>\\n<p>[dssat]<br>\\nshapefile: /home/oware/data/kecounty.shp<br>\\nensemble size: 40</p>', 'url': 'https://github.com/nasa/RHEAS/issues/7', 'state': 'CLOSED', 'createdAt': '2016-02-25T20:27:27Z', 'lastEditedAt': None, 'publishedAt': '2016-02-25T20:27:27Z', 'updatedAt': '2016-02-26T04:01:37Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'RHEAS', 'repo_owner_name': 'NASA', 'repo_owner_email': 'github@lists.nasa.gov', 'repo_owner_user_name': 'nasa', 'repo_owner_profile_url': 'https://github.com/nasa', 'title': 'Cannot fetch GPM data pre-Sept 2015', 'bodyHTML': \"<p>Every date I've tried post-September has worked. Everything in September and earlier has not. I've tried it with both Kostas's and my account. This is over the entire Mekong basin.</p>\", 'url': 'https://github.com/nasa/RHEAS/issues/22', 'state': 'CLOSED', 'createdAt': '2016-03-23T07:52:25Z', 'lastEditedAt': None, 'publishedAt': '2016-03-23T07:52:25Z', 'updatedAt': '2016-03-23T08:38:06Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'RHEAS', 'repo_owner_name': 'NASA', 'repo_owner_email': 'github@lists.nasa.gov', 'repo_owner_user_name': 'nasa', 'repo_owner_profile_url': 'https://github.com/nasa', 'title': 'severity equation', 'bodyHTML': '<p>Sorry, \\'severity\\' is pdsi, right? I\\'m getting the same issue as smdi where the results don\\'t align with outside examples I\\'m seeing. I know the index won\\'t be very accurate until I go decades back but again, we\\'re talking orders of magnitude.</p>\\n<p>Example from March 1 2016, 14 months into the run, NCEP/CMORPH, 0.25, entire region: <a href=\"http://i.imgur.com/Mzly8b9.png\" rel=\"nofollow\">http://i.imgur.com/Mzly8b9.png</a></p>', 'url': 'https://github.com/nasa/RHEAS/issues/28', 'state': 'CLOSED', 'createdAt': '2016-03-26T15:09:25Z', 'lastEditedAt': None, 'publishedAt': '2016-03-26T15:09:25Z', 'updatedAt': '2016-03-28T01:20:39Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'RHEAS', 'repo_owner_name': 'NASA', 'repo_owner_email': 'github@lists.nasa.gov', 'repo_owner_user_name': 'nasa', 'repo_owner_profile_url': 'https://github.com/nasa', 'title': 'writeForcings - CHIRPS - Maximum area?', 'bodyHTML': '<p>Did you ever come across this when doing Africa? Smaller BBoxes work (for both land and ocean... not an issue that CHIRPS gives ocean \\'nodata\\' as opposed to GPM/TRMM/CMORPH). But for the full LMR BBox I get:</p>\\n<pre><code>  File \"/media/adam/UbuData/RHEAS/RHEAS/src/vic/vic.py\", line 397, in writeForcings\\n    prec[i][2], tmax[i][2], tmin[i][2], wind[i][2]))\\nValueError: Unknown format code \\'f\\' for object of type \\'str\\'\\n</code></pre>\\n<p>Last section of the log... error occurs at the 4419th pixel.</p>\\n<pre><code>writing data_27.875_98.375\\nwriting data_27.875_98.625\\nwriting data_27.875_98.875\\nwriting data_27.875_99.125\\nwriting data_27.875_99.375\\nwriting data_8.125_93.125\\n</code></pre>\\n<p>It\\'s not that pixel (which is on an island, btw), which passes smoothly in a smaller area. There\\'s nothing out of the ordinary for the precip.chirps rasters in that area. It also runs fine when replacing CHIRPS/NCEP with CMORPH/NCEP.</p>\\n<p>Since CHIRPS has the highest spatial resolution and this 5-country LMR BBox has the largest extent that I\\'ve worked with, I\\'m tempted to believe there\\'s a limit to writing forcings. Did you ever run into this?</p>', 'url': 'https://github.com/nasa/RHEAS/issues/34', 'state': 'CLOSED', 'createdAt': '2016-03-30T07:49:21Z', 'lastEditedAt': None, 'publishedAt': '2016-03-30T07:49:21Z', 'updatedAt': '2016-04-26T02:19:52Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Serialization and const correctness?', 'bodyHTML': \"<p>I'm starting in on my first class using JSON, which will be a version of the NestedStructureSineWaves controller which reads the relevant variables from a text file. With the original controlelr, most of these variables were set in the constructor's initializer list and never changed, so they could be const. However, JSON has enough overhead that if I do the parsing in the class itself, I lose the ability to make these variables const, which is mildly undesirable.</p>\\n<p>I'd like some help thinking of the correct way to use JSON and maintain const correctness. Right now my best idea is to have JSON unload the variables into a struct (first thing on the initializer list), and then have the const variables read from that struct. That's a fair bit of extra code (every change like a new variable has to occur in two places), but isn't much worse than what we were already doing with some of our existing config structs or the config.ini in the learning code. Any other ideas? Any way to generalize my idea to an arbitrary number of variables so the code can be re-used?</p>\", 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/57', 'state': 'CLOSED', 'createdAt': '2014-09-03T18:38:21Z', 'lastEditedAt': None, 'publishedAt': '2014-09-03T18:38:21Z', 'updatedAt': '2014-09-04T17:37:38Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'MAC OSX 10.9 and the new building scripts', 'bodyHTML': '<p>I am trying to compile with OSX 10.9 again. With the new building scripts I ran into few problems, some of them are fixed, some of them are not.<br>\\n-We need to compile everything with gcc/g++ instead of clang. Clang doesn\\'t have tr1 libraries anymore (apple stopped supporting with 10.9).  We have to explicitely put this to every build script (setup_bullet, setup_neuralnet, etc.):<br>\\n-DCMAKE_C_COMPILER=\"gcc\" <br>\\n-DCMAKE_CXX_COMPILER=\"g++\" \\\\</p>\\n<p>This fixes the first level of compilation problems. Then we run into linking problems due to boost being compiled with clang while the rest is compiled using gcc.</p>\\n<p>-Second, we have to internally change the build script of the boost by enabling gcc.<br>\\nThis is why, we have this line at the end of build_boost.sh, it is currently commented out.</p>\\n<h1>For MAC and gcc</h1>\\n<pre><code>sed -i \\'\\' \\'s/^# using gcc ;/using gcc ;/g\\' tools/build/v2/user-config.jam\\n</code></pre>\\n<p>This solves the linker problems.</p>\\n<p>Then the next level of problems arise:<br>\\nthe setup script cannot compile bullet for some reason: I get these errors (bunch of them):</p>\\n<p>/opt/local/bin/ranlib: file: libOpenGLSupport.a(Win32DemoApplication.o) has no symbols<br>\\n/opt/local/bin/ranlib: file: libOpenGLSupport.a(Win32DemoApplication.o) has no symbols</p>\\n<p>This part is interesting because when I get into env/build/bullet folder and run the command \"make\", it compiles successfully.</p>\\n<p>So, somehow, I can run make in bullet, but our setup scripts receive linking errors.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/58', 'state': 'CLOSED', 'createdAt': '2014-09-03T20:22:11Z', 'lastEditedAt': None, 'publishedAt': '2014-09-03T20:22:11Z', 'updatedAt': '2014-09-06T16:26:19Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Review my README', 'bodyHTML': \"<p>I just pushed a README for my escape module to my dev folder (src/dev/steve/Escape_T6). If any of you could give it a quick read through and let me know what to change, I'd greatly appreciate it.</p>\", 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/81', 'state': 'OPEN', 'createdAt': '2014-09-24T21:48:30Z', 'lastEditedAt': None, 'publishedAt': '2014-09-24T21:48:30Z', 'updatedAt': '2014-09-25T22:29:53Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Change to Double Precision?', 'bodyHTML': '<p>Prior to merging in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"49291243\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/99\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/pull/99/hovercard\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/pull/99\">#99</a>, we need to determine if double precision breaks any of the validation results we have previously published. MuscleNP functions better with it (more stable) and the results from 6WCSCM I have tested move slightly further. A comparison to the ICRA 2015 results, as well as other validation results as available is required before making the change.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/100', 'state': 'CLOSED', 'createdAt': '2014-11-18T21:00:49Z', 'lastEditedAt': None, 'publishedAt': '2014-11-18T21:00:49Z', 'updatedAt': '2014-11-20T20:18:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Unit tests for tgUtil and the builder tools', 'bodyHTML': '<p>As identified in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"49291243\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/99\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/pull/99/hovercard\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/pull/99\">#99</a>, I had to make a change to tgUtil to get deterministic simulations, but I haven\\'t identified the cases that required the use of rand instead of negative identity. Ideally, solutions to this issue would generate tests for these cases and relevant functions of the builder tools.</p>\\n<p>This should be a prerequisite to merging in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"49291243\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/99\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/pull/99/hovercard\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/pull/99\">#99</a>.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/101', 'state': 'OPEN', 'createdAt': '2014-11-18T21:41:42Z', 'lastEditedAt': None, 'publishedAt': '2014-11-18T21:41:42Z', 'updatedAt': '2014-11-24T21:52:14Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Transition from SetRestLengthSingleStep to Pretension Parameter', 'bodyHTML': '<p>tgLinearString\\'s setRestLengthSingleStep should be deprecated in favor of the config\\'s pretension parameter. Users should make this transition ASAP as it solves issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"36706576\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/5\" data-hovercard-type=\"issue\" data-hovercard-url=\"/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/5/hovercard\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/5\">#5</a>, and we\\'re going to force it before version 1.1. T6RestLengthController is the file that needs to be changed in examples, there may be others in dev.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/104', 'state': 'CLOSED', 'createdAt': '2014-12-02T14:18:31Z', 'lastEditedAt': None, 'publishedAt': '2014-12-02T14:18:31Z', 'updatedAt': '2015-01-07T15:15:10Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'NTRT Default Scale?', 'bodyHTML': '<p>As we prep for version 1.1, it would be good to introduce a default scale throughout NTRT. Right now most of the spine demos seem to run at cm scale, while most of the SUPERBall run at dm, and the default for tgWorld is at meter scale. Some Config structs have a scale function, others do not.</p>\\n<p>Thoughts on what default units should be? Bullet default is MKS. Should we attempt to implement this for version 1.1, or just leave it as a recommendation? A tgWorld.getScale() would also be useful for model setup.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/105', 'state': 'OPEN', 'createdAt': '2014-12-04T19:25:25Z', 'lastEditedAt': None, 'publishedAt': '2014-12-04T19:25:25Z', 'updatedAt': '2014-12-04T20:23:54Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Core Dump on closing of AppT6Escape ', 'bodyHTML': '<p>I am running AppT6Escape with manual parameters for the controller and after the last pull, the program crashes at the very end of the program run.</p>\\n<p>I am on commit <a class=\"commit-link\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/commit/09ab2225887344bc7df34ec1622d871855019982\"><tt>09ab222</tt></a></p>\\n<p>********************** Termianl output on crash: *******************************<br>\\n*** Error in `./AppEscape_T6\\': double free or corruption (fasttop): 0x00000000015d1c20 ***<br>\\n======= Backtrace: =========<br>\\n/lib64/libc.so.6(+0x75a4f)[0x7f20fed95a4f]<br>\\n/lib64/libc.so.6(+0x7cd78)[0x7f20fed9cd78]<br>\\n/home/jonathan/Projects/Simulator/NTRTsim/build/tgcreator/libtgcreator.so(_ZN12CProfileNodeD1Ev+0x22)[0x7f2100c9b562]<br>\\n/lib64/libc.so.6(__cxa_finalize+0x9a)[0x7f20fed5945a]<br>\\n/home/jonathan/Projects/Simulator/NTRTsim/build/core/libcore.so(+0x715c3)[0x7f21006265c3]<br>\\n======= Memory map: ========<br>\\n00400000-0044d000 r-xp 00000000 00:21 2293364                            /home/jonathan/Projects/Simulator/NTRTsim/build/dev/steve/AppEscape_T6<br>\\n0064d000-0064e000 r--p 0004d000 00:21 2293364                            /home/jonathan/Projects/Simulator/NTRTsim/build/dev/steve/AppEscape_T6<br>\\n0064e000-0064f000 rw-p 0004e000 00:21 2293364                            /home/jonathan/Projects/Simulator/NTRTsim/build/dev/steve/AppEscape_T6<br>\\n01562000-05612000 rw-p 00000000 00:00 0                                  [heap]<br>\\n7f20fc43b000-7f20fc43d000 r-xp 00000000 00:21 15110                      /usr/lib64/libXau.so.6.0.0<br>\\n7f20fc43d000-7f20fc63d000 ---p 00002000 00:21 15110                      /usr/lib64/libXau.so.6.0.0<br>\\n7f20fc63d000-7f20fc63e000 r--p 00002000 00:21 15110                      /usr/lib64/libXau.so.6.0.0<br>\\n7f20fc63e000-7f20fc63f000 rw-p 00003000 00:21 15110                      /usr/lib64/libXau.so.6.0.0<br>\\n7f20fc63f000-7f20fc663000 r-xp 00000000 00:21 1389337                    /usr/lib64/liblzma.so.5.0.99<br>\\n7f20fc663000-7f20fc862000 ---p 00024000 00:21 1389337                    /usr/lib64/liblzma.so.5.0.99<br>\\n7f20fc862000-7f20fc863000 r--p 00023000 00:21 1389337                    /usr/lib64/liblzma.so.5.0.99<br>\\n7f20fc863000-7f20fc864000 rw-p 00024000 00:21 1389337                    /usr/lib64/liblzma.so.5.0.99<br>\\n7f20fc864000-7f20fc8c9000 r-xp 00000000 00:21 2538048                    /usr/lib64/libpcre.so.1.2.1<br>\\n7f20fc8c9000-7f20fcac8000 ---p 00065000 00:21 2538048                    /usr/lib64/libpcre.so.1.2.1<br>\\n7f20fcac8000-7f20fcac9000 r--p 00064000 00:21 2538048                    /usr/lib64/libpcre.so.1.2.1<br>\\n7f20fcac9000-7f20fcaca000 rw-p 00065000 00:21 2538048                    /usr/lib64/libpcre.so.1.2.1<br>\\n7f20fcaca000-7f20fcacd000 r-xp 00000000 00:21 2183116                    /usr/lib64/libdl-2.18.so<br>\\n7f20fcacd000-7f20fcccc000 ---p 00003000 00:21 2183116                    /usr/lib64/libdl-2.18.so<br>\\n7f20fcccc000-7f20fcccd000 r--p 00002000 00:21 2183116                    /usr/lib64/libdl-2.18.so<br>\\n7f20fcccd000-7f20fccce000 rw-p 00003000 00:21 2183116                    /usr/lib64/libdl-2.18.so<br>\\n7f20fccce000-7f20fccd9000 r-xp 00000000 00:21 2539068                    /usr/lib64/libdrm.so.2.4.0<br>\\n7f20fccd9000-7f20fced8000 ---p 0000b000 00:21 2539068                    /usr/lib64/libdrm.so.2.4.0<br>\\n7f20fced8000-7f20fced9000 r--p 0000a000 00:21 2539068                    /usr/lib64/libdrm.so.2.4.0<br>\\n7f20fced9000-7f20fceda000 rw-p 0000b000 00:21 2539068                    /usr/lib64/libdrm.so.2.4.0<br>\\n7f20fceda000-7f20fcefa000 r-xp 00000000 00:21 15969                      /usr/lib64/libxcb.so.1.1.0<br>\\n7f20fcefa000-7f20fd0f9000 ---p 00020000 00:21 15969                      /usr/lib64/libxcb.so.1.1.0<br>\\n7f20fd0f9000-7f20fd0fa000 r--p 0001f000 00:21 15969                      /usr/lib64/libxcb.so.1.1.0<br>\\n7f20fd0fa000-7f20fd0fb000 rw-p 00020000 00:21 15969                      /usr/lib64/libxcb.so.1.1.0<br>\\n7f20fd0fb000-7f20fd0ff000 r-xp 00000000 00:21 15949                      /usr/lib64/libxcb-dri2.so.0.0.0<br>\\n7f20fd0ff000-7f20fd2fe000 ---p 00004000 00:21 15949                      /usr/lib64/libxcb-dri2.so.0.0.0<br>\\n7f20fd2fe000-7f20fd2ff000 r--p 00003000 00:21 15949                      /usr/lib64/libxcb-dri2.so.0.0.0<br>\\n7f20fd2ff000-7f20fd300000 rw-p 00004000 00:21 15949                      /usr/lib64/libxcb-dri2.so.0.0.0<br>\\n7f20fd300000-7f20fd317000 r-xp 00000000 00:21 15950                      /usr/lib64/libxcb-glx.so.0.0.0<br>\\n7f20fd317000-7f20fd517000 ---p 00017000 00:21 15950                      /usr/lib64/libxcb-glx.so.0.0.0<br>\\n7f20fd517000-7f20fd519000 r--p 00017000 00:21 15950                      /usr/lib64/libxcb-glx.so.0.0.0<br>\\n7f20fd519000-7f20fd51a000 rw-p 00019000 00:21 15950                      /usr/lib64/libxcb-glx.so.0.0.0<br>\\n7f20fd51a000-7f20fd51b000 r-xp 00000000 00:21 15107                      /usr/lib64/libX11-xcb.so.1.0.0<br>\\n7f20fd51b000-7f20fd71a000 ---p 00001000 00:21 15107                      /usr/lib64/libX11-xcb.so.1.0.0<br>\\n7f20fd71a000-7f20fd71b000 r--p 00000000 00:21 15107                      /usr/lib64/libX11-xcb.so.1.0.0<br>\\n7f20fd71b000-7f20fd71c000 rw-p 00001000 00:21 15107                      /usr/lib64/libX11-xcb.so.1.0.0<br>\\n7f20fd71c000-7f20fd721000 r-xp 00000000 00:21 15117                      /usr/lib64/libXfixes.so.3.1.0<br>\\n7f20fd721000-7f20fd920000 ---p 00005000 00:21 15117                      /usr/lib64/libXfixes.so.3.1.0<br>\\n7f20fd920000-7f20fd921000 r--p 00004000 00:21 15117                      /usr/lib64/libXfixes.so.3.1.0<br>\\n7f20fd921000-7f20fd922000 rw-p 00005000 00:21 15117                      /usr/lib64/libXfixes.so.3.1.0<br>\\n7f20fd922000-7f20fd924000 r-xp 00000000 00:21 15113                      /usr/lib64/libXdamage.so.1.1.0<br>\\n7f20fd924000-7f20fdb23000 ---p 00002000 00:21 15113                      /usr/lib64/libXdamage.so.1.1.0<br>\\n7f20fdb23000-7f20fdb24000 r--p 00001000 00:21 15113                      /usr/lib64/libXdamage.so.1.1.0<br>\\n7f20fdb24000-7f20fdb25000 rw-p 00002000 00:21 15113                      /usr/lib64/libXdamage.so.1.1.0<br>\\n7f20fdb25000-7f20fdb46000 r-xp 00000000 00:21 117671                     /usr/lib64/libselinux.so.1<br>\\n7f20fdb46000-7f20fdd45000 ---p 00021000 00:21 117671                     /usr/lib64/libselinux.so.1<br>\\n7f20fdd45000-7f20fdd46000 r--p 00020000 00:21 117671                     /usr/lib64/libselinux.so.1<br>\\n7f20fdd46000-7f20fdd47000 rw-p 00021000 00:21 117671                     /usr/lib64/libselinux.so.1<br>\\n7f20fdd47000-7f20fdd49000 rw-p 00000000 00:00 0<br>\\n7f20fdd49000-7f20fdd6e000 r-xp 00000000 00:21 2538067                    /usr/lib64/libglapi.so.0.0.0<br>\\n7f20fdd6e000-7f20fdf6e000 ---p 00025000 00:21 2538067                    /usr/lib64/libglapi.so.0.0.0<br>\\n7f20fdf6e000-7f20fdf71000 r--p 00025000 00:21 2538067                    /usr/lib64/libglapi.so.0.0.0<br>\\n7f20fdf71000-7f20fdf72000 rw-p 00028000 00:21 2538067                    /usr/lib64/libglapi.so.0.0.0<br>\\n7f20fdf72000-7f20fdf73000 rw-p 00000000 00:00 0<br>\\n7f20fdf73000-7f20fdf9a000 r-xp 00000000 00:21 15311                      /usr/lib64/libexpat.so.1.6.0<br>\\n7f20fdf9a000-7f20fe19a000 ---p 00027000 00:21 15311                      /usr/lib64/libexpat.so.1.6.0<br>\\n7f20fe19a000-7f20fe19c000 r--p 00027000 00:21 15311                      /usr/lib64/libexpat.so.1.6.0<br>\\n7f20fe19c000-7f20fe19d000 rw-p 00029000 00:21 15311                      /usr/lib64/libexpat.so.1.6.0<br>\\n7f20fe19d000-7f20fe1a2000 r-xp 00000000 00:21 15134                      /usr/lib64/libXxf86vm.so.1.0.0<br>\\n7f20fe1a2000-7f20fe3a1000 ---p 00005000 00:21 15134                      /usr/lib64/libXxf86vm.so.1.0.0<br>\\n7f20fe3a1000-7f20fe3a2000 r--p 00004000 00:21 15134                      /usr/lib64/libXxf86vm.so.1.0.0<br>\\n7f20fe3a2000-7f20fe3a3000 rw-p 00005000 00:21 15134                      /usr/lib64/libXxf86vm.so.1.0.0<br>\\n7f20fe3a3000-7f20fe3b2000 r-xp 00000000 00:21 1734976                    /usr/lib64/libXi.so.6.1.0<br>\\n7f20fe3b2000-7f20fe5b1000 ---p 0000f000 00:21 1734976                    /usr/lib64/libXi.so.6.1.0<br>\\n7f20fe5b1000-7f20fe5b2000 r--p 0000e000 00:21 1734976                    /usr/lib64/libXi.so.6.1.0<br>\\n7f20fe5b2000-7f20fe5b3000 rw-p 0000f000 00:21 1734976                    /usr/lib64/libXi.so.6.1.0<br>\\n7f20fe5b3000-7f20fe6eb000 r-xp 00000000 00:21 15108                      /usr/lib64/libX11.so.6.3.0<br>\\n7f20fe6eb000-7f20fe8eb000 ---p 00138000 00:21 15108                      /usr/lib64/libX11.so.6.3.0<br>\\n7f20fe8eb000-7f20fe8ec000 r--p 00138000 00:21 15108                      /usr/lib64/libX11.so.6.3.0<br>\\n7f20fe8ec000-7f20fe8f1000 rw-p 00139000 00:21 15108                      /usr/lib64/libX11.so.6.3.0<br>\\n7f20fe8f1000-7f20fe902000 r-xp 00000000 00:21 15116                      /usr/lib64/libXext.so.6.4.0<br>\\n7f20fe902000-7f20feb01000 ---p 00011000 00:21 15116                      /usr/lib64/libXext.so.6.4.0<br>\\n7f20feb01000-7f20feb02000 r--p 00010000 00:21 15116                      /usr/lib64/libXext.so.6.4.0<br>\\n7f20feb02000-7f20feb03000 rw-p 00011000 00:21 15116                      /usr/lib64/libXext.so.6.4.0<br>\\n7f20feb03000-7f20feb1b000 r-xp 00000000 00:21 2183136                    /usr/lib64/libpthread-2.18.so<br>\\n7f20feb1b000-7f20fed1a000 ---p 00018000 00:21 2183136                    /usr/lib64/libpthread-2.18.so<br>\\n7f20fed1a000-7f20fed1b000 r--p 00017000 00:21 2183136                    /usr/lib64/libpthread-2.18.so<br>\\n7f20fed1b000-7f20fed1c000 rw-p 00018000 00:21 2183136                    /usr/lib64/libpthread-2.18.so<br>\\n7f20fed1c000-7f20fed20000 rw-p 00000000 00:00 0<br>\\n7f20fed20000-7f20feed4000 r-xp 00000000 00:21 2183110                    /usr/lib64/libc-2.18.so<br>\\n7f20feed4000-7f20ff0d3000 ---p 001b4000 00:21 2183110                    /usr/lib64/libc-2.18.so<br>\\n7f20ff0d3000-7f20ff0d7000 r--p 001b3000 00:21 2183110                    /usr/lib64/libc-2.18.so<br>\\n7f20ff0d7000-7f20ff0d9000 rw-p 001b7000 00:21 2183110                    /usr/lib64/libc-2.18.so<br>\\n7f20ff0d9000-7f20ff0de000 rw-p 00000000 00:00 0<br>\\n7f20ff0de000-7f20ff0f3000 r-xp 00000000 00:21 2076806                    /usr/lib64/libgcc_s-4.8.3-20140911.so.1<br>\\n7f20ff0f3000-7f20ff2f2000 ---p 00015000 00:21 2076806                    /usr/lib64/libgcc_s-4.8.3-20140911.so.1<br>\\n7f20ff2f2000-7f20ff2f3000 r--p 00014000 00:21 2076806                    /usr/lib64/libgcc_s-4.8.3-20140911.so.1<br>\\n7f20ff2f3000-7f20ff2f4000 rw-p 00015000 00:21 2076806                    /usr/lib64/libgcc_s-4.8.3-20140911.so.1<br>\\n7f20ff2f4000-7f20ff3f9000 r-xp 00000000 00:21 2183118                    /usr/lib64/libm-2.18.so<br>\\n7f20ff3f9000-7f20ff5f9000 ---p 00105000 00:21 2183118                    /usr/lib64/libm-2.18.so<br>\\n7f20ff5f9000-7f20ff5fa000 r--p 00105000 00:21 2183118                    /usr/lib64/libm-2.18.so<br>\\n7f20ff5fa000-7f20ff5fb000 rw-p 00106000 00:21 2183118                    /usr/lib64/libm-2.18.so<br>\\n7f20ff5fb000-7f20ff6e4000 r-xp 00000000 00:21 2076820                    /usr/lib64/libstdc++.so.6.0.19<br>\\n7f20ff6e4000-7f20ff8e4000 ---p 000e9000 00:21 2076820                    /usr/lib64/libstdc++.so.6.0.19<br>\\n7f20ff8e4000-7f20ff8ec000 r--p 000e9000 00:21 2076820                    /usr/lib64/libstdc++.so.6.0.19<br>\\n7f20ff8ec000-7f20ff8ee000 rw-p 000f1000 00:21 2076820                    /usr/lib64/libstdc++.so.6.0.19<br>\\n7f20ff8ee000-7f20ff903000 rw-p 00000000 00:00 0<br>\\n7f20ff903000-7f20ff90c000 r-xp 00000000 00:21 2269915                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Configuration/libConfiguration.so<br>\\n7f20ff90c000-7f20ffb0b000 ---p 00009000 00:21 2269915                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Configuration/libConfiguration.so<br>\\n7f20ffb0b000-7f20ffb0c000 r--p 00008000 00:21 2269915                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Configuration/libConfiguration.so<br>\\n7f20ffb0c000-7f20ffb0d000 rw-p 00009000 00:21 2269915                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Configuration/libConfiguration.so<br>\\n7f20ffb0d000-7f20ffb31000 r-xp 00000000 00:21 2270020                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/NeuroEvolution/libNeuroEvolution.so<br>\\n7f20ffb31000-7f20ffd30000 ---p 00024000 00:21 2270020                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/NeuroEvolution/libNeuroEvolution.so<br>\\n7f20ffd30000-7f20ffd31000 r--p 00023000 00:21 2270020                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/NeuroEvolution/libNeuroEvolution.so<br>\\n7f20ffd31000-7f20ffd32000 rw-p 00024000 00:21 2270020                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/NeuroEvolution/libNeuroEvolution.so<br>\\n7f20ffd32000-7f20ffd34000 r-xp 00000000 00:21 2269910                    /home/jonathan/Projects/Simulator/NTRTsim/build/helpers/libFileHelpers.so<br>\\n7f20ffd34000-7f20fff33000 ---p 00002000 00:21 2269910                    /home/jonathan/Projects/Simulator/NTRTsim/build/helpers/libFileHelpers.so<br>\\n7f20fff33000-7f20fff34000 r--p 00001000 00:21 2269910                    /home/jonathan/Projects/Simulator/NTRTsim/build/helpers/libFileHelpers.so<br>\\n7f20fff34000-7f20fff35000 rw-p 00002000 00:21 2269910                    /home/jonathan/Projects/Simulator/NTRTsim/build/helpers/libFileHelpers.so<br>\\n7f20fff35000-7f20fff56000 r-xp 00000000 00:21 2270013                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/AnnealEvolution/libAnnealEvolution.so<br>\\n7f20fff56000-7f2100155000 ---p 00021000 00:21 2270013                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/AnnealEvolution/libAnnealEvolution.so<br>\\n7f2100155000-7f2100156000 r--p 00020000 00:21 2270013                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/AnnealEvolution/libAnnealEvolution.so<br>\\n7f2100156000-7f2100157000 rw-p 00021000 00:21 2270013                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/AnnealEvolution/libAnnealEvolution.so<br>\\n7f2100157000-7f210019b000 r-xp 00000000 00:21 2270046                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/terrain/libterrain.so<br>\\n7f210019b000-7f210039b000 ---p 00044000 00:21 2270046                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/terrain/libterrain.so<br>\\n7f210039b000-7f210039d000 r--p 00044000 00:21 2270046                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/terrain/libterrain.so<br>\\n7f210039d000-7f210039e000 rw-p 00046000 00:21 2270046                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/terrain/libterrain.so<br>\\n7f210039e000-7f210039f000 rw-p 00000000 00:00 0<br>\\n7f210039f000-7f21003b4000 r-xp 00000000 00:21 2270123                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Adapters/libAdapters.so<br>\\n7f21003b4000-7f21005b3000 ---p 00015000 00:21 2270123                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Adapters/libAdapters.so<br>\\n7f21005b3000-7f21005b4000 r--p 00014000 00:21 2270123                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Adapters/libAdapters.so<br>\\n7f21005b4000-7f21005b5000 rw-p 00015000 00:21 2270123                    /home/jonathan/Projects/Simulator/NTRTsim/build/learning/Adapters/libAdapters.so<br>\\n7f21005b5000-7f210075c000 r-xp 00000000 00:21 2292597                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/libcore.so<br>\\n7f210075c000-7f210095c000 ---p 001a7000 00:21 2292597                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/libcore.so<br>\\n7f210095c000-7f2100964000 r--p 001a7000 00:21 2292597                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/libcore.so<br>\\n7f2100964000-7f210099d000 rw-p 001af000 00:21 2292597                    /home/jonathan/Projects/Simulator/NTRTsim/build/core/libcore.so<br>\\n7f210099d000-7f2100bbf000 rw-p 00000000 00:00 0<br>\\n7f2100bbf000-7f2100cbd000 r-xp 00000000 00:21 2292847                    /home/jonathan/Projects/Simulator/NTRTsim/build/tgcreator/libtgcreator.so<br>\\n7f2100cbd000-7f2100ebc000 ---p 000fe000 00:21 2292847                    /home/jonathan/Projects/Simulator/NTRTsim/build/tgcreator/libtgcreator.so<br>\\n7f2100ebc000-7f2100ec0000 r--p 000fd000 00:21 2292847                    /home/jonathan/Projects/Simulator/NTRTsim/build/tgcreator/libtgcreator.so<br>\\n7f2100ec0000-7f2100ec4000 rw-p 00101000 00:21 2292847                    /home/jonathan/Projects/Simulator/NTRTsim/build/tgcreator/libtgcreator.so<br>\\n7f2100ec4000-7f2100ec5000 rw-p 00000000 00:00 0<br>\\n7f2100ec5000-7f2100f32000 r-xp 00000000 00:21 1204971                    /usr/lib64/libGLU.so.1.3.1<br>\\n7f2100f32000-7f2101131000 ---p 0006d000 00:21 1204971                    /usr/lib64/libGLU.so.1.3.1<br>\\n7f2101131000-7f2101133000 r--p 0006c000 00:21 1204971                    /usr/lib64/libGLU.so.1.3.1<br>\\n7f2101133000-7f2101134000 rw-p 0006e000 00:21 1204971                    /usr/lib64/libGLU.so.1.3.1<br>\\n7f2101134000-7f21011c4000 r-xp 00000000 00:21 2539081                    /usr/lib64/libGL.so.1.2.0<br>\\n7f21011c4000-7f21013c3000 ---p 00090000 00:21 2539081                    /usr/lib64/libGL.so.1.2.0<br>\\n7f21013c3000-7f21013c6000 r--p 0008f000 00:21 2539081                    /usr/lib64/libGL.so.1.2.0<br>\\n7f21013c6000-7f21013c7000 rw-p 00092000 00:21 2539081                    /usr/lib64/libGL.so.1.2.0<br>\\n7f21013c7000-7f21013c8000 rw-p 00000000 00:00 0<br>\\n7f21013c8000-7f210140a000 r-xp 00000000 00:21 1214644                    /usr/lib64/libglut.so.3.9.0<br>\\n7f210140a000-7f2101609000 ---p 00042000 00:21 1214644                    /usr/lib64/libglut.so.3.9.0<br>\\n7f2101609000-7f210160d000 r--p 00041000 00:21 1214644                    /usr/lib64/libglut.so.3.9.0<br>\\n7f210160d000-7f2101612000 rw-p 00045000 00:21 1214644                    /usr/lib64/libglut.so.3.9.0<br>\\n7f2101612000-7f2101613000 rw-p 00000000 00:00 0<br>\\n7f2101613000-7f2101633000 r-xp 00000000 00:21 2183103                    /usr/lib64/ld-2.18.so<br>\\n7f21017f6000-7f2101808000 rw-p 00000000 00:00 0<br>\\n7f210182f000-7f2101832000 rw-p 00000000 00:00 0<br>\\n7f2101832000-7f2101833000 r--p 0001f000 00:21 2183103                    /usr/lib64/ld-2.18.so<br>\\n7f2101833000-7f2101834000 rw-p 00020000 00:21 2183103                    /usr/lib64/ld-2.18.so<br>\\n7f2101834000-7f2101835000 rw-p 00000000 00:00 0<br>\\n7fffc0b7f000-7fffc0ba0000 rw-p 00000000 00:00 0                          [stack]<br>\\n7fffc0bfc000-7fffc0bfe000 r--p 00000000 00:00 0                          [vvar]<br>\\n7fffc0bfe000-7fffc0c00000 r-xp 00000000 00:00 0                          [vdso]<br>\\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]<br>\\nAborted (core dumped)</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/111', 'state': 'CLOSED', 'createdAt': '2014-12-12T21:59:35Z', 'lastEditedAt': None, 'publishedAt': '2014-12-12T21:59:35Z', 'updatedAt': '2014-12-23T19:44:36Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': \"Seeking a Mac dev to maintain NTRT's mac builds.\", 'bodyHTML': \"<p>We're currently seeking a Mac dev who can help maintain NTRT on OS X systems. NTRTSim is currently broken for OS X, so that's the immediate concern. Once we have it working, we would like someone who can help ensure it remains that way!</p>\", 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/143', 'state': 'OPEN', 'createdAt': '2015-03-19T23:41:17Z', 'lastEditedAt': None, 'publishedAt': '2015-03-19T23:41:17Z', 'updatedAt': '2017-09-13T10:25:08Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Where to install NTRT libs', 'bodyHTML': \"<p>As a part of the Dev migration, we should provide a common file for NTRT libraries such that applications don't need to dig to a specific folder in the build path to get the libraries. Something like a lib or include at the top level as a common location.</p>\", 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/182', 'state': 'OPEN', 'createdAt': '2016-01-09T22:13:01Z', 'lastEditedAt': None, 'publishedAt': '2016-01-09T22:13:01Z', 'updatedAt': '2017-02-08T04:49:36Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'YAML parser code style consistency in App names and related', 'bodyHTML': '<p>Currently, the YAML parser / builder code does not meet the informal NTRT style that we have developed. For example, \"BuildTensegrityModel.cpp\" is compiled into \"BuildModel\" which is bad because the name changes, but this is also bad since BuildTensegrityModel.cpp has a main{} function, e.g., it\\'s an App file.</p>\\n<p>We should (a) come up with specific style guidelines about file names, particularly for App files, and (b) change the YAML parser code to match.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/206', 'state': 'OPEN', 'createdAt': '2017-02-07T23:28:52Z', 'lastEditedAt': None, 'publishedAt': '2017-02-07T23:28:52Z', 'updatedAt': '2017-02-07T23:28:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Various improvements to the tutorials framework.', 'bodyHTML': '<p>It\\'s currently unclear how to build the tutorials: my students and I had to dig around to figure out that we needed to install python-sphinx in our ubuntu environments. We should include these dependencies in our install instructions, and provide a guide on how to build them and use them,</p>\\n<p>Also, we should consider having the tutorials build automatically when the simulator is compiled. Maybe build.sh can have a flag to call make in the tutorials directory.</p>\\n<p>Also, the location and purpose of our tutorials, as well as the differentiation between tutorials and code documentation, should be better described: for example, the \"doc\" folder has the tutorials in it, while the src/DoxyDocs folder has the code documentation in it (?!?!)</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/207', 'state': 'OPEN', 'createdAt': '2017-02-07T23:35:00Z', 'lastEditedAt': None, 'publishedAt': '2017-02-07T23:35:00Z', 'updatedAt': '2017-04-04T11:07:04Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Learning Library understanding issue', 'bodyHTML': '<p>Hello all,</p>\\n<p>My goal is to develop new locomotion control algorithms for SUPERball. I have thus a controller with a given number of open parameters that need to be set. The learning library thus seemed appropriate for that. I have a few questions regarding its use.</p>\\n<ol>\\n<li>\\n<p>Everything seems to be running, but I am not sure I am understanding the output correctly. My actions are scaled and returned, but when I try to turn off the learning library and put the \"optimized parameters\" manually, the resulting distance using the graphical output of tgSimViewGraphics is not close at all to what was being obtained with tgSimView. Why would that be the case?</p>\\n</li>\\n<li>\\n<p>Additionally, I am not really sure I am understanding the log files correctly. Though the evolutiondefault.csv and scores.csv files seem to update correctly with my series of episodes, the bestParameters ones save parameters that I do not see throughout my run of episodes (I std::cout everything in my console and check that they really do not appear). Shouldn\\'t the best parameters reflect the best values returned by the adapter?</p>\\n</li>\\n<li>\\n<p>Finally, I am not really sure the results of one generation is being used in the next. There are indeed a few generations where the distance traveled is relatively high, but at the next ones drops back to relatively low values. I\\'ve been trying many combinations of the learning, startSeed, coevolution, leniencyCoef and MonteCarlo parameters, but still have not succeeded in achieving the results I am hoping for.</p>\\n</li>\\n</ol>\\n<p>Thanks in advance for your help!</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/213', 'state': 'OPEN', 'createdAt': '2017-04-13T16:15:41Z', 'lastEditedAt': None, 'publishedAt': '2017-04-13T16:15:41Z', 'updatedAt': '2017-05-13T16:30:30Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Reset errors', 'bodyHTML': '<p>Hello all,</p>\\n<p>I\\'ve been having some strange behavior in my SUPERball_CPG branch (latest commit <a class=\"commit-link\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/commit/fd62e0cbb16c3d56a91e84bd25a2211039cb8820\"><tt>fd62e0c</tt></a>). Specifically with the AppSUPERballPosition app, which I call with a YAML file.</p>\\n<p>I\\'ve been trying to run multiple episodes with the same controller parameters (that are manually set), just to check that I get the same traveled path between runs, but each episode gives a different total distance.</p>\\n<p>I checked that my time counters are correctly reset to 0 between runs, as well as my controller\\'s states. I also check that the model\\'s initial position is always the same.</p>\\n<p>In case somebody wants to try to re-create these problems, what you should be looking for is that when you run the app (by typing once the branch is cloned ./build/dev/mleroy/SUPERballPosition/AppSUPERballPosition ./resources/YamlStructures/mleroy_test3.yaml), it will run 3 episodes. Some details about each of those runs are as follows:</p>\\n<ul>\\n<li>On my onSetup function, my controller parameters are always set to the same values (which will be output on the console);</li>\\n<li>Two values are also cout-ed and correspond to states of my controller at the same timestamp (also to check that they are equal between runs);</li>\\n<li>The CoM position is then also cout-ed at another timestamp, along with all states of the controller. Even though states are equal, positions are not;</li>\\n<li>The polar distance traveled is then cout-ed at the end of the 30s run.<br>\\n(These are all implemented within src/dev/mleroy/SUPERballPosition/HopfControllerML.cpp/h)</li>\\n</ul>\\n<p>I also reset the time counters and controller states between runs, and check that the model\\'s initial position is always the same at time t=0.<br>\\n(These are called in src/dev/mleroy/SUPERballPosition/AppSUPERballPosition.cpp) My guess is that the error is at some point with the reset call.</p>\\n<p>You\\'ll see that if you call ./build/dev/mleroy/SUPERballPosition/AppSUPERballPosition ./resources/YamlStructures/mleroy_test3.yaml multiple times, you\\'ll always get the same x1, x2 and x3 total distances traveled, but that x1!=x2!=x3.</p>\\n<p>Thanks in advance!</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/14554016/26267584/e0f8ebb6-3c9f-11e7-9d5d-eaf910b69708.png\"><img src=\"https://cloud.githubusercontent.com/assets/14554016/26267584/e0f8ebb6-3c9f-11e7-9d5d-eaf910b69708.png\" alt=\"screen shot 2017-05-19 at 14 30 45 2\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/215', 'state': 'OPEN', 'createdAt': '2017-05-19T21:33:41Z', 'lastEditedAt': None, 'publishedAt': '2017-05-19T21:33:41Z', 'updatedAt': '2018-06-09T17:56:49Z', 'labels': ['bug', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'NTRTsim', 'repo_owner_name': 'NASA Tensegrity Robotics Toolkit', 'repo_owner_email': '', 'repo_owner_user_name': 'NASA-Tensegrity-Robotics-Toolkit', 'repo_owner_profile_url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit', 'title': 'Previously built executables not deleted with build.sh -c', 'bodyHTML': '<p>Similar to issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"296136838\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/220\" data-hovercard-type=\"issue\" data-hovercard-url=\"/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/220/hovercard\" href=\"https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/220\">#220</a> , executables under build/ are still present when switching branches and running build.sh or even build.sh -c. Makes it very confusing to see what\\'s being built. We need to do something to clear out old, compiled files when switching branches. Could include...</p>\\n<p>Having extra flags (or just adjusting make clean) with the build.sh script<br>\\nForcing a run of make clean (build.sh -c) when changing branches</p>\\n<p>This must be a solved problem with other cpp code? We should find a solution online.</p>', 'url': 'https://github.com/NASA-Tensegrity-Robotics-Toolkit/NTRTsim/issues/221', 'state': 'OPEN', 'createdAt': '2018-02-10T21:49:41Z', 'lastEditedAt': None, 'publishedAt': '2018-02-10T21:49:41Z', 'updatedAt': '2018-02-10T21:49:41Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'GSAOpenSourceImplementation', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Code Review Checklist - Questions to ask during code review', 'bodyHTML': '<p>Code review is one of the steps in the Open Source process.  Our team has developed a checklist for the application development project Subject-Matter Experts such as System Analysts and Programmers to review the project source code.</p>\\n<ol>\\n<li>Does the app source code contain PII or financial sensitive Information?</li>\\n<li>Does the apps source code contain password?</li>\\n<li>Does the apps source code contain security management features such as security keys, encryption and decryption business logics? \\xa0</li>\\n</ol>\\n<p>All the answers need to be NO before the project team can release the source code to public or store it in a public repo.</p>\\n<p>I suggest that this might be code review guideline we can add to this Open Source Policy.</p>\\n<p>Controlled Unclassified Information (CUI) is probably the updated terminology for PII or financial sensitive Information.</p>', 'url': 'https://github.com/GSA/GSAOpenSourceImplementation/issues/5', 'state': 'CLOSED', 'createdAt': '2017-05-30T15:49:09Z', 'lastEditedAt': '2017-05-31T19:00:52Z', 'publishedAt': '2017-05-30T15:49:09Z', 'updatedAt': '2017-06-05T13:07:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'testing-cookbook', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Identify good browser testing tools and provide guidance for different use cases', 'bodyHTML': '<p>So, I\\'ve been researching this topic on and off for months now, and have basically gotten nowhere. What we desperately need at 18F is a good browser (\"functional\") testing tool that we can easily add to our projects. My ideal would be one that does the following:</p>\\n<ol>\\n<li>Uses Selenium (both locally and remotely)</li>\\n<li>Supports cloud services like <a href=\"https://saucelabs.com/\" rel=\"nofollow\">Sauce Labs</a> or <a href=\"https://www.browserstack.com/\" rel=\"nofollow\">BrowserStack</a> out of the box</li>\\n<li>Runs easily on CI services like Travis and Circle</li>\\n</ol>\\n<p>The CI requirement is tricky, as I\\'ve documented in <a href=\"https://github.com/18F/college-choice/pull/1260\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/RTICWDT/college-scorecard/pull/1260/hovercard\">this pull request</a>, especially when your app needs to run alongside the test suite with a language other than Node. So, in addition to just identifying a tool, we should also provide some recipes and/or boilerplate for the following matrix of environments:</p>\\n<ol>\\n<li>Running tests on different Selenium environments:\\n<ul>\\n<li>with local browsers (including PhantomJS) using Selenium Server</li>\\n<li>with virtual browsers on cloud services like Sauce Labs</li>\\n</ul>\\n</li>\\n<li>Running tests against different app/site URLs:\\n<ul>\\n<li>a static, public URL</li>\\n<li>a local URL over a tunnel, e.g. with <a href=\"https://docs.saucelabs.com/reference/sauce-connect/\" rel=\"nofollow\">Sauce Connect</a></li>\\n<li>an \"ephemeral\" local server URL, e.g. when you run your app server alongside the test suite on CI services</li>\\n</ul>\\n</li>\\n<li>A series of target browsers, hopefully identified via analytics and/or research, <em>on one or more of the above environments</em>, for instance:\\n<ul>\\n<li>Chrome and Firefox (theoretically the same on all platforms, locally or virtually)</li>\\n<li>Internet Explorer (9, 10, 11, Edge, etc.) on Windows, virtually</li>\\n<li>Safari on iOS (virtually)</li>\\n<li>Chrome on Android (virtually)</li>\\n</ul>\\n</li>\\n</ol>\\n<p>Also, I think it would be good for this cookbook to help people avoid writing tons of browser tests by writing better unit tests to cover \"core\" JavaScript, and <em>only</em> browser test the parts of their code that interface with browser APIs. This should help us avoid writing <a href=\"https://github.com/18F/calc/blob/master/selenium_tests/tests.py\">bloated, difficult-to-maintain browser test suites</a> and save a bunch of time waiting for the tests to run on (potentially) lots of different browsers.</p>\\n<p>It feels to me like I\\'m the wrong person for this job, not only because I\\'m relatively new to testing, but because I also just don\\'t have any time for it right now. So I\\'m tapping <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=933586\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/DavidEBest\">@DavidEBest</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=173848\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yozlet\">@yozlet</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1633460\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jmcarp\">@jmcarp</a>, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1701077\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/msecret\">@msecret</a> and <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4153048\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/vzvenyach\">@vzvenyach</a> because they have some interest and/or experience with this stuff, and I wholeheartedly defer to their judgement. Feel free to rope in other folks who know about this, and share thoughts or resources here.</p>\\n<p>I mentioned to Yoz that I\\'ve had a hard time finding any good examples of browser testing tools like <a href=\"http://nightwatchjs.org/\" rel=\"nofollow\">Nightwatch</a> and <a href=\"http://webdriver.io/\" rel=\"nofollow\">WebDriverIO</a> in practice (as used on an actual site, as opposed to just usage examples), so that might be a good place to start. It\\'s also probably worth listing the testing needs of projects that we\\'ve all worked on so that we can get a better sense of what our needs as an organization are. I\\'m happy to contribute those for the projects I\\'ve worked on so far.</p>', 'url': 'https://github.com/18F/testing-cookbook/issues/18', 'state': 'OPEN', 'createdAt': '2015-10-15T18:53:57Z', 'lastEditedAt': None, 'publishedAt': '2015-10-15T18:53:57Z', 'updatedAt': '2016-02-18T23:58:38Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'cloud-foundry-cli', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Better support for cloud.gov Service Accounts', 'bodyHTML': '<p>Because of <a href=\"https://cloud.gov/docs/services/cloud-gov-service-account/\" rel=\"nofollow\">cloud.gov Service Accounts</a> being scoped to an org and space, the <code>cf_deploy.sh</code> shouldn\\'t require an org or space in order to <em>better</em> enforce deployments using these cloud.gov Service Accounts.</p>\\n<p>Documentation in the Read Me should also talk about how to set multiple credentials in CircleCI for different deploying to separate spaces since cloud.gov Service Accounts can no longer be shared across spaces.</p>', 'url': 'https://github.com/18F/cloud-foundry-cli/issues/7', 'state': 'OPEN', 'createdAt': '2018-01-26T23:07:23Z', 'lastEditedAt': None, 'publishedAt': '2018-01-26T23:07:23Z', 'updatedAt': '2018-04-23T21:11:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cloud-foundry-cli', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Better support for first-time deployments', 'bodyHTML': \"<p>Because <code>cf_deploy.sh</code> only uses the Autopilot plugin, apps will fail to push if it's the first time they're being deployed. The deployment script should support the scenario when the application doesn't already exist in the supplied org and space.</p>\", 'url': 'https://github.com/18F/cloud-foundry-cli/issues/8', 'state': 'CLOSED', 'createdAt': '2018-01-26T23:09:06Z', 'lastEditedAt': None, 'publishedAt': '2018-01-26T23:09:06Z', 'updatedAt': '2018-04-09T12:32:30Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cloud-foundry-cli', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Better support for existing deployments', 'bodyHTML': '<p>We should leverage <a href=\"https://github.com/odlp/antifreeze\">Anitfreeze</a> here in order to be absolutely sure that CF manifests match when doing an Autopilot deployment.</p>', 'url': 'https://github.com/18F/cloud-foundry-cli/issues/9', 'state': 'OPEN', 'createdAt': '2018-01-26T23:10:41Z', 'lastEditedAt': None, 'publishedAt': '2018-01-26T23:10:41Z', 'updatedAt': '2018-01-26T23:11:22Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cloud-foundry-cli', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add a login script without any cf push', 'bodyHTML': '<p>I want to be able to run arbitrary cf commands like <code>cf run-task</code>. To do this I have to run all the login commands myslef. If this was a script, I could use it and it could be re-used in <code>cf_deploy.sh</code>.</p>', 'url': 'https://github.com/18F/cloud-foundry-cli/issues/11', 'state': 'OPEN', 'createdAt': '2018-04-07T16:53:23Z', 'lastEditedAt': None, 'publishedAt': '2018-04-07T16:53:23Z', 'updatedAt': '2018-04-07T18:33:54Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-style', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Increase Width of Data Quality Score Tag', 'bodyHTML': '<p><strong>Is your feature request related to a problem? Please describe.</strong><br>\\nA clear and concise description of what the problem is. Ex. I\\'m always frustrated when [...]<br>\\nNeed width to be larger per <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"375665960\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/GSA/caribou/issues/8\" data-hovercard-type=\"issue\" data-hovercard-url=\"/GSA/caribou/issues/8/hovercard\" href=\"https://github.com/GSA/caribou/issues/8\">GSA/caribou#8</a></p>\\n<p><strong>Describe the solution you\\'d like</strong><br>\\nA clear and concise description of what you want to happen.<br>\\nEdit the scss file for the card <a href=\"https://github.com/GSA/code-gov-style/blob/master/_sass/_cards.scss#L21\">https://github.com/GSA/code-gov-style/blob/master/_sass/_cards.scss#L21</a></p>\\n<p><strong>Describe alternatives you\\'ve considered</strong><br>\\nA clear and concise description of any alternative solutions or features you\\'ve considered.<br>\\nN/A</p>\\n<p><strong>Additional context</strong><br>\\nAdd any other context or screenshots about the feature request here.<br>\\nAfter the update in made the code-gov-style, we\\'ll need to update the version of code-gov-style for the main site.</p>', 'url': 'https://github.com/GSA/code-gov-style/issues/31', 'state': 'OPEN', 'createdAt': '2018-11-08T15:49:25Z', 'lastEditedAt': None, 'publishedAt': '2018-11-08T15:49:25Z', 'updatedAt': '2018-11-08T15:51:19Z', 'labels': ['enhancement', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-style', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Sidebar should change text to blue on hover', 'bodyHTML': '<p><strong>Is your feature request related to a problem? Please describe.</strong><br>\\nA clear and concise description of what the problem is. Ex. I\\'m always frustrated when [...]<br>\\nChange styling on hover in sidebar</p>\\n<p><strong>Describe the solution you\\'d like</strong><br>\\nA clear and concise description of what you want to happen.<br>\\nHover should change text to blue and shouldn\\'t change background</p>\\n<p><strong>Describe alternatives you\\'ve considered</strong><br>\\nA clear and concise description of any alternative solutions or features you\\'ve considered.</p>\\n<p><strong>Additional context</strong><br>\\nAdd any other context or screenshots about the feature request here.<br>\\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"378336855\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/GSA/caribou/issues/41\" data-hovercard-type=\"issue\" data-hovercard-url=\"/GSA/caribou/issues/41/hovercard\" href=\"https://github.com/GSA/caribou/issues/41\">GSA/caribou#41</a></p>\\n<p>The sidebar styling is used by the about section</p>', 'url': 'https://github.com/GSA/code-gov-style/issues/37', 'state': 'CLOSED', 'createdAt': '2018-11-13T18:46:42Z', 'lastEditedAt': None, 'publishedAt': '2018-11-13T18:46:42Z', 'updatedAt': '2018-11-14T03:38:44Z', 'labels': ['enhancement', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-style', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Internet Explorer: Filter Box Text Misplaced', 'bodyHTML': '<p><strong>Describe the bug</strong><br>\\nA clear and concise description of what the bug is.</p>\\n<p><strong>To Reproduce</strong><br>\\nSteps to reproduce the behavior:</p>\\n<ol>\\n<li>Go to <a href=\"https://gsa.github.io/code-gov-style/components/filter\" rel=\"nofollow\">https://gsa.github.io/code-gov-style/components/filter</a></li>\\n</ol>\\n<p><strong>Expected behavior</strong><br>\\nA clear and concise description of what you expected to happen.</p>\\n<p><strong>Screenshots</strong><br>\\nIf applicable, add screenshots to help explain your problem.<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4313463/48498056-5e556200-e803-11e8-8cfe-6bf27104d3bb.png\"><img src=\"https://user-images.githubusercontent.com/4313463/48498056-5e556200-e803-11e8-8cfe-6bf27104d3bb.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p><strong>Desktop (please complete the following information):</strong></p>\\n<ul>\\n<li>OS: [e.g. iOS]</li>\\n<li>Browser [e.g. chrome, safari] IE</li>\\n<li>Version [e.g. 22]</li>\\n</ul>\\n<p><strong>Smartphone (please complete the following information):</strong></p>\\n<ul>\\n<li>Device: [e.g. iPhone6]</li>\\n<li>OS: [e.g. iOS8.1]</li>\\n<li>Browser [e.g. stock browser, safari]</li>\\n<li>Version [e.g. 22]</li>\\n</ul>\\n<p><strong>Additional context</strong><br>\\nAdd any other context about the problem here.</p>', 'url': 'https://github.com/GSA/code-gov-style/issues/41', 'state': 'OPEN', 'createdAt': '2018-11-14T16:50:45Z', 'lastEditedAt': None, 'publishedAt': '2018-11-14T16:50:45Z', 'updatedAt': '2018-11-14T16:50:45Z', 'labels': ['bug', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'openIAE', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Does anyone out there use a .NET client to consume RPC web services?', 'bodyHTML': '<p>One of SAM\\'s interfacing systems has reported an issue consuming the SAM web service from a Microsoft .NET client. Microsoft .NET supports only Document-style WSDL formats. RPC is typically used with Java programming language.</p>\\n<p>The SAM WSDL, \"<a href=\"https://gw.sam.gov/SAMWS/1.0/Entity?wsdl\" rel=\"nofollow\">https://gw.sam.gov/SAMWS/1.0/Entity?wsdl</a>\", is in RPC format.  Has anyone had to consume a Java RPC web service using a .NET client? Please reply if you can help out.</p>\\n<p>Here is a link on the difference between RPC and Document formats:  <a href=\"http://www.ibm.com/developerworks/library/ws-whichwsdl\" rel=\"nofollow\">http://www.ibm.com/developerworks/library/ws-whichwsdl</a><br>\\nHere is the link on MSDN with a background:<br>\\n<a href=\"https://social.msdn.microsoft.com/Forums/vstudio/en-US/07edda1a-d0d5-4920-b2fb-a25c803269d6/trouble-with-consuming-a-java-rpc-web-service-using-net-client?forum=wcf\" rel=\"nofollow\">https://social.msdn.microsoft.com/Forums/vstudio/en-US/07edda1a-d0d5-4920-b2fb-a25c803269d6/trouble-with-consuming-a-java-rpc-web-service-using-net-client?forum=wcf</a></p>\\n<p>Thanks in advance!!</p>', 'url': 'https://github.com/GSA/openIAE/issues/14', 'state': 'OPEN', 'createdAt': '2015-01-08T14:31:40Z', 'lastEditedAt': None, 'publishedAt': '2015-01-08T14:31:40Z', 'updatedAt': '2015-01-08T15:54:37Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'iPad: image capture mode can break map', 'bodyHTML': '<p>On iPad, if</p>\\n<ul>\\n<li>image download mode is invoked</li>\\n<li>then it\\'s closed</li>\\n<li>then you rotate the screen a few times</li>\\n</ul>\\n<p>the usable map area becomes greatly reduced.  See attached screen capture - the bottom part of the map is missing.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/7243823/18457953/e58cb7a4-792a-11e6-94b1-5e80628c1732.PNG\"><img src=\"https://cloud.githubusercontent.com/assets/7243823/18457953/e58cb7a4-792a-11e6-94b1-5e80628c1732.PNG\" alt=\"ipad-bottom-map-missing\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/61', 'state': 'CLOSED', 'createdAt': '2016-09-13T00:53:25Z', 'lastEditedAt': None, 'publishedAt': '2016-09-13T00:53:25Z', 'updatedAt': '2018-05-04T19:14:05Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Open source projects link is broken on mobile', 'bodyHTML': '<p>In the \"About\" window, there is a link to the other open source projects used by Worldview:</p>\\n<ul>\\n<li>Worldview is built by the NASA/GSFC Earth Science Data and Information System (ESDIS) Project and is grateful for the use of many open source projects.</li>\\n</ul>\\n<p>If on a desktop-sized browser, it links here (and works):<br>\\n<a href=\"https://worldview.earthdata.nasa.gov/pages/worldview-opensourcelibs.html\" rel=\"nofollow\">https://worldview.earthdata.nasa.gov/pages/worldview-opensourcelibs.html</a></p>\\n<p>If on a mobile-sized browser, it links here (and breaks):<br>\\n<a href=\"https://worldview.earthdata.nasa.gov/brand/pages/pages/worldview-opensourcelibs.html\" rel=\"nofollow\">https://worldview.earthdata.nasa.gov/brand/pages/pages/worldview-opensourcelibs.html</a></p>\\n<p>This can be reproduced in the desktop if you make the browser small enough to switch into \"mobile mode\".</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/62', 'state': 'CLOSED', 'createdAt': '2016-09-13T01:03:17Z', 'lastEditedAt': None, 'publishedAt': '2016-09-13T01:03:17Z', 'updatedAt': '2017-11-28T19:53:50Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Include ability to add marker/pin by entering specific lat/long coordinates', 'bodyHTML': \"<p>User request: Hi, I'm trying to use the satellite images in NASA Worldview to look at cloud cover over particular places. I know the lat/lon of these places, but I'd like to be able to put a marker where they are, so it can be seen if there's cloud cover over these places at exact times. I was just wondering if there was a way of doing this, because once the image is downloaded, I don't know exactly where my locations are. Thanks.</p>\", 'url': 'https://github.com/nasa-gibs/worldview/issues/97', 'state': 'OPEN', 'createdAt': '2016-12-21T20:49:51Z', 'lastEditedAt': '2016-12-21T21:02:13Z', 'publishedAt': '2016-12-21T20:49:51Z', 'updatedAt': '2018-08-23T16:04:18Z', 'labels': ['help wanted', 'idea'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Remove wv.mobile.css separate stylesheet; convert rules to mobile first', 'bodyHTML': '<p>We do not not need a separate mobile stylesheet. We should set mobile rules in their respective stylesheet and use @min-width rules not @max-width to prioritize mobile-first and better organize rules.</p>\\n<p>It is harder to read when a rule is in a separate location and it is better for mobile devices when the mobile rule is specified first followed by an @min-width rule for desktop.</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/426', 'state': 'OPEN', 'createdAt': '2017-07-24T13:30:27Z', 'lastEditedAt': None, 'publishedAt': '2017-07-24T13:30:27Z', 'updatedAt': '2018-10-22T16:04:09Z', 'labels': ['good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'WV SIT in GIBS environment - Multiple issues', 'bodyHTML': '<p>First issue is when I run \"fetch\". We unset the proxy to allow fetching of the getCapabilities:</p>\\n<pre><code>[gibs@tools-sit ~]$ cd /usr/share/gibs/ecc/worldview\\n[gibs@tools-sit worldview]$ unset https_proxy\\n[gibs@tools-sit worldview]$ unset HTTPS_PROXY\\n[gibs@tools-sit worldview]$ unset http_proxy\\n[gibs@tools-sit worldview]$ unset HTTP_PROXY\\n[gibs@tools-sit worldview]$ cd /usr/share/gibs/ecc/worldview\\n[gibs@tools-sit worldview]$ /usr/bin/grunt fetch --env sit-ext --force\\nRunning \"exec:fetch\" (exec) task\\n&gt;&gt; wv-options-fetch: ERROR: local variable \\'ident\\' referenced before assignment\\n&gt;&gt; wv-options-fetch: ERROR: local variable \\'ident\\' referenced before assignment\\nwv-options-fetch: https://sit.gibs.earthdata.nasa.gov/wmts/epsg4326/all/wmts.cgi?request=GetCapabilities\\nwv-options-fetch: https://sit.gibs.earthdata.nasa.gov/wmts/epsg4326/best/wmts.cgi?request=GetCapabilities\\nwv-options-fetch: https://sit.gibs.earthdata.nasa.gov/wmts/epsg4326/nrt/wmts.cgi?request=GetCapabilities\\nwv-options-fetch: https://sit.gibs.earthdata.nasa.gov/wmts/epsg4326/std/wmts.cgi?request=GetCapabilities\\n</code></pre>\\n<p>Next issue is when \"config\" is ran: We reset the proxies for this part.</p>\\n<pre><code>[gibs@tools-sit worldview]$ set HTTP_PROXY\\n[gibs@tools-sit worldview]$ set http_proxy\\n[gibs@tools-sit worldview]$ set HTTPS_PROXY\\n[gibs@tools-sit worldview]$ set https_proxy\\n[gibs@tools-sit worldview]$ /usr/bin/grunt config --env sit-ext\\nRunning \"remove:build_config\" (remove) task\\n&gt;&gt; 2 paths cleaned.\\n\\nRunning \"git-rev-parse:config\" (git-rev-parse) task\\n&gt;&gt; 91ce88\\n\\nRunning \"remove:config_src\" (remove) task\\n&gt;&gt; 0 paths cleaned.\\n\\nRunning \"exec:config\" (exec) task\\nwv-options-wmts: 0 error(s), 0 warning(s), 2 layers for GIBS:epsg4326:all\\nwv-options-wmts: 0 error(s), 0 warning(s), 540 layers for GIBS:epsg4326:best\\nwv-options-wmts: 0 error(s), 0 warning(s), 227 layers for GIBS:epsg4326:nrt\\nwv-options-wmts: 0 error(s), 0 warning(s), 455 layers for GIBS:epsg4326:std\\n&gt;&gt; Traceback (most recent call last):\\n&gt;&gt;   File \"bin/../bin/wv-options-wmts\", line 232, in &lt;module&gt;\\n&gt;&gt;     error_count, warning_count, layer_count = process_entry(entry, colormaps)\\n&gt;&gt;   File \"bin/../bin/wv-options-wmts\", line 192, in process_entry\\n&gt;&gt;     id = gc_layer[\"ows:Identifier\"]\\n&gt;&gt; TypeError: string indices must be integers\\n&gt;&gt; Exited with code: 1.\\nWarning: Task \"exec:config\" failed. Use --force to continue.\\n</code></pre>', 'url': 'https://github.com/nasa-gibs/worldview/issues/491', 'state': 'CLOSED', 'createdAt': '2017-08-31T13:05:44Z', 'lastEditedAt': '2017-08-31T13:08:09Z', 'publishedAt': '2017-08-31T13:05:44Z', 'updatedAt': '2017-08-31T21:50:39Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Separate dependencies and devDependencies in the package.json', 'bodyHTML': '<p>To let people know what dependences are used in the end product.</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/500', 'state': 'CLOSED', 'createdAt': '2017-09-06T19:32:54Z', 'lastEditedAt': None, 'publishedAt': '2017-09-06T19:32:54Z', 'updatedAt': '2018-01-17T18:05:32Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Date selector is positioned strangely on mobile', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/516388/30445433-ed95ef7a-9953-11e7-85bd-37de84e4010e.jpg\"><img src=\"https://user-images.githubusercontent.com/516388/30445433-ed95ef7a-9953-11e7-85bd-37de84e4010e.jpg\" alt=\"image uploaded from ios\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/518', 'state': 'CLOSED', 'createdAt': '2017-09-14T17:52:24Z', 'lastEditedAt': None, 'publishedAt': '2017-09-14T17:52:24Z', 'updatedAt': '2018-02-07T19:21:22Z', 'labels': ['bug', 'good first issue', 'help wanted', 'wontfix'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': \"Script for checking links in metadata/layer description files for 404's\", 'bodyHTML': '<p>Check for 404\\'s or redirects.<br>\\nScript should also change the md file links to html links. MD links don\\'t allow for target blank so to get that functionality now in the js modal windows / search descriptions, we are looping through those ares and adding target=\"_blank\" to each link open them in a new window. But the md link syntax doesn\\'t allow for target=_blank so it needs to be changed to html syntax</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/520', 'state': 'CLOSED', 'createdAt': '2017-09-15T15:43:05Z', 'lastEditedAt': None, 'publishedAt': '2017-09-15T15:43:05Z', 'updatedAt': '2018-06-26T20:36:52Z', 'labels': ['good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Animation Download not working in Internet Explorer [id.gif.4, date.animation.gif.3-6]', 'bodyHTML': \"<p>Displays message <code>Do you want to allow this website to open an app on your computer?</code> Then it is saying it is trying to open a blob.</p>\\n<p>Tests<br>\\n<code>id.gif.4</code><br>\\n<code>date.animation.gif.3</code> - Download button doesn't work in IE11<br>\\n<code>date.animation.gif.4-6</code> - An unexpected error has occurred. No errors in console</p>\", 'url': 'https://github.com/nasa-gibs/worldview/issues/530', 'state': 'CLOSED', 'createdAt': '2017-09-22T19:06:41Z', 'lastEditedAt': '2017-09-22T19:37:46Z', 'publishedAt': '2017-09-22T19:06:41Z', 'updatedAt': '2018-05-24T19:39:30Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Replacement solution for scroll bar', 'bodyHTML': \"<p>Right now, we've got several third party libraries that remove native scrollbars and replace them with JavaScript versions. This was originally done to improve the style of the app, since native scrollbars were ugly and obtrusive. Native scrollbars have recently improved to the point where we don't need to rely on replacements anymore. We should remove all references to and dependencies on Perfect Scrollbar, Mobiscroll, and jScrollPane and use native scrollbars everywhere.</p>\\n<p>This will require some attention to detail to make sure that the appearance and functionality of all affected scrollbars is acceptable in all browsers; Chrome/Safari/Firefox on Windows and Mac, as well as Chrome on Android and Safari on iOS.</p>\", 'url': 'https://github.com/nasa-gibs/worldview/issues/558', 'state': 'CLOSED', 'createdAt': '2017-10-05T18:17:45Z', 'lastEditedAt': '2017-10-16T18:37:30Z', 'publishedAt': '2017-10-05T18:17:45Z', 'updatedAt': '2018-10-01T16:27:36Z', 'labels': ['good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Fix links to issue tags in the contributing docs', 'bodyHTML': '<p>The <a href=\"https://github.com/nasa-gibs/worldview/blob/master/CONTRIBUTING.md\">contributing docs</a> have a number of links to issue that are not linked correctly.</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/570', 'state': 'CLOSED', 'createdAt': '2017-10-16T18:30:14Z', 'lastEditedAt': None, 'publishedAt': '2017-10-16T18:30:14Z', 'updatedAt': '2017-10-24T14:45:55Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Implement better mobile detection', 'bodyHTML': '<p>Right now, we do not have a consistent way of recognizing mobile devices such as tablets and mobile. The tour code, for example, uses a function called <code>validScreenSize</code> which looks for a window width and height. What we really want here is an ability to detect mobile devices. We use separate functions throughout the rest of the code base for similar mobile / screen size detection. Some possible solutions are:</p>\\n<ul>\\n<li>Detect mobile devices using userAgent strings: this is an iffy solution because there are so many userAgent strings and they are constantly changing but probably the best.</li>\\n<li>Use modernizer to detect touch events but with hybrid desktop / touch-enabled laptop devices, this is not consistent either.</li>\\n<li>Use a combination of the above solutions plus screen-size detection.</li>\\n</ul>', 'url': 'https://github.com/nasa-gibs/worldview/issues/709', 'state': 'OPEN', 'createdAt': '2018-01-19T20:20:25Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T20:20:25Z', 'updatedAt': '2018-05-04T17:43:48Z', 'labels': ['enhancement', 'good first issue', 'help wanted', 'technical'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Replace mobiscroll for mobile timewheels', 'bodyHTML': \"<p>We are currently running mobiscroll 2.6.0 and are pulling it in via a browserify-shim. Ideally, we would update this package to include the latest version (3.2.6 / 4.0.0beta-3.1) and pull it in via npm but version 2.7+ have a new license agreement so we can't use the latest version. So, we need to find a replacement solution.</p>\\n<p>mobiscroll is only being used in <code>web/js/date/wheels.js</code></p>\", 'url': 'https://github.com/nasa-gibs/worldview/issues/757', 'state': 'OPEN', 'createdAt': '2018-02-20T16:32:53Z', 'lastEditedAt': '2018-02-20T17:49:34Z', 'publishedAt': '2018-02-20T16:32:53Z', 'updatedAt': '2018-09-19T15:08:43Z', 'labels': ['good first issue', 'help wanted', 'technical'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Create a print stylesheet', 'bodyHTML': '<h3>Description</h3>\\n<p>Printing worldview should just show the map with the UI removed or minimized.</p>\\n<h3>Steps to Reproduce</h3>\\n<ol>\\n<li>Ctrl-P</li>\\n</ol>\\n<p><strong>Expected behavior:</strong><br>\\nWorldview should show an un-stretched map without UI elements.</p>\\n<p><strong>Actual behavior:</strong><br>\\nThe worldview map and UI is stretched, UI is unreadable.</p>\\n<h3>Environment</h3>\\n<p>Version: 2.3.0<br>\\nBrowser: all</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/922', 'state': 'OPEN', 'createdAt': '2018-04-25T20:07:26Z', 'lastEditedAt': None, 'publishedAt': '2018-04-25T20:07:26Z', 'updatedAt': '2018-10-01T17:32:36Z', 'labels': ['enhancement', 'good first issue', 'hacktoberfest', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'Add cssnext, a postcss plugin, to the build process', 'bodyHTML': '<h3>Description</h3>\\n<p>Right now we are using these <code>postcss</code> plugins to build our CSS: <code>postcssImport</code>, <code>autoprefixer</code> and <code>cssnano</code>.</p>\\n<p>I suggest we add the <a href=\"http://cssnext.io/\" rel=\"nofollow\">cssnext</a> plugin to this pipeline. <code>cssnext</code> will allow us to use features found in SASS and LESS without having to write in a separate style sheet language. Using <code>postcss</code> will make our CSS future-proof since browsers will eventually support these features.</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/923', 'state': 'OPEN', 'createdAt': '2018-04-25T20:25:13Z', 'lastEditedAt': None, 'publishedAt': '2018-04-25T20:25:13Z', 'updatedAt': '2018-04-25T20:25:13Z', 'labels': ['enhancement', 'good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'worldview', 'repo_owner_name': 'Global Imagery Browse Services', 'repo_owner_email': '', 'repo_owner_user_name': 'nasa-gibs', 'repo_owner_profile_url': 'https://github.com/nasa-gibs', 'title': 'GIBS Metadata Needs Gathering', 'bodyHTML': '<p>Were GIBS to provide metadata to Worldview for its layers, what does Worldview need?  This would cover titles, subtitles, abstracts, platforms, instruments, source/target dataset information, granule filters, temporal/spatial resolution, etc...</p>', 'url': 'https://github.com/nasa-gibs/worldview/issues/1120', 'state': 'OPEN', 'createdAt': '2018-06-26T19:52:29Z', 'lastEditedAt': None, 'publishedAt': '2018-06-26T19:52:29Z', 'updatedAt': '2018-09-25T13:29:57Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in app.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 153)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000ea\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000ea</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/62', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:10:34Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:10:34Z', 'updatedAt': '2018-07-31T17:39:16Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in app.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 153)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000eb\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000eb</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/63', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:11:36Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:11:36Z', 'updatedAt': '2018-07-31T17:39:05Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in app.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 89)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000f7\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000f7</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/64', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:11:39Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:11:39Z', 'updatedAt': '2018-07-31T17:38:58Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in app.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 89)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000f8\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c5c1a8fa00010000f8</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/65', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:11:41Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:11:41Z', 'updatedAt': '2018-07-31T17:38:51Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in services/validator/index.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 85)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/validator/index.js#issue_59b194c5c1a8fa00010000fd\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/validator/index.js#issue_59b194c5c1a8fa00010000fd</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/66', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:11:45Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:11:45Z', 'updatedAt': '2018-07-31T17:38:22Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Identical code\" issue in services/indexer/repo/index.js', 'bodyHTML': '<p>Identical code found in 1 other location (mass = 82)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c5c1a8fa00010000e9\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c5c1a8fa00010000e9</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/67', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:12:44Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:12:44Z', 'updatedAt': '2018-07-31T17:38:14Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in services/indexer/abstract_indexer.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 81)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/abstract_indexer.js#issue_59b194c5c1a8fa00010000ff\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/abstract_indexer.js#issue_59b194c5c1a8fa00010000ff</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/68', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:12:56Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:12:56Z', 'updatedAt': '2018-07-31T17:38:08Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in services/indexer/repo/index.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 72)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c5c1a8fa000100010c\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c5c1a8fa000100010c</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/69', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:13:07Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:13:07Z', 'updatedAt': '2018-07-31T17:37:47Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in services/indexer/term/index.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 72)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/term/index.js#issue_59b194c5c1a8fa000100010b\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/term/index.js#issue_59b194c5c1a8fa000100010b</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/70', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:13:19Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:13:19Z', 'updatedAt': '2018-07-31T17:37:28Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in services/formatter/index.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 66)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/formatter/index.js#issue_59b194c5c1a8fa0001000116\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/formatter/index.js#issue_59b194c5c1a8fa0001000116</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/71', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:13:26Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:13:26Z', 'updatedAt': '2018-07-31T17:37:16Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in services/formatter/index.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 66)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/formatter/index.js#issue_59b194c5c1a8fa0001000117\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/formatter/index.js#issue_59b194c5c1a8fa0001000117</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/72', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:13:36Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:13:36Z', 'updatedAt': '2018-07-31T17:37:05Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Identical code\" issue in services/searcher/index.js', 'bodyHTML': '<p>Identical code found in 1 other location (mass = 65)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/searcher/index.js#issue_59b194c5c1a8fa00010000ec\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/searcher/index.js#issue_59b194c5c1a8fa00010000ec</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/73', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:13:59Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:13:59Z', 'updatedAt': '2018-07-31T17:36:56Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Similar code\" issue in scripts/find_gh_gov_orgs/index.js', 'bodyHTML': '<p>Similar code found in 1 other location (mass = 63)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/scripts/find_gh_gov_orgs/index.js#issue_59b194c5c1a8fa000100011b\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/scripts/find_gh_gov_orgs/index.js#issue_59b194c5c1a8fa000100011b</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/74', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:14:10Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:14:10Z', 'updatedAt': '2018-07-31T17:36:43Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Identical code\" issue in utils/index.js', 'bodyHTML': '<p>Identical code found in 1 other location (mass = 61)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/utils/index.js#issue_59b194c5c1a8fa00010000ee\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/utils/index.js#issue_59b194c5c1a8fa00010000ee</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/75', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:14:18Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:14:18Z', 'updatedAt': '2018-07-31T17:36:38Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"Identical code\" issue in utils/index.js', 'bodyHTML': '<p>Identical code found in 1 other location (mass = 61)</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/utils/index.js#issue_59b194c5c1a8fa00010000ef\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/utils/index.js#issue_59b194c5c1a8fa00010000ef</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/76', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:14:25Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:14:25Z', 'updatedAt': '2018-07-31T17:36:29Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"no-unused-vars\" issue in utils/logger.js', 'bodyHTML': '<p>\\'config\\' is defined but never used.</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/utils/logger.js#issue_59b194c7c1a8fa0001000130\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/utils/logger.js#issue_59b194c7c1a8fa0001000130</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/77', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:15:05Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:15:05Z', 'updatedAt': '2018-07-31T17:36:20Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in app.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000133\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000133</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/78', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:15:28Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:15:28Z', 'updatedAt': '2018-07-31T17:35:53Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in app.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000134\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000134</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/79', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:15:36Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:15:36Z', 'updatedAt': '2018-07-31T17:35:42Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in app.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000135\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000135</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/80', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:15:44Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:15:44Z', 'updatedAt': '2018-07-31T17:35:32Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in app.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000136\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000136</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/81', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:15:48Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:15:48Z', 'updatedAt': '2018-07-31T17:35:21Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in app.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000136\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000136</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/82', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:38Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:38Z', 'updatedAt': '2018-07-31T17:35:10Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in app.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000137\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/app.js#issue_59b194c9c1a8fa0001000137</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/83', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:40Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:40Z', 'updatedAt': '2018-07-31T17:34:58Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in scripts/find_gh_gov_repos/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/scripts/find_gh_gov_repos/index.js#issue_59b194c9c1a8fa0001000144\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/scripts/find_gh_gov_repos/index.js#issue_59b194c9c1a8fa0001000144</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/84', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:43Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:43Z', 'updatedAt': '2018-07-31T17:34:46Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/formatter/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/formatter/index.js#issue_59b194c9c1a8fa0001000140\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/formatter/index.js#issue_59b194c9c1a8fa0001000140</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/85', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:47Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:47Z', 'updatedAt': '2018-07-31T17:34:13Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/indexer/index_cleaner.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/index_cleaner.js#issue_59b194c9c1a8fa000100013c\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/index_cleaner.js#issue_59b194c9c1a8fa000100013c</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/86', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:53Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:53Z', 'updatedAt': '2018-07-31T17:34:03Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/indexer/repo/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa0001000138\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa0001000138</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/87', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:56Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:56Z', 'updatedAt': '2018-07-31T17:33:51Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/indexer/repo/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa0001000139\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa0001000139</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/88', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:16:59Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:16:59Z', 'updatedAt': '2018-07-31T17:33:42Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/indexer/repo/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa000100013a\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa000100013a</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/89', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:17:02Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:17:02Z', 'updatedAt': '2018-07-31T17:33:15Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/indexer/repo/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa000100013b\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/indexer/repo/index.js#issue_59b194c9c1a8fa000100013b</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/90', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:17:06Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:17:06Z', 'updatedAt': '2018-07-31T17:33:06Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix \"TODO\" issue in services/searcher/index.js', 'bodyHTML': '<p>TODO found</p>\\n<p><a href=\"https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/searcher/index.js#issue_59b194c9c1a8fa000100013d\" rel=\"nofollow\">https://codeclimate.com/github/presidential-innovation-fellows/code-gov-api/services/searcher/index.js#issue_59b194c9c1a8fa000100013d</a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/91', 'state': 'CLOSED', 'createdAt': '2017-09-08T19:17:08Z', 'lastEditedAt': None, 'publishedAt': '2017-09-08T19:17:08Z', 'updatedAt': '2018-07-31T17:32:56Z', 'labels': ['[code.gov]', '[priority] low', 'cleanup', 'code-climate', 'code-quality', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Evaluate upgrade to Swagger docs to OpenAPI v3', 'bodyHTML': '<p>OpenAPI v3 was released was recently released. We should consider evaluating an upgrade path to our Swagger docs from version 2.0</p>\\n<p>Links with more info:</p>\\n<ul>\\n<li><a href=\"https://swagger.io/announcing-openapi-3-0/\" rel=\"nofollow\">Announcement</a></li>\\n<li><a href=\"https://swagger.io/specification/\" rel=\"nofollow\">Swagger Specification</a></li>\\n<li><a href=\"https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md#oasDocument\">OpenApi Specification on Github</a></li>\\n</ul>', 'url': 'https://github.com/GSA/code-gov-api/issues/126', 'state': 'OPEN', 'createdAt': '2017-11-02T12:55:50Z', 'lastEditedAt': None, 'publishedAt': '2017-11-02T12:55:50Z', 'updatedAt': '2018-10-11T17:32:02Z', 'labels': ['[code.gov]', '[effort] medium', '[impact] government-open-source', '[issue-type] enhancement', '[issue-type] good first issue', '[priority] low', '[skill-level] intermediate', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Error when running with Elastic Search Version 6.x', 'bodyHTML': '<p>Your issue may already be reported!<br>\\nPlease search on the <a href=\"../\">issue track</a> before creating one.</p>\\n<h2>Expected Behavior</h2>\\n\\n\\n<p>Should build ES index</p>\\n<h2>Current Behavior</h2>\\n\\n\\n<p>Receive error when trying to build ES index with newest version of ES<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4313463/35303974-dfe74020-0061-11e8-9853-e053ad195020.png\"><img src=\"https://user-images.githubusercontent.com/4313463/35303974-dfe74020-0061-11e8-9853-e053ad195020.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<h2>Possible Solution</h2>\\n\\n\\n<p>Requires migration to newer version and changing some of the JSON definition files</p>\\n<h2>Steps to Reproduce (for bugs)</h2>\\n\\n\\n<ol>\\n<li>install 6.x version of Elastic Search</li>\\n<li>npm run index</li>\\n</ol>\\n<h2>Context</h2>\\n\\n\\n<p>I\\'m trying to run backend in dev env</p>\\n<h2>Your Environment</h2>\\n\\n<ul>\\n<li>Version used:</li>\\n<li>Browser Name and version:</li>\\n<li>Operating System and version (desktop or mobile): Ubuntu 16.04</li>\\n<li>Link to your project:</li>\\n</ul>', 'url': 'https://github.com/GSA/code-gov-api/issues/159', 'state': 'CLOSED', 'createdAt': '2018-01-23T22:22:48Z', 'lastEditedAt': None, 'publishedAt': '2018-01-23T22:22:48Z', 'updatedAt': '2018-08-20T05:33:36Z', 'labels': ['[code.gov]', '[effort] small', '[issue-type] enhancement', '[issue-type] feedback', '[issue-type] good first issue', '[priority] medium', '[skill-level] intermediate', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add sort functionality', 'bodyHTML': '<h2>Context</h2>\\n<p>Sorting has not been implemented. The frontend would benefit from receiving sorted responses from the API.</p>\\n<p>There seems to be an initial attempt to implement this. Take a look at <code>services/searcher/index.js</code></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/163', 'state': 'CLOSED', 'createdAt': '2018-01-30T00:03:15Z', 'lastEditedAt': None, 'publishedAt': '2018-01-30T00:03:15Z', 'updatedAt': '2018-02-05T07:13:21Z', 'labels': ['[code.gov]', '[issue-type] enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Fix terms search error', 'bodyHTML': '<h2>Expected Behavior</h2>\\n<p>Searching for terms using the <code>/terms</code> endpoint should return terms data filtered and search by the parameters passed in the URL.</p>\\n<h2>Current Behavior</h2>\\n<p>We are currently receiving a <code>500 - Internal Server error</code> when searching for terms with the following URL <code>http://localhost:3001/api/0.1/terms?term=S&amp;term_type=agency.acronym</code></p>\\n<h2>Possible Solution</h2>\\n<p>Refactor the way our elasticsearch query body is being created.</p>\\n<h2>Steps to Reproduce (for bugs)</h2>\\n<ol>\\n<li>Run <code>npm start</code> from the master branch</li>\\n<li>Run <code>curl \"http://0.0.0.0:3001/api/0.1/terms?term=S&amp;term_type=agency.acronym&amp;term_type=agency.name\"</code></li>\\n</ol>\\n<h2>Context</h2>\\n<p>The code.gov frontend can\\'t use the terms endpoint as expected.</p>\\n<h2>Your Environment</h2>\\n<ul>\\n<li>Version used: All versions of the api</li>\\n</ul>', 'url': 'https://github.com/GSA/code-gov-api/issues/164', 'state': 'CLOSED', 'createdAt': '2018-01-30T00:10:06Z', 'lastEditedAt': None, 'publishedAt': '2018-01-30T00:10:06Z', 'updatedAt': '2018-02-22T07:44:31Z', 'labels': ['[code.gov]', '[issue-type] bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Remove status discovered endpoint', 'bodyHTML': '<p>The <code>status/:agency/discovered</code> endpoint does not serve a purpose anymore. The code-gov-api or code-gov-harvester does not do any discoverability. Our inventory is purely made up of repositories that US federal agencies supply.</p>\\n<h2>Current Behavior</h2>\\n<p>Endpoint is returning old data that the API is not refreshing.</p>\\n<h2>Possible Solution</h2>\\n<p>Eliminate endpoint from routes and swagger docs.</p>\\n<h2>Your Environment</h2>\\n<p>This is the current status in all environments (production and staging).</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/170', 'state': 'OPEN', 'createdAt': '2018-02-04T22:08:10Z', 'lastEditedAt': None, 'publishedAt': '2018-02-04T22:08:10Z', 'updatedAt': '2018-07-31T17:43:44Z', 'labels': ['[code.gov]', '[effort] small', '[impact] government-open-source', '[issue-type] enhancement', '[issue-type] good first issue', '[priority] low', '[skill-level] beginner', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Create Visualizations of Data from API', 'bodyHTML': '<h2>Expected Behavior</h2>\\n<p>Create cool data visualizations of the data from the API.</p>\\n<h2>Current Behavior</h2>\\n<p>Here\\'s some examples:</p>\\n<ul>\\n<li><a href=\"https://beta.observablehq.com/@danieljdufour/python-vs-ruby-number-of-projects-on-code-gov\" rel=\"nofollow\">https://beta.observablehq.com/@danieljdufour/python-vs-ruby-number-of-projects-on-code-gov</a></li>\\n<li><a href=\"https://beta.observablehq.com/@danieljdufour/top-10-languages-of-projects-on-code-gov\" rel=\"nofollow\">https://beta.observablehq.com/@danieljdufour/top-10-languages-of-projects-on-code-gov</a></li>\\n</ul>\\n<h2>Possible Solution</h2>\\n<ul>\\n<li>Create a data visualization using D3 or any library you might like.</li>\\n</ul>\\n<h2>Context</h2>\\n<p>Your visualization will help us and others understand what code is currently being captured by code.gov and help improve our understanding of what open-source throughout the government looks like.</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/198', 'state': 'OPEN', 'createdAt': '2018-03-02T22:13:39Z', 'lastEditedAt': None, 'publishedAt': '2018-03-02T22:13:39Z', 'updatedAt': '2018-10-11T17:31:20Z', 'labels': ['[code.gov]', '[effort] small', '[impact] government-open-source', '[priority] low', '[skill-level] beginner', 'community', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add endpoint for exposing the code.json file', 'bodyHTML': '<p>It would be great to add an endpoint to the REST API to enable an end user to get the full code.json file for all the federal agencies. That would allow comparisons against the data from agencies.</p>\\n<p>For instance, I am interesting in comparing Federal wide information to the data at DOECode. Additionally, I have am investigating other integrations with, for instance, GitHub.com/llnl/scraper</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/202', 'state': 'OPEN', 'createdAt': '2018-03-07T17:00:17Z', 'lastEditedAt': None, 'publishedAt': '2018-03-07T17:00:17Z', 'updatedAt': '2018-03-22T18:44:37Z', 'labels': ['[effort] small', '[issue-type] enhancement', '[skill-level] beginner', 'community', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add broken links to status report', 'bodyHTML': '<p>During the harvesting process, we need to add data about any broken links that appear in the repository data.</p>\\n<h2>Possible solution</h2>\\n<p>During the harvesting process make a get request to every link to verify that they are accessible.</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/207', 'state': 'OPEN', 'createdAt': '2018-03-22T00:55:18Z', 'lastEditedAt': None, 'publishedAt': '2018-03-22T00:55:18Z', 'updatedAt': '2018-10-11T17:29:53Z', 'labels': ['[code.gov]', '[effort] large', '[impact] government-open-source', '[issue-type] enhancement', '[priority] high', '[skill-level] intermediate', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Create a new healthcheck endpoint', 'bodyHTML': \"<p>We are currently using the root of the API (<code>/api</code>) as an informative and  healthcheck endpoint for our API. This endpoint can only be accessed using an API key. We want to create a separate healthcheck endpoint and leave the <code>/api</code> endpoint for informative uses.</p>\\n<p><strong>Describe the solution you'd like</strong></p>\\n<ul>\\n<li>Create a <code>/healthcheck</code> endpoint with API status information</li>\\n<li>Modify the <code>/api</code> endpoint to display only informative data about the API. Eg. where are the developer docs, where are the swagger docs, the running API version. etc.</li>\\n</ul>\", 'url': 'https://github.com/GSA/code-gov-api/issues/242', 'state': 'OPEN', 'createdAt': '2018-07-24T20:45:17Z', 'lastEditedAt': '2018-07-31T17:51:45Z', 'publishedAt': '2018-07-24T20:45:17Z', 'updatedAt': '2018-07-31T17:51:45Z', 'labels': ['[code.gov]', '[effort] medium', '[impact] government-open-source', '[priority] medium', '[skill-level] intermediate', 'feature request', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Replace Bunyan with another logger package', 'bodyHTML': '<p><strong>Is your feature request related to a problem? Please describe.</strong><br>\\nReplace <a href=\"https://github.com/trentm/node-bunyan/\">Bunyan</a> for another logger package. Bunyan seems to be a dead project, see the following <a href=\"https://github.com/trentm/node-bunyan/issues/586\" data-hovercard-type=\"issue\" data-hovercard-url=\"/trentm/node-bunyan/issues/586/hovercard\">conversation</a>.</p>\\n<p><strong>Describe the solution you\\'d like</strong><br>\\nit\\'s probably safe to change this package for <a href=\"https://github.com/winstonjs/winston\">Winston</a> logger package.</p>\\n<p><strong>Describe alternatives you\\'ve considered</strong><br>\\nI\\'ve gone over some of the other options on NPM and Winston is probably the best option. It has a very active community and is actively maintained.</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/243', 'state': 'OPEN', 'createdAt': '2018-08-06T22:17:05Z', 'lastEditedAt': None, 'publishedAt': '2018-08-06T22:17:05Z', 'updatedAt': '2018-08-06T22:17:05Z', 'labels': ['[effort] small', '[impact] government-open-source', '[issue-type] enhancement', '[issue-type] good first issue', '[priority] low', '[skill-level] beginner', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'autogenerate client sdk from swagger definition', 'bodyHTML': '<h3>What\\'s up?</h3>\\n<p>The existing/POC API GSA/code-gov-api-client is out of date, and instead of trying to update it, you\\'re probably better off generating an entirely new client, based on your existing swagger documentation.</p>\\n<h3>What am I looking for</h3>\\n<p>Configuring some sort of client generation process into the build pipeline for this application that will also keep a modern client up to date.</p>\\n<h3>Alternatives?</h3>\\n<p>Rewriting the existing API client to be up to date. But it doesn\\'t even know about API_KEY, let alone all the current endpoints and params. This also seems like a losing battle as the api and site evolve <g-emoji class=\"g-emoji\" alias=\"crossed_fingers\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f91e.png\"></g-emoji></p>\\n<h3>Additional context</h3>\\n<p>Mucked around with this: <a href=\"https://www.npmjs.com/package/swagger-node-codegen\" rel=\"nofollow\">https://www.npmjs.com/package/swagger-node-codegen</a><br>\\nBut I think it only generates a server based on a swagger def</p>\\n<p>This looks like a thing (<a href=\"https://app.swaggerhub.com/help/apis/generating-code/client-sdk\" rel=\"nofollow\">https://app.swaggerhub.com/help/apis/generating-code/client-sdk</a>), but i\\'m not installing a desktop app for this.</p>\\n<p>This seems like exactly what I want (<a href=\"https://github.com/swagger-api/swagger-codegen/wiki/FAQ\">https://github.com/swagger-api/swagger-codegen/wiki/FAQ</a>), but like hell am I installing maven and java on this computer just for this task.</p>\\n<p>So, what am I really doing? Hoping yall will do me a solid and build this thing for me in exchange for me doing the leg work.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://camo.githubusercontent.com/6ec4cb13a3604a54dcf194c6a15069719a455b1d/687474703a2f2f7777772e616374696f6e65642e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30322f7465616d776f726b2d6d616b65732d7468652d647265616d776f726b2d312d31303234783934392e6a7067\"><img src=\"https://camo.githubusercontent.com/6ec4cb13a3604a54dcf194c6a15069719a455b1d/687474703a2f2f7777772e616374696f6e65642e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f30322f7465616d776f726b2d6d616b65732d7468652d647265616d776f726b2d312d31303234783934392e6a7067\" alt=\"\" data-canonical-src=\"http://www.actioned.com/wp-content/uploads/2018/02/teamwork-makes-the-dreamwork-1-1024x949.jpg\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/GSA/code-gov-api/issues/246', 'state': 'OPEN', 'createdAt': '2018-08-17T16:41:58Z', 'lastEditedAt': '2018-08-20T19:28:10Z', 'publishedAt': '2018-08-17T16:41:58Z', 'updatedAt': '2018-10-11T17:29:15Z', 'labels': ['[code.gov]', '[effort] large', '[impact] government-open-source', '[issue-type] enhancement', '[priority] low', '[skill-level] advanced', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Filter By License', 'bodyHTML': \"<p><strong>Is your feature request related to a problem? Please describe.</strong><br>\\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]<br>\\nI want to load as little unnecessary data as possible when searching for repos.  It'd be ideal to be able to filter by license.</p>\\n<p><strong>Describe the solution you'd like</strong><br>\\nA clear and concise description of what you want to happen.<br>\\nadd an ability to filter by license.  The tree structure is really weird, so I'm not sure how you want to do the mapping.  Maybe <code>...&amp;licenses_name=</code> or <code>licenses.0.name=...</code></p>\\n<p><strong>Describe alternatives you've considered</strong><br>\\nA clear and concise description of any alternative solutions or features you've considered.<br>\\nI can filter client side, but would prefer server side</p>\\n<p><strong>Additional context</strong><br>\\nAdd any other context or screenshots about the feature request here.<br>\\nThanks!</p>\", 'url': 'https://github.com/GSA/code-gov-api/issues/260', 'state': 'CLOSED', 'createdAt': '2018-09-15T03:00:51Z', 'lastEditedAt': None, 'publishedAt': '2018-09-15T03:00:51Z', 'updatedAt': '2018-10-30T07:52:51Z', 'labels': ['[effort] medium', '[impact] government-open-source', '[issue-type] enhancement', '[issue-type] good first issue', '[priority] high', '[skill-level] beginner', 'feature request', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Sort /agencies endpoint', 'bodyHTML': \"<p><strong>Is your feature request related to a problem? Please describe.</strong><br>\\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]<br>\\nIt's not really a problem, but I display the agencies sorted by name in the dropdown in the banner in the home area.  It would be useful if I could do the sorting server-side.</p>\\n<p><strong>Describe the solution you'd like</strong><br>\\nA clear and concise description of what you want to happen.<br>\\n<code>&amp;sort=name</code> or <code>&amp;sort=acronym</code> should work</p>\\n<p><strong>Describe alternatives you've considered</strong><br>\\nA clear and concise description of any alternative solutions or features you've considered.<br>\\nSorting client side</p>\\n<p><strong>Additional context</strong><br>\\nAdd any other context or screenshots about the feature request here.<br>\\nThis is low priority because I can sort client side</p>\", 'url': 'https://github.com/GSA/code-gov-api/issues/269', 'state': 'OPEN', 'createdAt': '2018-09-25T18:51:00Z', 'lastEditedAt': None, 'publishedAt': '2018-09-25T18:51:00Z', 'updatedAt': '2018-10-11T17:28:15Z', 'labels': ['[code.gov]', '[impact] government-open-source', '[issue-type] enhancement', '[issue-type] good first issue', '[priority] low', '[skill-level] intermediate', 'feature request', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add /licenses endpoint', 'bodyHTML': '<p><strong>Is your feature request related to a problem? Please describe.</strong><br>\\nA clear and concise description of what the problem is. Ex. I\\'m always frustrated when [...]<br>\\nWe want to be able to dynamically display filter options for licenses in the browse projects page without having to make a request for data from all of the repositories.  It would be great if we could hit a licenses endpoint, which returns the valid, normalized, and standardized licenses that exist within our index.</p>\\n<p><strong>Describe the solution you\\'d like</strong><br>\\nA clear and concise description of what you want to happen.<br>\\nI\\'d like to fetch <code>/licenses</code> and have it return an array of objects like</p>\\n<div class=\"highlight highlight-source-json\"><pre>[\\n    { <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Creative Commons Zero v1.0 Universal<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>id<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CC0-1.0<span class=\"pl-pds\">\"</span></span> },\\n    { <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>name<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Apache License 2.0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>id<span class=\"pl-pds\">\"</span></span>: <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Apache-2.0<span class=\"pl-pds\">\"</span></span> }\\n]</pre></div>\\n<p><strong>Describe alternatives you\\'ve considered</strong><br>\\nA clear and concise description of any alternative solutions or features you\\'ve considered.<br>\\nI can write a script that runs this process and saves it to a file as a part of the webpack build process.  This would mean however the licenses filter box would not auto-update.</p>\\n<p><strong>Additional context</strong><br>\\nAdd any other context or screenshots about the feature request here.<br>\\nThis is a medium priority because I can work around this with a static manually-generated licenses file.  The set of licenses used on code.gov doesn\\'t change at a high frequency.</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/270', 'state': 'OPEN', 'createdAt': '2018-09-25T19:58:13Z', 'lastEditedAt': None, 'publishedAt': '2018-09-25T19:58:13Z', 'updatedAt': '2018-10-11T17:27:18Z', 'labels': ['[effort] small', '[issue-type] good first issue', '[priority] medium', '[skill-level] beginner', 'feature request', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Filter By Languages Not Working', 'bodyHTML': '<p><strong>Describe the bug</strong><br>\\nA clear and concise description of what the bug is.</p>\\n<p><strong>To Reproduce</strong><br>\\nSteps to reproduce the behavior:</p>\\n<ol>\\n<li>Go to <a href=\"https://api.code.gov/repos?api_key=DEMO_KEY&amp;languages=Python\" rel=\"nofollow\">https://api.code.gov/repos?api_key=DEMO_KEY&amp;languages=Python</a></li>\\n</ol>\\n<p><strong>Expected behavior</strong><br>\\nA clear and concise description of what you expected to happen.<br>\\nIt should only return the repositories that are in Python</p>\\n<p><strong>Screenshots</strong><br>\\nIf applicable, add screenshots to help explain your problem.<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/4313463/46217634-86027080-c310-11e8-8c1f-91c481b2a906.png\"><img src=\"https://user-images.githubusercontent.com/4313463/46217634-86027080-c310-11e8-8c1f-91c481b2a906.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p><strong>Additional context</strong><br>\\nAdd any other context about the problem here.<br>\\nThis is important because we want to do server-side filtering in the browse projects page.</p>', 'url': 'https://github.com/GSA/code-gov-api/issues/273', 'state': 'OPEN', 'createdAt': '2018-09-28T15:21:06Z', 'lastEditedAt': None, 'publishedAt': '2018-09-28T15:21:06Z', 'updatedAt': '2018-10-11T17:26:37Z', 'labels': ['[code.gov]', '[effort] medium', '[impact] government-open-source', '[issue-type] bug', '[issue-type] good first issue', '[priority] high', '[skill-level] intermediate', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'code-gov-api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Website issue report for code.gov - Walkoff project link returning 404', 'bodyHTML': '<p>The following bug report was sent to us via <a href=\"mailto:code@gsa.gov\">code@gsa.gov</a>:</p>\\n<blockquote>\\n<p>I was browsing code.gov and ran into a minor error that might be useful to know about</p>\\n<p>Summary: code.gov homepage has a 404 in the walkoff project link.<br>\\nImpact: Small - users visiting the home page will not see details of a<br>\\nfeatured project - the link to the repo still works.</p>\\n<p>Details:<br>\\nwhen opening <a href=\"https://code.gov\" rel=\"nofollow\">https://code.gov</a><br>\\nthen scrolling down to featured project walkoff<br>\\nthen clicking \"view project\"<br>\\nthen it opens url<br>\\n<a href=\"https://code.gov/#!/explore-code/agencies/NSA/repos/nsa_walkoff\" rel=\"nofollow\">https://code.gov/#!/explore-code/agencies/NSA/repos/nsa_walkoff</a></p>\\n<p>Expected: we would see project info on the walkoff project<br>\\nActual:</p>\\n<ul>\\n<li>only the site template renders (see screen shot)</li>\\n<li>there was a 404 error logged on the javascript console \"Failed to load resource: the server responded with a status of 404 (Not Found)\" referencing this url <a href=\"https://api.code.gov/repos/nsa_walkoff?api_key=OC457325hyT6DpFm5HBBZ1i8SR6gtp5U2CdqtHZQ\" rel=\"nofollow\">https://api.code.gov/repos/nsa_walkoff?api_key=OC457325hyT6DpFm5HBBZ1i8SR6gtp5U2CdqtHZQ</a></li>\\n</ul>\\n<p>Recommendation: This error would be hidden from many standard link checkers and site monitors because the error is only presented in javascript and the site renders but with no contextually relevant content - only a human or a link checker that checks for javascript errors would discover it.<br>\\nTherefore,</p>\\n<ol>\\n<li>Periodically run a link checker on the site that inspects javascript errors - or periodically run your end-to-end test suite, if one is available.</li>\\n<li>Present an error with more detail to the user when javascript encounters this condition.</li>\\n<li>Monitor for similar kinds errors by monitoring browser javascript errors.</li>\\n</ol>\\n<p>Browser was: Chrome Version 69.0.3497.100 (Official Build) (64-bit)<br>\\nRegion was: conus west<br>\\nTime was:   08:49:07 UTC Tuesday, October 23, 2018</p>\\n</blockquote>', 'url': 'https://github.com/GSA/code-gov-api/issues/284', 'state': 'CLOSED', 'createdAt': '2018-10-23T15:08:12Z', 'lastEditedAt': None, 'publishedAt': '2018-10-23T15:08:12Z', 'updatedAt': '2018-10-30T15:26:02Z', 'labels': ['[code.gov]', '[effort] small', '[issue-type] bug', '[issue-type] good first issue', '[priority] medium', '[skill-level] beginner', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cg-style', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Make the library easily importable by webpack', 'bodyHTML': '<p>This would mean you could import one JS file with webpack and get the CSS and possibly images.</p>', 'url': 'https://github.com/18F/cg-style/issues/44', 'state': 'CLOSED', 'createdAt': '2016-03-01T00:25:58Z', 'lastEditedAt': None, 'publishedAt': '2016-03-01T00:25:58Z', 'updatedAt': '2016-04-22T04:42:39Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'C2', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Reporting/Filtering frontend', 'bodyHTML': '<p>Bring visibility to the following:</p>\\n<ol>\\n<li>Total transactions</li>\\n<li>Total dollars spent (filter by: vendor, date)</li>\\n<li>Rejection data: amount of requests rejected and reasons why</li>\\n<li>Engagement time / average time to completion</li>\\n<li>Policy related: (e.g. split transactions)</li>\\n</ol>\\n<p>/cc <a href=\"https://www.pivotaltracker.com/story/show/86061736\" rel=\"nofollow\">https://www.pivotaltracker.com/story/show/86061736</a></p>', 'url': 'https://github.com/18F/C2/issues/246', 'state': 'CLOSED', 'createdAt': '2015-03-18T19:56:06Z', 'lastEditedAt': None, 'publishedAt': '2015-03-18T19:56:06Z', 'updatedAt': '2015-11-18T23:25:51Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'C2', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Admin UI for creating users', 'bodyHTML': '<p>/cc <a href=\"https://www.pivotaltracker.com/story/show/90204026\" rel=\"nofollow\">https://www.pivotaltracker.com/story/show/90204026</a></p>', 'url': 'https://github.com/18F/C2/issues/247', 'state': 'CLOSED', 'createdAt': '2015-03-18T20:03:07Z', 'lastEditedAt': None, 'publishedAt': '2015-03-18T20:03:07Z', 'updatedAt': '2015-11-18T22:24:21Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'C2', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Consolidate project documentation', 'bodyHTML': '<p>We currently have documentation about the project scattered around:</p>\\n<ul>\\n<li><a href=\"http://18f.github.io/C2/\" rel=\"nofollow\">The GItHub Pages site</a></li>\\n<li><a href=\"https://cap.18f.us\" rel=\"nofollow\">The app homepage</a></li>\\n<li><a href=\"https://github.com/18F/C2#readme\">The README</a></li>\\n<li><a href=\"https://github.com/18F/C2/tree/master/doc\">The <code>doc/</code> folder</a></li>\\n<li><a href=\"https://18f.gsa.gov/dashboard/project/C2/\" rel=\"nofollow\">The 18F Dashboard</a></li>\\n</ul>\\n<p>which seems like too many. At the very least, I think we can make the messaging more consistent. There are a handful of audiences that we want to speak to:</p>\\n<ul>\\n<li>Program officers or other potential users / new use cases</li>\\n<li>Current users looking to get more information</li>\\n<li>New 18F teammates</li>\\n<li>Potential outside contributors</li>\\n<li>Curious passerby</li>\\n</ul>\\n<p>Questions:</p>\\n<ul>\\n<li>What can we consolidate?</li>\\n<li>Where should different pieces of information live?</li>\\n<li>How should it be organized?</li>\\n</ul>\\n<p>Would love some content (and content design) help!</p>\\n<p>/cc <a href=\"https://www.pivotaltracker.com/story/show/83786688\" rel=\"nofollow\">https://www.pivotaltracker.com/story/show/83786688</a></p>', 'url': 'https://github.com/18F/C2/issues/263', 'state': 'CLOSED', 'createdAt': '2015-03-26T05:06:51Z', 'lastEditedAt': None, 'publishedAt': '2015-03-26T05:06:51Z', 'updatedAt': '2015-11-18T22:26:15Z', 'labels': ['content', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'C2', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add multiple line-items/vendors', 'bodyHTML': '<p>Proposals require a way to depict having multiple line-items and multiple vendors.</p>\\n<p>Reference doc: <a href=\"https://docs.google.com/document/d/1_gjq_3m16Ug7_JcfsV28Lt4dCQTDnEhvWVFofbNaw4g/edit\" rel=\"nofollow\">https://docs.google.com/document/d/1_gjq_3m16Ug7_JcfsV28Lt4dCQTDnEhvWVFofbNaw4g/edit</a></p>\\n<p>Reference issue: 18F/C2: Issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"146678044\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/C2/issues/1151\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/C2/issues/1151/hovercard\" href=\"https://github.com/18F/C2/issues/1151\">#1151</a></p>', 'url': 'https://github.com/18F/C2/issues/1151', 'state': 'CLOSED', 'createdAt': '2016-04-07T16:34:03Z', 'lastEditedAt': None, 'publishedAt': '2016-04-07T16:34:03Z', 'updatedAt': '2016-09-15T13:18:18Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Integrate w/Team API?', 'bodyHTML': \"<p>Right now, Dolores doesn't worry about any other data in order to function. This is good because it makes the app easily forkable / usable by other entities. But the downside to this is that we are duplicating Team data in our db that should also be included in the 18F Team API.</p>\\n<p>After speaking with Mike Bland about this today, it doesn't seem wise for us to move to using the Team API immediately. He hopes to change the way the Team API works in the medium term so that people can update their own records. He even suggested that the Team API might pull data from Dolores. Until we come to a conclusion on how the Team API should relate to Dolores, we shouldn't adapt the Slackbot to use the Team API.</p>\", 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/55', 'state': 'OPEN', 'createdAt': '2015-10-01T21:22:01Z', 'lastEditedAt': None, 'publishedAt': '2015-10-01T21:22:01Z', 'updatedAt': '2016-06-28T17:48:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add ability to subscribe to specific tagged messages', 'bodyHTML': '<p>As a new hire at 18F, I would like to be able to manage which messages I receive from the Dolores Landingham Slackbot so that I have control over the information that I see.</p>\\n<p>This work will likely require a general preferences management area for users beforehand and a way to store and retrieve those preferences.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/66', 'state': 'OPEN', 'createdAt': '2015-10-08T14:38:42Z', 'lastEditedAt': None, 'publishedAt': '2015-10-08T14:38:42Z', 'updatedAt': '2016-04-12T18:53:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Interactive \"checkers\"', 'bodyHTML': '<p>Reading over some of the Landingham scripts Mel sent me, got me thinking it\\'d be great if we could have Mrs. Landingham verify things we expect new hires to do in as automated a way as possible. Example: In the current script, Mrs. Landingham asks:</p>\\n<blockquote>\\n<p>I also wanted to make sure your computer is securely set up. Please make sure you have:</p>\\n<ol>\\n<li>Two factor authentication set up for both Slack and GitHub</li>\\n</ol>\\n</blockquote>\\n<p>What if instead of telling the new hire to be sure, we ask them for their username and do a reliable check to make sure 2FA is set up.</p>\\n<blockquote>\\n<p><strong>Dolores Landingham:</strong> I also wanted ot make sure your GitHub account is set up correctly. Can you tell me your username?<br>\\n<strong>New Hire:</strong> It\\'s <code>18fnewhire</code><br>\\n<strong>DL:</strong> Hmm... it looks like you\\'re not a member of the 18F team yet. Please make sure your account is set up correctly and ask for help in #admins-github if you need assistance. I\\'ll check back again tomorrow. Is that <strong>OK</strong> or do you want me to <strong>check again</strong> now<br>\\n<strong>NH:</strong> OK</p>\\n</blockquote>\\n<p>A check for membership in the 18F team is a pretty good indicator that the user turned on 2FA and did all the right things to become a member of the team.</p>\\n<p>If the new hire says OK, then DL continues on and asks the same question the next day. This continues until the user has completed the task. If the user says \"check again\" then DL asks for the GitHub username again and checks the 18F team.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/70', 'state': 'OPEN', 'createdAt': '2015-10-14T19:54:43Z', 'lastEditedAt': None, 'publishedAt': '2015-10-14T19:54:43Z', 'updatedAt': '2016-04-12T19:09:26Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add ability to retrieve all users/employees in an organization from Slack', 'bodyHTML': '<p>When the Dolores app first starts, she starts with an empty list of employees.  It would be very helpful if we could provide some way of retrieving all employees and placing them into the app automatically for the admins to make things easier.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/72', 'state': 'OPEN', 'createdAt': '2015-10-16T14:21:08Z', 'lastEditedAt': None, 'publishedAt': '2015-10-16T14:21:08Z', 'updatedAt': '2016-07-13T21:53:56Z', 'labels': ['help wanted', 'in progress'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Save Slack channel ID in DB', 'bodyHTML': \"<p>we do a query each time we send a message to get the slack channel ID for a user. We should save this on the <code>employee</code> record so we don't need to hit the slack API each time we send a message</p>\", 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/74', 'state': 'CLOSED', 'createdAt': '2015-10-16T17:32:26Z', 'lastEditedAt': None, 'publishedAt': '2015-10-16T17:32:26Z', 'updatedAt': '2016-03-20T16:07:11Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'no @ is required for Slack names', 'bodyHTML': '<p>make note of this in docs and/or form for adding employees</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/81', 'state': 'CLOSED', 'createdAt': '2015-10-19T21:36:15Z', 'lastEditedAt': None, 'publishedAt': '2015-10-19T21:36:15Z', 'updatedAt': '2016-03-25T17:50:55Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Ability to put \"end date\" on message', 'bodyHTML': '<p>Would love to tell all new hires between now and offsite that offsite will be on xx dates - but do not want new hires beyond that date to receive a message. Is there a way to put an \"end date\" on certain messages?</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/95', 'state': 'CLOSED', 'createdAt': '2015-10-30T17:38:23Z', 'lastEditedAt': None, 'publishedAt': '2015-10-30T17:38:23Z', 'updatedAt': '2016-04-11T20:11:53Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Messages cannot be sent out late at night', 'bodyHTML': '<p>It appears there is another issue related to the employee message matching when sending messages late at night, this time in checking the start date of the employee.  After a certain point in time in the evening (I was testing between 9:00 PM and 10:00 PM) two tests start to fail:</p>\\n<ul>\\n<li>MessageEmployeeMatcher#run matches messages to users based on days after start</li>\\n<li>MessageEmployeeMatcher#run ignores messages that have already been sent to users</li>\\n</ul>\\n<p>And messages will not be sent when testing things manually.</p>\\n<p>I suspect this is a similar issue that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=601515\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jessieay\">@jessieay</a> and I had fixed with the time matching where we also had to check that the user\\'s local time was still during the same day as the UTC time the app uses internally.  Checking to see which day to send a message out may require a similar guard clause in it.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/111', 'state': 'CLOSED', 'createdAt': '2015-11-19T14:24:03Z', 'lastEditedAt': None, 'publishedAt': '2015-11-19T14:24:03Z', 'updatedAt': '2016-09-16T18:02:12Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Consider replacing capybara-webkit with poltergeist', 'bodyHTML': '<p>This repo is currently using v1.x of capybara-webkit, which results in the following warning when running the specs:</p>\\n<pre><code>WARNING: The next major version of capybara-webkit will require at least version 5.0 of Qt. You\\'re using version 4.8.7.\\n</code></pre>\\n<p>If you\\'re planning on upgrading to v2 of capybara-webkit when it comes out, then it will require anyone who is contributing to this repo to have Qt 5.0 installed on their machine, which in turn requires the full Xcode app to be installed.</p>\\n<p>Having to download a multi-gigabyte app just to be able to run some tests is not a great developer experience IMO. Instead, I recommend switching to <a href=\"https://github.com/teampoltergeist/poltergeist\">Poltergeist</a>, which does not depend on Xcode, and works just as well as capybara-webkit. In some ways, it\\'s even better because it does not require <code>xvfb</code>, and makes running tests on Travis or Vagrant easier.</p>\\n<p>Here is an example of the changes required to make the switch: <a href=\"https://github.com/codeforamerica/ohana-web-search/pull/601/files\">https://github.com/codeforamerica/ohana-web-search/pull/601/files</a></p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/113', 'state': 'CLOSED', 'createdAt': '2015-11-20T20:03:51Z', 'lastEditedAt': None, 'publishedAt': '2015-11-20T20:03:51Z', 'updatedAt': '2016-04-13T14:20:42Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Ability to send message to all Dolores users *right now*', 'bodyHTML': \"<p>This is a slightly different use case for Dolores but would immensely help the @18F/comms and @18F/blog teams: the ability to message all Dolores users with the same message at once.</p>\\n<p>Use cases:</p>\\n<ol>\\n<li>Alerting people to new features in Dolores</li>\\n<li>Asking people for information for the all-hands</li>\\n<li>Querying for upcoming blog posts or newsletters</li>\\n</ol>\\n<p>The Comms team needs a way to communicate with each member of 18F on a regular basis. We've been individually DMing people, but that takes time and is not the easiest as 18F scales.</p>\", 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/125', 'state': 'OPEN', 'createdAt': '2016-01-06T18:00:56Z', 'lastEditedAt': None, 'publishedAt': '2016-01-06T18:00:56Z', 'updatedAt': '2016-07-19T18:01:07Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Ability to delete a message', 'bodyHTML': \"<p>As the onboarding lead, I need to be able to delete messages that are no longer important or relevant (or, in today's case, added by mistake).</p>\", 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/142', 'state': 'CLOSED', 'createdAt': '2016-02-16T17:22:41Z', 'lastEditedAt': None, 'publishedAt': '2016-02-16T17:22:41Z', 'updatedAt': '2016-03-03T22:29:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Username validation or send failure error', 'bodyHTML': '<p>I\\'m not sure how hard this would be, but Dolores should let us know if a username is failing to receive messages. I added <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17731307\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/amandaschonfeld\">@amandaschonfeld</a>\\'s initial username when she joined Slack, and then she changed itI didn\\'t know the messages weren\\'t coming through until she DMed me asking what happened and I realized the name change wasn\\'t throwing an error etc.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/157', 'state': 'CLOSED', 'createdAt': '2016-03-16T14:49:58Z', 'lastEditedAt': None, 'publishedAt': '2016-03-16T14:49:58Z', 'updatedAt': '2016-05-31T16:03:30Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Readme missing Google Doc Link', 'bodyHTML': '<p>Under Usage Instructions for 18-F employees, in the first item under \"To add new messages\": <a href=\"https://github.com/18F/dolores-landingham-bot#usage-instructions-for-18f-employees\">https://github.com/18F/dolores-landingham-bot#usage-instructions-for-18f-employees</a></p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/164', 'state': 'CLOSED', 'createdAt': '2016-04-30T15:19:41Z', 'lastEditedAt': None, 'publishedAt': '2016-04-30T15:19:41Z', 'updatedAt': '2016-05-02T21:59:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'ease the setup', 'bodyHTML': \"<p>Hey team-<br>\\nHaving had used this project in a couple of open source workshops thus far, I've watched a bunch of people hit a lot of hurdles when trying to set up the app locally. In particular, setting up the MyUSA application and the Slack token are a bit of a nuisance. I was wondering: thoughts about feature-flagging those connections, where in development it could just post to the console or something, and have the user automatically logged in as a dummy admin user? Just thinking it could get people up and running a lot faster. Thoughts?</p>\", 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/170', 'state': 'OPEN', 'createdAt': '2016-04-30T18:18:03Z', 'lastEditedAt': None, 'publishedAt': '2016-04-30T18:18:03Z', 'updatedAt': '2016-08-28T20:55:23Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Localize error messages', 'bodyHTML': '<p>Right now, our flash messages are strings in the controller. We should move them into I18n so they are all in one place and easier to look for in tests.</p>\\n<p><a href=\"https://github.com/18F/dolores-landingham-bot/blob/master/config/locales/en.yml\">https://github.com/18F/dolores-landingham-bot/blob/master/config/locales/en.yml</a></p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/194', 'state': 'CLOSED', 'createdAt': '2016-07-19T21:31:17Z', 'lastEditedAt': None, 'publishedAt': '2016-07-19T21:31:17Z', 'updatedAt': '2016-08-29T21:29:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Rename `Message` to `BroadcastMessage`', 'bodyHTML': '<p>Clearer name! See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"166433548\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/dolores-landingham-slack-bot/issues/193\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/dolores-landingham-slack-bot/pull/193/hovercard?comment_id=234114686&amp;comment_type=issue_comment\" href=\"https://github.com/18F/dolores-landingham-slack-bot/pull/193#issuecomment-234114686\">#193 (comment)</a> for background</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/196', 'state': 'CLOSED', 'createdAt': '2016-07-20T23:45:24Z', 'lastEditedAt': None, 'publishedAt': '2016-07-20T23:45:24Z', 'updatedAt': '2016-09-19T23:07:30Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add ability to log out', 'bodyHTML': '<p>RIght not, only way to log out is to de-authorize to delete a cookie! Logout button in nav would be great.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/197', 'state': 'CLOSED', 'createdAt': '2016-07-21T17:37:14Z', 'lastEditedAt': None, 'publishedAt': '2016-07-21T17:37:14Z', 'updatedAt': '2016-08-02T20:41:02Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Create \"log in\" page', 'bodyHTML': '<p>Right now, authentication is required to view any and all pages. So if login fails, we don\\'t have any pages where we can show the user the generated auth errors.</p>\\n<p>We should create a simple page with a \"login with github\" that we can redirect users to if login fails.</p>\\n<p>This can also serve as the non-authed root path.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/198', 'state': 'CLOSED', 'createdAt': '2016-07-21T17:50:39Z', 'lastEditedAt': None, 'publishedAt': '2016-07-21T17:50:39Z', 'updatedAt': '2016-08-02T20:40:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Automate deployment via Travis', 'bodyHTML': '<p>When the build passes on master, we should deploy to production.</p>\\n<p>Micropurchase also uses Travis and Cloud.gov so their setup can be used as as guide for how to do this <a href=\"https://github.com/18F/micropurchase/blob/develop/.travis.yml\">https://github.com/18F/micropurchase/blob/develop/.travis.yml</a></p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/204', 'state': 'OPEN', 'createdAt': '2016-07-26T16:41:54Z', 'lastEditedAt': None, 'publishedAt': '2016-07-26T16:41:54Z', 'updatedAt': '2016-07-26T16:41:59Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Consider breaking out `Quarterly message` from `ScheduledMessage`', 'bodyHTML': '<p>right now, quarterly messages are a type of scheduled message. You create them in the same form, there is just a checkbox you check if you want something to be a quarterly message</p>\\n<p>It would be more obvious from an admin standpoint how to create a quarterly message if it had its own section in the lefthand nav.  This means a separate form (with no checkbox required, and only fields that you need for a quarterly message) and a separate list view for quarterly messages.</p>\\n<p>This might not mean we need to change anything at the admin level, but we could have views for each type that are separate. I am also open to separating them out in the database, though.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/206', 'state': 'CLOSED', 'createdAt': '2016-08-02T20:58:47Z', 'lastEditedAt': '2016-08-02T21:00:07Z', 'publishedAt': '2016-08-02T20:58:47Z', 'updatedAt': '2016-10-25T23:35:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add seeds', 'bodyHTML': '<p>It may be helpful to have some sample data to play around with when getting started</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/212', 'state': 'OPEN', 'createdAt': '2016-09-14T21:23:28Z', 'lastEditedAt': None, 'publishedAt': '2016-09-14T21:23:28Z', 'updatedAt': '2016-09-14T21:23:33Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Silence time zone deprecation warning', 'bodyHTML': \"<p>seeing this in Travis;</p>\\n<pre><code>DEPRECATION WARNING: Time columns will become time zone aware in Rails 5.1. This\\nstill causes `String`s to be parsed as if they were in `Time.zone`,\\nand `Time`s to be converted to `Time.zone`.\\nTo keep the old behavior, you must add the following to your initializer:\\n    config.active_record.time_zone_aware_types = [:datetime]\\nTo silence this deprecation warning, add the following:\\n    config.active_record.time_zone_aware_types = [:datetime, :time]\\n (called from _app_views_scheduled_messages_index_html_erb___3955218739433732987_29240280 at /home/travis/build/18F/dolores-landingham-slack-bot/app/views/scheduled_messages/index.html.erb:29)\\n.You're running an old version of PhantomJS, update to &gt;= 2.1.1 for a better experience.\\nDEPRECATION WARNING: Time columns will become time zone aware in Rails 5.1. This\\nstill causes `String`s to be parsed as if they were in `Time.zone`,\\nand `Time`s to be converted to `Time.zone`.\\nTo keep the old behavior, you must add the following to your initializer:\\n    config.active_record.time_zone_aware_types = [:datetime]\\nTo silence this deprecation warning, add the following:\\n    config.active_record.time_zone_aware_types = [:datetime, :time]\\n (called from quarterly_message_not_already_sent? at /home/travis/build/18F/dolores-landingham-slack-bot/app/services/quarterly_message_employee_matcher.rb:35)\\n.DEPRECATION WARNING: ActionController::TestCase HTTP request methods will accept only\\nkeyword arguments in future Rails versions.\\nExamples:\\nget :show, params: { id: 1 }, session: { user_id: 1 }\\nprocess :update, method: :post, params: { id: 1 }\\n (called from block (3 levels) in &lt;top (required)&gt; at /home/travis/build/18F/dolores-landingham-slack-bot/spec/controllers/send_messages_controller_spec.rb:9)\\nDEPRECATION WARNING: ActionController::TestCase HTTP request methods will accept only\\nkeyword arguments in future Rails versions.\\nExamples:\\nget :show, params: { id: 1 }, session: { user_id: 1 }\\nprocess :update, method: :post, params: { id: 1 }\\n (called from block (3 levels) in &lt;top (required)&gt; at /home/travis/build/18F/dolores-landingham-slack-bot/spec/controllers/send_messages_controller_spec.rb:9)\\n</code></pre>\", 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/228', 'state': 'OPEN', 'createdAt': '2016-09-21T18:46:04Z', 'lastEditedAt': None, 'publishedAt': '2016-09-21T18:46:04Z', 'updatedAt': '2016-09-21T18:46:04Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update sinatra gem', 'bodyHTML': '<p>We are downloading from source, would be better to use the released gem</p>\\n<p>this is the warning we see:</p>\\n<pre><code> The git source `git://github.com/sinatra/sinatra.git` uses the `git` protocol, which transmits data without encryption. Disable this warning with `bundle config git.allow_insecure true`, or switch to the `https` protocol to keep your data secure\\n</code></pre>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/229', 'state': 'OPEN', 'createdAt': '2016-09-21T18:59:57Z', 'lastEditedAt': None, 'publishedAt': '2016-09-21T18:59:57Z', 'updatedAt': '2018-07-01T19:23:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Move \"flashes\" partial into layout', 'bodyHTML': '<p>We may want to consider moving the partial that displays the flash messages into <code>application/layout</code> instead of depending on individual views to render it.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/230', 'state': 'OPEN', 'createdAt': '2016-09-27T18:00:17Z', 'lastEditedAt': None, 'publishedAt': '2016-09-27T18:00:17Z', 'updatedAt': '2016-09-27T18:05:35Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add filter query object for messages', 'bodyHTML': '<p>Currently, the <code>OnboardingMessage</code> and <code>QuarterlyMessage</code> models implement identical filter methods. This may be a good use case for a <a href=\"http://craftingruby.com/posts/2015/06/29/query-objects-through-scopes.html\" rel=\"nofollow\">query object</a>.</p>\\n<p>A filter object may also allow us to add filtering to broadcast messages.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/231', 'state': 'OPEN', 'createdAt': '2016-09-27T18:04:42Z', 'lastEditedAt': None, 'publishedAt': '2016-09-27T18:04:42Z', 'updatedAt': '2016-09-27T18:05:42Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update PR template', 'bodyHTML': '<p>Right now, our PR template includes</p>\\n<blockquote>\\n<p>Fixes issue(s)</p>\\n</blockquote>\\n<p>This does <em>not</em> auto-close the issue you link to. We should update so that we get that awesome auto-close behavior. So, change to one of these words/formats: <a href=\"https://help.github.com/articles/closing-issues-via-commit-messages/\">https://help.github.com/articles/closing-issues-via-commit-messages/</a></p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/237', 'state': 'OPEN', 'createdAt': '2016-10-25T23:36:27Z', 'lastEditedAt': None, 'publishedAt': '2016-10-25T23:36:27Z', 'updatedAt': '2016-10-25T23:36:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Non-admins should not be able to test messages, edit or delete users', 'bodyHTML': '<p>We should perform a full audit of which actions non-admins can take. Currently, regular users see the option to test messages and edit or delete users. No bueno.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/241', 'state': 'OPEN', 'createdAt': '2017-02-03T23:55:41Z', 'lastEditedAt': None, 'publishedAt': '2017-02-03T23:55:41Z', 'updatedAt': '2017-02-03T23:55:48Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix deprecation messsage', 'bodyHTML': '<p>After upgrading to Ruby 2.3.3, we starting seeing this OVER AND OVER when running <code>bundle exec rake</code></p>\\n<p>\"You are setting a key that conflicts with a built-in method`</p>\\n<p>Screenshot of how many times this shows up:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/601515/22613985/fb353e1e-ea31-11e6-8630-ed9820da8414.png\"><img src=\"https://cloud.githubusercontent.com/assets/601515/22613985/fb353e1e-ea31-11e6-8630-ed9820da8414.png\" alt=\"screen shot 2017-02-03 at 4 44 31 pm\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/244', 'state': 'OPEN', 'createdAt': '2017-02-04T00:59:16Z', 'lastEditedAt': None, 'publishedAt': '2017-02-04T00:59:16Z', 'updatedAt': '2017-02-04T00:59:45Z', 'labels': ['help wanted', 'ready-for-development'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix issues with employee records without slack user ids', 'bodyHTML': '<p>Right now, there are 100+ employee records on prod that do not have a slack user id.</p>\\n<p>This is problematic because we use the slack user id to send messages.</p>\\n<p>We should write code into our existing employee import tasks that:</p>\\n<ul>\\n<li>updates existing employee records that do not have slack user ids (find them by slack username).</li>\\n<li>soft delete that employee record that no longer exist (if find by slack username returns nil)</li>\\n</ul>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/245', 'state': 'OPEN', 'createdAt': '2017-02-04T01:24:18Z', 'lastEditedAt': None, 'publishedAt': '2017-02-04T01:24:18Z', 'updatedAt': '2017-02-04T01:24:24Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Issue with testing same message to same person', 'bodyHTML': '<p>in <code>app/services/message_sender.rb</code>, we create a <code>SentMessage</code> record for each message sent. This is so that we can record who receives what and when.</p>\\n<p>Right now, we validate the uniqueness of the employee id, message id, and message type for each sent message. So, if we try to test the same message to the same employee, that <code>SentMessage</code> creation while fail on the second try.</p>\\n<p>We do not need to create <code>SentMessage</code> records in the testing context. We need to find a way around this.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/250', 'state': 'CLOSED', 'createdAt': '2017-03-08T00:27:31Z', 'lastEditedAt': None, 'publishedAt': '2017-03-08T00:27:31Z', 'updatedAt': '2017-05-18T21:15:29Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'dolores-landingham-slack-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Move from Travis to Circle', 'bodyHTML': '<p>18F is moving away from TravisCI. We need to migrate Dolores over to CircleCI.</p>', 'url': 'https://github.com/18F/dolores-landingham-slack-bot/issues/257', 'state': 'OPEN', 'createdAt': '2017-09-01T15:31:47Z', 'lastEditedAt': None, 'publishedAt': '2017-09-01T15:31:47Z', 'updatedAt': '2018-04-02T19:57:19Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'handbook', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'consolidate Google Docs/Drive guidance', 'bodyHTML': '<p>There is very little in <a href=\"https://handbook.18f.gov/google-docs/\" rel=\"nofollow\">https://handbook.18f.gov/google-docs/</a> that is Docs-specific, and therefore we should merge the page into <a href=\"https://handbook.18f.gov/google-drive/\" rel=\"nofollow\">https://handbook.18f.gov/google-drive/</a>. We should also make sure to mention <a href=\"https://insite.gsa.gov/portal/content/517805\" rel=\"nofollow\">GACA Accounts</a> for sharing outside of GSA.</p>', 'url': 'https://github.com/18F/handbook/issues/22', 'state': 'OPEN', 'createdAt': '2016-10-11T18:17:10Z', 'lastEditedAt': None, 'publishedAt': '2016-10-11T18:17:10Z', 'updatedAt': '2016-12-11T07:01:44Z', 'labels': ['HIGH PRIORITY', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'fedramp-dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Use Case: Suspended Vendors', 'bodyHTML': '<p>New use case:<br>\\nWhen a vendor is suspended or loses FedRAMP (or Agency) authorization, what data field should be updated? How do we want this to display?</p>', 'url': 'https://github.com/18F/fedramp-dashboard/issues/54', 'state': 'OPEN', 'createdAt': '2016-09-06T17:56:11Z', 'lastEditedAt': None, 'publishedAt': '2016-09-06T17:56:11Z', 'updatedAt': '2016-09-16T20:18:23Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ojo-processing', 'repo_owner_name': 'Vightel Corporation', 'repo_owner_email': '', 'repo_owner_user_name': 'vightel', 'repo_owner_profile_url': 'https://github.com/vightel', 'title': 'Docker build gives error', 'bodyHTML': '<div class=\"highlight highlight-source-shell\"><pre>Thomas@biostar MINGW64 <span class=\"pl-k\">~</span>/Development/workshop/ojo-processing (master)\\n$ docker build -t ojo-processing <span class=\"pl-c1\">.</span></pre></div>\\n<p>gave this error:</p>\\n<p>Removing intermediate container e46740449913<br>\\nStep 4 : RUN sh /tmp/install_gdal2.sh<br>\\n---&gt; Running in 77cb3712852e<br>\\n: not foundl_gdal2.sh: 2: /tmp/install_gdal2.sh:<br>\\n/tmp/install_gdal2.sh: 3: cd: can\\'t cd to gdal2<br>\\n--2015-10-14 01:43:25--  <a href=\"http://download.osgeo.org/gdal/2.0.0/gdal-2.0.0.tar.gz%0D\" rel=\"nofollow\">http://download.osgeo.org/gdal/2.0.0/gdal-2.0.0.tar.gz%0D</a><br>\\nResolving download.osgeo.org (download.osgeo.org)... 140.211.15.132<br>\\nConnecting to download.osgeo.org (download.osgeo.org)|140.211.15.132|:80... connected.<br>\\nHTTP request sent, awaiting response... 404 Not Found<br>\\n2015-10-14 01:43:25 ERROR 404: Not Found.</p>\\n<p>tar (child): gdal-2.0.0.tar.gz\\\\r: Cannot open: No such file or directory<br>\\ntar (child): Error is not recoverable: exiting now<br>\\ntar: Child returned status 2<br>\\ntar: Error is not recoverable: exiting now<br>\\nrm: cannot remove \\'gdal-2.0.0.tar.gz\\\\r\\': No such file or directory<br>\\n: not foundl_gdal2.sh: 7: /tmp/install_gdal2.sh:<br>\\n/tmp/install_gdal2.sh: 8: cd: can\\'t cd to /tmp/gdal2/gdal-2.0.0/<br>\\n/tmp/install_gdal2.sh: 9: /tmp/install_gdal2.sh: ./configure: not found<br>\\n: not foundl_gdal2.sh: 10: /tmp/install_gdal2.sh: make<br>\\n\\'.  Stop. No rule to make target `install<br>\\n: not foundl_gdal2.sh: 12: /tmp/install_gdal2.sh: ldconfig<br>\\nrm: cannot remove \\'*\\\\r\\': No such file or directory<br>\\nSECURITY WARNING: You are building a Docker image from Windows against a non-Windows Docker host. All files and directories added to build context will have \\'-rwxr-xr-x\\' permissions. It is recommended to double check and reset permissions for sensitive files and directories.<br>\\nThe command \\'/bin/sh -c sh /tmp/install_gdal2.sh\\' returned a non-zero code: 1</p>', 'url': 'https://github.com/vightel/ojo-processing/issues/2', 'state': 'CLOSED', 'createdAt': '2015-10-14T01:49:44Z', 'lastEditedAt': None, 'publishedAt': '2015-10-14T01:49:44Z', 'updatedAt': '2015-11-12T21:51:49Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ojo-processing', 'repo_owner_name': 'Vightel Corporation', 'repo_owner_email': '', 'repo_owner_user_name': 'vightel', 'repo_owner_profile_url': 'https://github.com/vightel', 'title': \"image test won't start\", 'bodyHTML': '<div class=\"highlight highlight-source-shell\"><pre>$ docker run <span class=\"pl-smi\">$DATAFOLDER</span> --name ojo-processing -it --rm ojo-processing /bin/bash -login</pre></div>\\n<p>gives this error:</p>\\n<p>invalid value \"C:\\\\Users\\\\Thomas\\\\Development\\\\workshop\\\\ojo-processing;C:\\\\Program Files\\\\Git\\\\home\\\\workshop\\\\ojo-processing\" for flag -v: bad mount mode specified : \\\\Program Files\\\\Git\\\\home\\\\workshop\\\\ojo-processing<br>\\nSee \\'C:\\\\Program Files\\\\Docker Toolbox\\\\docker.exe run --help\\'.</p>', 'url': 'https://github.com/vightel/ojo-processing/issues/3', 'state': 'OPEN', 'createdAt': '2015-11-12T22:08:38Z', 'lastEditedAt': None, 'publishedAt': '2015-11-12T22:08:38Z', 'updatedAt': '2015-11-12T22:08:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'jobs_api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': \"Jobs API doesn't return postings that close on the current date\", 'bodyHTML': '<p>It appears that the jobs API doesn\\'t return postings that close on the current date.  The following screenshots were taken on Aug 26 and reference these URL\\'s</p>\\n<p><a href=\"https://api.usa.gov/jobs/search.json?organization_ids=IB00\" rel=\"nofollow\">https://api.usa.gov/jobs/search.json?organization_ids=IB00</a><br>\\n<a href=\"https://www.usajobs.gov/Search/RSSFeed/7085915/\" rel=\"nofollow\">https://www.usajobs.gov/Search/RSSFeed/7085915/</a></p>\\n<p><strong>This screenshot, taken Aug 26, shows that the USA Jobs website includes eleven jobs at BBG.gov.  Eight of them end on Aug 26</strong><br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/1021048/18012576/2b5b59a8-6b88-11e6-92d1-00ddb22fbe7a.png\"><img width=\"1296\" alt=\"usajobsfrontendaug26\" src=\"https://cloud.githubusercontent.com/assets/1021048/18012576/2b5b59a8-6b88-11e6-92d1-00ddb22fbe7a.png\" style=\"max-width:100%;\"></a></p>\\n<p><strong>This screenshot, also taken Aug 26, shows that the USA Jobs JSON feed only shows 3 jobs at BBG.gov</strong><br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/1021048/18012574/2b545ca2-6b88-11e6-9c64-c2ea20575006.png\"><img width=\"1040\" alt=\"usajobsjsonaug26\" src=\"https://cloud.githubusercontent.com/assets/1021048/18012574/2b545ca2-6b88-11e6-9c64-c2ea20575006.png\" style=\"max-width:100%;\"></a></p>\\n<p><strong>This screenshot, also taken Aug 26, shows that RSS Search shows all 11 jobs</strong><br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/1021048/18012575/2b59b030-6b88-11e6-9c52-afbb29fc195c.png\"><img width=\"1047\" alt=\"rsssearchaug26\" src=\"https://cloud.githubusercontent.com/assets/1021048/18012575/2b59b030-6b88-11e6-9c52-afbb29fc195c.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/GSA/jobs_api/issues/7', 'state': 'CLOSED', 'createdAt': '2016-08-26T16:33:16Z', 'lastEditedAt': None, 'publishedAt': '2016-08-26T16:33:16Z', 'updatedAt': '2018-03-12T14:49:31Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'jobs_api', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'jobs_api should work with Elasticsearch 5.x', 'bodyHTML': '<p>The current jobs_api codebase works (and is tested against) Elasticsearch 1.x. Since ES 1.x has been EOL since 2016, it makes sense to update it to work with Elasticsearch 5.x instead. For extra bonus future-proofing points, support for ES 6.x would be great, too.</p>', 'url': 'https://github.com/GSA/jobs_api/issues/15', 'state': 'CLOSED', 'createdAt': '2017-12-12T14:49:28Z', 'lastEditedAt': None, 'publishedAt': '2017-12-12T14:49:28Z', 'updatedAt': '2018-01-11T20:31:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Training and resources', 'bodyHTML': \"<p>From Nickolas Nikolic via Quora:</p>\\n<p>would suggest the inclusion of training resources so that consuming the data products be made more broad in respect to the perspectives interpreting the data. I would put resources ranging from introductory to quite comfortable using the content. For instance, the visualization demo at itdashboard.gov is quite useful for intuitive comparison and as a learning tool.</p>\\n<p>I'm sure that those in your department know of good resources for all skill levels.</p>\\n<p>The fundamental cause that guides most libraries is that providing training resources are necessary for equal access to services.</p>\\n<p>For instance, even if you are unable to read you can enlist the aid of the Library of Congress. And this organization is quite thorough in its conviction to provide the best research resources consistently through a mix of guided research suggestions as well as lending their librarians' research prowess to virtually any requester.</p>\\n<p>Home | Data.gov might consider a similar range of services for it's consumers at all levels of statistical knowledge. The 'meaning' of the offered numbers could very well represent very different things to unusual audiences with different perspectives and experiences.</p>\\n<p>Possibly the Library of Congress could be contacted regarding their methods of enabling equal access directly through their services in-house, as well as robust standards forming and molding of information science trickling to institutions that train other librarians who then go on to serve other populations? (Yes, it realize it's a very long sentence, but you get the point: they have a fairly complete model of impact as a research resource to the entire country ;-) )</p>\", 'url': 'https://github.com/GSA/data.gov/issues/43', 'state': 'CLOSED', 'createdAt': '2013-11-09T22:46:38Z', 'lastEditedAt': None, 'publishedAt': '2013-11-09T22:46:38Z', 'updatedAt': '2014-10-31T20:51:25Z', 'labels': ['content', 'help wanted', 'public feedback'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Training resources for statistics understanding (via Library of Congress)', 'bodyHTML': '<p>Training resources for statistics understanding (via Library of Congress)</p>', 'url': 'https://github.com/GSA/data.gov/issues/100', 'state': 'CLOSED', 'createdAt': '2013-11-20T15:59:20Z', 'lastEditedAt': None, 'publishedAt': '2013-11-20T15:59:20Z', 'updatedAt': '2017-03-01T20:35:41Z', 'labels': ['content', 'help wanted', 'public feedback'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Provide CKAN API documentation for catalog.data.gov', 'bodyHTML': '<p>This should be featured in the developer section and you can refer to <a href=\"http://www.healthdata.gov/catalog-api\" rel=\"nofollow\">http://www.healthdata.gov/catalog-api</a> as an example</p>', 'url': 'https://github.com/GSA/data.gov/issues/180', 'state': 'OPEN', 'createdAt': '2013-11-23T21:25:26Z', 'lastEditedAt': None, 'publishedAt': '2013-11-23T21:25:26Z', 'updatedAt': '2015-04-28T16:57:58Z', 'labels': ['api', 'content', 'developers', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Analysis on what open source projects are using federal datasets, using GitHub search', 'bodyHTML': '<p>You can search the full text of all open source code on GitHub (which is insane and magnificent), and one trick is to search it for domain names and URLs.</p>\\n<p>There are over 45,000 results for <a href=\"https://github.com/search?q=%22data.gov%22&amp;type=Code&amp;utf8=%E2%9C%93\">searching for \"data.gov\" on code in GitHub</a>, and <a href=\"https://github.com/search?q=%22data.gov%22&amp;type=Issues&amp;utf8=%E2%9C%93\">~350 issues</a>. There\\'s all kinds of data quality issues -- for example, <code>data.gov</code> is a subset of <code>api.data.gov</code>, dots aren\\'t handled perfectly, and many repos will come up more than once. But it\\'s still pretty cool.</p>\\n<p>I think it\\'d be more useful to take the URLs of datasets (and landing pages for datasets) known to Data.gov and run them through GitHub search and see what sort of things come up. It\\'d be a neat lead generator to find people working on niche or in-progress tools, that you\\'d be unlikely to come across in the press. Maybe it\\'s even a way to get deserving projects more press.</p>\\n<p>Unfortunately, GitHub doesn\\'t offer an API or feed of search result data across GitHub -- you have to use the web interface. (There is a <a href=\"https://developer.github.com/v3/search/\">Search API</a>, but unlike the web interface, it requires that searches be limited to a user, organization, or repository.)</p>\\n<p>So you\\'d probably have to scrape GitHub.com, the website, and page through data. Which sounds no fun, but to the right kind of brain might also sound <em>actually really fun</em>.</p>\\n<p>One other maybe-fun caveat is that if there are datasets that have support libraries built for them, some projects may just reference those libraries instead -- and so the URL for the dataset would only appear in the library, not the project. I can imagine this being the case for a well-established data agency like the US Census, for example. So identifying support libraries, and searching GitHub\\'s code for references to <em>them</em> would also help dig up some leads. But even for the Census\\' domain name, there are <a href=\"https://github.com/search?q=%22census.gov%22&amp;ref=searchresults&amp;type=Code&amp;utf8=%E2%9C%93\">lots of little projects</a>.</p>', 'url': 'https://github.com/GSA/data.gov/issues/464', 'state': 'OPEN', 'createdAt': '2014-09-16T06:13:51Z', 'lastEditedAt': None, 'publishedAt': '2014-09-16T06:13:51Z', 'updatedAt': '2015-02-16T04:28:08Z', 'labels': ['content', 'feature-request', 'help wanted', 'public feedback'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'update Data.gov README & Developers page to reflect more places to contribute', 'bodyHTML': '<p>Include:</p>\\n<ul>\\n<li><a href=\"https://github.com/GSA/ckanext-geodatagov\">https://github.com/GSA/ckanext-geodatagov</a></li>\\n<li><a href=\"https://github.com/GSA/ckanext-datajson\">https://github.com/GSA/ckanext-datajson</a></li>\\n<li><a href=\"https://github.com/GSA/project-open-data-dashboard\">https://github.com/GSA/project-open-data-dashboard</a></li>\\n<li><a href=\"https://github.com/GSA/idm\">https://github.com/GSA/idm</a></li>\\n<li><a href=\"https://github.com/GSA/custom-post-view-generator\">https://github.com/GSA/custom-post-view-generator</a></li>\\n<li><a href=\"https://github.com/GSA/USMetadata\">https://github.com/GSA/USMetadata</a></li>\\n<li><a href=\"https://github.com/GSA/ckan-php-client\">https://github.com/GSA/ckan-php-client</a></li>\\n<li><a href=\"https://github.com/GSA/ckan-php-manager\">https://github.com/GSA/ckan-php-manager</a></li>\\n<li><a href=\"https://github.com/GSA/data_gov_json_validator\">https://github.com/GSA/data_gov_json_validator</a></li>\\n<li><a href=\"https://github.com/GSA/datagov-design\">https://github.com/GSA/datagov-design</a></li>\\n<li><a href=\"https://github.com/GSA/wp-open311\">https://github.com/GSA/wp-open311</a></li>\\n<li><a href=\"https://github.com/GSA/enterprise-data-inventory\">https://github.com/GSA/enterprise-data-inventory</a></li>\\n<li><a href=\"https://github.com/GSA/open311-simple-crm\">https://github.com/GSA/open311-simple-crm</a></li>\\n<li><a href=\"https://github.com/GSA/datagov-custom\">https://github.com/GSA/datagov-custom</a></li>\\n<li><a href=\"https://github.com/GSA/data.gov-styleguide\">https://github.com/GSA/data.gov-styleguide</a></li>\\n</ul>\\n<p>Update those READMEs as well as old READMEs in forked/testing projects and /idp</p>', 'url': 'https://github.com/GSA/data.gov/issues/490', 'state': 'OPEN', 'createdAt': '2014-10-24T18:10:22Z', 'lastEditedAt': None, 'publishedAt': '2014-10-24T18:10:22Z', 'updatedAt': '2017-10-18T01:31:25Z', 'labels': ['content', 'help wanted', 'usability'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Redesign Applications Section of Data.gov', 'bodyHTML': '<p>It would be great if a user could sort all applications of datasets by topic and specific location. For instance, an easier way to identify the public safety applications in Chicago created from the data available on data.gov.</p>', 'url': 'https://github.com/GSA/data.gov/issues/578', 'state': 'CLOSED', 'createdAt': '2015-02-11T12:20:31Z', 'lastEditedAt': None, 'publishedAt': '2015-02-11T12:20:31Z', 'updatedAt': '2016-05-09T20:28:44Z', 'labels': ['apps', 'help wanted', 'public feedback', 'wordpress'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'data.gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Publisher links in breadcrumb need to include the organization', 'bodyHTML': '<p>The <a href=\"https://github.com/GSA/ckanext-datagovtheme/blob/master/ckanext/datagovtheme/templates/package/base.html#L16\">publisher breadcrumb links</a> currently don\\'t specify an organization and occasionally multiple organizations have the same publisher name. For example the organization/publisher breadcrumb in <a href=\"http://catalog.data.gov/dataset/mission-statement-vision-and-core-values\" rel=\"nofollow\">this Department of Commerce dataset</a> links to <a href=\"http://catalog.data.gov/dataset?publisher=Office+of+Inspector+General\" rel=\"nofollow\">Office of Inspector General</a> which includes datasets from multiple organizations instead of just the Department of Commerce</p>', 'url': 'https://github.com/GSA/data.gov/issues/666', 'state': 'CLOSED', 'createdAt': '2015-07-28T19:23:31Z', 'lastEditedAt': None, 'publishedAt': '2015-07-28T19:23:31Z', 'updatedAt': '2016-02-18T22:54:41Z', 'labels': ['catalog', 'ckan', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add Page to FAQ section on IV&V', 'bodyHTML': '<p>Draft from <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15947293\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/AlanAtlas\">@AlanAtlas</a> is <a href=\"https://docs.google.com/document/d/1lN6om6cvgbP5WOe27bzpPMAC9fhDU5vb3sTkbC2ryuE/edit?ts=58a6339a\" rel=\"nofollow\">here</a>.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/16', 'state': 'OPEN', 'createdAt': '2017-03-16T13:54:44Z', 'lastEditedAt': None, 'publishedAt': '2017-03-16T13:54:44Z', 'updatedAt': '2018-01-19T15:15:13Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add relevant content from 18F blog', 'bodyHTML': '<p>There are some posts on the 18F blog that can be used to reinforce and amplify the the points made on the site.</p>\\n<p>For example,<br>\\n<a href=\"https://18f.gsa.gov/2017/01/11/the-best-way-to-build-big-is-to-start-small/\" rel=\"nofollow\">https://18f.gsa.gov/2017/01/11/the-best-way-to-build-big-is-to-start-small/</a><br>\\n<a href=\"https://18f.gsa.gov/2014/09/08/the-encasement-strategy-on-legacy-systems-and-the/\" rel=\"nofollow\">https://18f.gsa.gov/2014/09/08/the-encasement-strategy-on-legacy-systems-and-the/</a></p>\\n<p>We should figure out a way to syndicate relevant content here.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/17', 'state': 'OPEN', 'createdAt': '2017-03-17T15:50:49Z', 'lastEditedAt': None, 'publishedAt': '2017-03-17T15:50:49Z', 'updatedAt': '2018-02-05T15:06:21Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Develop Vision Statement', 'bodyHTML': '<p>Develop a vision statement for the site and populate the README with it.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/24', 'state': 'OPEN', 'createdAt': '2017-08-08T18:33:19Z', 'lastEditedAt': None, 'publishedAt': '2017-08-08T18:33:19Z', 'updatedAt': '2018-01-19T15:14:41Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add captions for images on example pages', 'bodyHTML': '<p>The selection of images for certain pages may not be intuitive. Adding captions can help users understand context better.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/27', 'state': 'OPEN', 'createdAt': '2017-09-06T15:42:11Z', 'lastEditedAt': None, 'publishedAt': '2017-09-06T15:42:11Z', 'updatedAt': '2018-01-19T15:14:22Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update header image', 'bodyHTML': '<p>Not making a change yet because I\\'m also struggling to find the right image. On a larger monitor the child\\'s hand in the header image is kind of large, so I\\'ve been on the search for a different image.</p>\\n<p>Not change proposed until I find a new one, no reason not to move forward for now. <g-emoji class=\"g-emoji\" alias=\"grimacing\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f62c.png\"></g-emoji></p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/28', 'state': 'OPEN', 'createdAt': '2017-09-11T13:48:00Z', 'lastEditedAt': None, 'publishedAt': '2017-09-11T13:48:00Z', 'updatedAt': '2017-09-11T13:48:00Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Rename \"Helping Those in Need\" Page about Alaska', 'bodyHTML': '<p>\"Helping those in Need\" doesn\\'t quite speak to the magnitude of the work, and  doesn\\'t quite say what the thing is. Gonna do some brainstorming on what else might be a more specific option.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/29', 'state': 'CLOSED', 'createdAt': '2017-09-11T13:49:24Z', 'lastEditedAt': None, 'publishedAt': '2017-09-11T13:49:24Z', 'updatedAt': '2018-01-03T21:22:37Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Review / refresh content in Q&A section', 'bodyHTML': '<p><a href=\"https://modularcontracting.18f.gov/common-questions/\" rel=\"nofollow\">This content</a> needs review and possibly a refresh.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/34', 'state': 'CLOSED', 'createdAt': '2018-01-19T15:12:48Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T15:12:48Z', 'updatedAt': '2018-07-20T15:23:57Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'Modular-Contracting-And-Agile-Development', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Review / refresh content in Resources section', 'bodyHTML': '<p>We should review <a href=\"https://modularcontracting.18f.gov/resources/\" rel=\"nofollow\">this list of resources &amp; presentations</a> to ensure it is updated with the latest materials we have.</p>', 'url': 'https://github.com/18F/Modular-Contracting-And-Agile-Development/issues/35', 'state': 'OPEN', 'createdAt': '2018-01-19T15:13:55Z', 'lastEditedAt': None, 'publishedAt': '2018-01-19T15:13:55Z', 'updatedAt': '2018-01-19T15:13:55Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'fpki-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Navigation Item - Glossary Page', 'bodyHTML': '<h4>Description of Issue:</h4>\\n<p>A glossary that includes an alphabetical list of terms or words found throughout the FPKI Guides Playbook</p>\\n<h4>Details of Issue:</h4>\\n<h4>References (Docs, Links, Files):</h4>\\n<p><a href=\"http://pki.treas.gov/glossary.htm\" rel=\"nofollow\">http://pki.treas.gov/glossary.htm</a></p>\\n<h4>If a New Page or Content is Needed, Expected Outcomes:</h4>\\n<p>A content page that includes a glossary for FPKI Guide Playbook</p>\\n<h4>Link to the Content Page for Contributors:</h4>\\n<p><a href=\"https://github.com/GSA/fpki-guides/blob/staging/pages/fpki_glossary.md\">https://github.com/GSA/fpki-guides/blob/staging/pages/fpki_glossary.md</a></p>', 'url': 'https://github.com/GSA/fpki-guides/issues/50', 'state': 'CLOSED', 'createdAt': '2016-09-29T19:55:58Z', 'lastEditedAt': None, 'publishedAt': '2016-09-29T19:55:58Z', 'updatedAt': '2018-02-07T23:54:58Z', 'labels': ['Priority - Medium', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'fpki-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Card Testing Common Issues Checklist', 'bodyHTML': \"<h4>Description of Issue:</h4>\\n<p>Create a list of common issues discovered during PIV/PIV-I card testing for agencies to use as a pre-checklist before scheduling a date for in-person testing of PIV/PIV-I cards</p>\\n<h4>Details of Issue:</h4>\\n<p>The checklist will be separated by issue with description of what the problem is, general guidance on how to check for the issue on their credential, and links to requirement/reference docs.</p>\\n<p>The idea is for this to be a 'living document' with new issues included as they are discovered.</p>\\n<h4>References (Docs, Links, Files):</h4>\\n<p>word version of doc already created, not currently posted</p>\\n<h4>If a New Page or Content is Needed, Expected Outcomes:</h4>\\n<p>New Page to be created</p>\\n<h4>Link to the Content Page for Contributors:</h4>\\n<p>pull request submitted to create \\\\pages\\\\PIV_Testing_Checklist.md</p>\", 'url': 'https://github.com/GSA/fpki-guides/issues/74', 'state': 'OPEN', 'createdAt': '2017-04-06T18:49:04Z', 'lastEditedAt': None, 'publishedAt': '2017-04-06T18:49:04Z', 'updatedAt': '2017-05-04T20:31:05Z', 'labels': ['Priority - Medium', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'fpki-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Host FPKI Change NOTIFICATIONS on this repo', 'bodyHTML': '<h4>Description of Issue:</h4>\\n<ul>\\n<li>Instead of posting documents to idmanagement.gov, use fpki-guides to post change NOTIFICATIONS</li>\\n</ul>\\n<h4>Details of Issue:</h4>\\n<ul>\\n<li>Add a running change proposal page</li>\\n</ul>\\n<h4>References (Docs, Links, Files):</h4>\\n<h4>If a New Page or Content is Needed, Expected Outcomes:</h4>\\n<h4>Link to the Content Page for Contributors:</h4>', 'url': 'https://github.com/GSA/fpki-guides/issues/76', 'state': 'CLOSED', 'createdAt': '2017-04-11T18:31:09Z', 'lastEditedAt': '2017-04-11T18:35:20Z', 'publishedAt': '2017-04-11T18:31:09Z', 'updatedAt': '2017-08-27T22:02:30Z', 'labels': ['CP Playbook Team', 'Priority - Medium', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'product-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'SECTION UPDATE (Project Start) - SOWs', 'bodyHTML': '<p>This guide doesn\\'t mention creating an SOW. Does that go under Project Start? Where does it belong?</p>\\n<p>A good point of reference for SOWs on the googledrive is <a href=\"https://drive.google.com/drive/u/0/search?q=SOW\" rel=\"nofollow\">this folder of examples</a>.</p>', 'url': 'https://github.com/18F/product-guide/issues/5', 'state': 'CLOSED', 'createdAt': '2016-01-12T18:00:38Z', 'lastEditedAt': None, 'publishedAt': '2016-01-12T18:00:38Z', 'updatedAt': '2018-01-16T21:46:05Z', 'labels': ['help wanted', 'question', 'waiting for content'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'product-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'SECTION UPDATE (Project Comms) - Product storytellers', 'bodyHTML': '<p>Product storytellers are something we may be implementing to handle project communications. It has not been fully socialized yet, but if we move forward with it, we will want to add to and perhaps edit the Project Communications section of the guide to fold this in.</p>', 'url': 'https://github.com/18F/product-guide/issues/12', 'state': 'CLOSED', 'createdAt': '2016-01-15T20:57:39Z', 'lastEditedAt': None, 'publishedAt': '2016-01-15T20:57:39Z', 'updatedAt': '2018-01-16T21:46:05Z', 'labels': ['help wanted', 'process change'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'product-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'SECTION UPDATE (Research) - Mindmaps', 'bodyHTML': '<p>Does 18F use mindmaps during early project discovery? If this is a useful tool to us, we should add it to our user research deliverables perhaps. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16668007\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/porta-antiporta\">@porta-antiporta</a> has created a mindmap that we could use as an example (not sure where it is documented, but more info about that <a href=\"https://18f.slack.com/archives/product/p1453925867000077\" rel=\"nofollow\">here</a>).</p>\\n<p><a href=\"https://18f.slack.com/archives/product/p1453846341000024\" rel=\"nofollow\">slack convo for background</a></p>', 'url': 'https://github.com/18F/product-guide/issues/19', 'state': 'CLOSED', 'createdAt': '2016-01-27T22:24:17Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T22:24:17Z', 'updatedAt': '2018-01-16T21:45:54Z', 'labels': ['help wanted', 'process change', 'question'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'product-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'UPDATE SECTION (Handoffs & renewals) - Post-handoff ATO', 'bodyHTML': '<p>Note from <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=86842\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/afeld\">@afeld</a> on the <strong>Renewals &amp; Handoffs</strong> section -</p>\\n<p>\"Is there anything that needs to happen in regards to the ATO? Do they need to re-complete one within their agency?\"</p>', 'url': 'https://github.com/18F/product-guide/issues/21', 'state': 'CLOSED', 'createdAt': '2016-01-27T23:14:37Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T23:14:37Z', 'updatedAt': '2018-01-16T21:45:54Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'product-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'UPDATE SECTION (Budgeting) - Team burn tracking template', 'bodyHTML': '<p>Add a template spreadsheet for tracking team hour burn rates.</p>\\n<p>Can/do we normally generate these types of reports from a formal system, like Tock?<br>\\nWhat can we use to manage resource allocation and also share easily with clients (though sharing with a client is tricky, and folks should talk with Finance to understand what they want to share, when we should share what data, etc.)</p>\\n<p><a href=\"https://18f.slack.com/archives/product/p1454017941000183\" rel=\"nofollow\">slack convo for background</a></p>', 'url': 'https://github.com/18F/product-guide/issues/30', 'state': 'CLOSED', 'createdAt': '2016-01-28T22:49:32Z', 'lastEditedAt': None, 'publishedAt': '2016-01-28T22:49:32Z', 'updatedAt': '2018-01-16T21:45:54Z', 'labels': ['help wanted', 'waiting for content'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'make the warning message configurable', 'bodyHTML': '', 'url': 'https://github.com/18F/private-eye/issues/1', 'state': 'CLOSED', 'createdAt': '2016-01-12T16:44:33Z', 'lastEditedAt': None, 'publishedAt': '2016-01-12T16:44:33Z', 'updatedAt': '2016-03-31T20:51:31Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'exclude unnecessary files from module', 'bodyHTML': '<p>Relevant after <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"126547293\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/private-eye/issues/7\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/private-eye/pull/7/hovercard\" href=\"https://github.com/18F/private-eye/pull/7\">#7</a> is merged. Not sure what the best practice is around, for example, whether files like the README and the related assets should be distributed or not... <code>package.json</code> and <code>private-eye.js</code> are the only files that are <em>really</em> needed. Would love input from others.</p>', 'url': 'https://github.com/18F/private-eye/issues/8', 'state': 'OPEN', 'createdAt': '2016-01-14T00:25:57Z', 'lastEditedAt': None, 'publishedAt': '2016-01-14T00:25:57Z', 'updatedAt': '2016-01-22T01:24:26Z', 'labels': ['enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'match URLs case-insensitively', 'bodyHTML': '<p>Unfortunate that the case-insensitive flag for <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/Attribute_selectors\" rel=\"nofollow\">attribute selectors</a> doesn\\'t have broad <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/Attribute_selectors#Browser_compatibility\" rel=\"nofollow\">browser support</a> yet.</p>', 'url': 'https://github.com/18F/private-eye/issues/9', 'state': 'CLOSED', 'createdAt': '2016-01-14T17:54:01Z', 'lastEditedAt': None, 'publishedAt': '2016-01-14T17:54:01Z', 'updatedAt': '2017-10-12T20:56:03Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'recommend using `defer`?', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=706004\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/rogeruiz\">@rogeruiz</a> made the suggestion in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"126547293\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/private-eye/issues/7\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/private-eye/pull/7/hovercard?comment_id=49684409&amp;comment_type=review_comment\" href=\"https://github.com/18F/private-eye/pull/7#discussion_r49684409\">#7 (comment)</a>  would be awesome to recommend it. The only tricky thing is that plugin needs to be initialized with the call to <code>PrivateEye()</code>...is the preferred way to do that through the <code>onload</code>, as recommended in <a href=\"https://webkit.org/blog/1395/running-scripts-in-webkit/\" rel=\"nofollow\">https://webkit.org/blog/1395/running-scripts-in-webkit/</a>? Also don\\'t want to make the setup any more confusing.</p>', 'url': 'https://github.com/18F/private-eye/issues/10', 'state': 'CLOSED', 'createdAt': '2016-01-14T18:42:23Z', 'lastEditedAt': None, 'publishedAt': '2016-01-14T18:42:23Z', 'updatedAt': '2017-10-12T19:35:43Z', 'labels': ['enhancement', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'investigate using CSS attribute selectors', 'bodyHTML': '<p>Rather than adding a class to each private link, what if the config generated CSS that achieved the same thing?</p>\\n<div class=\"highlight highlight-source-css\"><pre><span class=\"pl-ent\">a</span>[<span class=\"pl-e\">href</span><span class=\"pl-k\">~=</span><span class=\"pl-s\">{{url}}</span>] {\\n  <span class=\"pl-c\"><span class=\"pl-c\">/*</span> styles <span class=\"pl-c\">*/</span></span>\\n}}</pre></div>\\n<p>Suggestion by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2970\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/andrewmaier\">@andrewmaier</a>.</p>', 'url': 'https://github.com/18F/private-eye/issues/12', 'state': 'OPEN', 'createdAt': '2016-02-25T16:03:57Z', 'lastEditedAt': None, 'publishedAt': '2016-02-25T16:03:57Z', 'updatedAt': '2016-02-25T16:03:57Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Can we scope this to a particular part of the page?', 'bodyHTML': '<blockquote>\\n<p>Id love to scope it to a selector. Right now its tagging administrative links in the footer of the Handbook, which are in the footer for just that reason! :simple_smile:</p>\\n</blockquote>', 'url': 'https://github.com/18F/private-eye/issues/13', 'state': 'CLOSED', 'createdAt': '2016-02-25T17:09:24Z', 'lastEditedAt': None, 'publishedAt': '2016-02-25T17:09:24Z', 'updatedAt': '2017-10-12T19:32:29Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'link to the repository (and instructions) from the demo site', 'bodyHTML': '<p><a href=\"https://pages.18f.gov/private-eye/\" rel=\"nofollow\">Demo site</a></p>\\n<p>This could be done via a <a href=\"https://github.com/simonwhitaker/github-fork-ribbon-css\">GitHub Ribbon</a> (with the assets copied into this repo, instead of using the CDN), or a simple link in the text somewhere.</p>', 'url': 'https://github.com/18F/private-eye/issues/15', 'state': 'CLOSED', 'createdAt': '2016-05-25T18:56:59Z', 'lastEditedAt': '2016-05-31T15:24:21Z', 'publishedAt': '2016-05-25T18:56:59Z', 'updatedAt': '2016-06-03T16:06:38Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'expand test suite', 'bodyHTML': '<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"126222504\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/private-eye/issues/4\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/private-eye/issues/4/hovercard?comment_id=336247323&amp;comment_type=issue_comment\" href=\"https://github.com/18F/private-eye/issues/4#issuecomment-336247323\">#4 (comment)</a></p>', 'url': 'https://github.com/18F/private-eye/issues/27', 'state': 'CLOSED', 'createdAt': '2017-10-12T21:42:17Z', 'lastEditedAt': None, 'publishedAt': '2017-10-12T21:42:17Z', 'updatedAt': '2017-10-16T17:35:23Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'private-eye', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'consolidate instructions', 'bodyHTML': '<p>Right now, the setup/usage/demo lives across the README and the homepage. We should pick one for the user-focused documentation to live (probably the homepage), and move all the relevant info there.</p>', 'url': 'https://github.com/18F/private-eye/issues/28', 'state': 'OPEN', 'createdAt': '2017-10-12T21:44:50Z', 'lastEditedAt': None, 'publishedAt': '2017-10-12T21:44:50Z', 'updatedAt': '2017-10-12T21:44:50Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'hub', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Reimagine the design of the Hub', 'bodyHTML': \"<p>If there is a designer with spare cycles, I would be happy to re-imagine the Hub design again now that we have learned more about where we're going and what people what to use it for. Ping me if you want background (sorry that I don't have time to write a nice issue for you now!) :(</p>\", 'url': 'https://github.com/18F/hub/issues/213', 'state': 'OPEN', 'createdAt': '2015-03-10T18:19:15Z', 'lastEditedAt': None, 'publishedAt': '2015-03-10T18:19:15Z', 'updatedAt': '2015-04-29T21:20:21Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'jkan', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add additional fields to core Dataset', 'bodyHTML': '<h2>Test on <a href=\"https://demo.jkan.io/data.json\" rel=\"nofollow\">https://demo.jkan.io/data.json</a></h2>\\n<h2>Using <a href=\"https://labs.data.gov/dashboard/validate\" rel=\"nofollow\">https://labs.data.gov/dashboard/validate</a> data.json v1.1</h2>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6350035/15082086/da7e8e7a-1393-11e6-9a5d-b415e21948a5.png\"><img src=\"https://cloud.githubusercontent.com/assets/6350035/15082086/da7e8e7a-1393-11e6-9a5d-b415e21948a5.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/6350035/15082060/cce7196c-1393-11e6-9501-507ba421ce33.png\"><img src=\"https://cloud.githubusercontent.com/assets/6350035/15082060/cce7196c-1393-11e6-9501-507ba421ce33.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/GSA/jkan/issues/1', 'state': 'OPEN', 'createdAt': '2016-05-06T18:08:34Z', 'lastEditedAt': None, 'publishedAt': '2016-05-06T18:08:34Z', 'updatedAt': '2016-05-10T04:15:41Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'jkan', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Consider moving \"Progress Bar\" attributes to Dataset and associate with a linkto field', 'bodyHTML': '<p>Right now the <a href=\"http://gsa.github.io/jkan/dashboard/1_Poverty/\" rel=\"nofollow\">Data Dashboard</a> page attributes are used to <code>status</code> the dataset. Would it make more sense to add this as an element of a dataset and use a linkto field to associate a dataset to an indicator?</p>', 'url': 'https://github.com/GSA/jkan/issues/2', 'state': 'OPEN', 'createdAt': '2016-05-06T18:11:20Z', 'lastEditedAt': None, 'publishedAt': '2016-05-06T18:11:20Z', 'updatedAt': '2016-05-06T20:29:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'jkan', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Use JSON-editor form to manage the editing of indicators', 'bodyHTML': '<p>Using the form in a modal pop-up to load the yaml from github API convert it into json -&gt; load it into a \"watched\" window in the form editor to pre-populate the contents using a validated json schema for the <code>indicator</code> collection type specific json schema:<br>\\n<a href=\"https://github.com/project-open-data/datajson-editor\">https://github.com/project-open-data/datajson-editor</a></p>\\n<p>...to edit entries here:<br>\\n<a href=\"http://gsa.github.io/jkan/dashboard/1_Poverty/\" rel=\"nofollow\">http://gsa.github.io/jkan/dashboard/1_Poverty/</a></p>', 'url': 'https://github.com/GSA/jkan/issues/3', 'state': 'OPEN', 'createdAt': '2016-05-06T18:15:46Z', 'lastEditedAt': None, 'publishedAt': '2016-05-06T18:15:46Z', 'updatedAt': '2016-05-06T20:29:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'jkan', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Best way to previewedit csv files from within the site', 'bodyHTML': '<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"124616196\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/prose/prose/issues/911\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/prose/prose/pull/911/hovercard\" href=\"https://github.com/prose/prose/pull/911\">prose/prose#911</a></p>', 'url': 'https://github.com/GSA/jkan/issues/4', 'state': 'OPEN', 'createdAt': '2016-05-06T18:16:40Z', 'lastEditedAt': None, 'publishedAt': '2016-05-06T18:16:40Z', 'updatedAt': '2016-05-06T20:29:25Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'sdg-indicators', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Translate Reporting Status', 'bodyHTML': '<p>sdg-indicators/fr/reporting-status.md is showing in Spanish</p>', 'url': 'https://github.com/GSA/sdg-indicators/issues/908', 'state': 'CLOSED', 'createdAt': '2018-05-08T12:07:28Z', 'lastEditedAt': None, 'publishedAt': '2018-05-08T12:07:28Z', 'updatedAt': '2018-06-01T13:27:03Z', 'labels': ['French', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'sdg-indicators', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'statistics.md', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1319083\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/brockfanning\">@brockfanning</a> - <a href=\"https://gsa.github.io/sdg-indicators/fr/statistics/\" rel=\"nofollow\">https://gsa.github.io/sdg-indicators/fr/statistics/</a> page does not render images ... the broken links are in Spanish when using the inspect tool</p>', 'url': 'https://github.com/GSA/sdg-indicators/issues/917', 'state': 'CLOSED', 'createdAt': '2018-05-09T00:18:43Z', 'lastEditedAt': '2018-05-09T00:51:35Z', 'publishedAt': '2018-05-09T00:18:43Z', 'updatedAt': '2018-05-21T14:01:16Z', 'labels': ['French', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'sdg-indicators', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'franais button', 'bodyHTML': '<p>insert button into banner</p>', 'url': 'https://github.com/GSA/sdg-indicators/issues/918', 'state': 'CLOSED', 'createdAt': '2018-05-09T00:29:40Z', 'lastEditedAt': None, 'publishedAt': '2018-05-09T00:29:40Z', 'updatedAt': '2018-05-21T14:00:46Z', 'labels': ['French', 'help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'sdg-indicators', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Landing page translation', 'bodyHTML': '<p>new image map: the original file is locked behind Max.gov</p>\\n<p>text translation for landing page</p>', 'url': 'https://github.com/GSA/sdg-indicators/issues/940', 'state': 'CLOSED', 'createdAt': '2018-07-13T13:37:07Z', 'lastEditedAt': None, 'publishedAt': '2018-07-13T13:37:07Z', 'updatedAt': '2018-10-15T13:10:39Z', 'labels': ['French', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': \"As a Student, once I've executed a Search, I'd like to be able to click on anyplace in the school box to get more School details, so that is super easy for me to dive in deeper.\", 'bodyHTML': '<p>Each school \"box\" should be clickable in its entirety especially on Desktop. There should be an outline hover state for the whole box and I should be able to click anywhere within the box to get to the Details page.</p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/241', 'state': 'CLOSED', 'createdAt': '2015-07-27T14:58:10Z', 'lastEditedAt': None, 'publishedAt': '2015-07-27T14:58:10Z', 'updatedAt': '2016-07-28T17:14:08Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Enhancement', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'BUG: On the Location search, the user should only be able to search by State OR Region OR Zip Code + Mile Radius. Not all 3 at once. Once one option is selected, the others should be disabled.', 'bodyHTML': '<p>Design comp showing search by State active:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9097614/8c68a060-3b92-11e5-9b98-c798565229ad.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9097614/8c68a060-3b92-11e5-9b98-c798565229ad.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/329', 'state': 'OPEN', 'createdAt': '2015-08-05T20:54:51Z', 'lastEditedAt': None, 'publishedAt': '2015-08-05T20:54:51Z', 'updatedAt': '2016-07-28T17:14:01Z', 'labels': ['Area - Consumer Tool', 'B', 'Backlog', 'Bang 2 - Med', 'Bang For Buck 1 - Low', 'Buck 2 - Med', 'Priority 2', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 7}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': \"BUG: There should only be an 'X' button or an 'ADD' button, never both\", 'bodyHTML': '<p>Current display:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9314870/a55789f4-44f9-11e5-9a9b-c4e58f47f312.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9314870/a55789f4-44f9-11e5-9a9b-c4e58f47f312.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Change to:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9315041/bd48fc2c-44fa-11e5-9230-7b5e9e648bbe.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9315041/bd48fc2c-44fa-11e5-9230-7b5e9e648bbe.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Please note that the \"x\" and \"add state\" icons should never display together. Only once the user selects a state, should the \"x\" icon display.</p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/426', 'state': 'CLOSED', 'createdAt': '2015-08-17T20:13:44Z', 'lastEditedAt': None, 'publishedAt': '2015-08-17T20:13:44Z', 'updatedAt': '2016-07-28T17:14:03Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'ENHANCEMENT: Add scrollbar to list of Available Areas of Study so that it is obvious that you can scroll up and down in this area', 'bodyHTML': '<p>Mac Chrome (2:53pm)</p>\\n<p>Hard to tell that this a scrollable region:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9502955/33be863e-4c02-11e5-8492-8b8597a0083d.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9502955/33be863e-4c02-11e5-8492-8b8597a0083d.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/635', 'state': 'CLOSED', 'createdAt': '2015-08-26T18:55:03Z', 'lastEditedAt': None, 'publishedAt': '2015-08-26T18:55:03Z', 'updatedAt': '2016-07-28T17:14:03Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 2 - Med', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'DISPLAY: On individual school page, size of basic information icons should get smaller on mobile to fit on one line', 'bodyHTML': '<p>Screenshot:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9692679/b5c794aa-5318-11e5-99a9-76c5fee7d0c8.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9692679/b5c794aa-5318-11e5-99a9-76c5fee7d0c8.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Original design:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9692686/c0232946-5318-11e5-837a-9a0786f389cf.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9692686/c0232946-5318-11e5-837a-9a0786f389cf.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/1040', 'state': 'CLOSED', 'createdAt': '2015-09-04T19:22:37Z', 'lastEditedAt': None, 'publishedAt': '2015-09-04T19:22:37Z', 'updatedAt': '2016-01-12T02:26:08Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': \"DISPLAY: On mobile, on individual school page expand/collapse containers, ensure there is ~10-15px of inner margin so the text doesn't run into the border\", 'bodyHTML': '<p>Screenshot:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9693128/f99294e8-531b-11e5-8c52-0825bebb16c7.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9693128/f99294e8-531b-11e5-8c52-0825bebb16c7.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>The \"mo\" should only go as wide as the inner horizontal rule.</p>\\n<p>Original design:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9693150/1b65a22c-531c-11e5-88e8-99078bb76810.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9693150/1b65a22c-531c-11e5-88e8-99078bb76810.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Changing the \"/mo\" font weight from bold to regular might help with this a bit, but not sure if it will eradicate the issue.</p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/1045', 'state': 'CLOSED', 'createdAt': '2015-09-04T19:47:37Z', 'lastEditedAt': None, 'publishedAt': '2015-09-04T19:47:37Z', 'updatedAt': '2016-01-12T02:26:08Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'DISPLAY: On iphone 5, to much space between \"of\" and \"students\" on % earning over $25K metric', 'bodyHTML': '<p>Screenshot:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9693272/187a4abc-531d-11e5-8be4-234ddf595219.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9693272/187a4abc-531d-11e5-8be4-234ddf595219.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>Reduce the line space between \"86% of\" and \"students\"</p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/1046', 'state': 'CLOSED', 'createdAt': '2015-09-04T19:54:04Z', 'lastEditedAt': None, 'publishedAt': '2015-09-04T19:54:04Z', 'updatedAt': '2016-01-12T02:26:09Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'DISPLAY: On iphone 5, possible to fit full-time/part-time % on one line?', 'bodyHTML': '<p>Screenshot:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9693313/64aab516-531d-11e5-9742-7fd6f6b63715.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9693313/64aab516-531d-11e5-9742-7fd6f6b63715.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/1047', 'state': 'CLOSED', 'createdAt': '2015-09-04T19:56:41Z', 'lastEditedAt': None, 'publishedAt': '2015-09-04T19:56:41Z', 'updatedAt': '2016-07-28T17:14:05Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'Add \"Higher than Average\" qualifier to earnings chart', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12847090/9696298/99fb2b60-533b-11e5-9454-415d9fb99259.png\"><img src=\"https://cloud.githubusercontent.com/assets/12847090/9696298/99fb2b60-533b-11e5-9454-415d9fb99259.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/1066', 'state': 'CLOSED', 'createdAt': '2015-09-04T23:32:20Z', 'lastEditedAt': None, 'publishedAt': '2015-09-04T23:32:20Z', 'updatedAt': '2016-07-28T17:14:14Z', 'labels': ['Area - Consumer Tool', 'B', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Theme 3 - Students To Value Metrics', 'Type - Enhancement', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'college-scorecard', 'repo_owner_name': 'RTICWDT', 'repo_owner_email': None, 'repo_owner_user_name': 'RTICWDT', 'repo_owner_profile_url': 'https://github.com/RTICWDT', 'title': 'DISPLAY: When selection made in search criteria, change selected item text to be #040404', 'bodyHTML': '<p>Screenshot:<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/12192706/9700264/8882881c-53ca-11e5-8741-700d3c9aa7be.png\"><img src=\"https://cloud.githubusercontent.com/assets/12192706/9700264/8882881c-53ca-11e5-8741-700d3c9aa7be.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\\n<p>In this case, \"New Jersey\" should change from <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"103348827\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/RTICWDT/college-scorecard/issues/666\" data-hovercard-type=\"issue\" data-hovercard-url=\"/RTICWDT/college-scorecard/issues/666/hovercard\" href=\"https://github.com/RTICWDT/college-scorecard/issues/666\">#666</a> to #040404 once it is selected.</p>', 'url': 'https://github.com/RTICWDT/college-scorecard/issues/1089', 'state': 'CLOSED', 'createdAt': '2015-09-05T16:35:31Z', 'lastEditedAt': None, 'publishedAt': '2015-09-05T16:35:31Z', 'updatedAt': '2016-01-12T02:26:09Z', 'labels': ['Area - Consumer Tool', 'Bang 1 - Low', 'Bang For Buck 1 - Low', 'Buck 1 - Low', 'Defer', 'Scrub (Sabrina)', 'Type - Bug', 'display', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'sirepo', 'repo_owner_name': 'RadiaSoft LLC', 'repo_owner_email': 'support@radiasoft.net', 'repo_owner_user_name': 'radiasoft', 'repo_owner_profile_url': 'https://github.com/radiasoft', 'title': 'Problem with long-running calculations on cpu-001', 'bodyHTML': '<p>When I try to import <a href=\"https://github.com/radiasoft/sirepo/blob/master/tests/importer_data/srx.py\">https://github.com/radiasoft/sirepo/blob/master/tests/importer_data/srx.py</a> and perform further calculation on the Beamline tab, the calculations fail after ~2 minutes. The calculation is running within radiasoft/sirepo:alpha Docker image on cpu-001. Here is the part of <code>uwsgi.log</code> log:</p>\\n<pre lang=\"log\"><code>*** Starting uWSGI 2.0.12 (64bit) on [Wed Apr 13 20:58:33 2016] ***\\ncompiled with version: 4.9.2 20150212 (Red Hat 4.9.2-6) on 12 April 2016 22:02:03\\nos: Linux-3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u4 (2016-02-29)\\nnodename: sirepo\\nmachine: x86_64\\nclock source: unix\\npcre jit disabled\\ndetected number of CPU cores: 72\\ncurrent working directory: /vagrant\\nwriting pidfile to /vagrant/uwsgi.pid\\ndetected binary path: /home/vagrant/.pyenv/versions/2.7.10/bin/uwsgi\\nyour processes number limit is 4096\\nyour memory page size is 4096 bytes\\ndetected max file descriptor number: 4096\\nlock engine: pthread robust mutexes\\nthunder lock: disabled (you can enable it with --thunder-lock)\\nuwsgi socket 0 bound to TCP address 0.0.0.0:7000 fd 3\\nPython version: 2.7.10 (default, Mar  3 2016, 17:24:18)  [GCC 4.9.2 20150212 (Red Hat 4.9.2-6)]\\nPython main interpreter initialized at 0x177a620\\npython threads support enabled\\nyour server socket listen backlog is limited to 100 connections\\nyour mercy for graceful operations on workers is 60 seconds\\nmapped 331008 bytes (323 KB) for 10 cores\\n*** Operational MODE: threaded ***\\nWSGI app 0 (mountpoint=\\'\\') ready in 2 seconds on interpreter 0x177a620 pid: 193 (default app)\\n*** uWSGI is running in multiple interpreter mode ***\\nspawned uWSGI master process (pid: 193)\\nspawned uWSGI worker 1 (pid: 198, cores: 10)\\n*** Stats server enabled on /vagrant/uwsgi.sock fd: 11 ***\\n.........................\\n[pid: 198|app: 0|req: 35/35] 10.0.137.37 () {48 vars in 904 bytes} [Wed Apr 13 21:02:50 2016] GET /file-list/srw/WrrpgRmU/mirror?20160407 =&gt; generated 35 bytes in 2 msecs (HTTP/1.1 200) 2 headers in 79 bytes (1 switches on core 8)\\nWed Apr 13 21:04:58 2016 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 331] during POST /run (10.0.137.37)\\nIOError: write error\\n[pid: 198|app: 0|req: 37/36] 10.0.137.37 () {52 vars in 948 bytes} [Wed Apr 13 21:02:51 2016] POST /run =&gt; generated 86803 bytes in 127534 msecs (HTTP/1.1 200) 2 headers in 77 bytes (0 switches on core 4)\\nWed Apr 13 21:07:05 2016 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 331] during POST /run (10.0.137.37)\\nIOError: write error\\n[pid: 198|app: 0|req: 37/37] 10.0.137.37 () {52 vars in 948 bytes} [Wed Apr 13 21:04:51 2016] POST /run =&gt; generated 86803 bytes in 134292 msecs (HTTP/1.1 200) 2 headers in 77 bytes (0 switches on core 6)\\n</code></pre>\\n<p>The same problem is observed on alpha, see <a href=\"http://alpha.sirepo.com/srw#/beamline/s95YvwnI\" rel=\"nofollow\">http://alpha.sirepo.com/srw#/beamline/s95YvwnI</a>.</p>', 'url': 'https://github.com/radiasoft/sirepo/issues/161', 'state': 'CLOSED', 'createdAt': '2016-04-13T21:18:39Z', 'lastEditedAt': None, 'publishedAt': '2016-04-13T21:18:39Z', 'updatedAt': '2016-04-14T12:41:12Z', 'labels': ['1', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'asis', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'ASIS should work with Elasticsearch 5.x', 'bodyHTML': '<p>The current ASIS codebase works (and is tested against) Elasticsearch 1.x. Since ES 1.x has been EOL since 2016, it makes sense to update it to work with Elasticsearch 5.x instead. For extra bonus future-proofing points, support for ES 6.x would be great, too.</p>', 'url': 'https://github.com/GSA/asis/issues/16', 'state': 'CLOSED', 'createdAt': '2017-12-12T14:48:27Z', 'lastEditedAt': None, 'publishedAt': '2017-12-12T14:48:27Z', 'updatedAt': '2018-01-04T04:53:23Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'piv-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Need scripts or common tools for identifying all Intermediate certificate authorities and certificates', 'bodyHTML': '<p>I\\'m trying to collect scripts, government or open source tools for identifying all the intermediate certificate authorities and valid intermediate certificates which chain to Federal Common Policy Certificate Authority (Common).</p>\\n<p>This is needed for legacy network authentication implementations, and for applications that do not fully implement path discovery or validation protocols (RFC 5280).   We have tools for visually viewing the certificate authorities; however, <strong>automated</strong> discovery and retrieval of all certificates can be a manually intensive process.</p>\\n<ul>\\n<li><a href=\"http://fpki-graph.fpki-lab.gov/\" rel=\"nofollow\">http://fpki-graph.fpki-lab.gov/</a></li>\\n</ul>\\n<p>Scripts could include:</p>\\n<ul>\\n<li>Powershell with certutil</li>\\n<li>Ksh with openssl</li>\\n<li>Java</li>\\n<li>Other</li>\\n</ul>', 'url': 'https://github.com/GSA/piv-guides/issues/8', 'state': 'OPEN', 'createdAt': '2016-04-18T01:52:25Z', 'lastEditedAt': None, 'publishedAt': '2016-04-18T01:52:25Z', 'updatedAt': '2017-03-28T14:05:20Z', 'labels': ['Priority - High', 'help wanted', 'network'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'piv-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'MacOSX and Network Auth', 'bodyHTML': '<p>For MacOSX and <em>network authentication</em> (aka bound to a network domain), NIH has a private repository for a plugin that builds upon the native smart card apis.</p>\\n<ul>\\n<li><a href=\"https://github.com/NIH-CIT/NIHAuthPlugin\">https://github.com/NIH-CIT/NIHAuthPlugin</a></li>\\n</ul>\\n<p>There are also commercially available options.<br>\\nNeed to add a section under network for MacOSX and considerations.</p>', 'url': 'https://github.com/GSA/piv-guides/issues/17', 'state': 'OPEN', 'createdAt': '2016-04-27T13:43:10Z', 'lastEditedAt': None, 'publishedAt': '2016-04-27T13:43:10Z', 'updatedAt': '2018-10-03T23:18:18Z', 'labels': ['Priority - Medium', 'help wanted', 'network'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'piv-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Caching behavior when switching between privileged and non-privileged contexts', 'bodyHTML': '<p>Add configurations and lessons learned regarding the caching behavior and workarounds for:</p>\\n<ul>\\n<li>Performing \"run as\" functions to escalate privileges to a privileged account</li>\\n<li>one cached credential stored for certificates</li>\\n<li>user switches back to normal account after disconnect from network</li>\\n<li>locked out because cache is privileged account</li>\\n</ul>\\n<p>Include:</p>\\n<ul>\\n<li>Cached credentials limit (2 to 5)</li>\\n<li>bug reports</li>\\n<li>Workarounds</li>\\n<li>VPN configurations</li>\\n</ul>', 'url': 'https://github.com/GSA/piv-guides/issues/19', 'state': 'OPEN', 'createdAt': '2016-04-27T17:17:15Z', 'lastEditedAt': None, 'publishedAt': '2016-04-27T17:17:15Z', 'updatedAt': '2016-06-02T01:07:01Z', 'labels': ['Priority - Medium', 'enhancement', 'help wanted', 'network'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'piv-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Importing intermediate CA certs into NSS', 'bodyHTML': '<p>PIV Auth via browser - specific for managed enterprise devices</p>\\n<ul>\\n<li>Firefox browsers in use</li>\\n<li>NSS needs to be updated using non-manual (no user intervention) methods by enterprise engineers</li>\\n<li>Some of the intermediate CAs in the FPKI stop the CA name at OU rather than using a CN</li>\\n<li>Do full chains for client (user) provided certificates need to be configured in the client for two-way TLS to succeed?</li>\\n</ul>\\n<p>certutil or other methods to manage <em>enterprise</em> configurations for NSS</p>', 'url': 'https://github.com/GSA/piv-guides/issues/20', 'state': 'OPEN', 'createdAt': '2016-04-27T17:45:22Z', 'lastEditedAt': None, 'publishedAt': '2016-04-27T17:45:22Z', 'updatedAt': '2018-05-09T16:16:09Z', 'labels': ['CP Playbook Team', 'Engineer FAQ', 'FAQ', 'Priority - Medium', 'applications', 'help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'piv-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Which platforms break when not using principal name?', 'bodyHTML': '<p>We need some feedback here to understand any repercussions with not using Principal Name mapping for network.</p>\\n<p>Primarily for common implementations and office automation tools (cloud email providers, common federation services).</p>', 'url': 'https://github.com/GSA/piv-guides/issues/23', 'state': 'OPEN', 'createdAt': '2016-04-27T22:25:51Z', 'lastEditedAt': None, 'publishedAt': '2016-04-27T22:25:51Z', 'updatedAt': '2016-06-02T01:04:27Z', 'labels': ['Priority - High', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'piv-guides', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Network authentication configurations to accept all Govt PIV/CACs', 'bodyHTML': \"<p>From hack the playbooks session</p>\\n<h4>Description of Issue:</h4>\\n<ul>\\n<li>How do I configure my  to accept any Govt User's PIV for Authentication</li>\\n<li>Network is the <strong>system</strong>, not an internet facing web application.</li>\\n</ul>\\n<h4>Use case:</h4>\\n<p>As an agency, I have other <strong>government</strong> users on detail or working in my agency through cross-collaboration on special programs.  These government users are provided a network account for my network, and I want to configure my network domain(s) to authenticate the user with their PIV/CAC credential without issuing a new PIV/CAC from my agency.</p>\\n<h4>Details of Issue:</h4>\\n<p>Challenges</p>\\n<ul>\\n<li>I need to manage multiple trust stores for network authentication or federation services or VPN services</li>\\n<li>I want a list of certificates and configurations to support this</li>\\n<li>Only for other Government agency users</li>\\n<li>I want notification on when new Intermediate certificates are generated and a place for me and my engineers to poll these certificates if I need to update my trust stores</li>\\n<li>I want clear information on account linking options and what is the lowest common denominator that will work for all PIV/CAC credentials and associated certificates that have been issued and are <strong>valid today</strong>.</li>\\n</ul>\\n<h4>If a New Page or Content is Needed, Expected Outcomes:</h4>\\n<h4>Link to the Content Page for Contributors:</h4>\\n<p>TBD</p>\", 'url': 'https://github.com/GSA/piv-guides/issues/97', 'state': 'OPEN', 'createdAt': '2017-03-27T13:22:05Z', 'lastEditedAt': None, 'publishedAt': '2017-03-27T13:22:05Z', 'updatedAt': '2018-06-14T13:48:57Z', 'labels': ['CP Playbook Team', 'Priority - High', 'help wanted', 'network'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'search-gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Upgrade to jQuery3', 'bodyHTML': '<p>Our jQuery implementations are currently a bit long in the tooth:</p>\\n<ul>\\n<li>The SAYT tool <a href=\"https://github.com/GSA/search-gov/blob/master/app/assets/javascripts/sayt_loader_libs.js\">uses jQuery 1.7.1</a></li>\\n<li>The SERP and admin tools use <a href=\"https://github.com/rails/jquery-rails/tree/v3.1.4\">jquery-rails 3.1.4</a>, and therefore jQuery 1.11.1</li>\\n</ul>\\n<p>It would be great if both of these uses were upgraded to the latest-and-greatest jQuery 3 without any loss of functionality <em>or</em> the introduction of any Javascript errors in the SERP pages of Search.gov customers who embed the SAYT library in their own pages.</p>', 'url': 'https://github.com/GSA/search-gov/issues/2', 'state': 'CLOSED', 'createdAt': '2018-03-07T18:29:46Z', 'lastEditedAt': '2018-03-07T18:30:37Z', 'publishedAt': '2018-03-07T18:29:46Z', 'updatedAt': '2018-04-03T21:30:30Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'search-gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Separate ELK ES client config from custom index ES client config', 'bodyHTML': '<p>Right now the <a href=\"https://github.com/GSA/search-gov/blob/master/lib/es.rb\">ES module</a> is designed in such a way that all accesses to Elasticsearch go to the same cluster endpoint(s).</p>\\n<p>We would like to be able to send requests related to <a href=\"https://github.com/GSA/search-gov/blob/79b80c4fac0ecbbff0a0ed2c70642a727fa7ac82/app/models/rtu_top_n.rb\">analytics</a> to one ES endpoint and requests related to our custom document indices (i.e. anything using <a href=\"https://github.com/GSA/search-gov/blob/79b80c4fac0ecbbff0a0ed2c70642a727fa7ac82/lib/indexable.rb\">Indexable</a>) to another ES endpoint. This separation would allow us to upgrade our Elasticsearch usage from ES 1.x to ES 5.x or 6.x independently: first for analytics, then for our custom indices; or vice versa.</p>', 'url': 'https://github.com/GSA/search-gov/issues/3', 'state': 'OPEN', 'createdAt': '2018-03-07T18:44:00Z', 'lastEditedAt': None, 'publishedAt': '2018-03-07T18:44:00Z', 'updatedAt': '2018-06-08T17:56:30Z', 'labels': ['good first issue', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'search-gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Upgrade Kibana/Logstash/analytics to Elasticsearch 5.6.x', 'bodyHTML': '<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"303214631\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/GSA/search-gov/issues/3\" data-hovercard-type=\"issue\" data-hovercard-url=\"/GSA/search-gov/issues/3/hovercard\" href=\"https://github.com/GSA/search-gov/issues/3\">#3</a> for background. Once we can separate ES connections for Kibana/Logstash/analytics from ES connections for custom indices, we would like to upgrade our ES server version for Logstash to use ES 5.6.x.</p>', 'url': 'https://github.com/GSA/search-gov/issues/4', 'state': 'OPEN', 'createdAt': '2018-03-07T18:45:47Z', 'lastEditedAt': None, 'publishedAt': '2018-03-07T18:45:47Z', 'updatedAt': '2018-03-07T18:45:58Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'search-gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Upgrade custom indices to use Elasticsearch 5.6.x', 'bodyHTML': '<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"303214631\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/GSA/search-gov/issues/3\" data-hovercard-type=\"issue\" data-hovercard-url=\"/GSA/search-gov/issues/3/hovercard\" href=\"https://github.com/GSA/search-gov/issues/3\">#3</a> for background. Once we can separate ES connections for Kibana/Logstash/analytics from ES connections for custom indices, we would like to upgrade our ES server version for custom indices to use ES 5.6.x.</p>', 'url': 'https://github.com/GSA/search-gov/issues/5', 'state': 'OPEN', 'createdAt': '2018-03-07T18:46:34Z', 'lastEditedAt': None, 'publishedAt': '2018-03-07T18:46:34Z', 'updatedAt': '2018-03-07T18:46:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'search-gov', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Upgrade search-gov to Rails 5.x', 'bodyHTML': \"<p>It's time to say farewell to the fours and hello to the fives, in order to keep the codebase current with security patches and the latest Rails features.</p>\\n<p>The search-gov app currently uses 4.2.10, and we should upgrade either to the latest 5.1.x release (5.1.5 at the time of writing), or 5.2.x if it is released prior to working on this story.</p>\", 'url': 'https://github.com/GSA/search-gov/issues/9', 'state': 'OPEN', 'createdAt': '2018-03-09T12:08:43Z', 'lastEditedAt': None, 'publishedAt': '2018-03-09T12:08:43Z', 'updatedAt': '2018-06-08T16:57:29Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cg-diagrams', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'The \"Save as PNG\" diagrams have un-styled text that is hard to read', 'bodyHTML': '<p>In order for our team to easily grab portable images of our diagrams to share with compliance reviewers and other interested people, the \"Save as PNG\" button should generate PNGs that match the styling of the displayed diagrams.</p>\\n<p>Right now the \"Save as PNG\" images have the wrong styling for text - here\\'s an example:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/391313/20573827/84f329d6-b166-11e6-97b2-b125f56f683a.png\"><img src=\"https://cloud.githubusercontent.com/assets/391313/20573827/84f329d6-b166-11e6-97b2-b125f56f683a.png\" alt=\"10-1-network 2\" style=\"max-width:100%;\"></a></p>\\n<p>Compare to the site:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/391313/20573837/8b0f4048-b166-11e6-82a0-ccded39fbba8.png\"><img src=\"https://cloud.githubusercontent.com/assets/391313/20573837/8b0f4048-b166-11e6-82a0-ccded39fbba8.png\" alt=\"screen shot 2016-11-23 at 10 20 23 am\" style=\"max-width:100%;\"></a></p>\\n<p>This isn\\'t a big deal since we can also export images by taking a whole-page screenshot, but it\\'d be nice to fix eventually.</p>', 'url': 'https://github.com/18F/cg-diagrams/issues/40', 'state': 'OPEN', 'createdAt': '2016-11-23T18:22:31Z', 'lastEditedAt': None, 'publishedAt': '2016-11-23T18:22:31Z', 'updatedAt': '2017-02-02T02:54:59Z', 'labels': ['HighBar', 'bug', 'help wanted'], 'is_locked': False, 'total_participants': 6}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add guidance for mass emails/newsletters', 'bodyHTML': '<p>More people are moving their email lists to MailChimp and are creating new lists of users of our products. They have been asking for guidance on 18F style for emails. Our content guidance could include:</p>\\n<ul>\\n<li>Subject line, header, and from best practices</li>\\n<li>Newsletter specific tone</li>\\n<li>Image, media, and video embedding guidance</li>\\n<li>Length an organization guidance</li>\\n<li>Strategies for responding</li>\\n</ul>', 'url': 'https://github.com/18F/content-guide/issues/82', 'state': 'OPEN', 'createdAt': '2015-12-30T21:52:22Z', 'lastEditedAt': None, 'publishedAt': '2015-12-30T21:52:22Z', 'updatedAt': '2017-11-21T16:28:48Z', 'labels': ['help wanted', 'new content needed'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Move content about link text to its own section?', 'bodyHTML': '<p>Currently it\\'s part of the URLs and filenames section: <a href=\"https://pages.18f.gov/content-guide/urls-and-filenames/#link-text\" rel=\"nofollow\">https://pages.18f.gov/content-guide/urls-and-filenames/#link-text</a></p>\\n<p>I think it should probably be its own section.</p>', 'url': 'https://github.com/18F/content-guide/issues/148', 'state': 'OPEN', 'createdAt': '2016-09-22T22:24:18Z', 'lastEditedAt': None, 'publishedAt': '2016-09-22T22:24:18Z', 'updatedAt': '2017-11-21T16:40:17Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add info from Federalist content guide', 'bodyHTML': '<p>There is content on the federalist site for how to write content that is not on the 18F Content Guide site. I think it would be beneficial to have all the content guidelines on the 18F Content Guide and move the following pages from the federalist docs to the content guide and reference them there.<br>\\nThis would give one source of truth for content.</p>\\n<ul>\\n<li><a href=\"https://federalist-docs.18f.gov/pages/content-guide/\" rel=\"nofollow\">Content guide</a></li>\\n<li><a href=\"https://federalist-docs.18f.gov/pages/content-guide/writing-content-for-your-federalist-homepage/\" rel=\"nofollow\">Writing content for your homepage</a></li>\\n<li><a href=\"https://federalist-docs.18f.gov/pages/content-guide/best-practices-for-writing-who-we-are/\" rel=\"nofollow\">Writing about your team</a></li>\\n<li><a href=\"https://federalist-docs.18f.gov/pages/content-guide/best-practices-for-writing-what-we-do/\" rel=\"nofollow\">Writing about your research</a></li>\\n<li><a href=\"https://federalist-docs.18f.gov/pages/content-guide/contact-forms/\" rel=\"nofollow\">Writing clear contact forms</a></li>\\n</ul>', 'url': 'https://github.com/18F/content-guide/issues/167', 'state': 'OPEN', 'createdAt': '2017-03-20T17:12:09Z', 'lastEditedAt': None, 'publishedAt': '2017-03-20T17:12:09Z', 'updatedAt': '2017-11-21T16:40:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Readme needs a few updates', 'bodyHTML': '<p>Still lists Kate and Emileigh as guild leads, for example.</p>\\n<p>Also has a few stray primes over apostrophes.</p>\\n<p><a href=\"https://github.com/18F/content-guide/blob/18f-pages/README.md\">https://github.com/18F/content-guide/blob/18f-pages/README.md</a></p>', 'url': 'https://github.com/18F/content-guide/issues/180', 'state': 'OPEN', 'createdAt': '2017-07-11T18:26:58Z', 'lastEditedAt': None, 'publishedAt': '2017-07-11T18:26:58Z', 'updatedAt': '2017-11-21T16:45:15Z', 'labels': ['help wanted', 'info is incorrect/out-of-date'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add section on socioeconomic status on the inclusive language (conscious style) page', 'bodyHTML': '<p>What should we keep in mind when we talk about class, socioeconomic status, or income of an individual or group?</p>', 'url': 'https://github.com/18F/content-guide/issues/190', 'state': 'OPEN', 'createdAt': '2017-08-16T20:56:54Z', 'lastEditedAt': None, 'publishedAt': '2017-08-16T20:56:54Z', 'updatedAt': '2017-11-21T16:44:42Z', 'labels': ['help wanted', 'new content needed'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add guidance on release notes', 'bodyHTML': '<p>Howdy! A cross-post from the xd content trello board - it might be worth adding guidance on writing human-centered release notes. (We could repurpose the checklist developed for the WDS as a starting point...)</p>', 'url': 'https://github.com/18F/content-guide/issues/197', 'state': 'OPEN', 'createdAt': '2017-10-31T20:01:33Z', 'lastEditedAt': None, 'publishedAt': '2017-10-31T20:01:33Z', 'updatedAt': '2017-11-21T16:46:04Z', 'labels': ['help wanted', 'new content needed'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Provide writing examples for your guidelines', 'bodyHTML': '<p>Can you provide examples to your writing recommendations? This can give people ideas for improving their writing.</p>', 'url': 'https://github.com/18F/content-guide/issues/198', 'state': 'OPEN', 'createdAt': '2017-11-15T12:15:20Z', 'lastEditedAt': None, 'publishedAt': '2017-11-15T12:15:20Z', 'updatedAt': '2017-11-21T16:45:03Z', 'labels': ['help wanted', 'new content needed'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add site metadescription', 'bodyHTML': '<p>Ex:</p>\\n<blockquote>\\n<p>How to plan, write, and manage content at 18F.</p>\\n</blockquote>', 'url': 'https://github.com/18F/content-guide/issues/200', 'state': 'OPEN', 'createdAt': '2017-11-20T17:14:42Z', 'lastEditedAt': None, 'publishedAt': '2017-11-20T17:14:42Z', 'updatedAt': '2017-11-21T16:45:07Z', 'labels': ['help wanted', 'new content needed', 'technical issue'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'content-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'collaborate: Use it or avoid it?', 'bodyHTML': '<p>The <a href=\"https://content-guide.18f.gov/plain-language/\" rel=\"nofollow\">https://content-guide.18f.gov/plain-language/</a> says to avoid <em>collaborate</em>. But <em>collaborate</em> is suggested in favor of <em>liase</em>.</p>', 'url': 'https://github.com/18F/content-guide/issues/206', 'state': 'OPEN', 'createdAt': '2017-12-08T14:26:55Z', 'lastEditedAt': None, 'publishedAt': '2017-12-08T14:26:55Z', 'updatedAt': '2018-01-03T15:49:43Z', 'labels': ['help wanted', 'info is unclear'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'API Cache Controls', 'bodyHTML': \"<p>The data in the API basically never changes. Once we're behind api.data.gov, it'd be nice to rely on their caching, which means we need to set the appropriate cache control headers.</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/28', 'state': 'OPEN', 'createdAt': '2015-09-17T15:39:42Z', 'lastEditedAt': None, 'publishedAt': '2015-09-17T15:39:42Z', 'updatedAt': '2016-01-13T01:29:52Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add about.yaml', 'bodyHTML': '<p>See <a href=\"https://github.com/18F/about_yml\">https://github.com/18F/about_yml</a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/61', 'state': 'CLOSED', 'createdAt': '2015-10-30T16:03:21Z', 'lastEditedAt': None, 'publishedAt': '2015-10-30T16:03:21Z', 'updatedAt': '2015-12-08T18:10:05Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update regulations-site frontend libs', 'bodyHTML': \"<p>From gemnasium results:</p>\\n<ul>\\n<li>backbone 1.0.0 -&gt; 1.2.3</li>\\n<li>htmlshiv 3.6.2 -&gt; 3.7.2</li>\\n<li>jquery 1.11.0 -&gt; 2.1.4 (may need to stay in the 1.X line)</li>\\n<li>respond 1.1.0 -&gt; 1.4.2</li>\\n</ul>\\n<p>Would be good to send these to CFPB (and/or pull in any updates they've made)</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/89', 'state': 'CLOSED', 'createdAt': '2015-11-13T18:23:33Z', 'lastEditedAt': None, 'publishedAt': '2015-11-13T18:23:33Z', 'updatedAt': '2015-12-07T15:58:43Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Investigate a loop-back between regulations-site and -core', 'bodyHTML': '<p>At the moment, we have a multi-tier app, with a hard separation between the API and UI. All communications are serialized into JSON over HTTP. This is rather inefficient, as every instance of eRegs to date has included both applications in a single django instance.</p>\\n<p>Would it make sense for <code>regulations-site</code> to be aware of this scenario and use more direct methods of accessing the data?</p>', 'url': 'https://github.com/18F/atf-eregs/issues/98', 'state': 'OPEN', 'createdAt': '2015-11-13T21:48:22Z', 'lastEditedAt': None, 'publishedAt': '2015-11-13T21:48:22Z', 'updatedAt': '2015-12-01T22:32:50Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'XML Sync corner case', 'bodyHTML': '<ul>\\n<li>User A runs <code>pipeline</code> for regulation 100</li>\\n<li>User B pushes an updated final rule affecting 100</li>\\n<li>User A runs <code>pipeline</code> again</li>\\n</ul>\\n<p>Although A pulls down the modified final rule, the parser skips over it since the rule parsed fine before. We just need to add a quick \"check if there is now a local notice\" step</p>\\n<p>Note that this is different than:</p>\\n<ul>\\n<li>User B pushes an updated final rule affecting 100</li>\\n<li>User A runs <code>pipeline</code> for regulation 100</li>\\n<li>User B modified the final rule further</li>\\n<li>User A runs <code>pipeline</code> again</li>\\n</ul>\\n<p>This scenario <em>is</em> already accounted for, despite being the less common situation</p>', 'url': 'https://github.com/18F/atf-eregs/issues/109', 'state': 'OPEN', 'createdAt': '2015-11-18T22:44:01Z', 'lastEditedAt': None, 'publishedAt': '2015-11-18T22:44:01Z', 'updatedAt': '2015-12-01T22:33:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Leverage pv-cfenv', 'bodyHTML': '<p>We\\'re parsing a few cloud.gov env vars ourself. Use <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1633460\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jmcarp\">@jmcarp</a>\\'s <a href=\"https://github.com/jmcarp/py-cfenv\">https://github.com/jmcarp/py-cfenv</a> instead</p>', 'url': 'https://github.com/18F/atf-eregs/issues/117', 'state': 'CLOSED', 'createdAt': '2015-11-22T01:52:32Z', 'lastEditedAt': None, 'publishedAt': '2015-11-22T01:52:32Z', 'updatedAt': '2016-02-08T21:19:29Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '478 numbered \"note\"', 'bodyHTML': '<p>See <code>478-103/2014-18392#478-103-e-p2-p4</code></p>\\n<p>There shouldn\\'t be a number here<br>\\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/326918/11478243/cbf83aec-9759-11e5-8431-6b103432248e.png\"><img width=\"596\" alt=\"screen shot 2015-11-30 at 11 59 54 am\" src=\"https://cloud.githubusercontent.com/assets/326918/11478243/cbf83aec-9759-11e5-8431-6b103432248e.png\" style=\"max-width:100%;\"></a></p>\\n<p>This hasn\\'t been an issue for previous \"note\"s because they were in the appendix.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/134', 'state': 'CLOSED', 'createdAt': '2015-11-30T17:00:36Z', 'lastEditedAt': None, 'publishedAt': '2015-11-30T17:00:36Z', 'updatedAt': '2015-12-17T18:54:44Z', 'labels': ['help wanted', 'waiting on pr'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'HTTPS for Google Tag Manager', 'bodyHTML': '<p>Pull in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"118885969\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/cfpb/regulations-site/issues/758\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/cfpb/regulations-site/pull/758/hovercard\" href=\"https://github.com/cfpb/regulations-site/pull/758\">cfpb/regulations-site#758</a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/135', 'state': 'CLOSED', 'createdAt': '2015-11-30T17:39:21Z', 'lastEditedAt': None, 'publishedAt': '2015-11-30T17:39:21Z', 'updatedAt': '2016-01-12T19:40:32Z', 'labels': ['help wanted', 'waiting on pr'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add warning for 478, 555', 'bodyHTML': '<p>Given that we\\'re displaying regulations which we haven\\'t quite validated, we should add some sort of warning on their landing pages. Here\\'s how CFPB does this:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/326918/11506035/4dbbc83e-981b-11e5-98b7-ba53293bb573.png\"><img width=\"1103\" alt=\"screen shot 2015-12-01 at 11 04 47 am\" src=\"https://cloud.githubusercontent.com/assets/326918/11506035/4dbbc83e-981b-11e5-98b7-ba53293bb573.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/137', 'state': 'CLOSED', 'createdAt': '2015-12-01T16:04:41Z', 'lastEditedAt': None, 'publishedAt': '2015-12-01T16:04:41Z', 'updatedAt': '2015-12-03T23:04:05Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Supplement I reference in the Help module', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4267825/11509202/c784b9e6-982a-11e5-9e1f-c2f7c98f7d03.png\"><img src=\"https://cloud.githubusercontent.com/assets/4267825/11509202/c784b9e6-982a-11e5-9e1f-c2f7c98f7d03.png\" alt=\"screen shot 2015-12-01 at 12 12 56 pm\" style=\"max-width:100%;\"></a></p>\\n<p>We should probably take this out since all other references to these explandables have been taken out.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/139', 'state': 'CLOSED', 'createdAt': '2015-12-01T17:55:40Z', 'lastEditedAt': None, 'publishedAt': '2015-12-01T17:55:40Z', 'updatedAt': '2016-01-13T21:51:00Z', 'labels': ['help wanted', 'waiting on pr'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Specifically note Python2 in READMEs', 'bodyHTML': \"<p>We only support Python2 &gt;= 2.7. We don't support Python3 at this time.</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/141', 'state': 'CLOSED', 'createdAt': '2015-12-01T22:25:44Z', 'lastEditedAt': None, 'publishedAt': '2015-12-01T22:25:44Z', 'updatedAt': '2015-12-07T18:51:57Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Switch badges to 18f repos', 'bodyHTML': '<p>Our README badges point to the CFPB repos</p>', 'url': 'https://github.com/18F/atf-eregs/issues/142', 'state': 'CLOSED', 'createdAt': '2015-12-01T22:26:20Z', 'lastEditedAt': None, 'publishedAt': '2015-12-01T22:26:20Z', 'updatedAt': '2015-12-07T16:44:15Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'TERMS -> LICENSE', 'bodyHTML': '<blockquote>\\n<p>Suggest a PR back to CFPB to change the TERMS.md to LICENSE.md. This aligns with our repos and how GitHub auto-creates these files, so it will be good for CFPB too. No need to wait for a yes or no, just checking the box we tried to align here.</p>\\n</blockquote>', 'url': 'https://github.com/18F/atf-eregs/issues/144', 'state': 'OPEN', 'createdAt': '2015-12-01T23:43:49Z', 'lastEditedAt': None, 'publishedAt': '2015-12-01T23:43:49Z', 'updatedAt': '2015-12-01T23:43:49Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Integrate About.yml for ATF eRegs on 18F Dashboard', 'bodyHTML': '<p>Dashboard Update (From Greg Boone)<br>\\nA small team from the Agile Guild is working on the Dashboard right now</p>\\n<p>A few months ago the Dashboard started pulling all project data from the Team API</p>\\n<p>We are working closely with the Team API and About.yml teams to get project data prepared for the Dashboard</p>\\n<p>If your project has an about.yml file in the main repo, that is where Dashboards data comes from</p>\\n<p>If your project doesnt have an about.yml file, we look for a file in the data-private repo</p>\\n<p>We also keep a whitelist of projects in the Dashboard repo to filter out GitHub repos that are in the team API that dont directly relate to a product or are components of products</p>\\n<p>if your product is not on this list get in touch with Greg or drop in the #dashboard channel to get it added</p>\\n<p>We are currently working on finding ways to better integrate child repos and understand how 18F product teams describe their products so that we can better represent the work 18F is doing to the public</p>', 'url': 'https://github.com/18F/atf-eregs/issues/167', 'state': 'CLOSED', 'createdAt': '2015-12-08T18:08:12Z', 'lastEditedAt': None, 'publishedAt': '2015-12-08T18:08:12Z', 'updatedAt': '2016-02-17T23:14:52Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Mobile menu broken on landing page', 'bodyHTML': '<ol>\\n<li>Go to <a href=\"https://atf-eregs.18f.gov/\" rel=\"nofollow\">https://atf-eregs.18f.gov/</a></li>\\n<li>Shrink the width until the mobile menu appears</li>\\n<li>Try to open it. At the moment, nothing happens</li>\\n</ol>', 'url': 'https://github.com/18F/atf-eregs/issues/169', 'state': 'OPEN', 'createdAt': '2015-12-08T18:12:08Z', 'lastEditedAt': None, 'publishedAt': '2015-12-08T18:12:08Z', 'updatedAt': '2016-01-13T01:29:27Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Review static analysis tools', 'bodyHTML': '<p>The world\\'s moved on since eregs first began. Research and consider integrating:</p>\\n<ul>\\n<li>Code Climate</li>\\n<li>Quantified Code</li>\\n<li>Scrutinizer-CI</li>\\n<li>Requires.io</li>\\n<li><a href=\"https://github.com/openstack/bandit\">https://github.com/openstack/bandit</a></li>\\n<li>Hound</li>\\n</ul>', 'url': 'https://github.com/18F/atf-eregs/issues/170', 'state': 'OPEN', 'createdAt': '2015-12-09T21:02:53Z', 'lastEditedAt': None, 'publishedAt': '2015-12-09T21:02:53Z', 'updatedAt': '2015-12-09T21:02:53Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'TOC is still visible when left drawer is closed', 'bodyHTML': '<p>When the left drawer is closed you can still see and use the Table of Contents sections. This shouldn\\'t happen.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4267825/11905639/8e367210-a595-11e5-8190-038d4225167b.png\"><img width=\"69\" alt=\"screen shot 2015-12-18 at 12 04 37 pm\" src=\"https://cloud.githubusercontent.com/assets/4267825/11905639/8e367210-a595-11e5-8190-038d4225167b.png\" style=\"max-width:100%;\"></a></p>\\n<p>Here\\'s what it looks like in the CFPB version:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4267825/11905725/f59940c2-a595-11e5-9d8b-3425442c5c1c.png\"><img width=\"56\" alt=\"screen shot 2015-12-18 at 2 45 02 pm\" src=\"https://cloud.githubusercontent.com/assets/4267825/11905725/f59940c2-a595-11e5-9d8b-3425442c5c1c.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/189', 'state': 'CLOSED', 'createdAt': '2015-12-18T19:45:28Z', 'lastEditedAt': None, 'publishedAt': '2015-12-18T19:45:28Z', 'updatedAt': '2016-06-03T03:29:57Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Spin up multiple instances', 'bodyHTML': '<p>Right now we use only a single instance, yet are paying for a quota. Spin up more instances for production.</p>\\n<p>This requires modifying the startup script so that only one instance clears the search index, migrates the DB, etc.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/199', 'state': 'CLOSED', 'createdAt': '2015-12-28T16:27:40Z', 'lastEditedAt': None, 'publishedAt': '2015-12-28T16:27:40Z', 'updatedAt': '2016-02-09T15:11:50Z', 'labels': ['1 complexity (low)', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Replace waitress', 'bodyHTML': '<p>With Gunicorn. Update cloud.gov docs to point to this as a recommendation.</p>\\n<p>See openFEC for an example.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/200', 'state': 'CLOSED', 'createdAt': '2015-12-28T16:28:19Z', 'lastEditedAt': None, 'publishedAt': '2015-12-28T16:28:19Z', 'updatedAt': '2016-03-02T18:45:17Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': \"Don't allow terms to be defined inside a Note\", 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/326918/12025780/b32f87ac-ad77-11e5-85d7-4fccd4f68289.png\"><img width=\"872\" alt=\"screen shot 2015-12-28 at 3 30 18 pm\" src=\"https://cloud.githubusercontent.com/assets/326918/12025780/b32f87ac-ad77-11e5-85d7-4fccd4f68289.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/204', 'state': 'CLOSED', 'createdAt': '2015-12-28T21:29:18Z', 'lastEditedAt': None, 'publishedAt': '2015-12-28T21:29:18Z', 'updatedAt': '2016-01-28T21:45:05Z', 'labels': ['2 complexity (medium low)', 'help wanted', 'waiting on pr'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Upgrade to Django 1.9', 'bodyHTML': '<p>Requires changes in <code>-core</code>, <code>-site</code>, <code>atf-eregs</code> and testing</p>', 'url': 'https://github.com/18F/atf-eregs/issues/208', 'state': 'OPEN', 'createdAt': '2015-12-30T05:06:21Z', 'lastEditedAt': None, 'publishedAt': '2015-12-30T05:06:21Z', 'updatedAt': '2016-02-01T22:06:23Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Super bold text in Safari', 'bodyHTML': '<p>In Safari I\\'m seeing a lot of extra bold text, I\\'m not sure why. The fonts look normal in Chrome and Firefox.</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4267825/12055684/7b4b23aa-aefd-11e5-93a9-97d70fdcd93a.png\"><img src=\"https://cloud.githubusercontent.com/assets/4267825/12055684/7b4b23aa-aefd-11e5-93a9-97d70fdcd93a.png\" alt=\"screen shot 2015-12-30 at 1 57 37 pm\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/211', 'state': 'CLOSED', 'createdAt': '2015-12-30T18:59:04Z', 'lastEditedAt': None, 'publishedAt': '2015-12-30T18:59:04Z', 'updatedAt': '2016-02-16T17:25:31Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Cover missing code path', 'bodyHTML': '<p>I needed to add <a class=\"commit-link\" href=\"https://github.com/eregs/regulations-site/commit/f9dbdf0bab612a00382c2ba3b9c860ebd738b166\">eregs/regulations-site@<tt>f9dbdf0</tt></a> to a PR recently. This is problematic as that\\'s a pretty well trodden code path but no tests caught it.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/215', 'state': 'OPEN', 'createdAt': '2016-01-02T20:17:40Z', 'lastEditedAt': None, 'publishedAt': '2016-01-02T20:17:40Z', 'updatedAt': '2016-01-13T01:27:02Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': \"Don't pull from github so often\", 'bodyHTML': '<p>Currently, <em>every</em> time we execute <code>pipeline</code>, we pull from github for the latest XML. This is a bit excessive, particularly when commands are restarted due to dependency resolution.</p>\\n<p>Instead, we should have some sort of timeout, say an hour from the last pull. This could be a configuration to the <code>sync_xml</code> command. See <a href=\"http://stackoverflow.com/a/9229377\" rel=\"nofollow\">http://stackoverflow.com/a/9229377</a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/216', 'state': 'CLOSED', 'createdAt': '2016-01-02T20:27:26Z', 'lastEditedAt': None, 'publishedAt': '2016-01-02T20:27:26Z', 'updatedAt': '2016-02-03T17:06:54Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Sorting tables', 'bodyHTML': '<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=737400\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jbarnicle\">@jbarnicle</a> made the tables in ATF regulations sortable when a user clicks on the headers. This is potentially extremely useful functionality, but we should add <g-emoji class=\"g-emoji\" alias=\"arrow_up_small\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f53c.png\"></g-emoji> and <g-emoji class=\"g-emoji\" alias=\"arrow_down_small\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f53d.png\"></g-emoji> icons to visually indicate this functionality to the user.</p>\\n<p>We can use the default icons here: <a href=\"http://datatables.net/examples/basic_init/table_sorting.html\" rel=\"nofollow\">http://datatables.net/examples/basic_init/table_sorting.html</a></p>\\n<p>The two things we should do to have it match ATF\\'s eregs instance:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Instead of purple for the \"ON\" or \"sorted\" color indication, we should use ATF\\'s link blue (or in theming terms - whatever color is the general link color).</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> The arrows should be aligned (vertically centered) with the heading text.</li>\\n</ul>', 'url': 'https://github.com/18F/atf-eregs/issues/230', 'state': 'OPEN', 'createdAt': '2016-01-08T16:18:51Z', 'lastEditedAt': None, 'publishedAt': '2016-01-08T16:18:51Z', 'updatedAt': '2017-07-27T14:31:12Z', 'labels': ['Low Priority', 'design', 'help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Write test for diff hash', 'bodyHTML': '<p>Write a test to ensure that the browser url retains the correct format when navigating to and from the diff view of a regulation.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/235', 'state': 'OPEN', 'createdAt': '2016-01-11T20:04:06Z', 'lastEditedAt': None, 'publishedAt': '2016-01-11T20:04:06Z', 'updatedAt': '2016-01-13T01:26:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Extra spacing beneath header in Firefox', 'bodyHTML': '<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/737400/12269440/03f03d4e-b917-11e5-9e47-5be11ad78ac7.png\"><img src=\"https://cloud.githubusercontent.com/assets/737400/12269440/03f03d4e-b917-11e5-9e47-5be11ad78ac7.png\" alt=\"screen shot 2016-01-12 at 10 24 54 am\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/240', 'state': 'CLOSED', 'createdAt': '2016-01-12T16:27:21Z', 'lastEditedAt': None, 'publishedAt': '2016-01-12T16:27:21Z', 'updatedAt': '2016-01-13T23:43:42Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix Pep8 Errors', 'bodyHTML': '<p>Version 1.6.0 and later of pep8 (which is now pulled in implicitly by flake8) indicate multiple lint errors in our code bases (regulations-parser, regulations-core, regulations-site).</p>\\n<p>For the time being, we can silence the errors by pegging the pep8 version to 1.5.7, but this issue is a placeholder to upgrade and fix those warnings.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/241', 'state': 'CLOSED', 'createdAt': '2016-01-12T21:34:09Z', 'lastEditedAt': None, 'publishedAt': '2016-01-12T21:34:09Z', 'updatedAt': '2016-02-22T15:40:21Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix travis warning', 'bodyHTML': '<pre><code>DEPRECATION: --use-mirrors has been deprecated and will be removed in the future. Explicit uses of --index-url and/or --extra-index-url is suggested.\\n</code></pre>', 'url': 'https://github.com/18F/atf-eregs/issues/242', 'state': 'CLOSED', 'createdAt': '2016-01-12T21:36:28Z', 'lastEditedAt': None, 'publishedAt': '2016-01-12T21:36:28Z', 'updatedAt': '2016-01-20T23:37:13Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add LESS/CSS linting to build process', 'bodyHTML': '<p>Our styles are diverging a bit, so let\\'s add a linter to -site and atf-eregs. 18f has a <a href=\"https://raw.githubusercontent.com/18F/frontend/18f-pages/.scss-lint.yml\" rel=\"nofollow\">SCSS config</a>; I wonder if that can be ported to the equivalent LESS.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/276', 'state': 'OPEN', 'createdAt': '2016-01-21T15:15:58Z', 'lastEditedAt': None, 'publishedAt': '2016-01-21T15:15:58Z', 'updatedAt': '2016-01-22T22:16:02Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Remove build_from', 'bodyHTML': \"<p>We don't use it at all, yet it causes lots of confusion for new devs</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/279', 'state': 'CLOSED', 'createdAt': '2016-01-22T16:21:19Z', 'lastEditedAt': None, 'publishedAt': '2016-01-22T16:21:19Z', 'updatedAt': '2016-01-27T20:04:34Z', 'labels': ['2 complexity (medium low)', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Implement cache control in parser', 'bodyHTML': '<p><a href=\"http://cachecontrol.readthedocs.org\" rel=\"nofollow\">CacheControl</a> is a nice library for <code>requests</code> which understands HTTP caching directives. Recently, an <a href=\"https://github.com/cmc333333/regulations-parser/tree/265-cachecontrol\">attempt</a> to include this library over requests-cache (which is not very intelligent) ran into multiple issues. For it to work well with tests, for example, we\\'ll need to inject it as a dependency throughout all of the existing parser app.</p>\\n<p>These are good things to do, but I\\'ve hit my time box.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/280', 'state': 'OPEN', 'createdAt': '2016-01-22T17:10:03Z', 'lastEditedAt': None, 'publishedAt': '2016-01-22T17:10:03Z', 'updatedAt': '2016-01-22T17:10:03Z', 'labels': ['3 complexity (medium)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Blue-green deploy', 'bodyHTML': '<p>Implement one of the zero-downtime deployment tools listed on <a href=\"https://docs.cloud.gov/apps/continuous-deployment/\" rel=\"nofollow\">https://docs.cloud.gov/apps/continuous-deployment/</a></p>\\n<p>Problems that\\'d need to be overcome: we currently store a few pieces of information in env vars. We can use user-provided services (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"114482753\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/atf-eregs/issues/63\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/atf-eregs/issues/63/hovercard\" href=\"https://github.com/18F/atf-eregs/issues/63\">#63</a>), but the New Relic configs will be a harder.</p>\\n<p>Also note that this depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"124087900\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/atf-eregs/issues/199\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/atf-eregs/issues/199/hovercard\" href=\"https://github.com/18F/atf-eregs/issues/199\">#199</a></p>', 'url': 'https://github.com/18F/atf-eregs/issues/284', 'state': 'CLOSED', 'createdAt': '2016-01-26T16:27:10Z', 'lastEditedAt': None, 'publishedAt': '2016-01-26T16:27:10Z', 'updatedAt': '2016-02-08T21:02:06Z', 'labels': ['2 complexity (medium low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Review django deploy checklist', 'bodyHTML': '<p><a href=\"https://docs.djangoproject.com/en/1.9/howto/deployment/checklist/\" rel=\"nofollow\">https://docs.djangoproject.com/en/1.9/howto/deployment/checklist/</a></p>\\n<p>Fix anything we\\'re missing.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/286', 'state': 'OPEN', 'createdAt': '2016-01-26T23:31:40Z', 'lastEditedAt': None, 'publishedAt': '2016-01-26T23:31:40Z', 'updatedAt': '2016-01-26T23:31:40Z', 'labels': ['2 complexity (medium low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update Watch Node to use the results of pipeline', 'bodyHTML': \"<p>Currently the <code>watch_node</code> command proceeds similar to how <code>build_from</code> used to work, using the final rules to build up versions of the regulation.</p>\\n<p>Instead, let's re-use the <code>.eregs_index</code>'s existing cache of versions and regulation trees.</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/289', 'state': 'OPEN', 'createdAt': '2016-01-27T19:55:15Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T19:55:15Z', 'updatedAt': '2016-01-27T19:58:32Z', 'labels': ['2 complexity (medium low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Remove the notice order command', 'bodyHTML': '<p>The <code>notice_order</code> command proceeds similarly as how <code>build_from</code> used to run. However, we already have a <code>versions</code> command which would be more accurate.</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Remove the notice_order command</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Add output (perhaps silence-able?) to the versions command to fill this gap</li>\\n</ul>', 'url': 'https://github.com/18F/atf-eregs/issues/290', 'state': 'OPEN', 'createdAt': '2016-01-27T19:58:17Z', 'lastEditedAt': '2016-06-03T03:43:44Z', 'publishedAt': '2016-01-27T19:58:17Z', 'updatedAt': '2016-06-03T03:43:44Z', 'labels': ['1 complexity (low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add \"import\" (needs better name) command', 'bodyHTML': \"<p>We used to allow arbitrary XML files to be used as the basis of parsing (via <code>build_from</code>). Though we've removed <code>build_from</code> now, there's still a reasonable use case for importing an arbitrary XML reg.</p>\\n<p>This command should have an optional argument for version_id; if not provided, it should use the guessing logic we've used in the past based on querying the federal register.</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/291', 'state': 'CLOSED', 'createdAt': '2016-01-27T20:01:27Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T20:01:27Z', 'updatedAt': '2016-06-03T03:45:20Z', 'labels': ['3 complexity (medium)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Remove additional cruft from `build_from`', 'bodyHTML': '<p><code>regparser.builder</code>, many of the <code>notice</code> functions, and all of the <code>checkpoint</code> logic can be removed now. Note <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"129252310\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/atf-eregs/issues/291\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/atf-eregs/issues/291/hovercard\" href=\"https://github.com/18F/atf-eregs/issues/291\">#291</a>, however.</p>', 'url': 'https://github.com/18F/atf-eregs/issues/292', 'state': 'CLOSED', 'createdAt': '2016-01-27T20:02:46Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T20:02:46Z', 'updatedAt': '2016-06-03T03:47:05Z', 'labels': ['2 complexity (medium low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Update \"modified documents\" in parser readme', 'bodyHTML': '<p><a href=\"https://github.com/18F/regulations-parser#quick-start-with-modified-documents\">https://github.com/18F/regulations-parser#quick-start-with-modified-documents</a> doesn\\'t work at the moment</p>', 'url': 'https://github.com/18F/atf-eregs/issues/293', 'state': 'OPEN', 'createdAt': '2016-01-27T20:03:40Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T20:03:40Z', 'updatedAt': '2016-03-09T21:40:09Z', 'labels': ['2 complexity (medium low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Make atf-eregs local install easier', 'bodyHTML': \"<p>Currently, install atf-eregs requires installing many reqs which are only used in production. Let's simplify that.</p>\\n<ul>\\n<li>Move shared core requirements into <code>requirements_core.txt</code> or similar. This doesn't need any of the cloud.gov configs, like dj-database, postgres, etc.</li>\\n<li>Move lxml into a <code>_test</code> requirements file or similar</li>\\n</ul>\\n<p>Note that we must include cloud.gov reqs in <code>requirements.txt</code> due to the buildpack.</p>\", 'url': 'https://github.com/18F/atf-eregs/issues/308', 'state': 'OPEN', 'createdAt': '2016-02-02T21:05:33Z', 'lastEditedAt': None, 'publishedAt': '2016-02-02T21:05:33Z', 'updatedAt': '2016-02-02T21:05:33Z', 'labels': ['1 complexity (low)', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '<section> tag not closed?', 'bodyHTML': '<p><a href=\"https://github.com/18F/regulations-site/blob/master/regulations/templates/regulations/regulation_text.html#L29\">https://github.com/18F/regulations-site/blob/master/regulations/templates/regulations/regulation_text.html#L29</a></p>\\n<p>I\\'m guessing this tag <em>is</em> closed somewhere.... but shouldn\\'t that be in this file?</p>', 'url': 'https://github.com/18F/atf-eregs/issues/309', 'state': 'CLOSED', 'createdAt': '2016-02-02T22:03:22Z', 'lastEditedAt': None, 'publishedAt': '2016-02-02T22:03:22Z', 'updatedAt': '2016-02-08T22:54:52Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'atf-eregs', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Missing CSS and JS source maps?', 'bodyHTML': '<p>Neither the CSS nor JS appear to have a source map from their compiled form.</p>\\n<p>Some of <code>compile_frontend</code>s output:</p>\\n<pre><code>Running \"browserify:dev\" (browserify) task\\n&gt;&gt; Bundle static/regulations/js/built/regulations.js created.\\n\\nRunning \"browserify:dist\" (browserify) task\\n&gt;&gt; Bundle static/regulations/js/built/regulations.js created.\\n\\nRunning \"uglify:dist\" (uglify) task\\n&gt;&gt; 1 file created.\\n\\nRunning \"less:dev\" (less) task\\nFile static/regulations/css/style.css.map created.\\nFile static/regulations/css/style.css created\\n</code></pre>', 'url': 'https://github.com/18F/atf-eregs/issues/338', 'state': 'OPEN', 'createdAt': '2016-02-08T22:02:09Z', 'lastEditedAt': None, 'publishedAt': '2016-02-08T22:02:09Z', 'updatedAt': '2016-02-10T19:30:27Z', 'labels': ['Medium Priority', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'us_web_design_standards_gem', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '[ refactor ] As a user of this gem, I would like to be able to consume this gem following the recent refactor of the Draft US Web Design Standards', 'bodyHTML': '<p>The Draft US Web Design Standards are going through a major refactoring. In doing so, <a href=\"https://github.com/18F/web-design-standards/blob/18f-pages-staging/Gemfile#L13-L15\">the uswds package has also decided to officially support this ruby gem</a>. This gem is a dependency of the <a href=\"http://playbook.cio.gov/designstandards/\" rel=\"nofollow\">uswds documentation website</a>.</p>\\n<h3>Discussion</h3>\\n<ol>\\n<li>Keeping track of the file changes for this migration by reference.</li>\\n<li>Discussion around the migration and documentation</li>\\n<li>Discussion around CSS and JS dependencies</li>\\n</ol>\\n<h3>Checklist</h3>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Rename <code>components.js</code> to <code>uswds.js</code></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Fully support <code>Jekyll</code>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> and <code>Rails</code></li>\\n</ul>\\n</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Update the documentation to reflect all of these changes</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Discuss including jQuery as a dependency for this gem ( <em>the <code>uswds</code> package depends on it</em> )</li>\\n</ul>', 'url': 'https://github.com/18F/us_web_design_standards_gem/issues/15', 'state': 'CLOSED', 'createdAt': '2016-02-08T22:09:15Z', 'lastEditedAt': None, 'publishedAt': '2016-02-08T22:09:15Z', 'updatedAt': '2016-08-05T20:40:06Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 9}, {'repo_name': 'unit-testing-node', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '[docker] Ensure compatibility with windows', 'bodyHTML': '<p>With the introduction of docker into this project (via <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128272732\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/5\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/unit-testing-node/pull/5/hovercard\" href=\"https://github.com/18F/unit-testing-node/pull/5\">#5</a>) , it would be nice to ensure there is compatibility with Windows</p>\\n<p>Ideas:</p>\\n<ul>\\n<li>Test on windows with <code>shelljs</code></li>\\n<li>Create .bat if <code>shelljs</code> does not work.</li>\\n</ul>', 'url': 'https://github.com/18F/unit-testing-node/issues/6', 'state': 'OPEN', 'createdAt': '2016-01-25T16:21:05Z', 'lastEditedAt': None, 'publishedAt': '2016-01-25T16:21:05Z', 'updatedAt': '2016-01-25T16:21:05Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'unit-testing-node', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '[docker] Automatically open browser when server in container is up', 'bodyHTML': '<p>With the introduction of docker into this project (via <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128272732\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/5\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/unit-testing-node/pull/5/hovercard\" href=\"https://github.com/18F/unit-testing-node/pull/5\">#5</a>), we can automate the setup of the server in the container.<br>\\nIt would be nice to automate opening of the user\\'s browser once the server is up to have a smoother user experience.<br>\\nWe need to make sure the is compatibility between OS X, Linux, and Windows which means we need the docker-startup script to detect which OS is using it.</p>\\n<p>Tips:</p>\\n<ul>\\n<li>Mac OS X can use <code>open \"http://$(docker-machine ip $DOCKER_MACHINE_NAME):4000\"</code> to open the browser.</li>\\n</ul>', 'url': 'https://github.com/18F/unit-testing-node/issues/7', 'state': 'OPEN', 'createdAt': '2016-01-25T16:24:53Z', 'lastEditedAt': None, 'publishedAt': '2016-01-25T16:24:53Z', 'updatedAt': '2016-01-25T16:24:53Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'unit-testing-node', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': '[docker] Clean up containers for user interruption', 'bodyHTML': '<p>With the introduction of docker into this project (via <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128272732\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/5\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/unit-testing-node/pull/5/hovercard\" href=\"https://github.com/18F/unit-testing-node/pull/5\">#5</a>), we can setup the server automatically in a container.</p>\\n<p>During the setup, it is possible for an impatient user to <code>ctrl-c</code> to send a SIGINT to the process and kill the setup in progress. It could leave the system in a state that is hard to recover for new docker users because a docker container will remain and it will be holding on to port 4000.</p>\\n<p><code>docker rm -f $DOCKER_ID</code> needs to be run in that case to clean up.</p>\\n<ul>\\n<li>We would like to put in the docker-startup script this command in case it detects the signal to kill the process.</li>\\n</ul>\\n<p>TIPS</p>\\n<ul>\\n<li>For Mac OS X and Linux use <code>trap</code> as described on this <a href=\"http://linuxcommand.org/wss0160.php\" rel=\"nofollow\">page</a></li>\\n<li>For Windows find equivalent.</li>\\n</ul>', 'url': 'https://github.com/18F/unit-testing-node/issues/8', 'state': 'OPEN', 'createdAt': '2016-01-25T16:35:55Z', 'lastEditedAt': None, 'publishedAt': '2016-01-25T16:35:55Z', 'updatedAt': '2016-01-25T16:36:05Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'unit-testing-node', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Technical and content reviews', 'bodyHTML': '<p>This is a master issue to track all of the content and technical review issues corresponding to sections of the tutorial.</p>\\n<p>\"Introduction\" through \"Designing the Core Logic Module\"</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995210\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/10\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/10/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/10\">#10</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#105</li>\\n</ul>\\n<p>\"Designing and testing the components\" through \"Config class\"</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995391\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/11\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/11/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/11\">#11</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#106</li>\\n</ul>\\n<p>Rule class</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995516\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/12\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/12/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/12\">#12</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#107</li>\\n</ul>\\n<p>SlackClient class</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995629\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/13\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/13/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/13\">#13</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#108</li>\\n</ul>\\n<p>GitHubClient class</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995724\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/14\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/14/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/14\">#14</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#109</li>\\n</ul>\\n<p>Logger class</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995864\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/15\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/15/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/15\">#15</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#110</li>\\n</ul>\\n<p>Middleware class</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128995969\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/16\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/16/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/16\">#16</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#111</li>\\n</ul>\\n<p>Testing component integration</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128996059\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/17\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/17/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/17\">#17</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#112</li>\\n</ul>\\n<p>Testing system integration</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128996166\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/18\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/18/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/18\">#18</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#113</li>\\n</ul>\\n<p>Concepts</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128996323\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/19\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/19/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/19\">#19</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#114</li>\\n</ul>\\n<p>\"Tools and automation\", \"Conclusion\", and \"Further reading\"</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128996451\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/20\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/20/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/20\">#20</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> 18F/writing-lab#115</li>\\n</ul>', 'url': 'https://github.com/18F/unit-testing-node/issues/21', 'state': 'OPEN', 'createdAt': '2016-01-27T01:30:44Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T01:30:44Z', 'updatedAt': '2016-01-27T16:09:01Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'unit-testing-node', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Notifying interested parties outside of 18F', 'bodyHTML': '<p>This is a notice to the folks listed below that a mostly-complete draft of the tutorial is available at <a href=\"https://pages.18f.gov/unit-testing-node/\" rel=\"nofollow\">https://pages.18f.gov/unit-testing-node/</a>. If any of y\\'all would like to subscribe to or participate in any of the technical issues listed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"128997899\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/unit-testing-node/issues/21\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/unit-testing-node/issues/21/hovercard\" href=\"https://github.com/18F/unit-testing-node/issues/21\">#21</a>, please feel free to do so.</p>\\n<p>And in case anyone is wondering, yes, it works on Windows (provided Node.js, Ruby, and Git are installed).</p>\\n<ul>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=166715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/arowla\">@arowla</a></li>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12899821\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nlesiecki\">@nlesiecki</a></li>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5424348\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/BrianLefler\">@BrianLefler</a></li>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14600183\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lorimt\">@lorimt</a></li>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=144579\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/awong-dev\">@awong-dev</a></li>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=627264\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alexose\">@alexose</a></li>\\n<li><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1174867\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/barkimedes\">@barkimedes</a></li>\\n</ul>', 'url': 'https://github.com/18F/unit-testing-node/issues/22', 'state': 'OPEN', 'createdAt': '2016-01-27T02:05:48Z', 'lastEditedAt': None, 'publishedAt': '2016-01-27T02:05:48Z', 'updatedAt': '2016-01-27T02:06:21Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'cf-core', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Utility request .respond-to-retina()', 'bodyHTML': '', 'url': 'https://github.com/cfpb/cf-core/issues/16', 'state': 'CLOSED', 'createdAt': '2014-10-28T22:49:46Z', 'lastEditedAt': None, 'publishedAt': '2014-10-28T22:49:46Z', 'updatedAt': '2015-11-04T17:47:17Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'hackathon', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': \"Find creative ways to use and/or visually present CFPB's Complaint Narratives\", 'bodyHTML': \"<p>As stated, complaint narratives was recently added in the public complaints data CFPB publishes. Want to find creative ways to make use of this data, and visually present the findings through Tableau and potentially other data visualization tools. The BI Team is making the proposal and we have sponsors from Consumer Response's Reporting Team joining on the effort as well. So anyone who can help in anyway is welcome to join us.</p>\", 'url': 'https://github.com/cfpb/hackathon/issues/45', 'state': 'CLOSED', 'createdAt': '2016-04-08T17:42:52Z', 'lastEditedAt': None, 'publishedAt': '2016-04-08T17:42:52Z', 'updatedAt': '2016-10-28T14:48:34Z', 'labels': ['design', 'help wanted', 'project'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'sam-design-system-site', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': '[Website]: Convert design to latest US & SAM Web Design Standards', 'bodyHTML': '<p>The <a href=\"https://standards.usa.gov\" rel=\"nofollow\">USWDS</a> recently updated the design of their standards site, which mirrored a lot of the functionality and aesthetics we were putting in place.</p>\\n<p>Would like to get this integration to get done ASAP</p>', 'url': 'https://github.com/GSA/sam-design-system-site/issues/1', 'state': 'CLOSED', 'createdAt': '2016-07-28T16:21:34Z', 'lastEditedAt': None, 'publishedAt': '2016-07-28T16:21:34Z', 'updatedAt': '2016-08-01T00:23:41Z', 'labels': ['help wanted', 'lvl2 defect - Annoying'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'sam-design-system-site', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': '[Website]: Code examples and samples require JavaScript', 'bodyHTML': '<h2>Issue type</h2>\\n<p>This is a duplication of the one from the UWDS: 18f/web-design-standards#1305</p>\\n<h2>What happened</h2>\\n<p>The code samples are generated after page load. There is a JS function that checks for a <code>div</code> with class <code>preview</code>. It copies the contents, inserts them into a string. Then adds the element to the page.</p>\\n<p>Therefore, if JS fails or is disabled the code sample boxes don\\'t show up. See the 18f ticket.</p>\\n<h2>What I expected</h2>\\n<p>Code samples would <em>always</em> be displayed. We can make this part of the Jekyll build - see the solution for the USWDS. It would change the file structure a bit, and make defining a component a little more interesting.</p>\\n<h2>Steps to reproduce the issue [optional]</h2>\\n<ol>\\n<li>Go to: <a href=\"https://gsa.github.io/sam-web-design-standards/elements/actions-icons/\" rel=\"nofollow\">https://gsa.github.io/sam-web-design-standards/elements/actions-icons/</a></li>\\n<li>Notice the code accordion.</li>\\n<li>Disable JavaScript in your browser.</li>\\n<li>Refresh the page</li>\\n<li>Notice the code accordion is missing.</li>\\n</ol>\\n<p>ps. I wasn\\'t sure if this would be a level 1 or 2 defect as they both apply; however, the dependency on JavaScript means it match our definition of done.</p>', 'url': 'https://github.com/GSA/sam-design-system-site/issues/37', 'state': 'CLOSED', 'createdAt': '2016-08-03T18:39:07Z', 'lastEditedAt': '2016-08-05T12:33:04Z', 'publishedAt': '2016-08-03T18:39:07Z', 'updatedAt': '2016-08-18T19:21:13Z', 'labels': ['help wanted', 'lvl1 defect - Broken', 'lvl2 defect - Annoying', 'sprint 2'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'sam-design-system-site', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': '[Package]: Build does not create full /dist', 'bodyHTML': '<h2>Issue type</h2>\\n<ul>\\n<li>Package</li>\\n</ul>\\n<h2>What happened</h2>\\n<p>See <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"168482444\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/GSA/sam-design-system-site/issues/13\" data-hovercard-type=\"issue\" data-hovercard-url=\"/GSA/sam-design-system-site/issues/13/hovercard\" href=\"https://github.com/GSA/sam-design-system-site/issues/13\">#13</a> as well.</p>\\n<p>The <code>dist</code> directory is incomplete and the copying of vendor files should be a thing.</p>\\n<p>Release cannot get past compiling JS - <code>politespace</code> throws error.</p>\\n<h2>What I expected</h2>\\n<p>In the Standards after performing: <code>$ gulp release</code></p>\\n<pre><code>- /dist\\n    - /css\\n        - samwds.min.css\\n        - samwds.css\\n    -/fonts\\n        - Font Awesome fonts\\n        - Pro source sans\\n    - /img\\n        - images from `/src`\\n        - images from `uswds/src`\\n    -/js\\n        - samwds.min.js\\n        - samwds.js\\n</code></pre>\\n<h2>What\\'s working</h2>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> /img</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> /fonts (missing pro source sans - getting merriweather)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> /css</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> /js</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> copy vendor images</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> copy vendor fonts</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> copy vendor css/scss</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> copy vendor js</li>\\n</ul>', 'url': 'https://github.com/GSA/sam-design-system-site/issues/45', 'state': 'CLOSED', 'createdAt': '2016-08-07T17:22:12Z', 'lastEditedAt': '2016-08-11T14:11:28Z', 'publishedAt': '2016-08-07T17:22:12Z', 'updatedAt': '2016-08-18T18:24:29Z', 'labels': ['help wanted', 'lvl1 defect - Broken'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'sam-design-system-site', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': '[Website & repos]: Host the Standards via webhooks', 'bodyHTML': '<h2>Description</h2>\\n<p>See also <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"168417610\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/GSA/sam-design-system-site/issues/12\" data-hovercard-type=\"issue\" data-hovercard-url=\"/GSA/sam-design-system-site/issues/12/hovercard\" href=\"https://github.com/GSA/sam-design-system-site/issues/12\">#12</a></p>\\n<ol>\\n<li>Contributors cannot easily see what is coming up in later revisions of the Standards.</li>\\n<li>Reviewers cannot easily see what changes are actually being proposed in pull requests.</li>\\n<li>Contributors cannot easily see what other contributors are suggesting with regard to changes to the site itself.</li>\\n<li>Contributors can become confused on where to put things due to the inclusion of an <code>assets</code> folder, which is built automatically, and could be ignored if the Jekyll build occurred outside of GitHub.</li>\\n</ol>\\n<h2>Proposal</h2>\\n<ol>\\n<li><code>standards.sam.gov</code>: Create standards.sam.gov domain on our hosting solution. Whenever a commit is performed to <code>master</code> (now called <code>gh-pages</code>), perform a checkout via a webhook, then do a Jekyll build. This updates the Standards site.</li>\\n<li><code>standards-staging.sam.gov</code>: Create standards-staging.sam.gov domain on our hosting solution. Whenever a commit is performed to <code>staging</code> (now called <code>gh-pages-staging</code>), perform a checkout via a webhook, then do a Jekyll build. This gives everyone in the program access to see a consolidation of proposed changes to the Standards.</li>\\n<li><code>standards-[pull request id].sam.gov</code> (experimental): Create capability to generate ad hoc wildcard sub-domains. Whenever a pull request is made a webhook should be able to fire - then the hosting solution should be able to sign in as an account with approval capability. Then checkout out the PR -&gt; create the subdomain using the PR ID -&gt; Perform the Jekyll build. This will allow anyone in the program to see what changes are being submitted without compromising the workflow by having everyone on the program being able to approve PRs.</li>\\n</ol>', 'url': 'https://github.com/GSA/sam-design-system-site/issues/83', 'state': 'OPEN', 'createdAt': '2016-08-19T17:17:45Z', 'lastEditedAt': '2016-08-20T12:59:27Z', 'publishedAt': '2016-08-19T17:17:45Z', 'updatedAt': '2016-09-21T16:54:31Z', 'labels': ['enhancement', 'help wanted', 'nf - New feature'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'sam-design-system-site', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': '[Website]: Gulp watch breaking when editing Sass', 'bodyHTML': '<h2>Issue type</h2>\\n<ul>\\n<li>Website</li>\\n</ul>\\n<h2>What happened</h2>\\n<p>Working on re-engineering the header and footer. Whenever I save a Sass file the Sass Gulp sequence crashes out. See below.</p>\\n<h2>What I expected</h2>\\n<p>Save changes to a Sass file would result in the Sass Gulp sequence recompiling the site Sass.</p>\\n<h2>Steps to reproduce the issue [optional]</h2>\\n<ol>\\n<li>Perform <code>$ gulp website:serve</code></li>\\n<li>Update one of the Sass files</li>\\n<li>Save the changes</li>\\n<li>Check terminal</li>\\n</ol>\\n<h2>Additional information [optional]</h2>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/15252830/18413247/37e849e4-7770-11e6-9bcd-463c64541ecc.png\"><img width=\"1732\" alt=\"screen shot 2016-09-10 at 4 04 01 pm\" src=\"https://cloud.githubusercontent.com/assets/15252830/18413247/37e849e4-7770-11e6-9bcd-463c64541ecc.png\" style=\"max-width:100%;\"></a></p>', 'url': 'https://github.com/GSA/sam-design-system-site/issues/120', 'state': 'CLOSED', 'createdAt': '2016-09-10T20:04:22Z', 'lastEditedAt': None, 'publishedAt': '2016-09-10T20:04:22Z', 'updatedAt': '2016-09-10T22:57:39Z', 'labels': ['help wanted', 'lvl1 defect - Broken'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cg-application-ssp-example', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'remove README info that does/should live in opencontrol', 'bodyHTML': '<p>It seems that a lot of the information in the README isn\\'t actually cloud.gov-specific, so we should remove it from here, and either link to the appropriate place in <a class=\"user-mention\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/opencontrol/hovercard\" href=\"https://github.com/opencontrol\">@opencontrol</a> if it exists, or move it there if it doesn\\'t.</p>\\n<p>Related: <a href=\"https://trello.com/c/xZ7zfepD/164-consolidate-information-about-using-masonry-for-apps\" rel=\"nofollow\">https://trello.com/c/xZ7zfepD/164-consolidate-information-about-using-masonry-for-apps</a></p>', 'url': 'https://github.com/18F/cg-application-ssp-example/issues/2', 'state': 'OPEN', 'createdAt': '2016-05-08T19:16:27Z', 'lastEditedAt': None, 'publishedAt': '2016-05-08T19:16:27Z', 'updatedAt': '2017-02-02T00:44:54Z', 'labels': ['F20', 'HighBar', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Parallelize domain scanning', 'bodyHTML': '<p>Doing this all in serial is a big waste, especially since the requests are hitting different domains. Parallelizing the tasks won\\'t increase load on any scanned site, but will drastically speed up completion time.</p>\\n<p><a href=\"https://docs.python.org/3/library/asyncio-dev.html\" rel=\"nofollow\">https://docs.python.org/3/library/asyncio-dev.html</a></p>', 'url': 'https://github.com/18F/domain-scan/issues/16', 'state': 'CLOSED', 'createdAt': '2015-05-29T16:04:03Z', 'lastEditedAt': None, 'publishedAt': '2015-05-29T16:04:03Z', 'updatedAt': '2015-06-14T02:13:24Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Suggestion: Split up the Dockerfile', 'bodyHTML': '<p>Just took a look at the Dockerfile for the first time, and was surprised to see how much is in there. I guess it\\'s because the various tools being used all have different dependencies?</p>\\n<p>Having multiple languages in a single Dockerfile is an antipattern (IMHO), and I think the setup for each scanner could be a lot simpler if you isolated each tool to its own Dockerfile. These could then be run independently, or via a <code>domain-scan</code> Dockerfile that calls out to <code>docker run &lt;scanner&gt;</code> and then stitches the results together.</p>\\n<p>I got this idea from the architecture of <a href=\"https://github.com/codeclimate/codeclimate\">the Code Climate CLI</a>, so you could look there for inspiration if you\\'re interested in pursuing this.</p>', 'url': 'https://github.com/18F/domain-scan/issues/66', 'state': 'CLOSED', 'createdAt': '2016-06-02T14:25:39Z', 'lastEditedAt': None, 'publishedAt': '2016-06-02T14:25:39Z', 'updatedAt': '2017-11-20T02:56:20Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'A recursive web crawler to gather domains', 'bodyHTML': '<p><strong>Note</strong>: this is a potentially big task, that should be broken into smaller tasks/stages. But also, there is value to starting with a naive, simple crawler and leveling it up in stages.</p>\\n<p>Either baked into domain-scan, or finding/making a separate tool that does this. We could also potentially use <a href=\"http://commoncrawl.org\" rel=\"nofollow\">Common Crawl</a> data.</p>\\n<p>But the basic need is to gather domains through web crawling, as this is a fertile source for hostnames that do not appear in Censys.io. For .gov, both Censys and the LOC\\'s web crawl (the End of Term Archive) each had ~50% of unique domains not found through any other public method. The LOC crawl data, performed in late 2016, is getting more stale by the month, and also won\\'t be helpful for non-USG sources.</p>', 'url': 'https://github.com/18F/domain-scan/issues/118', 'state': 'OPEN', 'createdAt': '2017-04-03T03:35:29Z', 'lastEditedAt': '2017-11-24T20:00:26Z', 'publishedAt': '2017-04-03T03:35:29Z', 'updatedAt': '2017-11-24T20:01:15Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Build scripts for remote compilation of dependencies for domain-scan.zip', 'bodyHTML': \"<p>The <code>lambda/remote_build.sh</code> script has the commands I use to build the domain-scan Lambda environment, but it's not repeatable, and rebuilds require me to copy/paste manual subsets of the instructions.</p>\\n<p>This is going to become more of a burden over time, as any updates to dependencies will require a rebuild to capture these changes (and <code>pshtt</code> itself is likely to keep rapidly improving in very relevant ways), followed by a re-upload to Lambda.</p>\", 'url': 'https://github.com/18F/domain-scan/issues/162', 'state': 'CLOSED', 'createdAt': '2017-11-19T21:59:33Z', 'lastEditedAt': None, 'publishedAt': '2017-11-19T21:59:33Z', 'updatedAt': '2018-03-20T17:17:32Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Allow mixing of Lambda and non-Lambda scanners', 'bodyHTML': \"<p>Not all scanners are designed for Lambda use, but it's nice to be able to employ them for the ones that do. If a scanner doesn't support Lambda, it'd be great to just assume local scans for that scanner.</p>\\n<p>Perhaps scanners can opt-in or -out of registering as Lambda-compatible, so that the orchestrator can override the CLI flag for scanners which aren't registered that way.</p>\", 'url': 'https://github.com/18F/domain-scan/issues/163', 'state': 'CLOSED', 'createdAt': '2017-11-20T00:36:42Z', 'lastEditedAt': None, 'publishedAt': '2017-11-20T00:36:42Z', 'updatedAt': '2017-12-02T00:09:27Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Output a meta CSV file, remove --meta flag', 'bodyHTML': \"<p>Instead of adding a --meta flag and cluttering up the resulting scan data, it's likely better to output a meta CSV file for each scan, with the local/Lambda error and timing information for each one. This could be output by default, rather than needing an opt-in with <code>--meta</code>.</p>\\n<p>This would need multiple meta CSV files, one per scanner, or some other way to represent the data. You could also imagine a meta.csv that merges the metadata of all scans, which might be the most convenient to do analysis of overall scan durations and reliability issues.</p>\", 'url': 'https://github.com/18F/domain-scan/issues/164', 'state': 'OPEN', 'createdAt': '2017-11-20T02:45:08Z', 'lastEditedAt': None, 'publishedAt': '2017-11-20T02:45:08Z', 'updatedAt': '2017-11-24T20:01:15Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Allow scanners to specify default Lambda timeout and memory size', 'bodyHTML': '<p>And have it drive the Lambda function create process.</p>\\n<p>Depends on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"276690926\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/domain-scan/issues/171\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/domain-scan/issues/171/hovercard\" href=\"https://github.com/18F/domain-scan/issues/171\">#171</a>.</p>', 'url': 'https://github.com/18F/domain-scan/issues/169', 'state': 'OPEN', 'createdAt': '2017-11-24T18:32:31Z', 'lastEditedAt': '2017-11-24T20:00:48Z', 'publishedAt': '2017-11-24T18:32:31Z', 'updatedAt': '2018-03-20T17:20:58Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Config file for persistent options', 'bodyHTML': \"<p>I think we're at the stage where want to define configuration in a <code>$HOME/.domain-scan</code> file or something like that, both for general options and for scanner-specific and Lambda-specific and gatherer-specific options. There are too many options!</p>\", 'url': 'https://github.com/18F/domain-scan/issues/170', 'state': 'OPEN', 'createdAt': '2017-11-24T19:35:49Z', 'lastEditedAt': None, 'publishedAt': '2017-11-24T19:35:49Z', 'updatedAt': '2018-03-20T17:20:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'domain-scan', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Move Lambda deploy scripts to Python', 'bodyHTML': '<p>The <code>lambda/deploy</code> script is reasonable, but we\\'d benefit a lot from having it in Python rather than a standalone bash script, so that it could get more sophisticated, import scanner code, and allow the scanners to set things like timeouts, memory size, etc.</p>\\n<p>Also a note:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Include facility to specify one or more tags for created Lambda functions.</li>\\n</ul>', 'url': 'https://github.com/18F/domain-scan/issues/171', 'state': 'OPEN', 'createdAt': '2017-11-24T19:55:55Z', 'lastEditedAt': None, 'publishedAt': '2017-11-24T19:55:55Z', 'updatedAt': '2018-03-20T17:20:36Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'emoji_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Test install instructions and revise for clarity', 'bodyHTML': '<p>Since this is a neat simple tool, it\\'d be nice to have the install instructions fixed up so that anyone can set this up for their own use even if they don\\'t have a lot of background knowledge. This is a task anyone can work on (inside or outside 18F) - could even be especially helpful for a non-18F person to test it.</p>\\n<p>More explanation: try setting this up and using it, note any problems or confusing parts you run into, either fix them in the readme (if you know how) or note them as an issue, and generally revise the instructions for clarity. For example, link to explanations for how to set up Python and virtualenv (for example if people don\\'t want to run the whole laptop script) and how to clone the repository. Maybe move the Slack API key setup instructions into the \"Installation\" section, if that makes more sense to you. You could also link to <a href=\"https://18f.gsa.gov/2015/12/08/using-emoji-for-knowledge-sharing/\" rel=\"nofollow\">the relevant blog post</a> and add other examples of interesting uses.</p>', 'url': 'https://github.com/18F/emoji_search/issues/1', 'state': 'OPEN', 'createdAt': '2016-01-15T23:29:56Z', 'lastEditedAt': None, 'publishedAt': '2016-01-15T23:29:56Z', 'updatedAt': '2016-02-09T22:40:07Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'emoji_search', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Handle API tokens in a more sensible/ less kludgey way', 'bodyHTML': '<p>From <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=828452\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/IanLee1521\">@IanLee1521</a>\\'s comment on <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"130568181\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/emoji_search/issues/2\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/emoji_search/pull/2/hovercard\" href=\"https://github.com/18F/emoji_search/pull/2\">#2</a>:</p>\\n<blockquote>\\n<p>I feel like the need to create an api_token.py file (currently what is documented) is a bit clunky... I propose that this might want to change to one of two approaches:</p>\\n<p>Added a --api-token=ABCXYZ commandline argument to allow it to be passed in to the script. And / or add the ability for the scrip to look in a particular location (something like ~/.slack/api_token ?) that could be where users are then instructed to look for it / to store their key.</p>\\n</blockquote>', 'url': 'https://github.com/18F/emoji_search/issues/3', 'state': 'OPEN', 'createdAt': '2016-02-03T22:54:28Z', 'lastEditedAt': None, 'publishedAt': '2016-02-03T22:54:28Z', 'updatedAt': '2016-02-03T22:54:45Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'api-standards', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add additional SOAP best practices', 'bodyHTML': '<p>This is a help wanted.</p>', 'url': 'https://github.com/GSA/api-standards/issues/22', 'state': 'OPEN', 'createdAt': '2017-02-16T15:06:38Z', 'lastEditedAt': None, 'publishedAt': '2017-02-16T15:06:38Z', 'updatedAt': '2017-02-16T15:06:38Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'convert to a CF CLI plugin', 'bodyHTML': '<p>Doing a lot of this functionality in shell is tricky...probably means converting to Go?</p>\\n<p><a href=\"https://docs.cloudfoundry.org/devguide/installcf/develop-cli-plugins.html\" rel=\"nofollow\">https://docs.cloudfoundry.org/devguide/installcf/develop-cli-plugins.html</a></p>', 'url': 'https://github.com/18F/cf-blue-green/issues/2', 'state': 'OPEN', 'createdAt': '2015-08-04T06:59:19Z', 'lastEditedAt': None, 'publishedAt': '2015-08-04T06:59:19Z', 'updatedAt': '2015-08-28T20:54:40Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'make verbose logging optional', 'bodyHTML': '', 'url': 'https://github.com/18F/cf-blue-green/issues/3', 'state': 'OPEN', 'createdAt': '2015-08-04T07:00:29Z', 'lastEditedAt': None, 'publishedAt': '2015-08-04T07:00:29Z', 'updatedAt': '2015-08-04T07:00:29Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add option to leave blue application running', 'bodyHTML': '<p>...or to <code>stop</code> it instead of <code>delete</code>ing, for faster deployment (due to dependency caching). There may be a way to achieve this using the application blobs.</p>', 'url': 'https://github.com/18F/cf-blue-green/issues/5', 'state': 'OPEN', 'createdAt': '2015-08-04T07:03:28Z', 'lastEditedAt': None, 'publishedAt': '2015-08-04T07:03:28Z', 'updatedAt': '2015-08-04T07:03:35Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'allow manifest file to be specified', 'bodyHTML': '<p>...and possibly other options be passed in? One specific use case is where you want to deploy a change to the manifest, though this is tricky if the manifest isn\\'t \"complete\". Might be able to do something fancy with <a href=\"https://docs.cloudfoundry.org/devguide/deploy-apps/manifest.html#multi-manifests\" rel=\"nofollow\">manifest inheritance</a>.</p>', 'url': 'https://github.com/18F/cf-blue-green/issues/6', 'state': 'OPEN', 'createdAt': '2015-08-05T14:49:17Z', 'lastEditedAt': None, 'publishedAt': '2015-08-05T14:49:17Z', 'updatedAt': '2015-08-07T08:14:54Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'mktemp command fails on Ubuntu', 'bodyHTML': '<p><a href=\"https://travis-ci.org/18F/federalist/builds/75512988#L591\" rel=\"nofollow\">https://travis-ci.org/18F/federalist/builds/75512988#L591</a></p>\\n<p><div class=\"border rounded-1 my-2\">\\n  <div class=\"f6 px-3 py-2 lh-condensed border-bottom bg-gray-light\">\\n    <p class=\"mb-0 text-bold\">\\n      <a href=\"https://github.com/18F/cf-blue-green/blob/93f4ad274a02ae39b70d1f7ba5fd3d4bdfa3dd2d/bin/cf-blue-green#L42\">cf-blue-green/bin/cf-blue-green</a>\\n    </p>\\n    <p class=\"mb-0 text-gray-light\">\\n         Line 42\\n      in\\n      <a data-pjax=\"true\" class=\"commit-tease-sha\" href=\"/18F/cf-blue-green/commit/93f4ad274a02ae39b70d1f7ba5fd3d4bdfa3dd2d\">93f4ad2</a>\\n    </p>\\n    </div>\\n    <div itemprop=\"text\" class=\"blob-wrapper blob-wrapper-embedded data\">\\n    <table class=\"highlight tab-size mb-0 js-file-line-container\" data-tab-size=\"8\">\\n\\n        <tbody><tr class=\"border-0\">\\n          <td id=\"L42\" class=\"blob-num border-0 px-3 py-0 bg-white js-line-number\" data-line-number=\"42\"></td>\\n          <td id=\"LC42\" class=\"blob-code border-0 px-3 py-0 bg-white blob-code-inner js-file-line\"> MANIFEST=<span class=\"pl-s\"><span class=\"pl-pds\">$(</span>mktemp -t <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">${BLUE}</span>_manifest<span class=\"pl-pds\">\"</span></span><span class=\"pl-pds\">)</span></span> </td>\\n        </tr>\\n    </tbody></table>\\n  </div>\\n</div>\\n</p>\\n<p>Totally fine with not templatizing the name, if that makes things easier.</p>', 'url': 'https://github.com/18F/cf-blue-green/issues/12', 'state': 'CLOSED', 'createdAt': '2015-08-13T22:05:00Z', 'lastEditedAt': None, 'publishedAt': '2015-08-13T22:05:00Z', 'updatedAt': '2015-08-13T22:48:49Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'trap seems to fail on Ubuntu', 'bodyHTML': '<p>Not sure how to make that compatible for different distributions <g-emoji class=\"g-emoji\" alias=\"confounded\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f616.png\"></g-emoji></p>\\n<p><a href=\"https://travis-ci.org/18F/federalist/builds/75516832#L604\" rel=\"nofollow\">https://travis-ci.org/18F/federalist/builds/75516832#L604</a></p>\\n<p>/cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=170641\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dhcole\">@dhcole</a></p>', 'url': 'https://github.com/18F/cf-blue-green/issues/13', 'state': 'CLOSED', 'createdAt': '2015-08-13T22:10:22Z', 'lastEditedAt': None, 'publishedAt': '2015-08-13T22:10:22Z', 'updatedAt': '2015-08-13T22:48:49Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': \"manifest changes aren't deployed\", 'bodyHTML': '<p>Since the manifest is pulled from the running application, any changes to the local manifest aren\\'t actually included in the push.</p>\\n<p>Have a note in the README, but should really figure this out.</p>\\n<p>/cc <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"99222177\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/cf-blue-green/issues/6\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/cf-blue-green/issues/6/hovercard\" href=\"https://github.com/18F/cf-blue-green/issues/6\">#6</a></p>', 'url': 'https://github.com/18F/cf-blue-green/issues/17', 'state': 'OPEN', 'createdAt': '2015-08-24T14:13:47Z', 'lastEditedAt': None, 'publishedAt': '2015-08-24T14:13:47Z', 'updatedAt': '2015-11-01T17:00:55Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cf-blue-green', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'investigate using autopilot under the hood', 'bodyHTML': '<p>Stealing <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1205061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pkarman\">@pkarman</a>\\'s idea from</p>\\n<p><a href=\"https://github.com/18F/e-manifest/blob/1872ab116266fe00e7d42aefa7eace414564c533/script/deploy\">https://github.com/18F/e-manifest/blob/1872ab116266fe00e7d42aefa7eace414564c533/script/deploy</a></p>\\n<p>This means most of the plugin can be gutted.</p>', 'url': 'https://github.com/18F/cf-blue-green/issues/27', 'state': 'OPEN', 'createdAt': '2016-02-12T15:54:52Z', 'lastEditedAt': None, 'publishedAt': '2016-02-12T15:54:52Z', 'updatedAt': '2016-02-12T15:54:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-service-connect', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add support for Redis', 'bodyHTML': '<p><a href=\"https://redis.io/topics/rediscli#interactive-mode\" rel=\"nofollow\">https://redis.io/topics/rediscli#interactive-mode</a></p>', 'url': 'https://github.com/18F/cf-service-connect/issues/8', 'state': 'CLOSED', 'createdAt': '2016-12-30T09:37:36Z', 'lastEditedAt': None, 'publishedAt': '2016-12-30T09:37:36Z', 'updatedAt': '2017-01-09T21:32:00Z', 'labels': ['AgentQ', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-service-connect', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add support for MongoDB', 'bodyHTML': '<p><a href=\"https://docs.mongodb.com/manual/mongo/\" rel=\"nofollow\">https://docs.mongodb.com/manual/mongo/</a></p>', 'url': 'https://github.com/18F/cf-service-connect/issues/9', 'state': 'CLOSED', 'createdAt': '2016-12-30T09:38:59Z', 'lastEditedAt': None, 'publishedAt': '2016-12-30T09:38:59Z', 'updatedAt': '2017-01-09T21:33:53Z', 'labels': ['AgentQ', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'cf-service-connect', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add support for ElasticSearch', 'bodyHTML': '<p>Doesn\\'t seem that ElasticSearch has a canonical REPL, though there is one out there:</p>\\n<p><a href=\"https://github.com/mkocikowski/elsec\">https://github.com/mkocikowski/elsec</a></p>\\n<p>Alternatively, we can just print out the <code>curl</code> command to use.</p>\\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/guide/current/_talking_to_elasticsearch.html#_restful_api_with_json_over_http\" rel=\"nofollow\">https://www.elastic.co/guide/en/elasticsearch/guide/current/_talking_to_elasticsearch.html#_restful_api_with_json_over_http</a></p>\\n<p>I know <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=173848\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yozlet\">@yozlet</a> was using the <a href=\"https://github.com/18F/cf-service-proxy\">cf-service-proxy</a> on College Scorecard...this might be a nice alternative for them.</p>', 'url': 'https://github.com/18F/cf-service-connect/issues/10', 'state': 'OPEN', 'createdAt': '2016-12-30T09:45:08Z', 'lastEditedAt': None, 'publishedAt': '2016-12-30T09:45:08Z', 'updatedAt': '2017-01-27T03:56:46Z', 'labels': ['AgentQ', 'Atlas', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cf-service-connect', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Handle unknown broker/service key structures', 'bodyHTML': '<p>If the plugin</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Encounters a broker for an unknown database</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Encounters a service key with a structure it can\\'t retrieve one or more of the (required) values for</li>\\n</ul>\\n<p>it chokes. Rather than failing, it should</p>\\n<ol>\\n<li>Create and expose the service key</li>\\n<li>Start the SSH tunnel (if the host+port are known)</li>\\n</ol>\\n<p>/cc <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"198247860\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/cf-service-connect/issues/18\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/cf-service-connect/issues/18/hovercard\" href=\"https://github.com/18F/cf-service-connect/issues/18\">#18</a></p>', 'url': 'https://github.com/18F/cf-service-connect/issues/19', 'state': 'OPEN', 'createdAt': '2017-01-01T22:42:28Z', 'lastEditedAt': '2017-01-06T19:10:37Z', 'publishedAt': '2017-01-01T22:42:28Z', 'updatedAt': '2017-01-27T03:56:46Z', 'labels': ['AgentQ', 'Atlas', 'enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cf-service-connect', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'fall back to -no-client behavior if corresponding REPL not found', 'bodyHTML': \"<p>For example, if trying to connect to a MySQL service and <code>mysql</code> isn't on the user's <code>PATH</code>, say so and spit out the connection information.</p>\", 'url': 'https://github.com/18F/cf-service-connect/issues/48', 'state': 'OPEN', 'createdAt': '2018-01-02T05:47:42Z', 'lastEditedAt': None, 'publishedAt': '2018-01-02T05:47:42Z', 'updatedAt': '2018-01-02T05:47:42Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'hubot-aws-cfpb', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'List instance creator in `ls` table', 'bodyHTML': \"<p>It'd be nice to have a column that lists the usernames of the people who created instances when you <code>ec2 ls</code>.</p>\", 'url': 'https://github.com/cfpb/hubot-aws-cfpb/issues/27', 'state': 'CLOSED', 'createdAt': '2017-05-15T21:18:54Z', 'lastEditedAt': None, 'publishedAt': '2017-05-15T21:18:54Z', 'updatedAt': '2018-03-16T20:53:52Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cg-compliance', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Check list of Controls for Cloud.Gov', 'bodyHTML': '<h4>FedRAMP Controls   Moderate    Checklist for <a href=\"https://cloud.gov/\" rel=\"nofollow\">cloud.gov</a></h4>\\n<p><em>Handles designate assignment of task to complete content for SSP</em></p>\\n<h5>Access Control</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-1  ACCESS CONTROL POLICY AND PROCEDURES    P1  AC-1            x <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-2  ACCOUNT MANAGEMENT  P1  AC-2 (1) (2) (3) (4) (5) (7) (9) (10)       x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-3  ACCESS ENFORCEMENT  P1  AC-3        x <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-4  INFORMATION FLOW ENFORCEMENT    P1  AC-4 (21) <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-5  SEPARATION OF DUTIES    P1  AC-5        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-6  LEAST PRIVILEGE P1  AC-6 (1) (2) (5) (9) (10)       x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-7  UNSUCCESSFUL LOGON ATTEMPTS P2  AC-7  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-8  SYSTEM USE NOTIFICATION P1  AC-8  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-10 CONCURRENT SESSION CONTROL  AC-10</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-11 SESSION LOCK    P3  AC-11 (1)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-12 SESSION TERMINATION P2  AC-12</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-14 PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION  P3  AC-14</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-17 REMOTE ACCESS   P1  AC-17 (1) (2) (3) (4)   (9) x <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-18     WIRELESS ACCESS P1  AC-18 (1)       n/a  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-19 ACCESS CONTROL FOR MOBILE DEVICES   P1  AC-19 (5)       n/a <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-20 USE OF EXTERNAL INFORMATION SYSTEMS P1  AC-20 (1) (2)   x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-21 INFORMATION SHARING P2  AC-21           x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AC-22 PUBLICLY ACCESSIBLE CONTENT P3  AC-22</li>\\n</ul>\\n<h5>Awareness and Training</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AT-1  SECURITY AWARENESS AND TRAINING POLICY AND PROCEDURES   P1  AT-1</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AT-2  SECURITY AWARENESS TRAINING P1  AT-2 (2)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AT-3  ROLE-BASED SECURITY TRAINING    P1  AT-3     x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AT-4  SECURITY TRAINING RECORDS   P3  AT-4     x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n</ul>\\n<h5>Audit and Accountability</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-1  AUDIT AND ACCOUNTABILITY POLICY AND PROCEDURES  P1  AU-1  x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-2  AUDIT EVENTS    P1  AU-2 (3)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-3  CONTENT OF AUDIT RECORDS    P1  AU-3 (1)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-4  AUDIT STORAGE CAPACITY  P1  AU-4  x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-5  RESPONSE TO AUDIT PROCESSING FAILURES   P1  AU-5  x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-6  AUDIT REVIEW, ANALYSIS, AND REPORTING   P1  AU-6 (1) (3)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-7  AUDIT REDUCTION AND REPORT GENERATION   P2  AU-7 (1)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-8  TIME STAMPS P1  AU-8 (1)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-9  PROTECTION OF AUDIT INFORMATION P1  AU-9 (2) (4)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-11 AUDIT RECORD RETENTION  P3  AU-11   x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> AU-12 AUDIT GENERATION    P1  AU-12   x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n</ul>\\n<h5>Security Assessment and Authorization</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-1  SECURITY ASSESSMENT AND AUTHORIZATION POLICY AND PROCEDURES P1  CA-1        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-2  SECURITY ASSESSMENTS    P2  CA-2 (1) (2) (3)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-3  SYSTEM INTERCONNECTIONS P1  CA-3 (2) (5)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-5  PLAN OF ACTION AND MILESTONES   P3  CA-5    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-6  SECURITY AUTHORIZATION  P2  CA-6        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-7  CONTINUOUS MONITORING   P2  CA-7 (1)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-8  PENETRATION TESTING P2  CA-8 exception  (1) x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CA-9  INTERNAL SYSTEM CONNECTIONS P2  CA-9        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n</ul>\\n<h5>Configuration Management</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-1  CONFIGURATION MANAGEMENT POLICY AND PROCEDURES  P1  CM-1    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-2  BASELINE CONFIGURATION  P1  CM-2 (1) (3) (7)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-3  CONFIGURATION CHANGE CONTROL    P1  CM-3    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-4  SECURITY IMPACT ANALYSIS    P2  CM-4</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-5  ACCESS RESTRICTIONS FOR CHANGE  P1  CM-5 (1) (3) (5)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-6  CONFIGURATION SETTINGS  P1  CM-6 (1)    x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-7  LEAST FUNCTIONALITY P1  CM-7 (1) (2) (5)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-8  INFORMATION SYSTEM COMPONENT INVENTORY  P1  CM-8 (1) (3) (5)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-9  CONFIGURATION MANAGEMENT PLAN   P1  CM-9  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-10 SOFTWARE USAGE RESTRICTIONS P2  CM-10 (1)   x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CM-11 USER-INSTALLED SOFTWARE P1  CM-11       x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n</ul>\\n<h5>Contingency Planning</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-1  CONTINGENCY PLANNING POLICY AND PROCEDURES  P1  CP-1    x <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-2  CONTINGENCY PLAN    P1  CP-2 (1) (2) (3) (8)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-3  CONTINGENCY TRAINING    P2  CP-3        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-4  CONTINGENCY PLAN TESTING    P2  CP-4 (1)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-6  ALTERNATE STORAGE SITE  P1  CP-6 (1) (3)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-7  ALTERNATE PROCESSING SITE   P1  CP-7 (1) (2) (3)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-8  TELECOMMUNICATIONS SERVICES P1  CP-8 (1)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-9  INFORMATION SYSTEM BACKUP   P1  CP-9 (1) (3)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> CP-10 INFORMATION SYSTEM RECOVERY AND RECONSTITUTION  P1  CP-10 (2)       x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12816761\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/clovett3\">@clovett3</a></li>\\n</ul>\\n<h5>Identification and Authentication</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-1  IDENTIFICATION AND AUTHENTICATION POLICY AND PROCEDURES P1  IA-1        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-2  IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS)    P1  IA-2 (1) (2)   (3) (5)(8) (11) (12)     x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-3  DEVICE IDENTIFICATION AND AUTHENTICATION    P1  IA-3  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-4  IDENTIFIER MANAGEMENT   P1  IA-4        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-5  AUTHENTICATOR MANAGEMENT    P1  IA-5 (1) (2) (3) (4) (6) (7) (11)       x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-6  AUTHENTICATOR FEEDBACK  P2  IA-6        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-7  CRYPTOGRAPHIC MODULE AUTHENTICATION P1  IA-7        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IA-8  IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS)    P1  IA-8 (1) (2) (3) (4)  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a></li>\\n</ul>\\n<h5>Incident Response</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-1  INCIDENT RESPONSE POLICY AND PROCEDURES P1  IR-1        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-2  INCIDENT RESPONSE TRAINING  P2  IR-2        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21148\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jacobian\">@jacobian</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-3  INCIDENT RESPONSE TESTING   P2  IR-3 (2)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21148\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jacobian\">@jacobian</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-4  INCIDENT HANDLING   P1  IR-4 (1)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21148\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jacobian\">@jacobian</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-5  INCIDENT MONITORING P1  IR-5        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21148\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jacobian\">@jacobian</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-6  INCIDENT REPORTING  P1  IR-6 (1)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-7  INCIDENT RESPONSE ASSISTANCE    P2  IR-7 (1)        x  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21148\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jacobian\">@jacobian</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-8  INCIDENT RESPONSE PLAN  P1  IR-8        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> IR-9  INFORMATION SPILLAGE RESPONSE P0  IR-9 (1) (2) (3) (4)  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=21148\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jacobian\">@jacobian</a></li>\\n</ul>\\n<h5>Maintenance</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MA-1  SYSTEM MAINTENANCE POLICY AND PROCEDURES    P1  MA-1        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MA-2  CONTROLLED MAINTENANCE  P2  MA-2        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MA-3  MAINTENANCE TOOLS   P3  MA-3 (1) (2) (3)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MA-4  NONLOCAL MAINTENANCE    P2  MA-4 (2)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MA-5  MAINTENANCE PERSONNEL   P2  MA-5 (1)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MA-6  TIMELY MAINTENANCE  P2  MA-6        x</li>\\n</ul>\\n<h5>Media Protection</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MP-1  MEDIA PROTECTION POLICY AND PROCEDURES  P1  MP-1  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MP-3  MEDIA MARKING   P2  MP-3  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MP-4  MEDIA STORAGE   P1  MP-4  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MP-5  MEDIA TRANSPORT P1  MP-5 (4)  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MP-6  MEDIA SANITIZATION  P1  MP-6 (2)  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> MP-7  MEDIA USE   P1  MP-7 (1)  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=565071\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/NoahKunin\">@NoahKunin</a></li>\\n</ul>\\n<h5>Physical and Environmental Protection</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-1  PHYSICAL AND ENVIRONMENTAL PROTECTION POLICY AND PROCEDURES P1  PE-1</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-2  PHYSICAL ACCESS AUTHORIZATIONS  P1  PE-2</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-3  PHYSICAL ACCESS CONTROL P1  PE-3</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-4  ACCESS CONTROL FOR TRANSMISSION MEDIUM  P1  PE-4</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-5  ACCESS CONTROL FOR OUTPUT DEVICES   P2  PE-5</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-6  MONITORING PHYSICAL ACCESS  P1  PE-6 (1)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-8  VISITOR ACCESS RECORDS  P3  PE-8</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-9  POWER EQUIPMENT AND CABLING P1  PE-9</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-10 EMERGENCY SHUTOFF   P1  PE-10</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-11 EMERGENCY POWER P1  PE-11</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-12 EMERGENCY LIGHTING  P1  PE-12</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-13 FIRE PROTECTION P1  PE-13 (2) (3)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-14 TEMPERATURE AND HUMIDITY CONTROLS   P1  PE-14</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-15 WATER DAMAGE PROTECTION P1  PE-15</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-16 DELIVERY AND REMOVAL    P2  PE-16</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PE-17 ALTERNATE WORK SITE P2  PE-17</li>\\n</ul>\\n<h5>Planning</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PL-1  SECURITY PLANNING POLICY AND PROCEDURES P1  PL-1</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PL-2  SYSTEM SECURITY PLAN    P1  PL-2 (3)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PL-4  RULES OF BEHAVIOR   P2  PL-4 (1)            x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PL-8  INFORMATION SECURITY ARCHITECTURE   P1  PL-8</li>\\n</ul>\\n<h5>Personnel Security</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-1  PERSONNEL SECURITY POLICY AND PROCEDURES    P1  PS-1</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-2  POSITION RISK DESIGNATION   P1  PS-2</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-3  PERSONNEL SCREENING P1  PS-3 (3)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-4  PERSONNEL TERMINATION   P1  PS-4</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-5  PERSONNEL TRANSFER  P2  PS-5</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-6  ACCESS AGREEMENTS   P3  PS-6</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-7  THIRD-PARTY PERSONNEL SECURITY  P1  PS-7</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> PS-8  PERSONNEL SANCTIONS P3  PS-8</li>\\n</ul>\\n<h5>Risk Assessment</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> RA-1  RISK ASSESSMENT POLICY AND PROCEDURES   P1  RA-1</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> RA-2  SECURITY CATEGORIZATION P1  RA-2</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> RA-3  RISK ASSESSMENT P1  RA-3</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> RA-5  VULNERABILITY SCANNING  P1  RA-5 (1) (2) (3) (5) (6) (8)            x</li>\\n</ul>\\n<h5>System and Services Acquisition</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-1  SYSTEM AND SERVICES ACQUISITION POLICY AND PROCEDURES   P1  SA-1</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-2  ALLOCATION OF RESOURCES P1  SA-2</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-3  SYSTEM DEVELOPMENT LIFE CYCLE   P1  SA-3</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-4  ACQUISITION PROCESS P1  SA-4 (1) (2) (8) (9) (10)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-5  INFORMATION SYSTEM DOCUMENTATION    P2  SA-5</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-8  SECURITY ENGINEERING PRINCIPLES P1  SA-8</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-9  EXTERNAL INFORMATION SYSTEM SERVICES    P1  SA-9 (1) (2) (4) (5)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-10 DEVELOPER CONFIGURATION MANAGEMENT  P1  SA-10 (1)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SA-11 DEVELOPER SECURITY TESTING AND EVALUATION   P1  SA-11 (1) (2) (8)</li>\\n</ul>\\n<h5>System and Communications Protection</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-1  SYSTEM AND COMMUNICATIONS PROTECTION POLICY AND PROCEDURES  P1  SC-1        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-2  APPLICATION PARTITIONING    P1  SC-2        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-4  INFORMATION IN SHARED RESOURCES P1  SC-4        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-5  DENIAL OF SERVICE PROTECTION    P1  SC-5        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-6  RESOURCE AVAILABILITY       P0  SC-6        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-7  BOUNDARY PROTECTION P1  SC-7 (3) (4) (5) (7) (8) (12) (13)(18)      x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-8  TRANSMISSION CONFIDENTIALITY AND INTEGRITY  P1  SC-8 (1)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-10 NETWORK DISCONNECT  P2  SC-10       x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT  P1  SC-12 (2) (3)           x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-13 CRYPTOGRAPHIC PROTECTION    P1  SC-13       x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-15 COLLABORATIVE COMPUTING DEVICES P1  SC-15       x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-17 PUBLIC KEY INFRASTRUCTURE CERTIFICATES  P1  SC-17</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-18 MOBILE CODE P2  SC-18</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-19 VOICE OVER INTERNET PROTOCOL    P1  SC-19</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-20 SECURE NAME / ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) P1  SC-20</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-21 SECURE NAME / ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER)    P1  SC-21</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-22 ARCHITECTURE AND PROVISIONING FOR NAME / ADDRESS RESOLUTION SERVICE P1  SC-22</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-23 SESSION AUTHENTICITY    P1  SC-23           x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-28 PROTECTION OF INFORMATION AT REST   P1  SC-28   (1)     x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SC-39 PROCESS ISOLATION   P1  SC-39       x</li>\\n</ul>\\n<h5>System and Information Integrity</h5>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-1  SYSTEM AND INFORMATION INTEGRITY POLICY AND PROCEDURES  P1  SI-1        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-2  FLAW REMEDIATION    P1  SI-2 (2) (3)            x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-3  MALICIOUS CODE PROTECTION   P1  SI-3 (1) (2) (7)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-4  INFORMATION SYSTEM MONITORING   P1  SI-4 (2) (4) (5) (14) (16) (23)         x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-5  SECURITY ALERTS, ADVISORIES, AND DIRECTIVES P1  SI-5            x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-6  SECURITY FUNCTION VERIFICATION  P1  SI-6            x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-7  SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY   P1  SI-7 (1) (7)        x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-8  SPAM PROTECTION P2  SI-8 (1) (2)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-10 INFORMATION INPUT VALIDATION    P1  SI-10           x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-11 ERROR HANDLING  P2  SI-11           x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-12 INFORMATION HANDLING AND RETENTION  P2  SI-12       x</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> SI-16 MEMORY PROTECTION   P1  SI-16       x</li>\\n</ul>', 'url': 'https://github.com/18F/cg-compliance/issues/68', 'state': 'CLOSED', 'createdAt': '2016-05-27T16:50:05Z', 'lastEditedAt': '2016-06-01T14:30:00Z', 'publishedAt': '2016-05-27T16:50:05Z', 'updatedAt': '2016-06-01T20:45:41Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'how-to-deploy', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'document how to deploy Discourse', 'bodyHTML': '<p>The good news is that we have a Concourse CI pipeline that does this, so should be fairly straightforward to turn that into instructions:</p>\\n<p><a href=\"https://github.com/18F/cg-deploy-discourse\">https://github.com/18F/cg-deploy-discourse</a></p>\\n<p>/cc <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4604\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dlapiduz\">@dlapiduz</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=24955\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jgrevich\">@jgrevich</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2424551\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/stroupaloop\">@stroupaloop</a></p>', 'url': 'https://github.com/18F/how-to-deploy/issues/10', 'state': 'OPEN', 'createdAt': '2016-06-30T16:51:48Z', 'lastEditedAt': None, 'publishedAt': '2016-06-30T16:51:48Z', 'updatedAt': '2016-06-30T17:09:11Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'terraform-vpc-flow-log', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'add a reasonable default retention period', 'bodyHTML': '<p>Good idea from Nadeem Ahmed.</p>\\n<ul>\\n<li><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SettingLogRetention.html\" rel=\"nofollow\">https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SettingLogRetention.html</a></li>\\n<li><a href=\"https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_group.html#retention_in_days\" rel=\"nofollow\">https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_group.html#retention_in_days</a></li>\\n</ul>', 'url': 'https://github.com/GSA/terraform-vpc-flow-log/issues/6', 'state': 'OPEN', 'createdAt': '2017-12-01T17:39:50Z', 'lastEditedAt': None, 'publishedAt': '2017-12-01T17:39:50Z', 'updatedAt': '2017-12-01T17:39:50Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'data', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Please commit to weekly exports at minimum of the software list', 'bodyHTML': \"<p>It's 2 months old, and the status of many elements have changed.</p>\\n<p>Someone should be assigned (and a calendar invite reminder created) to re-upload / update weekly.</p>\", 'url': 'https://github.com/GSA/data/issues/46', 'state': 'CLOSED', 'createdAt': '2016-11-07T15:16:25Z', 'lastEditedAt': None, 'publishedAt': '2016-11-07T15:16:25Z', 'updatedAt': '2017-07-02T00:50:14Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'fssi-file-processor', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Need explanation of FSSI', 'bodyHTML': '<p>I do not know what the acronym means. Would you be able to explain in the Wiki or the readme?</p>', 'url': 'https://github.com/GSA/fssi-file-processor/issues/1', 'state': 'CLOSED', 'createdAt': '2015-02-17T14:07:08Z', 'lastEditedAt': None, 'publishedAt': '2015-02-17T14:07:08Z', 'updatedAt': '2015-02-19T19:46:36Z', 'labels': ['help wanted', 'question'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'codeclimate-bandit', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add instructions about how to use', 'bodyHTML': '', 'url': 'https://github.com/18F/codeclimate-bandit/issues/1', 'state': 'OPEN', 'createdAt': '2017-09-06T03:58:01Z', 'lastEditedAt': None, 'publishedAt': '2017-09-06T03:58:01Z', 'updatedAt': '2017-09-21T18:31:35Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'codeclimate-bandit', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add instructions about how to develop', 'bodyHTML': '', 'url': 'https://github.com/18F/codeclimate-bandit/issues/2', 'state': 'OPEN', 'createdAt': '2017-09-06T03:58:08Z', 'lastEditedAt': None, 'publishedAt': '2017-09-06T03:58:08Z', 'updatedAt': '2017-09-21T18:31:35Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'codeclimate-bandit', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'add automated tests', 'bodyHTML': '<p>Ensure that the thing works!</p>', 'url': 'https://github.com/18F/codeclimate-bandit/issues/3', 'state': 'OPEN', 'createdAt': '2017-09-21T18:24:06Z', 'lastEditedAt': None, 'publishedAt': '2017-09-21T18:24:06Z', 'updatedAt': '2017-09-21T18:31:35Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'codeclimate-bandit', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'evaluate the current status', 'bodyHTML': '<p>I started on this project a while ago, but never got it done. Need to figure out what steps/features are missing/remaining and make issues for them.</p>', 'url': 'https://github.com/18F/codeclimate-bandit/issues/4', 'state': 'OPEN', 'createdAt': '2017-09-21T18:31:15Z', 'lastEditedAt': None, 'publishedAt': '2017-09-21T18:31:15Z', 'updatedAt': '2017-09-21T18:31:35Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 1}, {'repo_name': 'glossary', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'set up example site', 'bodyHTML': '<p>...or at least add screenshots in the README. As a potential user, I want to see it in action!</p>', 'url': 'https://github.com/18F/glossary/issues/9', 'state': 'OPEN', 'createdAt': '2016-01-12T04:08:08Z', 'lastEditedAt': None, 'publishedAt': '2016-01-12T04:08:08Z', 'updatedAt': '2016-04-10T14:00:48Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'glossary', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Feature: close glossary drawer by clicking outside of it', 'bodyHTML': '<p>User testing for EITI has demonstrated that people instinctively want to close the glossary drawer by clicking outside of it. So...<em>drumroll</em>...new feature suggestion!</p>\\n<p>I added this to EITI, but as I had time to add the new 18F/glossary to our site, my additions are wrapped up in our bespoke version of the glossary. Eventually I would like to add this glossary, at which time it would be nice to have this feature available.</p>', 'url': 'https://github.com/18F/glossary/issues/11', 'state': 'CLOSED', 'createdAt': '2016-02-12T05:43:40Z', 'lastEditedAt': None, 'publishedAt': '2016-02-12T05:43:40Z', 'updatedAt': '2017-10-19T17:51:30Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'glossary', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Suggestion: improve readme to help people reuse this', 'bodyHTML': '<p>It\\'d be nice to add some basic info to this readme since people inside and outside 18F may be interested in reusing a glossary widget for future projects. Suggestions:</p>\\n<ul class=\"contains-task-list\">\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Add brief introduction to what this does</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Explain the status of the code (is this usable? still experimental? an experimental forked version of a usable thing found elsewhere?)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\" checked=\"\"> Link to examples of the glossary in use (such as beta FEC and US EITI)</li>\\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"\" disabled=\"\" class=\"task-list-item-checkbox\"> Ideally link to the files in those projects where those versions of the glossary code are living</li>\\n</ul>', 'url': 'https://github.com/18F/glossary/issues/12', 'state': 'OPEN', 'createdAt': '2016-02-24T23:49:11Z', 'lastEditedAt': '2017-10-12T21:38:32Z', 'publishedAt': '2016-02-24T23:49:11Z', 'updatedAt': '2017-11-09T02:54:46Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 5}, {'repo_name': 'glossary', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Description for the repo', 'bodyHTML': '<p>The repository could use a description, in its project fields at the top of its homepage, and its README.</p>', 'url': 'https://github.com/18F/glossary/issues/15', 'state': 'CLOSED', 'createdAt': '2016-03-09T15:20:13Z', 'lastEditedAt': None, 'publishedAt': '2016-03-09T15:20:13Z', 'updatedAt': '2016-04-10T14:01:34Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'glossary', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Glossary library in main.js is overriding src/glossary.js', 'bodyHTML': '', 'url': 'https://github.com/18F/glossary/issues/17', 'state': 'CLOSED', 'createdAt': '2016-04-10T18:28:30Z', 'lastEditedAt': None, 'publishedAt': '2016-04-10T18:28:30Z', 'updatedAt': '2017-10-16T17:32:53Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'glossary', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Suggestion: Remove mochify', 'bodyHTML': '<p><a href=\"https://github.com/mantoni/mochify.js\">Mochify</a> relies on PhantomJS, which is more or less deprecated and currently doesn\\'t support ES2015 syntax, which makes it somewhat challenging to reduce reliance on utility libraries like Underscore or Lodash. I discovered this while attempting to remove Underscore in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"265089500\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/glossary/issues/29\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/glossary/pull/29/hovercard\" href=\"https://github.com/18F/glossary/pull/29\">#29</a> (see issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"257223680\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/glossary/issues/27\" data-hovercard-type=\"issue\" data-hovercard-url=\"/18F/glossary/issues/27/hovercard\" href=\"https://github.com/18F/glossary/issues/27\">#27</a>) -- while the merged solution does reduce overall size, it doesn\\'t feel quite like the right fix.</p>\\n<p>There are a few ways to potentially circumvent the PhantomJS issue, but I think a good, long-lasting solution would be to remove Mochify entirely, replacing it with standalone mocha running Headless chrome, maybe using <a href=\"https://github.com/GoogleChrome/puppeteer\">Puppeteer</a>.</p>\\n<p>Alternatively, it might be worth submitting a PR to solve <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"251147715\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/mantoni/mochify.js/issues/159\" data-hovercard-type=\"issue\" data-hovercard-url=\"/mantoni/mochify.js/issues/159/hovercard\" href=\"https://github.com/mantoni/mochify.js/issues/159\">mantoni/mochify.js#159</a>, as that would this issue for you and other uses of the library as well.</p>', 'url': 'https://github.com/18F/glossary/issues/30', 'state': 'OPEN', 'createdAt': '2017-10-13T20:45:19Z', 'lastEditedAt': '2017-10-13T20:45:28Z', 'publishedAt': '2017-10-13T20:45:19Z', 'updatedAt': '2017-12-08T17:42:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'cg-sandbox-bot', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'switch to using a user-provided service instance', 'bodyHTML': '<p>User-provided service instances are more durable than normal environment variables, so we should use those for the configuration.</p>', 'url': 'https://github.com/18F/cg-sandbox-bot/issues/4', 'state': 'CLOSED', 'createdAt': '2016-05-09T20:01:32Z', 'lastEditedAt': None, 'publishedAt': '2016-05-09T20:01:32Z', 'updatedAt': '2017-02-18T05:29:30Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'checklistomania', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Consider changing descriptions of lists to not use the word \"TODO\"', 'bodyHTML': '<p>When I first logged into Checklistomania on my first day of work at 18F, I saw this:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/124687/15288119/28cb2788-1b36-11e6-8b2d-2ee696aa2b67.png\"><img width=\"293\" alt=\"screen shot 2016-05-16 at 7 16 10 am\" src=\"https://cloud.githubusercontent.com/assets/124687/15288119/28cb2788-1b36-11e6-8b2d-2ee696aa2b67.png\" style=\"max-width:100%;\"></a></p>\\n<p>This sounds kind of meta, but I immediately read \"TODO\" as meaning \"This is something we haven\\'t yet implemented in Checklistomania yet\". In other words, I thought it was a note from the creators of Checklistomania to remember to actually write a checklist, rather than an actual fully-completed checklist ready for use.</p>\\n<p>I think this confusion could have been alleviated if \"TODO\" were simply written \"To-do\". Or, alternatively, the phrase \"TODO Items\" could be replaced with \"A checklist\". If either of these seem amenable, I\\'m happy to issue a PR.</p>\\n<p>That said, this might just be something that confused me, rather than something that could be confusing to others, in which case feel free to close this issue.</p>', 'url': 'https://github.com/18F/checklistomania/issues/71', 'state': 'CLOSED', 'createdAt': '2016-05-16T11:22:21Z', 'lastEditedAt': '2016-05-16T11:23:36Z', 'publishedAt': '2016-05-16T11:22:21Z', 'updatedAt': '2016-12-29T16:36:11Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'checklistomania', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fullscreen dialogs only seem to happen after first opening a non-fullscreen dialog', 'bodyHTML': \"<p>Steps to reproduce:</p>\\n<ol>\\n<li>Shrink browser window to 450px wide.</li>\\n<li>Click 'Assign to Me' on any checklist. A non-fullscreen dialog will appear.</li>\\n<li>Close the dialog.</li>\\n<li>Click 'Assign to Me' again on any checklist. A fullscreen dialog will appear.</li>\\n</ol>\", 'url': 'https://github.com/18F/checklistomania/issues/83', 'state': 'OPEN', 'createdAt': '2016-06-06T15:08:41Z', 'lastEditedAt': None, 'publishedAt': '2016-06-06T15:08:41Z', 'updatedAt': '2016-11-06T14:27:48Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'checklistomania', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'First time use of checklistomania leads to minor confusion', 'bodyHTML': '<p>Hi all,</p>\\n<p>Just started at 18F (first day is monday) and I was going through checklistomania - super awesome app! I was trying to figure out how to check things off my tasks.  Had to ask how to do this.</p>\\n<p>Proposed change:</p>\\n<p>Tasks Tab to My Tasks Tab Or Tasks Assigned To Me Or Tasks I Control</p>\\n<p>This gives the user an intuitive sense that these are there tasks.</p>\\n<p>Unclear if this is a good change</p>', 'url': 'https://github.com/18F/checklistomania/issues/93', 'state': 'CLOSED', 'createdAt': '2016-08-06T03:21:36Z', 'lastEditedAt': '2016-08-06T03:22:09Z', 'publishedAt': '2016-08-06T03:21:36Z', 'updatedAt': '2016-12-29T18:21:42Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 4}, {'repo_name': 'checklistomania', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'As a user, I want to know how add/edit checklists', 'bodyHTML': \"<p>Would be great to have some instructions somewhere (if there aren't already), and link to them from the UI.</p>\", 'url': 'https://github.com/18F/checklistomania/issues/94', 'state': 'OPEN', 'createdAt': '2016-08-08T19:48:22Z', 'lastEditedAt': None, 'publishedAt': '2016-08-08T19:48:22Z', 'updatedAt': '2016-11-06T14:27:22Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'checklistomania', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Updated README screen shots', 'bodyHTML': '<p>They are out of date with the current app styling.</p>', 'url': 'https://github.com/18F/checklistomania/issues/101', 'state': 'OPEN', 'createdAt': '2016-08-17T13:34:48Z', 'lastEditedAt': None, 'publishedAt': '2016-08-17T13:34:48Z', 'updatedAt': '2017-10-10T12:31:43Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 3}, {'repo_name': 'checklistomania', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Upgrade to a cloud.gov-supported v6 version of node', 'bodyHTML': '<p>Checklistomania is currently using a v5 version of node, but v5 is no longer supported: <a href=\"https://nodesource.com/blog/farewell-to-node-js-v5-preparing-for-v7/\" rel=\"nofollow\">https://nodesource.com/blog/farewell-to-node-js-v5-preparing-for-v7/</a></p>\\n<p>v6 is a Long-Term Support version.</p>', 'url': 'https://github.com/18F/checklistomania/issues/108', 'state': 'CLOSED', 'createdAt': '2016-09-06T22:04:36Z', 'lastEditedAt': None, 'publishedAt': '2016-09-06T22:04:36Z', 'updatedAt': '2016-11-17T22:58:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'ffd-toolkit', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Document developer-practices from the ffd-microsite', 'bodyHTML': '<p>With work starting on the Federal Front Door Microsite, there is workflow and documentation that would be valuable for this repo. This issue should be referenced in any PRs or Issues in <a href=\"https://github.com/18f/ffd-microsite\">18f/ffd-microsite</a> that should be brought into this project.</p>', 'url': 'https://github.com/18F/ffd-toolkit/issues/2', 'state': 'CLOSED', 'createdAt': '2016-02-19T14:22:27Z', 'lastEditedAt': None, 'publishedAt': '2016-02-19T14:22:27Z', 'updatedAt': '2016-04-11T14:59:40Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'embed civic issues tracker on each project page', 'bodyHTML': '<p>Embed civic issues tracker on each project page once they add 18F. ht <a class=\"user-mention\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/codeforamerica/hovercard\" href=\"https://github.com/codeforamerica\">@codeforamerica</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=595778\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ondrae\">@ondrae</a></p>\\n', 'url': 'https://github.com/18F/dashboard/issues/36', 'state': 'OPEN', 'createdAt': '2014-09-18T17:38:11Z', 'lastEditedAt': None, 'publishedAt': '2014-09-18T17:38:11Z', 'updatedAt': '2017-05-12T18:15:44Z', 'labels': ['0 - Backlog', 'help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Use project description for open graph tags', 'bodyHTML': '<p>Here\\'s me linking to a project page in Slack:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4592/4758572/837b9036-5ae0-11e4-9001-51aeb9b6f742.png\"><img src=\"https://cloud.githubusercontent.com/assets/4592/4758572/837b9036-5ae0-11e4-9001-51aeb9b6f742.png\" alt=\"og tags\" style=\"max-width:100%;\"></a></p>\\n<p>It\\'s got the project title in there, but not the project description. (Which right now sort of implies that myRA <em>is</em> 18F. <g-emoji class=\"g-emoji\" alias=\"smile_cat\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f638.png\"></g-emoji>)</p>', 'url': 'https://github.com/18F/dashboard/issues/124', 'state': 'CLOSED', 'createdAt': '2014-10-23T18:15:38Z', 'lastEditedAt': None, 'publishedAt': '2014-10-23T18:15:38Z', 'updatedAt': '2015-03-06T14:41:21Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Link to partner agency?', 'bodyHTML': '<p>This seems begging for a link to Treasury\\'s website:</p>\\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4592/4758628/d94450ac-5ae0-11e4-99c5-9a0d25599d8e.png\"><img src=\"https://cloud.githubusercontent.com/assets/4592/4758628/d94450ac-5ae0-11e4-99c5-9a0d25599d8e.png\" alt=\"og tags\" style=\"max-width:100%;\"></a></p>\\n<p>It might be less necessary for Treasury, but for lesser-known partners it could be a help.</p>', 'url': 'https://github.com/18F/dashboard/issues/125', 'state': 'CLOSED', 'createdAt': '2014-10-23T18:17:43Z', 'lastEditedAt': None, 'publishedAt': '2014-10-23T18:17:43Z', 'updatedAt': '2015-07-07T18:29:17Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 3}, {'repo_name': 'dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'check out dashboard and provide feedback', 'bodyHTML': '<p>18f.gsa.gov/dashboard</p>\\n<p>Open thread! Share your thoughts here!</p>\\n<ul>\\n<li>What are you interested in learning about 18F?</li>\\n<li>Does dashboard provide that?</li>\\n<li>Is it easy to find?</li>\\n<li>What is confusing about dashboard?</li>\\n</ul>', 'url': 'https://github.com/18F/dashboard/issues/152', 'state': 'OPEN', 'createdAt': '2014-11-06T17:16:44Z', 'lastEditedAt': None, 'publishedAt': '2014-11-06T17:16:44Z', 'updatedAt': '2015-05-08T14:55:50Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 9}, {'repo_name': 'dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'need feedback: analytics', 'bodyHTML': \"<p>If we start releasing some of the data from google analytics from the sites we're building, what would you use it for? What would you actually use and find helpful?</p>\", 'url': 'https://github.com/18F/dashboard/issues/153', 'state': 'OPEN', 'createdAt': '2014-11-06T17:18:00Z', 'lastEditedAt': None, 'publishedAt': '2014-11-06T17:18:00Z', 'updatedAt': '2014-11-13T19:14:23Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 4}, {'repo_name': 'dashboard', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'more descriptive link text', 'bodyHTML': '<p>The project stages page has four \"learn more\" links -- this can make for a sub-par experience for screen reader users, as many such users will have their screen reader read them all of the links on the page -- in a context like that, it\\'s nearly impossible to know where the links go.</p>\\n<p>I suggest something more descriptive like \"Learn more about the alpha stage.\", etc.</p>', 'url': 'https://github.com/18F/dashboard/issues/154', 'state': 'CLOSED', 'createdAt': '2014-11-06T18:32:22Z', 'lastEditedAt': None, 'publishedAt': '2014-11-06T18:32:22Z', 'updatedAt': '2015-03-25T17:39:14Z', 'labels': ['help wanted'], 'is_locked': True, 'total_participants': 2}, {'repo_name': 'development-guide', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Fix broken link in [FY2017] end-of-year assessment guide', 'bodyHTML': '<p>On <a href=\"https://github.com/18F/development-guide/blob/master/people/2017-Assessment-Guide.md#3-synthesize-feedback-and-draft-a-written-review\">this page</a>, the text [GSA has] <code>guidance on writing objective and fair reviews</code> links to this URL:</p>\\n<blockquote>\\n<p><a href=\"https://insite.gsa.gov/portal/getMediaData?mediaId=614006\" rel=\"nofollow\">https://insite.gsa.gov/portal/getMediaData?mediaId=614006</a></p>\\n</blockquote>\\n<p>...which yields this error message:</p>\\n<blockquote>\\n<p>Error - Legecy ASTO mediaId not found.</p>\\n</blockquote>\\n<p>[sic]</p>\\n<p>Presumably this is because many pages on InSite have been reorganized. Let\\'s track down the new one.</p>\\n<p>(Note: this bug appears in the FY2017 end-of-year assessment guide, but because we\\'ve thus far been using it for FY2018 as well, it\\'s still relevant.)</p>', 'url': 'https://github.com/18F/development-guide/issues/80', 'state': 'OPEN', 'createdAt': '2018-10-31T18:04:46Z', 'lastEditedAt': None, 'publishedAt': '2018-10-31T18:04:46Z', 'updatedAt': '2018-10-31T18:05:24Z', 'labels': ['bug', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'salesforce-docs', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Add syntax pattern for naming conventions', 'bodyHTML': '<p>This should show how naming conventions should be articulated; e.g.,</p>\\n<pre><code>[FOO]_[BAR]_[DESCRIPTION] ...\\n</code></pre>', 'url': 'https://github.com/cfpb/salesforce-docs/issues/5', 'state': 'OPEN', 'createdAt': '2016-09-09T14:42:09Z', 'lastEditedAt': None, 'publishedAt': '2016-09-09T14:42:09Z', 'updatedAt': '2016-10-18T16:24:06Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'salesforce-docs', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Set ApexDoc as commenting standard', 'bodyHTML': '<p>Current CFPB Salesforce standards set the comment blocks like:</p>\\n<pre><code>/*------------------------------------------------------------\\nAuthor:       Joe Somebody\\nCompany:       Salesforce.com\\nDescription:   A utility class for the contact trigger\\nInputs:        \"customers\" - Contact objects that are being triggered\\n               \"oldCustomers\" - Contacts object values before trigger event\\n               \"ta\" - Trigger action that is occurring\\nTest Class:    CustomerManagementTest\\nHistory\\n&lt;Date&gt;      &lt;Authors Name&gt;     &lt;Brief Description of Change&gt;\\n------------------------------------------------------------*/\\n</code></pre>\\n<p>Instead, it seems preferable to follow <a href=\"https://github.com/SalesforceFoundation/ApexDoc\">https://github.com/SalesforceFoundation/ApexDoc</a>, which follows familiar javadoc and jsdoc syntax (in use in other CFPB projects) and provides a tool to aggregate documentation.</p>', 'url': 'https://github.com/cfpb/salesforce-docs/issues/7', 'state': 'CLOSED', 'createdAt': '2016-09-09T16:48:08Z', 'lastEditedAt': None, 'publishedAt': '2016-09-09T16:48:08Z', 'updatedAt': '2016-12-06T13:46:20Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'salesforce-docs', 'repo_owner_name': 'Consumer Financial Protection Bureau', 'repo_owner_email': '', 'repo_owner_user_name': 'cfpb', 'repo_owner_profile_url': 'https://github.com/cfpb', 'title': 'Add Permission Set Naming convention', 'bodyHTML': '<p>This is the idea we will add to the docs<br>\\n<code>[App Short Name] - [Persona or Permission] - [C|R|E|D]</code></p>\\n<p>E.g., <code>Mos - Contact Center Agent - CRE</code>  or <code>Mos - Delete Contacts - D</code></p>\\n<p>Note that for permission sets that are not aligned with a persona, use a present-tense verb to help describe the permission.</p>\\n<p>As per, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4053083\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mvogelgesang\">@mvogelgesang</a> let\\'s also add <code>Org Wide - [Permission Type] - System [C|R|E|D]</code></p>\\n<p>/c <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1289158\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/miklane\">@miklane</a></p>', 'url': 'https://github.com/cfpb/salesforce-docs/issues/8', 'state': 'OPEN', 'createdAt': '2016-10-18T16:23:32Z', 'lastEditedAt': '2016-12-05T22:23:18Z', 'publishedAt': '2016-10-18T16:23:32Z', 'updatedAt': '2016-12-05T22:23:18Z', 'labels': ['enhancement', 'help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'cf-route-lookup', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Show unbound routes', 'bodyHTML': '<p>It would be nice if looking up an unbound route would show the org and space. Instead of:</p>\\n<p>$ cf lookup-route unbound.app.example.org<br>\\nNot bound to any applications.</p>\\n<p>I would expect:</p>\\n<p>$ cf lookup-route unbound.app.example.org<br>\\nNot bound in:<br>\\nORG/space</p>', 'url': 'https://github.com/18F/cf-route-lookup/issues/8', 'state': 'OPEN', 'createdAt': '2018-03-06T21:54:27Z', 'lastEditedAt': None, 'publishedAt': '2018-03-06T21:54:27Z', 'updatedAt': '2018-03-06T22:07:44Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 2}, {'repo_name': 'concourse-broker', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Use lager throughout instead of log', 'bodyHTML': '<p>With the exception of all the functions called before the broker is started at the end <code>main</code>, we should be using <code>lager</code> throughout especially since the <code>brokerapi</code> gives it to you.<br>\\nIn an attempt to quickly assemble this, we used <code>log</code> however, <code>lager</code> can give you better context of what\\'s happening in the app.</p>\\n<p>This PR <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"199214693\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/18F/concourse-broker/issues/3\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/18F/concourse-broker/pull/3/hovercard\" href=\"https://github.com/18F/concourse-broker/pull/3\">#3</a> shows this conversion for the <code>concourse</code> package.</p>\\n<p>It just needs to happen for the other packages. In particular the <code>cf</code> package when errors happen.</p>\\n<p>Also, would be helpful to add any logs of level INFO and DEBUG. (Right now, most logs are of type ERROR)</p>', 'url': 'https://github.com/18F/concourse-broker/issues/6', 'state': 'OPEN', 'createdAt': '2017-01-06T20:06:22Z', 'lastEditedAt': '2017-01-06T20:13:52Z', 'publishedAt': '2017-01-06T20:06:22Z', 'updatedAt': '2017-01-06T20:13:52Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'concourse-broker', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add unit tests for config package', 'bodyHTML': '', 'url': 'https://github.com/18F/concourse-broker/issues/7', 'state': 'OPEN', 'createdAt': '2017-01-06T20:15:07Z', 'lastEditedAt': None, 'publishedAt': '2017-01-06T20:15:07Z', 'updatedAt': '2017-01-06T20:15:07Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'concourse-broker', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add unit tests for logger package', 'bodyHTML': '', 'url': 'https://github.com/18F/concourse-broker/issues/8', 'state': 'OPEN', 'createdAt': '2017-01-06T20:15:29Z', 'lastEditedAt': None, 'publishedAt': '2017-01-06T20:15:29Z', 'updatedAt': '2017-01-06T20:15:29Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'concourse-broker', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add unit tests for cf package', 'bodyHTML': '<p>Similar to the tests for the concourse package</p>', 'url': 'https://github.com/18F/concourse-broker/issues/9', 'state': 'OPEN', 'createdAt': '2017-01-06T20:16:16Z', 'lastEditedAt': None, 'publishedAt': '2017-01-06T20:16:16Z', 'updatedAt': '2017-01-06T20:16:16Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'concourse-broker', 'repo_owner_name': '18F', 'repo_owner_email': '18f@gsa.gov', 'repo_owner_user_name': '18F', 'repo_owner_profile_url': 'https://github.com/18F', 'title': 'Add unit tests for broker package', 'bodyHTML': '<p>You will probably want to use something like <a href=\"https://github.com/vektra/mockery\">mockery</a> to mock the <code>concourse.Client</code> and the <code>cf.Client</code>.</p>', 'url': 'https://github.com/18F/concourse-broker/issues/11', 'state': 'OPEN', 'createdAt': '2017-01-06T20:27:21Z', 'lastEditedAt': None, 'publishedAt': '2017-01-06T20:27:21Z', 'updatedAt': '2017-01-06T20:27:21Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'i14y', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Implement Swagger API docs', 'bodyHTML': '<p><a href=\"https://github.com/tim-vandecasteele/grape-swagger\">https://github.com/tim-vandecasteele/grape-swagger</a></p>\\n<p>I kept running into problems integrating this. Perhaps someone else will have better luck.</p>', 'url': 'https://github.com/GSA/i14y/issues/1', 'state': 'OPEN', 'createdAt': '2015-04-23T16:10:17Z', 'lastEditedAt': None, 'publishedAt': '2015-04-23T16:10:17Z', 'updatedAt': '2015-06-11T17:50:35Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}, {'repo_name': 'i14y', 'repo_owner_name': 'U.S. General Services Administration', 'repo_owner_email': 'gsa-github.support@gsa.gov', 'repo_owner_user_name': 'GSA', 'repo_owner_profile_url': 'https://github.com/GSA', 'title': 'Add CircleCI testing support', 'bodyHTML': \"<p>We have enabled CircleCI testing for this repo but we still need to add a properly-configured <code>.circleci/config.yml</code> file to enable testing of this app against CircleCI 2.0.</p>\\n<p>Since there are no secrets in this repo, we have enabled CircleCI testing of forked branches. We'd love it if someone would step in and implement a <code>.circleci/config.yml</code> with these behaviors:</p>\\n<ul>\\n<li>Trigger on pull requests only (already configured in CircleCI)</li>\\n<li>Execute the specs in <code>spec/</code></li>\\n<li>Fail on any spec failures, or on any drop below 100% coverage</li>\\n<li>Verify that the CircleCI status badge in the README.md works correctly.</li>\\n</ul>\", 'url': 'https://github.com/GSA/i14y/issues/33', 'state': 'CLOSED', 'createdAt': '2018-02-28T06:28:17Z', 'lastEditedAt': None, 'publishedAt': '2018-02-28T06:28:17Z', 'updatedAt': '2018-03-07T07:28:47Z', 'labels': ['help wanted'], 'is_locked': False, 'total_participants': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(github_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'repo_name': 'Intelligent Transportation Systems Public Data Hub', 'repo_url': 'https://github.com/usdot-its-jpo-data-portal/microsite/', 'error': 'Owner: microsite or Repo name:  as missing'}, {'repo_name': 'usepa-harmonization', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'QA-SDMP-Project', 'repo_url': 'https://github.com/USEPA/QA-SDMP-Project.git', 'errors': Exception('[ERROR] while getting issues for USEPA/QA-SDMP-Project. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'QA-SDMP-Project\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'NHPP for FRBs, Version 1.0', 'repo_url': 'https://github.com/losalamos/NHPP-for-FRBs', 'errors': Exception('[ERROR] while getting issues for losalamos/NHPP-for-FRBs. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'NHPP-for-FRBs\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Soil Carbon Data: long tail recovery', 'repo_url': 'https://github.com/ktoddbrown/soils-long-tail-recovery', 'errors': Exception('[ERROR] while getting issues for ktoddbrown/soils-long-tail-recovery. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'soils-long-tail-recovery\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'LCI-Primer', 'repo_url': 'https://github.com/USEPA/LCI-Primer', 'errors': Exception('[ERROR] while getting issues for USEPA/LCI-Primer. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'LCI-Primer\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'U.S. Army Research Laboratory (ARL) Discrete Chemical Compound Space Optimization (DCCSO)', 'repo_url': 'https://github.com/USArmyResearchLab/DCCSO', 'errors': Exception('[ERROR] while getting issues for USArmyResearchLab/DCCSO. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'DCCSO\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'domain-scanning', 'repo_url': 'https://github.com/GSA/domain-scanning', 'errors': Exception('[ERROR] while getting issues for GSA/domain-scanning. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'domain-scanning\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': '18franklin', 'repo_url': 'https://github.com/18F/18franklin', 'errors': Exception('[ERROR] while getting issues for 18F/18franklin. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'18franklin\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Flight Dynamics Simulation of a Generic Transport Model', 'repo_url': 'https://github.com/nasa/GTM_DesignSim/', 'error': 'Owner: GTM_DesignSim or Repo name:  as missing'}, {'repo_name': 'libSPRITE', 'repo_url': 'https://github.com/nasa/libSPRITE/', 'error': 'Owner: libSPRITE or Repo name:  as missing'}, {'repo_name': 'fedspendingtransparency.github.io', 'repo_url': 'https://github.com/18F/fedspendingtransparency.github.io', 'errors': Exception('[ERROR] while getting issues for 18F/fedspendingtransparency.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'fedspendingtransparency.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'FDTool', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Kepler Community Data Analysis Tools (PyKE)', 'repo_url': 'https://github.com/KeplerGO/PyKE/', 'error': 'Owner: PyKE or Repo name:  as missing'}, {'repo_name': 'ksnp', 'repo_url': 'https://github.com/USDA-VS/ksnp', 'errors': Exception('[ERROR] while getting issues for USDA-VS/ksnp. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'ksnp\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'PHP Data Sample for Envirofacts API, Using Safe Drinking Water Information Systems (SDIWS) Data', 'repo_url': 'https://github.com/USEPA/PHP-SDWIS-Data-Sample-Envirofacts-API', 'errors': Exception('[ERROR] while getting issues for USEPA/PHP-SDWIS-Data-Sample-Envirofacts-API. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'PHP-SDWIS-Data-Sample-Envirofacts-API\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'dev_4_sustainable_purchasing', 'repo_url': 'https://github.com/USEPA/dev_4_sustainable_purchasing', 'errors': Exception('[ERROR] while getting issues for USEPA/dev_4_sustainable_purchasing. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'dev_4_sustainable_purchasing\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'R micromap package development', 'repo_url': 'https://github.com/USEPA/R-micromap-package-development', 'errors': Exception('[ERROR] while getting issues for USEPA/R-micromap-package-development. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'R-micromap-package-development\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'ORD Applications Integration and Modernization GitHub repository', 'repo_url': 'https://github.com/USEPA/O-AIM', 'errors': Exception('[ERROR] while getting issues for USEPA/O-AIM. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'O-AIM\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Phytoplankton data analysis project', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'BMDS Model Averaging', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'TEST (Toxicity Estimation Software Tool)', 'repo_url': 'https://github.com/USEPA/ORD_TEST', 'errors': Exception('[ERROR] while getting issues for USEPA/ORD_TEST. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'ORD_TEST\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'XCode Data Sample for Envirofacts API, Using RadNet Data', 'repo_url': 'https://github.com/USEPA/XCode-RadNet-Sample-Data-Envirofacts-API', 'errors': Exception('[ERROR] while getting issues for USEPA/XCode-RadNet-Sample-Data-Envirofacts-API. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'XCode-RadNet-Sample-Data-Envirofacts-API\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'GREENSCOPE Tool', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'reference_guided_assembly', 'repo_url': 'https://github.com/USDA-VS/reference_guided_assembly', 'errors': Exception('[ERROR] while getting issues for USDA-VS/reference_guided_assembly. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'reference_guided_assembly\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'snp_analysis', 'repo_url': 'https://github.com/USDA-VS/snp_analysis', 'errors': Exception('[ERROR] while getting issues for USDA-VS/snp_analysis. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'snp_analysis\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Montana Data Search Tools - Demo Code', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'SSNM-CIMEK', 'repo_url': 'https://github.com/USEPA/SSNM-CIMEK.git', 'errors': Exception('[ERROR] while getting issues for USEPA/SSNM-CIMEK. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'SSNM-CIMEK\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Bioinformatics Module Development', 'repo_url': 'https://github.com/USEPA/CAT.git', 'errors': Exception('[ERROR] while getting issues for USEPA/CAT. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'CAT\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Water Network Tool for Resilience', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'US EPA Region 7 Introduction to R Workshop', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Drupal WebCMS GitHub Repository', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'GMAP Data Analysis GitHub repo', 'repo_url': 'https://github.com/USEPA/GMAP-data-analysis', 'errors': Exception('[ERROR] while getting issues for USEPA/GMAP-data-analysis. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'GMAP-data-analysis\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'CityWaterBalance', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'modelling_hab_indices', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'dev_1_fish_advisories', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Create public APEX Page', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Software Design, Development and Implementation QA Tracking Database Model', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Envite - 2.0', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'EPAs Avoided Emissions and Generation Tool', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Tool for the Reduction and Assessment of Chemical and other environmental Impacts.', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'region_2r', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'HELP', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'sustainable-chemistry-synthesis-expert-framework', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Python CoP', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'mulitResSurvey', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': '2017 US EPA R User Group Workshop', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'EPANET-legacy-user-interface', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'ORD@workphase2', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Kokkos GPU Compiler', 'repo_url': 'https://github.com/losalamos/kokkos-clang', 'errors': Exception('[ERROR] while getting issues for losalamos/kokkos-clang. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'kokkos-clang\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'pyCroscopy', 'repo_url': 'https://github.com/pycroscopy/pycroscopy/', 'error': 'Owner: pycroscopy or Repo name:  as missing'}, {'repo_name': 'CICE, The Los Alamos Sea Ice Model', 'repo_url': 'https://github.com/CICE-Consortium/CICE/', 'error': 'Owner: CICE or Repo name:  as missing'}, {'repo_name': 'GlobiPack v. 1.0', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Nuflood, Version 1.x', 'repo_url': 'https://github.com/losalamos/nuflood', 'errors': Exception('[ERROR] while getting issues for losalamos/nuflood. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'nuflood\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Simple rANDom wALk simulation', 'repo_url': 'https://github.com/losalamos/Sandal', 'errors': Exception('[ERROR] while getting issues for losalamos/Sandal. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'Sandal\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Progress Version 1.0', 'repo_url': 'https://github.com/progress/progress.github.io', 'errors': Exception('[ERROR] while getting issues for progress/progress.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'progress.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Multi Infrastructure Control and Optimization Toolkit, Resilient Design Module (MICOT-RDT), version 2.X', 'repo_url': 'https://github.com/lanl-ansi/micot-rdt', 'errors': Exception('[ERROR] while getting issues for lanl-ansi/micot-rdt. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'micot-rdt\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Pamgen', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'exomatlab', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'PyTrilinos', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'SIERRA Toolkit v. 2.0', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Virtual Machine Builder', 'repo_url': 'https://github.com/csd-dev-tools/VmBuilder', 'errors': Exception('[ERROR] while getting issues for csd-dev-tools/VmBuilder. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'VmBuilder\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Flexible Computer Science Infrastructure (FleCSI)', 'repo_url': 'https://github.com/losalamos/flecsi-third-party', 'errors': Exception('[ERROR] while getting issues for losalamos/flecsi-third-party. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'flecsi-third-party\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'ClockworkVMs', 'repo_url': 'https://github.com/csd-dev-tools/VmBuilder', 'errors': Exception('[ERROR] while getting issues for csd-dev-tools/VmBuilder. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'VmBuilder\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'rsed', 'repo_url': 'https://github.com/pnnl/rsed/', 'error': 'Owner: rsed or Repo name:  as missing'}, {'repo_name': 'genshell', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Quinoa, Version 0.1', 'repo_url': 'https://github.com/quinoacomputing/quinoa/', 'error': 'Owner: quinoa or Repo name:  as missing'}, {'repo_name': 'SearhEFbyCounty widget js', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Inorganic_Chloramine_-Formation_and_Decay_Application', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Geographic Response Plan Application', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'ri_wq_trends', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'esgf.github.io', 'repo_url': 'https://github.com/ESGF/esgf.github.io', 'errors': Exception('[ERROR] while getting issues for ESGF/esgf.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'esgf.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'LLNL Software Catalog', 'repo_url': 'https://github.com/LLNL/llnl.github.io', 'errors': Exception('[ERROR] while getting issues for LLNL/llnl.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'llnl.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Nux, V.1.0', 'repo_url': 'https://github.com/er1c/nux/', 'error': 'Owner: nux or Repo name:  as missing'}, {'repo_name': 'MAPVAR V1.9', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Phalanx V1.0', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Galacticus HDF5 Example, Version 1.0', 'repo_url': 'https://github.com/losalamos/Galacticus-HDF5-Example', 'errors': Exception('[ERROR] while getting issues for losalamos/Galacticus-HDF5-Example. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'Galacticus-HDF5-Example\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'lustre-tools-llnl', 'repo_url': 'https://github.com/chaos/lustre-tools-llnl', 'errors': Exception('[ERROR] while getting issues for chaos/lustre-tools-llnl. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'lustre-tools-llnl\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Ravel', 'repo_url': 'https://github.com/scalability-llnl/Ravel', 'errors': Exception('[ERROR] while getting issues for scalability-llnl/Ravel. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'scalability-llnl\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Tpetra Next-Generation Templated Petra V1.0', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'F3D Image Processing and Analysis for Many - and Multi-core Platforms', 'repo_url': 'https://github.com/CameraIA/F3D/', 'error': 'Owner: F3D or Repo name:  as missing'}, {'repo_name': 'Climate Data Analysis Tools', 'repo_url': 'https://github.com/UV-CDAT/uvcdat', 'errors': Exception('[ERROR] while getting issues for UV-CDAT/uvcdat. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'UV-CDAT\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Percept', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Draco,Version 6.x.x', 'repo_url': 'https://github.com/losalamos/Draco', 'errors': Exception('[ERROR] while getting issues for losalamos/Draco. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'Draco\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'GlobalSums, Version 1.x', 'repo_url': 'https://github.com/losalamos/GlobalSums', 'errors': Exception('[ERROR] while getting issues for losalamos/GlobalSums. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'GlobalSums\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'VERAIn', 'repo_url': 'https://github.com/CASL/VERAin/', 'error': 'Owner: VERAin or Repo name:  as missing'}, {'repo_name': 'Parser for Sabin-to-Mahoney Transition Model of Quasispecies Replication', 'repo_url': 'https://www.github.com/carolzhou/virus', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'INteroperable Tools for Rapid dEveloPment of compatible Discretizations', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'PetaVision version 2.0', 'repo_url': 'https://github.com/PetaVision/OpenPV/', 'error': 'Owner: OpenPV or Repo name:  as missing'}, {'repo_name': 'iDASH 2018: Task 1', 'repo_url': 'https://www.github.com/sandialabs/idash2018task1', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'Machine Learning Toolkit for Extreme Scale', 'repo_url': 'https://github.com/matex-org/matex/', 'error': 'Owner: matex or Repo name:  as missing'}, {'repo_name': 'BLOT Ver. 1.65', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'SIERRA Toolkit v. 1.0', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'EpetraExt (Epetra Extended) - Linear Algebra Services', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'SEACAS Trilinos', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Moertel Fe Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'gopcap', 'repo_url': 'https://github.com/ornl-sava/gopcap', 'errors': Exception('[ERROR] while getting issues for ornl-sava/gopcap. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'gopcap\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'LCLS Lightpath', 'repo_url': 'https://github.com/slaclab/lightpath', 'errors': Exception('[ERROR] while getting issues for slaclab/lightpath. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'lightpath\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Portals Reference Implementation v. 1.0', 'repo_url': 'https://github.com/portals4/portals4/', 'error': 'Owner: portals4 or Repo name:  as missing'}, {'repo_name': 'EPU v.3.0.08', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'sandialabs/BioCompoundML', 'repo_url': 'https://github.com/sandialabs/BioCompoundDB', 'errors': Exception('[ERROR] while getting issues for sandialabs/BioCompoundDB. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'BioCompoundDB\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'GHOST (Grid Hardware Open Source Testbed)', 'repo_url': 'https://github.com/PowerSystemsHIL/EPHCC/tree/NREL_merge ', 'errors': Exception('[ERROR] while getting issues for tree/NREL_merge . Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'tree\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'archapp', 'repo_url': 'https://github.com/slaclab/archapp', 'errors': Exception('[ERROR] while getting issues for slaclab/archapp. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'archapp\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Normalized Elution Time Prediction Utility', 'repo_url': 'https://github.com/PNNL-Comp-Mass-Spec/Protein-Digestion-Simulator/', 'error': 'Owner: Protein-Digestion-Simulator or Repo name:  as missing'}, {'repo_name': 'GEN3D Ver. 1.37', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Grope Ver. 1.38', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'MemAxes Visualization Software', 'repo_url': 'https://github.com/scalability-llnl/MemAxes', 'errors': Exception('[ERROR] while getting issues for scalability-llnl/MemAxes. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'scalability-llnl\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'KLU2 Direct Linear Solver Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Mat2exo', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Kokkos Array', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Volttron version 3.x', 'repo_url': 'https://github.com/VOLTTRON/volttron/', 'error': 'Owner: volttron or Repo name:  as missing'}, {'repo_name': 'Physics Integration KErnels (PIKE)', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Demeter-W', 'repo_url': 'https://github.com/JGCRI/demeter-w', 'errors': Exception('[ERROR] while getting issues for JGCRI/demeter-w. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'demeter-w\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Rapid Optimization Library', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'ROSSTEP v1.3', 'repo_url': 'https://github.com/Kukanani/ROSSTEP/', 'error': 'Owner: ROSSTEP or Repo name:  as missing'}, {'repo_name': 'pcircle - A Suite of Scalable Parallel File System Tools', 'repo_url': 'https://github.com/ORNL-TechInt/pcircle', 'errors': Exception('[ERROR] while getting issues for ORNL-TechInt/pcircle. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'pcircle\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'colormap_util', 'repo_url': 'https://github.com/jamienunez/cmaputil', 'errors': Exception('[ERROR] while getting issues for jamienunez/cmaputil. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'cmaputil\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Home Energy Management System - VOLTTRON Integration', 'repo_url': 'https://github.com/VOLTTRON/volttron-applications/', 'error': 'Owner: volttron-applications or Repo name:  as missing'}, {'repo_name': 'Neurons to Algorithms', 'repo_url': 'https://github.com/frothga/n2a/', 'error': 'Owner: n2a or Repo name:  as missing'}, {'repo_name': 'Ejoin', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Conjoin', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'magpie', 'repo_url': 'https://github.com/chu11/magpie', 'errors': Exception('[ERROR] while getting issues for chu11/magpie. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'magpie\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Domi', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Constructing Hardware in a Scale Embedded Language', 'repo_url': 'https://github.com/ucb-bar/chisel/', 'error': 'Owner: chisel or Repo name:  as missing'}, {'repo_name': 'Cram', 'repo_url': 'https://github.com/scalability-llnl/cram', 'errors': Exception('[ERROR] while getting issues for scalability-llnl/cram. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'scalability-llnl\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Exodiff v. 2.09', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Heuristic Access to Positions of Photon Instruments (HAPPI)', 'repo_url': 'https://github.com/slaclab/happi', 'errors': Exception('[ERROR] while getting issues for slaclab/happi. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'happi\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'PSWALKER', 'repo_url': 'https://github.com/slaclab/pswalker', 'errors': Exception('[ERROR] while getting issues for slaclab/pswalker. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'pswalker\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'GOTTCHA Database, Version 1', 'repo_url': 'https://github.com/losalamos/GOTTCHA', 'errors': Exception('[ERROR] while getting issues for losalamos/GOTTCHA. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'GOTTCHA\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'ALGEBRA v.1.27', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Framework for Analysis and Visualization of Simulation Data (VizAly)', 'repo_url': 'https://github.com/lanl/VizAly', 'errors': Exception('[ERROR] while getting issues for lanl/VizAly. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'VizAly\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'DOE CODE', 'repo_url': 'https://github.com/doecode/doecode/', 'error': 'Owner: doecode or Repo name:  as missing'}, {'repo_name': 'ForTrilinos v 10.1', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Automatic Differentiation Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Distributed File System Utilities to Manage Large DatasetsVersion 0.5', 'repo_url': 'https://github.com/hpc/fileutils', 'errors': Exception('[ERROR] while getting issues for hpc/fileutils. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'fileutils\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Javascript Code for ARCS APEX tool', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'GED Ecosystem Services Project', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'dev_2_farm_workers', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Basic Matrix Library (bml), Version 0.x', 'repo_url': 'https://github.com/qmmd/bml', 'errors': Exception('[ERROR] while getting issues for qmmd/bml. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'bml\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Integrated Earth System Model (iESM)', 'repo_url': 'https://github.com/ACME-Climate/iESM/', 'error': 'Owner: iESM or Repo name:  as missing'}, {'repo_name': 'Standard Energy Efficiency Data Platform', 'repo_url': 'https://github.com/SEED-platform/seed/', 'error': 'Owner: seed or Repo name:  as missing'}, {'repo_name': 'CUDA Enabled Graph Subset Examiner', 'repo_url': 'https://github.com/jtjohnston/computational_combinatorics/', 'error': 'Owner: computational_combinatorics or Repo name:  as missing'}, {'repo_name': 'TRANSFORM - TRANsient Simulation Framework of Reconfigurable Models', 'repo_url': 'https://github.com/ORNL-TRANSFORM/TRANSFORM-Library', 'errors': Exception('[ERROR] while getting issues for ORNL-TRANSFORM/TRANSFORM-Library. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'ORNL-TRANSFORM\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'VOLTTRON/volttron-applications', 'repo_url': 'https://github.com/VOLTTRON/volttron-applications/', 'error': 'Owner: volttron-applications or Repo name:  as missing'}, {'repo_name': 'Trilinos', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'dbglog', 'repo_url': 'https://github.com/bronevet/dbglog', 'errors': Exception('[ERROR] while getting issues for bronevet/dbglog. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'dbglog\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'ex1ex2v2 Version 2.10', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'nem_spread Ver. 5.10', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'nem_slice ver. 3.34', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'jShyLU Scalable Hybrid Preconditioner and Solver', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'IBTopo', 'repo_url': 'https://github.com/hpc/ibtopo', 'errors': Exception('[ERROR] while getting issues for hpc/ibtopo. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'ibtopo\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Trios', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Panzer', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Amesos2 Templated Direct Sparse Solver Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'flume-plugins Version 1.0', 'repo_url': 'https://github.com/chu11/flume-plugins', 'errors': Exception('[ERROR] while getting issues for chu11/flume-plugins. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'flume-plugins\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Tycho 2, Version 0.1', 'repo_url': 'https://github.com/losalamos/tycho2', 'errors': Exception('[ERROR] while getting issues for losalamos/tycho2. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'tycho2\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'UCNB_Analyzer', 'repo_url': 'https://github.com/losalamos/UCNB_Analyzer/', 'error': 'Owner: UCNB_Analyzer or Repo name:  as missing'}, {'repo_name': 'Amesos Solver Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'GJOIN', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'transfocate', 'repo_url': 'https://github.com/slaclab/transfocate', 'errors': Exception('[ERROR] while getting issues for slaclab/transfocate. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'transfocate\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Aristos Optimization Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Xpetra Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Aprepro - Algebraic Preprocessor', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'CompTox-ExpoCast-invivoPKfit', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'micromap', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'ONG-NSPS-OOOOa-Technical-Reconsideration-Analysis', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'pcds-recipes', 'repo_url': 'https://github.com/slaclab/pcds-recipes', 'errors': Exception('[ERROR] while getting issues for slaclab/pcds-recipes. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'pcds-recipes\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'GOTTCHA, Version 1', 'repo_url': 'https://github.com/losalamos/GOTTCHA', 'errors': Exception('[ERROR] while getting issues for losalamos/GOTTCHA. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'GOTTCHA\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Galeri Matrix Generation Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'smwflow.v2018.05.0', 'repo_url': 'https://github.com/NERSC/smwflow/', 'error': 'Owner: smwflow or Repo name:  as missing'}, {'repo_name': 'GREPOS', 'repo_url': 'https://github.com/gsjaardema/seacas/', 'error': 'Owner: seacas or Repo name:  as missing'}, {'repo_name': 'Code Analysis and Refactoring with Clang Tools, Version 0.1', 'repo_url': 'https://github.com/losalamos/CoARCT', 'errors': Exception('[ERROR] while getting issues for losalamos/CoARCT. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'CoARCT\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'ECoG Cluster Flow v1.0', 'repo_url': 'https://github.com/sugeerth/ECoG-ClusterFlow/', 'error': 'Owner: ECoG-ClusterFlow or Repo name:  as missing'}, {'repo_name': 'Campus Energy Model for Control and Performance Validation', 'repo_url': 'https://github.com/NREL/CampusEnergyModeling/', 'error': 'Owner: CampusEnergyModeling or Repo name:  as missing'}, {'repo_name': 'XACC - eXtreme-scale Accelerator Programming Framework', 'repo_url': 'https://github.com/ORNL-QCI/xacc', 'errors': Exception('[ERROR] while getting issues for ORNL-QCI/xacc. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'xacc\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Libparty, Version 1.x', 'repo_url': 'https://github.com/losalamos/libparty', 'errors': Exception('[ERROR] while getting issues for losalamos/libparty. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'libparty\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Arion', 'repo_url': 'https://github.com/pnnl/arion/', 'error': 'Owner: arion or Repo name:  as missing'}, {'repo_name': 'MADSpython 1.x', 'repo_url': 'https://github.com/losalamos/madspython', 'errors': Exception('[ERROR] while getting issues for losalamos/madspython. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'madspython\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Coulomb Logarithm, Version 1.0', 'repo_url': 'https://github.com/losalamos/clog', 'errors': Exception('[ERROR] while getting issues for losalamos/clog. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'clog\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Tight-binding model for materials at mesoscale', 'repo_url': 'https://github.com/TDIV/TBM3/', 'error': 'Owner: TBM3 or Repo name:  as missing'}, {'repo_name': 'Epetra Linear Algebra Services Package', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'PyUtilib: A Pythos Utility Library v. 1.0', 'repo_url': 'https://github.com/PyUtilib/pyutilib/', 'error': 'Owner: pyutilib or Repo name:  as missing'}, {'repo_name': 'The Datatype Compare Library v.1.0', 'repo_url': 'https://github.com/hpc/dtcmp', 'errors': Exception('[ERROR] while getting issues for hpc/dtcmp. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'dtcmp\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'PylotDB - A Database Management, Graphing, and Analysis Tool Written in Python', 'repo_url': 'https://github.com/dwbarne/PYLOTDB/', 'error': 'Owner: PYLOTDB or Repo name:  as missing'}, {'repo_name': 'phdMesh', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'Modular Aquatic Simulation System 1D', 'repo_url': 'https://github.com/pnnl/mass1/', 'error': 'Owner: mass1 or Repo name:  as missing'}, {'repo_name': 'Edge Bioinformatics', 'repo_url': 'https://github.com/losalamos/edge', 'errors': Exception('[ERROR] while getting issues for losalamos/edge. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'edge\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Open SHMEM Reference Implementation', 'repo_url': 'https://github.com/openshmem-org/openshmem', 'errors': Exception('[ERROR] while getting issues for openshmem-org/openshmem. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'openshmem\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Hard X-Ray Split and Delay Automated Controls System', 'repo_url': 'https://github.com/slaclab/HXRSnD', 'errors': Exception('[ERROR] while getting issues for slaclab/HXRSnD. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'HXRSnD\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'PCDS Devices', 'repo_url': 'https://github.com/slaclab/pcds-devices', 'errors': Exception('[ERROR] while getting issues for slaclab/pcds-devices. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'pcds-devices\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Slycat v 1.0 Beta', 'repo_url': 'https://github.com/sandialabs/slycat/', 'error': 'Owner: slycat or Repo name:  as missing'}, {'repo_name': 'Optipack', 'repo_url': 'https://github.com/trilinos/Trilinos/', 'error': 'Owner: Trilinos or Repo name:  as missing'}, {'repo_name': 'CDX to ARCS SQL', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Chlorine_Breakpoint_Curve_Simulator', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'Free_Chlorine_and_Cyanuric_Acid_Simulator', 'repo_url': 'https://github.com/USEPA', 'error': 'Owner: USEPA or Repo name: None as missing'}, {'repo_name': 'The National Solar Permitting Database', 'repo_url': 'https://github.com/solarpermit/solarpermit/', 'error': 'Owner: solarpermit or Repo name:  as missing'}, {'repo_name': 'Learning Registry', 'repo_url': 'https://github.com/LearningRegistry/', 'error': 'Owner: LearningRegistry or Repo name:  as missing'}, {'repo_name': 'Open Scheduling and Planning Interface for Exploration (OpenSPIFe)', 'repo_url': 'https://github.com/nasa/OpenSPIFe/', 'error': 'Owner: OpenSPIFe or Repo name:  as missing'}, {'repo_name': 'IMCE Ontological Modeling Framework', 'repo_url': 'https://github.com/JPL-IMCE', 'error': 'Owner: JPL-IMCE or Repo name: None as missing'}, {'repo_name': 'Prognostics Model Library', 'repo_url': 'https://github.com/nasa/PrognosticsModelLibrary/', 'error': 'Owner: PrognosticsModelLibrary or Repo name:  as missing'}, {'repo_name': 'Channel Emulator', 'repo_url': 'https://github.com/nasa/channel-emulator/', 'error': 'Owner: channel-emulator or Repo name:  as missing'}, {'repo_name': 'IPv6 Python Extension Module', 'repo_url': 'https://github.com/nasa/ipv6_python/', 'error': 'Owner: ipv6_python or Repo name:  as missing'}, {'repo_name': 'Tolerance Domain Specific Language', 'repo_url': 'https://github.com/kleb/nasarb/blob/master/uq4sim', 'errors': Exception('[ERROR] while getting issues for master/uq4sim. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'uq4sim\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Surface Aquatic Vegetation Detection Tool (SAVDT)', 'repo_url': 'https://github.com/NASA-DEVELOP/SAVDT', 'errors': Exception('[ERROR] while getting issues for NASA-DEVELOP/SAVDT. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'SAVDT\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'cfpb.github.io', 'repo_url': 'https://github.com/GSA/cfpb.github.io', 'errors': Exception('[ERROR] while getting issues for GSA/cfpb.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'cfpb.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Prognostics Algorithm Library', 'repo_url': 'https://github.com/nasa/PrognosticsAlgorithmLibrary/', 'error': 'Owner: PrognosticsAlgorithmLibrary or Repo name:  as missing'}, {'repo_name': 'EEPROM File System', 'repo_url': 'https://github.com/nasa/eefs/', 'error': 'Owner: eefs or Repo name:  as missing'}, {'repo_name': 'Virtual Flow Simulator', 'repo_url': 'https://github.com/SAFL-CFD-Lab/VFS-Wind/', 'error': 'Owner: VFS-Wind or Repo name:  as missing'}, {'repo_name': 'X-Plane Communication Toolbox (XPC)', 'repo_url': 'https://github.com/nasa/XPlaneConnect/', 'error': 'Owner: XPlaneConnect or Repo name:  as missing'}, {'repo_name': 'NASA WorldWind Research: EarthquakeApp', 'repo_url': 'https://github.com/NASAWorldWindResearch/EarthquakeApp', 'errors': Exception('[ERROR] while getting issues for NASAWorldWindResearch/EarthquakeApp. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'NASAWorldWindResearch\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Open Mission Control Technologies (Open MCT)', 'repo_url': 'https://github.com/nasa/openmct/', 'error': 'Owner: openmct or Repo name:  as missing'}, {'repo_name': 'EADIN Communication Protocol', 'repo_url': 'https://github.com/nasa/EADINLite/', 'error': 'Owner: EADINLite or Repo name:  as missing'}, {'repo_name': 'NASA WorldWind Research: SpaceBirds', 'repo_url': 'https://github.com/NASAWorldWindResearch/SpaceBirds', 'errors': Exception('[ERROR] while getting issues for NASAWorldWindResearch/SpaceBirds. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'NASAWorldWindResearch\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': '18f.github.io', 'repo_url': 'https://github.com/18F/18f.github.io', 'errors': Exception('[ERROR] while getting issues for 18F/18f.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'18f.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'Policies-and-Guidance', 'repo_url': 'git://github.com/CommerceGov/Policies-and-Guidance.git', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'cfpb.github.io', 'repo_url': 'https://github.com/cfpb/cfpb.github.io', 'errors': Exception('[ERROR] while getting issues for cfpb/cfpb.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'cfpb.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'grace-core', 'repo_url': 'https://github.com/GSA/grace-core', 'errors': Exception('[ERROR] while getting issues for GSA/grace-core. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'grace-core\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'NASAWorldWind.github.io', 'repo_url': 'https://github.com/NASAWorldWind/NASAWorldWind.github.io', 'errors': Exception('[ERROR] while getting issues for NASAWorldWind/NASAWorldWind.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'NASAWorldWind.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'NASA WorldWind Research: AgroSphere', 'repo_url': 'https://github.com/NASAWorldWindResearch/AgroSphere', 'errors': Exception('[ERROR] while getting issues for NASAWorldWindResearch/AgroSphere. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'NASAWorldWindResearch\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'NASA WorldWind Research: WxOps-WorldWind', 'repo_url': 'https://github.com/NASAWorldWindResearch/WxOps-WorldWind', 'errors': Exception('[ERROR] while getting issues for NASAWorldWindResearch/WxOps-WorldWind. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'NASAWorldWindResearch\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'DLT', 'repo_url': 'https://github.com/GSA/DLT', 'errors': Exception('[ERROR] while getting issues for GSA/DLT. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'DLT\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'NASA WorldWind Research: Quake-Hunter', 'repo_url': 'https://github.com/NASAWorldWindResearch/Quake-Hunter', 'errors': Exception('[ERROR] while getting issues for NASAWorldWindResearch/Quake-Hunter. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'NASAWorldWindResearch\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'NASA WorldWind Research: CitySmart', 'repo_url': 'https://github.com/NASAWorldWindResearch/CitySmart', 'errors': Exception('[ERROR] while getting issues for NASAWorldWindResearch/CitySmart. Errors: [{\\'message\\': \"Could not resolve to a User with the username \\'NASAWorldWindResearch\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'open.gsa.gov.github.io', 'repo_url': 'https://github.com/GSA/open.gsa.gov.github.io', 'errors': Exception('[ERROR] while getting issues for GSA/open.gsa.gov.githu. Errors: [{\\'message\\': \"Could not resolve to a Repository with the name \\'open.gsa.gov.githu\\'.\", \\'type\\': \\'NOT_FOUND\\', \\'path\\': [\\'repository\\'], \\'locations\\': [{\\'line\\': 3, \\'column\\': 13}]}]')}, {'repo_name': 'bronto', 'repo_url': 'https://github.com/18F/bronto', 'errors': Exception(\"[ERROR] while getting issues for 18F/bronto. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '2015-foia-design', 'repo_url': 'https://github.com/18F/2015-foia-design', 'errors': Exception(\"[ERROR] while getting issues for 18F/2015-foia-design. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'parse-shopping-list', 'repo_url': 'https://github.com/18F/parse-shopping-list', 'errors': Exception(\"[ERROR] while getting issues for 18F/parse-shopping-list. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'vagrant-chef-elasticsearch', 'repo_url': 'https://github.com/18F/vagrant-chef-elasticsearch', 'errors': Exception(\"[ERROR] while getting issues for 18F/vagrant-chef-elasticsearch. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'bpa-dash', 'repo_url': 'https://github.com/18F/bpa-dash', 'errors': Exception(\"[ERROR] while getting issues for 18F/bpa-dash. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'elk-docker', 'repo_url': 'https://github.com/18F/elk-docker', 'errors': Exception(\"[ERROR] while getting issues for 18F/elk-docker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'epa-emanifest-data', 'repo_url': 'https://github.com/18F/epa-emanifest-data', 'errors': Exception(\"[ERROR] while getting issues for 18F/epa-emanifest-data. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'e-manifest-cromerr-client', 'repo_url': 'https://github.com/18F/e-manifest-cromerr-client', 'errors': Exception(\"[ERROR] while getting issues for 18F/e-manifest-cromerr-client. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pdf-forms-tutorial', 'repo_url': 'https://github.com/18F/pdf-forms-tutorial', 'errors': Exception(\"[ERROR] while getting issues for 18F/pdf-forms-tutorial. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'peacecorps-site', 'repo_url': 'https://github.com/18F/peacecorps-site', 'errors': Exception(\"[ERROR] while getting issues for 18F/peacecorps-site. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-s3-proxy', 'repo_url': 'https://github.com/18F/cg-s3-proxy', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-s3-proxy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-gitaware', 'repo_url': 'https://github.com/18F/cf-gitaware', 'errors': Exception(\"[ERROR] while getting issues for 18F/cf-gitaware. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'joining-18f-app', 'repo_url': 'https://github.com/18F/joining-18f-app', 'errors': Exception(\"[ERROR] while getting issues for 18F/joining-18f-app. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-uaa', 'repo_url': 'https://github.com/18F/cg-uaa', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-uaa. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'federalist-builder', 'repo_url': 'https://github.com/18F/federalist-builder', 'errors': Exception(\"[ERROR] while getting issues for 18F/federalist-builder. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sheet-to-csv', 'repo_url': 'https://github.com/18F/sheet-to-csv', 'errors': Exception(\"[ERROR] while getting issues for 18F/sheet-to-csv. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'discussions', 'repo_url': 'https://github.com/18F/discussions', 'errors': Exception(\"[ERROR] while getting issues for 18F/discussions. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'wg-dataservices', 'repo_url': 'https://github.com/18F/wg-dataservices', 'errors': Exception(\"[ERROR] while getting issues for 18F/wg-dataservices. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'angrytock', 'repo_url': 'https://github.com/18F/angrytock', 'errors': Exception(\"[ERROR] while getting issues for 18F/angrytock. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'accordion', 'repo_url': 'https://github.com/18F/accordion', 'errors': Exception(\"[ERROR] while getting issues for 18F/accordion. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'about-yml-validator', 'repo_url': 'https://github.com/18F/about-yml-validator', 'errors': Exception(\"[ERROR] while getting issues for 18F/about-yml-validator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'zap-core-help', 'repo_url': 'https://github.com/18F/zap-core-help', 'errors': Exception(\"[ERROR] while getting issues for 18F/zap-core-help. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'engineering-team-faq', 'repo_url': 'https://github.com/18F/engineering-team-faq', 'errors': Exception(\"[ERROR] while getting issues for 18F/engineering-team-faq. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fpds-getter', 'repo_url': 'https://github.com/18F/fpds-getter', 'errors': Exception(\"[ERROR] while getting issues for 18F/fpds-getter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'kibana-cf_authentication', 'repo_url': 'https://github.com/18F/kibana-cf_authentication', 'errors': Exception(\"[ERROR] while getting issues for 18F/kibana-cf_authentication. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'logsearch-for-cloudfoundry', 'repo_url': 'https://github.com/18F/logsearch-for-cloudfoundry', 'errors': Exception(\"[ERROR] while getting issues for 18F/logsearch-for-cloudfoundry. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'security-group-test-app', 'repo_url': 'https://github.com/18F/security-group-test-app', 'errors': Exception(\"[ERROR] while getting issues for 18F/security-group-test-app. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'trello-card-velocity', 'repo_url': 'https://github.com/18F/trello-card-velocity', 'errors': Exception(\"[ERROR] while getting issues for 18F/trello-card-velocity. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'json-editor', 'repo_url': 'https://github.com/18F/json-editor', 'errors': Exception(\"[ERROR] while getting issues for 18F/json-editor. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-abacus', 'repo_url': 'https://github.com/18F/cf-abacus', 'errors': Exception(\"[ERROR] while getting issues for 18F/cf-abacus. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'about-yml-editor', 'repo_url': 'https://github.com/18F/about-yml-editor', 'errors': Exception(\"[ERROR] while getting issues for 18F/about-yml-editor. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'lunr-server', 'repo_url': 'https://github.com/18F/lunr-server', 'errors': Exception(\"[ERROR] while getting issues for 18F/lunr-server. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-style-gem', 'repo_url': 'https://github.com/18F/cg-style-gem', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-style-gem. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-goshin', 'repo_url': 'https://github.com/18F/cg-goshin', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-goshin. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'mocha-casperjs', 'repo_url': 'https://github.com/18F/mocha-casperjs', 'errors': Exception(\"[ERROR] while getting issues for 18F/mocha-casperjs. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pa11y-rails', 'repo_url': 'https://github.com/18F/pa11y-rails', 'errors': Exception(\"[ERROR] while getting issues for 18F/pa11y-rails. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-logsearch', 'repo_url': 'https://github.com/18F/cg-deploy-logsearch', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-logsearch. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-ga-report', 'repo_url': 'https://github.com/GSA/ckanext-ga-report', 'errors': Exception(\"[ERROR] while getting issues for GSA/ckanext-ga-report. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CodeInventory', 'repo_url': 'https://github.com/GSA/codeinventory', 'errors': Exception(\"[ERROR] while getting issues for GSA/codeinventory. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sf-ProjectDashboard', 'repo_url': 'https://github.com/GSA/sf-ProjectDashboard', 'errors': Exception(\"[ERROR] while getting issues for GSA/sf-ProjectDashboard. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sdg-nrp-scripts', 'repo_url': 'https://github.com/GSA/sdg-nrp-scripts', 'errors': Exception(\"[ERROR] while getting issues for GSA/sdg-nrp-scripts. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ansible-tomcat', 'repo_url': 'https://github.com/GSA/ansible-tomcat', 'errors': Exception(\"[ERROR] while getting issues for GSA/ansible-tomcat. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'GEAR2-NodeJS', 'repo_url': 'https://github.com/GSA/GEAR2-NodeJS', 'errors': Exception(\"[ERROR] while getting issues for GSA/GEAR2-NodeJS. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'FM-ULO', 'repo_url': 'https://github.com/GSA/FM-ULO', 'errors': Exception(\"[ERROR] while getting issues for GSA/FM-ULO. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'coffeemate', 'repo_url': 'https://github.com/18F/coffeemate', 'errors': Exception(\"[ERROR] while getting issues for 18F/coffeemate. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-admin-ui', 'repo_url': 'https://github.com/18F/cg-deploy-admin-ui', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-admin-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-bosh', 'repo_url': 'https://github.com/18F/cg-deploy-bosh', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-bosh. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hub-v2', 'repo_url': 'https://github.com/18F/hub-v2', 'errors': Exception(\"[ERROR] while getting issues for 18F/hub-v2. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'API-Class', 'repo_url': 'https://github.com/GSA/API-Class', 'errors': Exception(\"[ERROR] while getting issues for GSA/API-Class. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fedramp-gov', 'repo_url': 'https://github.com/GSA/fedramp-gov', 'errors': Exception(\"[ERROR] while getting issues for GSA/fedramp-gov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'digitalgov-redir', 'repo_url': 'https://github.com/GSA/digitalgov-redir', 'errors': Exception(\"[ERROR] while getting issues for GSA/digitalgov-redir. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'time-estimator', 'repo_url': 'https://github.com/GSA/time-estimator', 'errors': Exception(\"[ERROR] while getting issues for GSA/time-estimator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'BSP_Mode1_Reporting', 'repo_url': 'https://github.com/GSA/BSP_Mode1_Reporting', 'errors': Exception(\"[ERROR] while getting issues for GSA/BSP_Mode1_Reporting. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-deploy-ckan-inventory', 'repo_url': 'https://github.com/GSA/datagov-deploy-ckan-inventory', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-deploy-ckan-inventory. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-deploy-tomcat', 'repo_url': 'https://github.com/GSA/datagov-deploy-tomcat', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-deploy-tomcat. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'data-strategy', 'repo_url': 'https://github.com/GSA/data-strategy', 'errors': Exception(\"[ERROR] while getting issues for GSA/data-strategy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '18fconsulting-proto-3', 'repo_url': 'https://github.com/18F/18fconsulting-proto-3', 'errors': Exception(\"[ERROR] while getting issues for 18F/18fconsulting-proto-3. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'api-playground', 'repo_url': 'https://github.com/18F/api-playground', 'errors': Exception(\"[ERROR] while getting issues for 18F/api-playground. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-formats', 'repo_url': 'https://github.com/18F/ckanext-formats', 'errors': Exception(\"[ERROR] while getting issues for 18F/ckanext-formats. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'flakes-flask', 'repo_url': 'https://github.com/18F/flakes-flask', 'errors': Exception(\"[ERROR] while getting issues for 18F/flakes-flask. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'usps-proxy', 'repo_url': 'https://github.com/18F/usps-proxy', 'errors': Exception(\"[ERROR] while getting issues for 18F/usps-proxy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'test_temp_file_helper', 'repo_url': 'https://github.com/18F/test_temp_file_helper', 'errors': Exception(\"[ERROR] while getting issues for 18F/test_temp_file_helper. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'jekyll_pages_api', 'repo_url': 'https://github.com/18F/jekyll_pages_api', 'errors': Exception(\"[ERROR] while getting issues for 18F/jekyll_pages_api. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-deploy', 'repo_url': 'https://github.com/18F/cf-deploy', 'errors': Exception(\"[ERROR] while getting issues for 18F/cf-deploy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'project-monitor', 'repo_url': 'https://github.com/18F/project-monitor', 'errors': Exception(\"[ERROR] while getting issues for 18F/project-monitor. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'd3-technical-debt', 'repo_url': 'https://github.com/18F/d3-technical-debt', 'errors': Exception(\"[ERROR] while getting issues for 18F/d3-technical-debt. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sauceclient', 'repo_url': 'https://github.com/18F/sauceclient', 'errors': Exception(\"[ERROR] while getting issues for 18F/sauceclient. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'abb', 'repo_url': 'https://github.com/18F/abb', 'errors': Exception(\"[ERROR] while getting issues for 18F/abb. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-scripts', 'repo_url': 'https://github.com/18F/cg-scripts', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-scripts. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'data-act-workshop', 'repo_url': 'https://github.com/18F/data-act-workshop', 'errors': Exception(\"[ERROR] while getting issues for 18F/data-act-workshop. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'project-monitor-helper', 'repo_url': 'https://github.com/18F/project-monitor-helper', 'errors': Exception(\"[ERROR] while getting issues for 18F/project-monitor-helper. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CHRISUpdate', 'repo_url': 'https://github.com/GSA/CHRISUpdate', 'errors': Exception(\"[ERROR] while getting issues for GSA/CHRISUpdate. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'code-gov-admin-backend', 'repo_url': 'https://github.com/GSA/code-gov-admin-backend', 'errors': Exception(\"[ERROR] while getting issues for GSA/code-gov-admin-backend. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'frntmttr', 'repo_url': 'https://github.com/GSA/frntmttr', 'errors': Exception(\"[ERROR] while getting issues for GSA/frntmttr. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'DevSecOps', 'repo_url': 'https://github.com/GSA/DevSecOps', 'errors': Exception(\"[ERROR] while getting issues for GSA/DevSecOps. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CorpIT-CloudSandbox', 'repo_url': 'https://github.com/GSA/CorpIT-CloudSandbox', 'errors': Exception(\"[ERROR] while getting issues for GSA/CorpIT-CloudSandbox. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fpkilint', 'repo_url': 'https://github.com/GSA/fpkilint', 'errors': Exception(\"[ERROR] while getting issues for GSA/fpkilint. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'opp-code-gov-web', 'repo_url': 'https://github.com/GSA/opp-code-gov-web', 'errors': Exception(\"[ERROR] while getting issues for GSA/opp-code-gov-web. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'feedback.usa.gov', 'repo_url': 'https://github.com/GSA/feedback.usa.gov', 'errors': Exception(\"[ERROR] while getting issues for GSA/feedback.usa.gov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'voc_public', 'repo_url': 'https://github.com/GSA/voc_public', 'errors': Exception(\"[ERROR] while getting issues for GSA/voc_public. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'newperformancedotgov1', 'repo_url': 'https://github.com/GSA/newperformancedotgov1', 'errors': Exception(\"[ERROR] while getting issues for GSA/newperformancedotgov1. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'inactive-logout', 'repo_url': 'https://github.com/GSA/inactive-logout', 'errors': Exception(\"[ERROR] while getting issues for GSA/inactive-logout. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'redir', 'repo_url': 'https://github.com/GSA/redir', 'errors': Exception(\"[ERROR] while getting issues for GSA/redir. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'slackin', 'repo_url': 'https://github.com/18F/slackin', 'errors': Exception(\"[ERROR] while getting issues for 18F/slackin. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'docker-elasticsearch', 'repo_url': 'https://github.com/18F/docker-elasticsearch', 'errors': Exception(\"[ERROR] while getting issues for 18F/docker-elasticsearch. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hubot-cf-notifications', 'repo_url': 'https://github.com/18F/hubot-cf-notifications', 'errors': Exception(\"[ERROR] while getting issues for 18F/hubot-cf-notifications. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'record-locator', 'repo_url': 'https://github.com/18F/record-locator', 'errors': Exception(\"[ERROR] while getting issues for 18F/record-locator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'citysdk-innov-district', 'repo_url': 'https://github.com/18F/citysdk-innov-district', 'errors': Exception(\"[ERROR] while getting issues for 18F/citysdk-innov-district. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'collector', 'repo_url': 'https://github.com/18F/collector', 'errors': Exception(\"[ERROR] while getting issues for 18F/collector. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'swagger-ui', 'repo_url': 'https://github.com/18F/swagger-ui', 'errors': Exception(\"[ERROR] while getting issues for 18F/swagger-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'devops-assessment', 'repo_url': 'https://github.com/18F/devops-assessment', 'errors': Exception(\"[ERROR] while getting issues for 18F/devops-assessment. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'noaabigdata-code', 'repo_url': 'https://github.com/18F/noaabigdata-code', 'errors': Exception(\"[ERROR] while getting issues for 18F/noaabigdata-code. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-landing', 'repo_url': 'https://github.com/18F/cg-landing', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-landing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'catalog-scheduler', 'repo_url': 'https://github.com/GSA/catalog-scheduler', 'errors': Exception(\"[ERROR] while getting issues for GSA/catalog-scheduler. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'catalog-pycsw', 'repo_url': 'https://github.com/GSA/catalog-pycsw', 'errors': Exception(\"[ERROR] while getting issues for GSA/catalog-pycsw. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'catalog-nginx', 'repo_url': 'https://github.com/GSA/catalog-nginx', 'errors': Exception(\"[ERROR] while getting issues for GSA/catalog-nginx. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-s3filestore', 'repo_url': 'https://github.com/GSA/ckanext-s3filestore', 'errors': Exception(\"[ERROR] while getting issues for GSA/ckanext-s3filestore. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ansible-https-proxy', 'repo_url': 'https://github.com/GSA/ansible-https-proxy', 'errors': Exception(\"[ERROR] while getting issues for GSA/ansible-https-proxy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'QueryToCSV', 'repo_url': 'https://github.com/GSA/QueryToCSV', 'errors': Exception(\"[ERROR] while getting issues for GSA/QueryToCSV. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'idea-box', 'repo_url': 'https://github.com/cfpb/idea-box', 'errors': Exception(\"[ERROR] while getting issues for cfpb/idea-box. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'regulations-parser', 'repo_url': 'https://github.com/cfpb/regulations-parser', 'errors': Exception(\"[ERROR] while getting issues for cfpb/regulations-parser. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-widgeter', 'repo_url': 'https://github.com/cfpb/django-widgeter', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-widgeter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-hud', 'repo_url': 'https://github.com/cfpb/django-hud', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-hud. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-buttons', 'repo_url': 'https://github.com/cfpb/cf-buttons', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-buttons. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'click-to-comment', 'repo_url': 'https://github.com/cfpb/click-to-comment', 'errors': Exception(\"[ERROR] while getting issues for cfpb/click-to-comment. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-tables', 'repo_url': 'https://github.com/cfpb/cf-tables', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-tables. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-tabs', 'repo_url': 'https://github.com/cfpb/cf-tabs', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-tabs. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fuzzy-state-search', 'repo_url': 'https://github.com/cfpb/fuzzy-state-search', 'errors': Exception(\"[ERROR] while getting issues for cfpb/fuzzy-state-search. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-explorer', 'repo_url': 'https://github.com/cfpb/hmda-explorer', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-explorer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'generator-cf', 'repo_url': 'https://github.com/cfpb/generator-cf', 'errors': Exception(\"[ERROR] while getting issues for cfpb/generator-cf. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'dotfiles', 'repo_url': 'https://github.com/cfpb/dotfiles', 'errors': Exception(\"[ERROR] while getting issues for cfpb/dotfiles. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-rule-spec', 'repo_url': 'https://github.com/cfpb/hmda-rule-spec', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-rule-spec. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-viz-prototype', 'repo_url': 'https://github.com/cfpb/hmda-viz-prototype', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-viz-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'grasshopper-ui', 'repo_url': 'https://github.com/cfpb/grasshopper-ui', 'errors': Exception(\"[ERROR] while getting issues for cfpb/grasshopper-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'regulations-bootstrap', 'repo_url': 'https://github.com/cfpb/regulations-bootstrap', 'errors': Exception(\"[ERROR] while getting issues for cfpb/regulations-bootstrap. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'node-wcag', 'repo_url': 'https://github.com/cfpb/node-wcag', 'errors': Exception(\"[ERROR] while getting issues for cfpb/node-wcag. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'grasshopper-retriever', 'repo_url': 'https://github.com/cfpb/grasshopper-retriever', 'errors': Exception(\"[ERROR] while getting issues for cfpb/grasshopper-retriever. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'generator-cf-component', 'repo_url': 'https://github.com/cfpb/generator-cf-component', 'errors': Exception(\"[ERROR] while getting issues for cfpb/generator-cf-component. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'rhobot', 'repo_url': 'https://github.com/cfpb/rhobot', 'errors': Exception(\"[ERROR] while getting issues for cfpb/rhobot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'zip-backfill', 'repo_url': 'https://github.com/cfpb/zip-backfill', 'errors': Exception(\"[ERROR] while getting issues for cfpb/zip-backfill. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'drake-el6-rpm', 'repo_url': 'https://github.com/cfpb/drake-el6-rpm', 'errors': Exception(\"[ERROR] while getting issues for cfpb/drake-el6-rpm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'test_hmda_pipeline', 'repo_url': 'https://github.com/cfpb/test_hmda_pipeline', 'errors': Exception(\"[ERROR] while getting issues for cfpb/test_hmda_pipeline. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hammerdb-el6-rpm', 'repo_url': 'https://github.com/cfpb/hammerdb-el6-rpm', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hammerdb-el6-rpm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'complaint', 'repo_url': 'https://github.com/cfpb/complaint', 'errors': Exception(\"[ERROR] while getting issues for cfpb/complaint. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open-source-checklist', 'repo_url': 'https://github.com/cfpb/open-source-checklist', 'errors': Exception(\"[ERROR] while getting issues for cfpb/open-source-checklist. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'capital-framework-sandbox', 'repo_url': 'https://github.com/cfpb/capital-framework-sandbox', 'errors': Exception(\"[ERROR] while getting issues for cfpb/capital-framework-sandbox. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'AtomicComponent', 'repo_url': 'https://github.com/cfpb/AtomicComponent', 'errors': Exception(\"[ERROR] while getting issues for cfpb/AtomicComponent. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfpb-chart-builder', 'repo_url': 'https://github.com/cfpb/cfpb-chart-builder', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfpb-chart-builder. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ansible-role-apache', 'repo_url': 'https://github.com/cfpb/ansible-role-apache', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ansible-role-apache. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ansible-role-java', 'repo_url': 'https://github.com/cfpb/ansible-role-java', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ansible-role-java. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'govdelivery', 'repo_url': 'https://github.com/cfpb/govdelivery', 'errors': Exception(\"[ERROR] while getting issues for cfpb/govdelivery. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'jenkins-sqs-plugin', 'repo_url': 'https://github.com/cfpb/jenkins-sqs-plugin', 'errors': Exception(\"[ERROR] while getting issues for cfpb/jenkins-sqs-plugin. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-satellite', 'repo_url': 'https://github.com/cfpb/cfgov-satellite', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-satellite. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'mesos-nr-infrastructure', 'repo_url': 'https://github.com/cfpb/mesos-nr-infrastructure', 'errors': Exception(\"[ERROR] while getting issues for cfpb/mesos-nr-infrastructure. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ED developer hub', 'repo_url': 'https://github.com/usedgov', 'error': 'Owner: usedgov or Repo name: None as missing'}, {'repo_name': 'GIBCT Data Service', 'repo_url': 'https://github.com/department-of-veterans-affairs/gibct-data-service', 'errors': Exception(\"[ERROR] while getting issues for department-of-veterans-affairs/gibct-data-service. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '39A', 'repo_url': 'https://github.com/nasa/39A', 'errors': Exception(\"[ERROR] while getting issues for nasa/39A. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Podaacpy', 'repo_url': 'https://github.com/nasa/podaacpy', 'errors': Exception(\"[ERROR] while getting issues for nasa/podaacpy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'NASA WorldWind Research: WorldWindExplorer', 'repo_url': 'https://github.com/NASAWorldWindResearch/WorldWindExplorer', 'errors': Exception(\"[ERROR] while getting issues for NASAWorldWindResearch/WorldWindExplorer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'NASA WorldWind Research: WorldWeather', 'repo_url': 'https://github.com/NASAWorldWindResearch/WorldWeather', 'errors': Exception(\"[ERROR] while getting issues for NASAWorldWindResearch/WorldWeather. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Sitepod', 'repo_url': 'https://github.com/nasa/sitepod/', 'error': 'Owner: sitepod or Repo name:  as missing'}, {'repo_name': 'Move Away Superfluous Clouds (MASC)', 'repo_url': 'https://github.com/NASA-DEVELOP/MASC', 'errors': Exception(\"[ERROR] while getting issues for NASA-DEVELOP/MASC. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Worldview Design', 'repo_url': 'https://github.com/nasa-gibs/worldview-design', 'errors': Exception(\"[ERROR] while getting issues for nasa-gibs/worldview-design. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'georef_deploy', 'repo_url': 'https://github.com/nasa/georef_deploy', 'errors': Exception(\"[ERROR] while getting issues for nasa/georef_deploy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CertWare Safety Case Workbench Software', 'repo_url': 'https://github.com/nasa/CertWare', 'errors': Exception(\"[ERROR] while getting issues for nasa/CertWare. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-terraform', 'repo_url': 'https://github.com/18F/identity-terraform', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-terraform. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sql_graphviz-docker', 'repo_url': 'https://github.com/18F/sql_graphviz-docker', 'errors': Exception(\"[ERROR] while getting issues for 18F/sql_graphviz-docker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '10X-Users-First', 'repo_url': 'https://github.com/18F/10X-Users-First', 'errors': Exception(\"[ERROR] while getting issues for 18F/10X-Users-First. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-buy-incident-response-saas', 'repo_url': 'https://github.com/18F/tts-buy-incident-response-saas', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-buy-incident-response-saas. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'navair-pa', 'repo_url': 'https://github.com/18F/navair-pa', 'errors': Exception(\"[ERROR] while getting issues for 18F/navair-pa. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'nginx-buildpack-release', 'repo_url': 'https://github.com/18F/nginx-buildpack-release', 'errors': Exception(\"[ERROR] while getting issues for 18F/nginx-buildpack-release. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'dtmo-jtr-prototype', 'repo_url': 'https://github.com/18F/dtmo-jtr-prototype', 'errors': Exception(\"[ERROR] while getting issues for 18F/dtmo-jtr-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Help', 'repo_url': 'git://github.com/USAJOBS/Help.git', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'analytics-reporter', 'repo_url': 'git://github.com/USAJOBS/analytics-reporter.git', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'design-system', 'repo_url': 'git://github.com/USAJOBS/design-system.git', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'HUBZone Map API', 'repo_url': 'https://github.com/USSBA/hubzone-api', 'errors': Exception(\"[ERROR] while getting issues for USSBA/hubzone-api. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'LetsEncrypt Certificate Renewal', 'repo_url': 'https://github.com/USSBA/sba-certificate-renewal', 'errors': Exception(\"[ERROR] while getting issues for USSBA/sba-certificate-renewal. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'qu', 'repo_url': 'https://github.com/cfpb/qu', 'errors': Exception(\"[ERROR] while getting issues for cfpb/qu. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-cache-tools', 'repo_url': 'https://github.com/cfpb/django-cache-tools', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-cache-tools. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'api', 'repo_url': 'https://github.com/cfpb/api', 'errors': Exception(\"[ERROR] while getting issues for cfpb/api. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'collab', 'repo_url': 'https://github.com/cfpb/collab', 'errors': Exception(\"[ERROR] while getting issues for cfpb/collab. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-typography', 'repo_url': 'https://github.com/cfpb/cf-typography', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-typography. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'capital-framework', 'repo_url': 'https://github.com/cfpb/capital-framework', 'errors': Exception(\"[ERROR] while getting issues for cfpb/capital-framework. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open-graph-control', 'repo_url': 'https://github.com/cfpb/open-graph-control', 'errors': Exception(\"[ERROR] while getting issues for cfpb/open-graph-control. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-demo', 'repo_url': 'https://github.com/cfpb/cf-demo', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-demo. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'loan-calc', 'repo_url': 'https://github.com/cfpb/loan-calc', 'errors': Exception(\"[ERROR] while getting issues for cfpb/loan-calc. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-refresh', 'repo_url': 'https://github.com/cfpb/cfgov-refresh', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-refresh. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfpb-wp-cli', 'repo_url': 'https://github.com/cfpb/cfpb-wp-cli', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfpb-wp-cli. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open-source-project-template', 'repo_url': 'https://github.com/cfpb/open-source-project-template', 'errors': Exception(\"[ERROR] while getting issues for cfpb/open-source-project-template. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'format-usd', 'repo_url': 'https://github.com/cfpb/format-usd', 'errors': Exception(\"[ERROR] while getting issues for cfpb/format-usd. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'unformat-usd', 'repo_url': 'https://github.com/cfpb/unformat-usd', 'errors': Exception(\"[ERROR] while getting issues for cfpb/unformat-usd. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'is-money-usd', 'repo_url': 'https://github.com/cfpb/is-money-usd', 'errors': Exception(\"[ERROR] while getting issues for cfpb/is-money-usd. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'shortstack', 'repo_url': 'https://github.com/cfpb/shortstack', 'errors': Exception(\"[ERROR] while getting issues for cfpb/shortstack. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'development', 'repo_url': 'https://github.com/cfpb/development', 'errors': Exception(\"[ERROR] while getting issues for cfpb/development. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'grasshopper-loader', 'repo_url': 'https://github.com/cfpb/grasshopper-loader', 'errors': Exception(\"[ERROR] while getting issues for cfpb/grasshopper-loader. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'aurora', 'repo_url': 'https://github.com/cfpb/aurora', 'errors': Exception(\"[ERROR] while getting issues for cfpb/aurora. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'regulations-stub', 'repo_url': 'https://github.com/cfpb/regulations-stub', 'errors': Exception(\"[ERROR] while getting issues for cfpb/regulations-stub. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'jenkins-automation', 'repo_url': 'https://github.com/cfpb/jenkins-automation', 'errors': Exception(\"[ERROR] while getting issues for cfpb/jenkins-automation. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'project-open-source', 'repo_url': 'https://github.com/cfpb/project-open-source', 'errors': Exception(\"[ERROR] while getting issues for cfpb/project-open-source. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'back-end', 'repo_url': 'https://github.com/cfpb/back-end', 'errors': Exception(\"[ERROR] while getting issues for cfpb/back-end. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'rural-or-underserved-test', 'repo_url': 'https://github.com/cfpb/rural-or-underserved-test', 'errors': Exception(\"[ERROR] while getting issues for cfpb/rural-or-underserved-test. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'college-costs', 'repo_url': 'https://github.com/cfpb/college-costs', 'errors': Exception(\"[ERROR] while getting issues for cfpb/college-costs. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'student-debt-calculator', 'repo_url': 'https://github.com/cfpb/student-debt-calculator', 'errors': Exception(\"[ERROR] while getting issues for cfpb/student-debt-calculator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'analytics-reporter', 'repo_url': 'https://github.com/cfpb/analytics-reporter', 'errors': Exception(\"[ERROR] while getting issues for cfpb/analytics-reporter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'imcs-el6-rpm', 'repo_url': 'https://github.com/cfpb/imcs-el6-rpm', 'errors': Exception(\"[ERROR] while getting issues for cfpb/imcs-el6-rpm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'auto-loans', 'repo_url': 'https://github.com/cfpb/auto-loans', 'errors': Exception(\"[ERROR] while getting issues for cfpb/auto-loans. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'regulations-xml', 'repo_url': 'https://github.com/cfpb/regulations-xml', 'errors': Exception(\"[ERROR] while getting issues for cfpb/regulations-xml. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pg_bulkload-el6-rpm', 'repo_url': 'https://github.com/cfpb/pg_bulkload-el6-rpm', 'errors': Exception(\"[ERROR] while getting issues for cfpb/pg_bulkload-el6-rpm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'postgis2-el6-rpm', 'repo_url': 'https://github.com/cfpb/postgis2-el6-rpm', 'errors': Exception(\"[ERROR] while getting issues for cfpb/postgis2-el6-rpm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pg_partman-el6-rpm', 'repo_url': 'https://github.com/cfpb/pg_partman-el6-rpm', 'errors': Exception(\"[ERROR] while getting issues for cfpb/pg_partman-el6-rpm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'intellij-idea-for-el6', 'repo_url': 'https://github.com/cfpb/intellij-idea-for-el6', 'errors': Exception(\"[ERROR] while getting issues for cfpb/intellij-idea-for-el6. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'mkDOCter', 'repo_url': 'https://github.com/cfpb/mkDOCter', 'errors': Exception(\"[ERROR] while getting issues for cfpb/mkDOCter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-django-setup', 'repo_url': 'https://github.com/cfpb/cfgov-django-setup', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-django-setup. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'prepaid-disclosure-files', 'repo_url': 'https://github.com/cfpb/prepaid-disclosure-files', 'errors': Exception(\"[ERROR] while getting issues for cfpb/prepaid-disclosure-files. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'consumer-credit-trends', 'repo_url': 'https://github.com/cfpb/consumer-credit-trends', 'errors': Exception(\"[ERROR] while getting issues for cfpb/consumer-credit-trends. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfpb-chart-builder-sandbox', 'repo_url': 'https://github.com/cfpb/cfpb-chart-builder-sandbox', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfpb-chart-builder-sandbox. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'marathon-cli', 'repo_url': 'https://github.com/cfpb/marathon-cli', 'errors': Exception(\"[ERROR] while getting issues for cfpb/marathon-cli. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'wagtail-sharing', 'repo_url': 'https://github.com/cfpb/wagtail-sharing', 'errors': Exception(\"[ERROR] while getting issues for cfpb/wagtail-sharing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'eregs-2.0', 'repo_url': 'https://github.com/cfpb/eregs-2.0', 'errors': Exception(\"[ERROR] while getting issues for cfpb/eregs-2.0. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'github-changelog', 'repo_url': 'https://github.com/cfpb/github-changelog', 'errors': Exception(\"[ERROR] while getting issues for cfpb/github-changelog. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'lambda-counselors', 'repo_url': 'https://github.com/cfpb/lambda-counselors', 'errors': Exception(\"[ERROR] while getting issues for cfpb/lambda-counselors. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'code-inventory-generator', 'repo_url': 'https://github.com/cfpb/code-inventory-generator', 'errors': Exception(\"[ERROR] while getting issues for cfpb/code-inventory-generator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-test-files', 'repo_url': 'https://github.com/cfpb/hmda-test-files', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-test-files. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'gitbook-plugin-theme-cfpb', 'repo_url': 'https://github.com/cfpb/gitbook-plugin-theme-cfpb', 'errors': Exception(\"[ERROR] while getting issues for cfpb/gitbook-plugin-theme-cfpb. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-crawler-app', 'repo_url': 'https://github.com/cfpb/cfgov-crawler-app', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-crawler-app. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'gleif_hmda', 'repo_url': 'https://github.com/cfpb/gleif_hmda', 'errors': Exception(\"[ERROR] while getting issues for cfpb/gleif_hmda. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-flags', 'repo_url': 'https://github.com/cfpb/django-flags', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-flags. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-jobmanager-example', 'repo_url': 'https://github.com/cfpb/cfgov-jobmanager-example', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-jobmanager-example. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'embedding-data-catalogs', 'repo_url': 'https://github.com/GSA/embedding-data-catalogs', 'errors': Exception(\"[ERROR] while getting issues for GSA/embedding-data-catalogs. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckan-php-manager', 'repo_url': 'https://github.com/GSA/ckan-php-manager', 'errors': Exception(\"[ERROR] while getting issues for GSA/ckan-php-manager. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-harvest', 'repo_url': 'https://github.com/GSA/ckanext-harvest', 'errors': Exception(\"[ERROR] while getting issues for GSA/ckanext-harvest. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'metric-count', 'repo_url': 'https://github.com/GSA/metric-count', 'errors': Exception(\"[ERROR] while getting issues for GSA/metric-count. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sticky-posts-in-category', 'repo_url': 'https://github.com/GSA/sticky-posts-in-category', 'errors': Exception(\"[ERROR] while getting issues for GSA/sticky-posts-in-category. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'FedCMS-Slider', 'repo_url': 'https://github.com/GSA/FedCMS-Slider', 'errors': Exception(\"[ERROR] while getting issues for GSA/FedCMS-Slider. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open.gsa.gov', 'repo_url': 'https://github.com/GSA/open.gsa.gov', 'errors': Exception(\"[ERROR] while getting issues for GSA/open.gsa.gov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-googleanalyticsbasic', 'repo_url': 'https://github.com/GSA/ckanext-googleanalyticsbasic', 'errors': Exception(\"[ERROR] while getting issues for GSA/ckanext-googleanalyticsbasic. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Crowdsource-Testing-ABMC.gov', 'repo_url': 'https://github.com/GSA/Crowdsource-Testing-ABMC.gov', 'errors': Exception(\"[ERROR] while getting issues for GSA/Crowdsource-Testing-ABMC.gov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Crowdsource-Testing-Central-Artifact-Repository', 'repo_url': 'https://github.com/GSA/Crowdsource-Testing-Central-Artifact-Repository', 'errors': Exception(\"[ERROR] while getting issues for GSA/Crowdsource-Testing-Central-Artifact-Repository. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'labs', 'repo_url': 'https://github.com/GSA/labs', 'errors': Exception(\"[ERROR] while getting issues for GSA/labs. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'data-json', 'repo_url': 'https://github.com/GSA/data-json', 'errors': Exception(\"[ERROR] while getting issues for GSA/data-json. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cmr-opensearch', 'repo_url': 'https://github.com/nasa/cmr-opensearch', 'errors': Exception(\"[ERROR] while getting issues for nasa/cmr-opensearch. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CF', 'repo_url': 'https://github.com/nasa/CF', 'errors': Exception(\"[ERROR] while getting issues for nasa/CF. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'structured_content_wordpress', 'repo_url': 'https://github.com/GSA/structured_content_wordpress', 'errors': Exception(\"[ERROR] while getting issues for GSA/structured_content_wordpress. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'GSA-Digital-Innovation', 'repo_url': 'https://github.com/GSA/GSA-Digital-Innovation', 'errors': Exception(\"[ERROR] while getting issues for GSA/GSA-Digital-Innovation. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'opensource-framework', 'repo_url': 'https://github.com/GSA/opensource-framework', 'errors': Exception(\"[ERROR] while getting issues for GSA/opensource-framework. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-datagovtheme', 'repo_url': 'https://github.com/GSA/ckanext-datagovtheme', 'errors': Exception(\"[ERROR] while getting issues for GSA/ckanext-datagovtheme. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'DigitalGov Search i14y Slate', 'repo_url': 'https://github.com/GSA/slate', 'errors': Exception(\"[ERROR] while getting issues for GSA/slate. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'vocab.data.gov', 'repo_url': 'https://github.com/GSA/vocab.data.gov', 'errors': Exception(\"[ERROR] while getting issues for GSA/vocab.data.gov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'DataCenterMashup', 'repo_url': 'https://github.com/GSA/DataCenterMashup', 'errors': Exception(\"[ERROR] while getting issues for GSA/DataCenterMashup. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'general-hackathon-administration', 'repo_url': 'https://github.com/GSA/general-hackathon-administration', 'errors': Exception(\"[ERROR] while getting issues for GSA/general-hackathon-administration. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-concourse', 'repo_url': 'https://github.com/GSA/cg-deploy-concourse', 'errors': Exception(\"[ERROR] while getting issues for GSA/cg-deploy-concourse. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'GSADigitalService', 'repo_url': 'https://github.com/GSA/GSADigitalService', 'errors': Exception(\"[ERROR] while getting issues for GSA/GSADigitalService. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'resque-priority', 'repo_url': 'https://github.com/GSA/resque-priority', 'errors': Exception(\"[ERROR] while getting issues for GSA/resque-priority. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open311-simple-crm', 'repo_url': 'https://github.com/GSA/open311-simple-crm', 'errors': Exception(\"[ERROR] while getting issues for GSA/open311-simple-crm. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'oauth2-provider', 'repo_url': 'https://github.com/GSA/oauth2-provider', 'errors': Exception(\"[ERROR] while getting issues for GSA/oauth2-provider. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'mygov-discovery', 'repo_url': 'https://github.com/GSA/mygov-discovery', 'errors': Exception(\"[ERROR] while getting issues for GSA/mygov-discovery. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CAP-Documentation', 'repo_url': 'https://github.com/GSA/CAP-Documentation', 'errors': Exception(\"[ERROR] while getting issues for GSA/CAP-Documentation. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'jekyll-centos-deploy', 'repo_url': 'https://github.com/GSA/jekyll-centos-deploy', 'errors': Exception(\"[ERROR] while getting issues for GSA/jekyll-centos-deploy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'mysql_to_cloudwatch', 'repo_url': 'https://github.com/GSA/mysql_to_cloudwatch', 'errors': Exception(\"[ERROR] while getting issues for GSA/mysql_to_cloudwatch. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hi', 'repo_url': 'https://github.com/GSA/hi', 'errors': Exception(\"[ERROR] while getting issues for GSA/hi. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'AAS_root', 'repo_url': 'https://github.com/GSA/AAS_root', 'errors': Exception(\"[ERROR] while getting issues for GSA/AAS_root. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open.usa.gov', 'repo_url': 'https://github.com/GSA/open.usa.gov', 'errors': Exception(\"[ERROR] while getting issues for GSA/open.usa.gov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ansible-microstrategy', 'repo_url': 'https://github.com/GSA/ansible-microstrategy', 'errors': Exception(\"[ERROR] while getting issues for GSA/ansible-microstrategy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'OMB-Max-Auth-for-Salesforce', 'repo_url': 'https://github.com/GSA/OMB-Max-Auth-for-Salesforce', 'errors': Exception(\"[ERROR] while getting issues for GSA/OMB-Max-Auth-for-Salesforce. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ficam-scvp-testing', 'repo_url': 'https://github.com/GSA/ficam-scvp-testing', 'errors': Exception(\"[ERROR] while getting issues for GSA/ficam-scvp-testing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'matter-maker', 'repo_url': 'https://github.com/GSA/matter-maker', 'errors': Exception(\"[ERROR] while getting issues for GSA/matter-maker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'training-pathway-data-practitioner', 'repo_url': 'https://github.com/GSA/training-pathway-data-practitioner', 'errors': Exception(\"[ERROR] while getting issues for GSA/training-pathway-data-practitioner. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CorpIT-GSAResp', 'repo_url': 'https://github.com/GSA/CorpIT-GSAResp', 'errors': Exception(\"[ERROR] while getting issues for GSA/CorpIT-GSAResp. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-infrastructure-live', 'repo_url': 'https://github.com/GSA/datagov-infrastructure-live', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-infrastructure-live. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'usagov-hub', 'repo_url': 'https://github.com/GSA/usagov-hub', 'errors': Exception(\"[ERROR] while getting issues for GSA/usagov-hub. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'DevSecOps-Mgmt-Tools-Deploy', 'repo_url': 'https://github.com/GSA/DevSecOps-Mgmt-Tools-Deploy', 'errors': Exception(\"[ERROR] while getting issues for GSA/DevSecOps-Mgmt-Tools-Deploy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'governmentwide-classifications', 'repo_url': 'https://github.com/GSA/governmentwide-classifications', 'errors': Exception(\"[ERROR] while getting issues for GSA/governmentwide-classifications. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'formk8s', 'repo_url': 'https://github.com/GSA/formk8s', 'errors': Exception(\"[ERROR] while getting issues for GSA/formk8s. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'christopher', 'repo_url': 'https://github.com/GSA/christopher', 'errors': Exception(\"[ERROR] while getting issues for GSA/christopher. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-deploy-ckan-common', 'repo_url': 'https://github.com/GSA/datagov-deploy-ckan-common', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-deploy-ckan-common. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-deploy-nginx', 'repo_url': 'https://github.com/GSA/datagov-deploy-nginx', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-deploy-nginx. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-deploy-elasticsearch', 'repo_url': 'https://github.com/GSA/datagov-deploy-elasticsearch', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-deploy-elasticsearch. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pycel', 'repo_url': 'https://github.com/18F/pycel', 'errors': Exception(\"[ERROR] while getting issues for 18F/pycel. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'influxdb-monitor', 'repo_url': 'https://github.com/18F/influxdb-monitor', 'errors': Exception(\"[ERROR] while getting issues for 18F/influxdb-monitor. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-logstash-output-s3-backport-release', 'repo_url': 'https://github.com/18F/cg-logstash-output-s3-backport-release', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-logstash-output-s3-backport-release. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Shibboleth-IdP3-TOTP-Auth', 'repo_url': 'https://github.com/18F/Shibboleth-IdP3-TOTP-Auth', 'errors': Exception(\"[ERROR] while getting issues for 18F/Shibboleth-IdP3-TOTP-Auth. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'node-continua11y-sitemapper', 'repo_url': 'https://github.com/18F/node-continua11y-sitemapper', 'errors': Exception(\"[ERROR] while getting issues for 18F/node-continua11y-sitemapper. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'accessibility-practice-site', 'repo_url': 'https://github.com/18F/accessibility-practice-site', 'errors': Exception(\"[ERROR] while getting issues for 18F/accessibility-practice-site. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'micropurchase-auctions', 'repo_url': 'https://github.com/18F/micropurchase-auctions', 'errors': Exception(\"[ERROR] while getting issues for 18F/micropurchase-auctions. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'e-QIP-prototype', 'repo_url': 'https://github.com/18F/e-QIP-prototype', 'errors': Exception(\"[ERROR] while getting issues for 18F/e-QIP-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'generator-uswds', 'repo_url': 'https://github.com/18F/generator-uswds', 'errors': Exception(\"[ERROR] while getting issues for 18F/generator-uswds. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'calc-analysis', 'repo_url': 'https://github.com/18F/calc-analysis', 'errors': Exception(\"[ERROR] while getting issues for 18F/calc-analysis. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'skills_share', 'repo_url': 'https://github.com/18F/skills_share', 'errors': Exception(\"[ERROR] while getting issues for 18F/skills_share. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ops-improvements', 'repo_url': 'https://github.com/18F/ops-improvements', 'errors': Exception(\"[ERROR] while getting issues for 18F/ops-improvements. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'visual-design', 'repo_url': 'https://github.com/18F/visual-design', 'errors': Exception(\"[ERROR] while getting issues for 18F/visual-design. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'bpa-fs-epermit-api', 'repo_url': 'https://github.com/18F/bpa-fs-epermit-api', 'errors': Exception(\"[ERROR] while getting issues for 18F/bpa-fs-epermit-api. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-rds-broker', 'repo_url': 'https://github.com/18F/cg-deploy-rds-broker', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-rds-broker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-oidc-ios', 'repo_url': 'https://github.com/18F/identity-oidc-ios', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-oidc-ios. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'deploy-ttslicenses', 'repo_url': 'https://github.com/18F/deploy-ttslicenses', 'errors': Exception(\"[ERROR] while getting issues for 18F/deploy-ttslicenses. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-homepage', 'repo_url': 'https://github.com/18F/tts-homepage', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-homepage. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'unified-analytics-dashboard', 'repo_url': 'https://github.com/18F/unified-analytics-dashboard', 'errors': Exception(\"[ERROR] while getting issues for 18F/unified-analytics-dashboard. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'bpa-disaster-data-portal-pilot', 'repo_url': 'https://github.com/18F/bpa-disaster-data-portal-pilot', 'errors': Exception(\"[ERROR] while getting issues for 18F/bpa-disaster-data-portal-pilot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'acq-mo-medicaid-prototype-realtime-view', 'repo_url': 'https://github.com/18F/acq-mo-medicaid-prototype-realtime-view', 'errors': Exception(\"[ERROR] while getting issues for 18F/acq-mo-medicaid-prototype-realtime-view. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-dockerized-buildpack', 'repo_url': 'https://github.com/18F/cf-dockerized-buildpack', 'errors': Exception(\"[ERROR] while getting issues for 18F/cf-dockerized-buildpack. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pages-redirects', 'repo_url': 'https://github.com/18F/pages-redirects', 'errors': Exception(\"[ERROR] while getting issues for 18F/pages-redirects. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'better-government', 'repo_url': 'https://github.com/18F/better-government', 'errors': Exception(\"[ERROR] while getting issues for 18F/better-government. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hud-disaster-data', 'repo_url': 'https://github.com/18F/hud-disaster-data', 'errors': Exception(\"[ERROR] while getting issues for 18F/hud-disaster-data. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'html-proofer', 'repo_url': 'https://github.com/18F/html-proofer', 'errors': Exception(\"[ERROR] while getting issues for 18F/html-proofer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hhs-acf-uc-dashboard', 'repo_url': 'https://github.com/18F/hhs-acf-uc-dashboard', 'errors': Exception(\"[ERROR] while getting issues for 18F/hhs-acf-uc-dashboard. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-saml-java', 'repo_url': 'https://github.com/18F/identity-saml-java', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-saml-java. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'markov_bot', 'repo_url': 'https://github.com/18F/markov_bot', 'errors': Exception(\"[ERROR] while getting issues for 18F/markov_bot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'riemann-firehose-nozzle', 'repo_url': 'https://github.com/18F/riemann-firehose-nozzle', 'errors': Exception(\"[ERROR] while getting issues for 18F/riemann-firehose-nozzle. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-riemann-firehose-nozzle', 'repo_url': 'https://github.com/18F/cg-deploy-riemann-firehose-nozzle', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-riemann-firehose-nozzle. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'felt-recipe-18F', 'repo_url': 'https://github.com/18F/felt-recipe-18F', 'errors': Exception(\"[ERROR] while getting issues for 18F/felt-recipe-18F. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'DCOI-recommendations', 'repo_url': 'https://github.com/18F/DCOI-recommendations', 'errors': Exception(\"[ERROR] while getting issues for 18F/DCOI-recommendations. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'workshops-lab', 'repo_url': 'https://github.com/18F/workshops-lab', 'errors': Exception(\"[ERROR] while getting issues for 18F/workshops-lab. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'forest-service-prototype', 'repo_url': 'https://github.com/18F/forest-service-prototype', 'errors': Exception(\"[ERROR] while getting issues for 18F/forest-service-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'dol-whd-14c', 'repo_url': 'https://github.com/18F/dol-whd-14c', 'errors': Exception(\"[ERROR] while getting issues for 18F/dol-whd-14c. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'devise-encryptable', 'repo_url': 'https://github.com/18F/devise-encryptable', 'errors': Exception(\"[ERROR] while getting issues for 18F/devise-encryptable. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ffd-info-exchange', 'repo_url': 'https://github.com/18F/ffd-info-exchange', 'errors': Exception(\"[ERROR] while getting issues for 18F/ffd-info-exchange. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'politespace', 'repo_url': 'https://github.com/18F/politespace', 'errors': Exception(\"[ERROR] while getting issues for 18F/politespace. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-analytics-etl', 'repo_url': 'https://github.com/18F/identity-analytics-etl', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-analytics-etl. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'acq-presentations', 'repo_url': 'https://github.com/18F/acq-presentations', 'errors': Exception(\"[ERROR] while getting issues for 18F/acq-presentations. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'swid-prototype', 'repo_url': 'https://github.com/18F/swid-prototype', 'errors': Exception(\"[ERROR] while getting issues for 18F/swid-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'FFD_landuse', 'repo_url': 'https://github.com/18F/FFD_landuse', 'errors': Exception(\"[ERROR] while getting issues for 18F/FFD_landuse. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '800-63-3', 'repo_url': 'https://github.com/18F/800-63-3', 'errors': Exception(\"[ERROR] while getting issues for 18F/800-63-3. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'kubernetes-broker-exporter', 'repo_url': 'https://github.com/18F/kubernetes-broker-exporter', 'errors': Exception(\"[ERROR] while getting issues for 18F/kubernetes-broker-exporter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'citadel-build', 'repo_url': 'https://github.com/18F/citadel-build', 'errors': Exception(\"[ERROR] while getting issues for 18F/citadel-build. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-buy-code-review', 'repo_url': 'https://github.com/18F/tts-buy-code-review', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-buy-code-review. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-oidc-java-spring-boot', 'repo_url': 'https://github.com/18F/identity-oidc-java-spring-boot', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-oidc-java-spring-boot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-oidc-java-spring-security', 'repo_url': 'https://github.com/18F/identity-oidc-java-spring-security', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-oidc-java-spring-security. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-oidc-python-django', 'repo_url': 'https://github.com/18F/identity-oidc-python-django', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-oidc-python-django. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-hostdata', 'repo_url': 'https://github.com/18F/identity-hostdata', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-hostdata. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'oauth2-proxy-boshrelease', 'repo_url': 'https://github.com/18F/oauth2-proxy-boshrelease', 'errors': Exception(\"[ERROR] while getting issues for 18F/oauth2-proxy-boshrelease. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagen', 'repo_url': 'https://github.com/18F/datagen', 'errors': Exception(\"[ERROR] while getting issues for 18F/datagen. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-buy-datagov-technical-support-services', 'repo_url': 'https://github.com/18F/tts-buy-datagov-technical-support-services', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-buy-datagov-technical-support-services. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-buy-crowdsourced-pentest', 'repo_url': 'https://github.com/18F/tts-buy-crowdsourced-pentest', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-buy-crowdsourced-pentest. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tsp-uswds', 'repo_url': 'https://github.com/18F/tsp-uswds', 'errors': Exception(\"[ERROR] while getting issues for 18F/tsp-uswds. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-buy-identity-proofing', 'repo_url': 'https://github.com/18F/tts-buy-identity-proofing', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-buy-identity-proofing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'omb-pdf', 'repo_url': 'https://github.com/18F/omb-pdf', 'errors': Exception(\"[ERROR] while getting issues for 18F/omb-pdf. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hubot-scripts-us-federal-holidays-reminder', 'repo_url': 'https://github.com/18F/hubot-scripts-us-federal-holidays-reminder', 'errors': Exception(\"[ERROR] while getting issues for 18F/hubot-scripts-us-federal-holidays-reminder. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-atlas', 'repo_url': 'https://github.com/18F/cg-atlas', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-atlas. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-idv', 'repo_url': 'https://github.com/18F/identity-idv', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-idv. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'legalese', 'repo_url': 'https://github.com/18F/legalese', 'errors': Exception(\"[ERROR] while getting issues for 18F/legalese. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-saml-sinatra', 'repo_url': 'https://github.com/18F/identity-saml-sinatra', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-saml-sinatra. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'e-manifest-spring', 'repo_url': 'https://github.com/18F/e-manifest-spring', 'errors': Exception(\"[ERROR] while getting issues for 18F/e-manifest-spring. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-cdn-service-broker', 'repo_url': 'https://github.com/18F/cf-cdn-service-broker', 'errors': Exception(\"[ERROR] while getting issues for 18F/cf-cdn-service-broker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pa11y-lambda', 'repo_url': 'https://github.com/18F/pa11y-lambda', 'errors': Exception(\"[ERROR] while getting issues for 18F/pa11y-lambda. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-awslogs-boshrelease', 'repo_url': 'https://github.com/18F/cg-awslogs-boshrelease', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-awslogs-boshrelease. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'acqstackdb', 'repo_url': 'https://github.com/18F/acqstackdb', 'errors': Exception(\"[ERROR] while getting issues for 18F/acqstackdb. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'request-circuit', 'repo_url': 'https://github.com/18F/request-circuit', 'errors': Exception(\"[ERROR] while getting issues for 18F/request-circuit. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'identity-saml-rails', 'repo_url': 'https://github.com/18F/identity-saml-rails', 'errors': Exception(\"[ERROR] while getting issues for 18F/identity-saml-rails. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-nessus-manager', 'repo_url': 'https://github.com/18F/cg-deploy-nessus-manager', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-nessus-manager. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-snort-boshrelease', 'repo_url': 'https://github.com/18F/cg-snort-boshrelease', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-snort-boshrelease. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'bpa-DOL-WHD-14-c', 'repo_url': 'https://github.com/18F/bpa-DOL-WHD-14-c', 'errors': Exception(\"[ERROR] while getting issues for 18F/bpa-DOL-WHD-14-c. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'react-redux-event-demo', 'repo_url': 'https://github.com/18F/react-redux-event-demo', 'errors': Exception(\"[ERROR] while getting issues for 18F/react-redux-event-demo. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'GSA-SaaS-Payroll-RFQ-BPA', 'repo_url': 'https://github.com/18F/GSA-SaaS-Payroll-RFQ-BPA', 'errors': Exception(\"[ERROR] while getting issues for 18F/GSA-SaaS-Payroll-RFQ-BPA. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'omb-eregs-static-prototypes', 'repo_url': 'https://github.com/18F/omb-eregs-static-prototypes', 'errors': Exception(\"[ERROR] while getting issues for 18F/omb-eregs-static-prototypes. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'tts-buy-IaaS-2018', 'repo_url': 'https://github.com/18F/tts-buy-IaaS-2018', 'errors': Exception(\"[ERROR] while getting issues for 18F/tts-buy-IaaS-2018. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-report-federalist-s3', 'repo_url': 'https://github.com/18F/cg-report-federalist-s3', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-report-federalist-s3. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'openFEC', 'repo_url': 'https://github.com/18F/openFEC', 'errors': Exception(\"[ERROR] while getting issues for 18F/openFEC. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pubmed-prototypes', 'repo_url': 'https://github.com/18F/pubmed-prototypes', 'errors': Exception(\"[ERROR] while getting issues for 18F/pubmed-prototypes. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'spelunker', 'repo_url': 'https://github.com/18F/spelunker', 'errors': Exception(\"[ERROR] while getting issues for 18F/spelunker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'chef-filebeat', 'repo_url': 'https://github.com/18F/chef-filebeat', 'errors': Exception(\"[ERROR] while getting issues for 18F/chef-filebeat. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'IT Accessibility Playbook', 'repo_url': 'https://github.com/GSA/it-accessibility-playbook', 'errors': Exception(\"[ERROR] while getting issues for GSA/it-accessibility-playbook. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fedramp', 'repo_url': 'https://github.com/GSA/fedramp', 'errors': Exception(\"[ERROR] while getting issues for GSA/fedramp. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'third-party-services', 'repo_url': 'https://github.com/GSA/third-party-services', 'errors': Exception(\"[ERROR] while getting issues for GSA/third-party-services. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'datagov-infrastructure', 'repo_url': 'https://github.com/GSA/datagov-infrastructure', 'errors': Exception(\"[ERROR] while getting issues for GSA/datagov-infrastructure. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Project-360', 'repo_url': 'https://github.com/GSA/Project-360', 'errors': Exception(\"[ERROR] while getting issues for GSA/Project-360. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'micropurchase-deck', 'repo_url': 'https://github.com/18F/micropurchase-deck', 'errors': Exception(\"[ERROR] while getting issues for 18F/micropurchase-deck. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fedramp-data', 'repo_url': 'https://github.com/18F/fedramp-data', 'errors': Exception(\"[ERROR] while getting issues for 18F/fedramp-data. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'compliance-docs', 'repo_url': 'https://github.com/18F/compliance-docs', 'errors': Exception(\"[ERROR] while getting issues for 18F/compliance-docs. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'internal-air-traffic-control', 'repo_url': 'https://github.com/18F/internal-air-traffic-control', 'errors': Exception(\"[ERROR] while getting issues for 18F/internal-air-traffic-control. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'passport-google-oauth2', 'repo_url': 'https://github.com/18F/passport-google-oauth2', 'errors': Exception(\"[ERROR] while getting issues for 18F/passport-google-oauth2. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fpki-testing', 'repo_url': 'https://github.com/18F/fpki-testing', 'errors': Exception(\"[ERROR] while getting issues for 18F/fpki-testing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'epa-notice', 'repo_url': 'https://github.com/18F/epa-notice', 'errors': Exception(\"[ERROR] while getting issues for 18F/epa-notice. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'huginn', 'repo_url': 'https://github.com/18F/huginn', 'errors': Exception(\"[ERROR] while getting issues for 18F/huginn. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'us-federal-holidays', 'repo_url': 'https://github.com/18F/us-federal-holidays', 'errors': Exception(\"[ERROR] while getting issues for 18F/us-federal-holidays. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'onena', 'repo_url': 'https://github.com/18F/onena', 'errors': Exception(\"[ERROR] while getting issues for 18F/onena. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'influxdb-firehose-nozzle-release', 'repo_url': 'https://github.com/18F/influxdb-firehose-nozzle-release', 'errors': Exception(\"[ERROR] while getting issues for 18F/influxdb-firehose-nozzle-release. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pages-shell', 'repo_url': 'https://github.com/18F/pages-shell', 'errors': Exception(\"[ERROR] while getting issues for 18F/pages-shell. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pulse-accessibility-data', 'repo_url': 'https://github.com/18F/pulse-accessibility-data', 'errors': Exception(\"[ERROR] while getting issues for 18F/pulse-accessibility-data. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-deploy-influxdb-firehose-nozzle', 'repo_url': 'https://github.com/18F/cg-deploy-influxdb-firehose-nozzle', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-deploy-influxdb-firehose-nozzle. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'htsql-docker', 'repo_url': 'https://github.com/18F/htsql-docker', 'errors': Exception(\"[ERROR] while getting issues for 18F/htsql-docker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '14c-prototype', 'repo_url': 'https://github.com/18F/14c-prototype', 'errors': Exception(\"[ERROR] while getting issues for 18F/14c-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ogp-payroll-server', 'repo_url': 'https://github.com/18F/ogp-payroll-server', 'errors': Exception(\"[ERROR] while getting issues for 18F/ogp-payroll-server. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-product', 'repo_url': 'https://github.com/18F/cg-product', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-product. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pa11y-docker', 'repo_url': 'https://github.com/18F/pa11y-docker', 'errors': Exception(\"[ERROR] while getting issues for 18F/pa11y-docker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'Mario', 'repo_url': 'https://github.com/18F/Mario', 'errors': Exception(\"[ERROR] while getting issues for 18F/Mario. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'codetalker', 'repo_url': 'https://github.com/18F/codetalker', 'errors': Exception(\"[ERROR] while getting issues for 18F/codetalker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '2015-foia-hub', 'repo_url': 'https://github.com/18F/2015-foia-hub', 'errors': Exception(\"[ERROR] while getting issues for 18F/2015-foia-hub. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'https', 'repo_url': 'https://github.com/18F/https', 'errors': Exception(\"[ERROR] while getting issues for 18F/https. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': '18f-bot', 'repo_url': 'https://github.com/18F/18f-bot', 'errors': Exception(\"[ERROR] while getting issues for 18F/18f-bot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'inclusive-design-guide', 'repo_url': 'https://github.com/18F/inclusive-design-guide', 'errors': Exception(\"[ERROR] while getting issues for 18F/inclusive-design-guide. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'bulk-storage', 'repo_url': 'https://github.com/18F/bulk-storage', 'errors': Exception(\"[ERROR] while getting issues for 18F/bulk-storage. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sendak-usage', 'repo_url': 'https://github.com/18F/sendak-usage', 'errors': Exception(\"[ERROR] while getting issues for 18F/sendak-usage. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'analytics-reporter', 'repo_url': 'https://github.com/18F/analytics-reporter', 'errors': Exception(\"[ERROR] while getting issues for 18F/analytics-reporter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hourofcode', 'repo_url': 'https://github.com/18F/hourofcode', 'errors': Exception(\"[ERROR] while getting issues for 18F/hourofcode. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'data-validator', 'repo_url': 'https://github.com/18F/data-validator', 'errors': Exception(\"[ERROR] while getting issues for 18F/data-validator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sails-postgresql', 'repo_url': 'https://github.com/18F/sails-postgresql', 'errors': Exception(\"[ERROR] while getting issues for 18F/sails-postgresql. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'usps-api-notes', 'repo_url': 'https://github.com/18F/usps-api-notes', 'errors': Exception(\"[ERROR] while getting issues for 18F/usps-api-notes. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-elasticache', 'repo_url': 'https://github.com/18F/django-elasticache', 'errors': Exception(\"[ERROR] while getting issues for 18F/django-elasticache. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'docker-fugacious', 'repo_url': 'https://github.com/18F/docker-fugacious', 'errors': Exception(\"[ERROR] while getting issues for 18F/docker-fugacious. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sbirez-prototype', 'repo_url': 'https://github.com/18F/sbirez-prototype', 'errors': Exception(\"[ERROR] while getting issues for 18F/sbirez-prototype. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'gitter', 'repo_url': 'https://github.com/18F/gitter', 'errors': Exception(\"[ERROR] while getting issues for 18F/gitter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cg-quotas-db', 'repo_url': 'https://github.com/18F/cg-quotas-db', 'errors': Exception(\"[ERROR] while getting issues for 18F/cg-quotas-db. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'open-data-maker', 'repo_url': 'https://github.com/18F/open-data-maker', 'errors': Exception(\"[ERROR] while getting issues for 18F/open-data-maker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'iaa-forms', 'repo_url': 'https://github.com/18F/iaa-forms', 'errors': Exception(\"[ERROR] while getting issues for 18F/iaa-forms. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'gittem-view', 'repo_url': 'https://github.com/18F/gittem-view', 'errors': Exception(\"[ERROR] while getting issues for 18F/gittem-view. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CMS.gov-developer', 'repo_url': 'https://github.com/18F/CMS.gov-developer', 'errors': Exception(\"[ERROR] while getting issues for 18F/CMS.gov-developer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fec-style', 'repo_url': 'https://github.com/18F/fec-style', 'errors': Exception(\"[ERROR] while getting issues for 18F/fec-style. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pa11y-scan', 'repo_url': 'https://github.com/18F/pa11y-scan', 'errors': Exception(\"[ERROR] while getting issues for 18F/pa11y-scan. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'css-linter', 'repo_url': 'https://github.com/18F/css-linter', 'errors': Exception(\"[ERROR] while getting issues for 18F/css-linter. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'usps', 'repo_url': 'https://github.com/18F/usps', 'errors': Exception(\"[ERROR] while getting issues for 18F/usps. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-service-proxy', 'repo_url': 'https://github.com/18F/cf-service-proxy', 'errors': Exception(\"[ERROR] while getting issues for 18F/cf-service-proxy. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'letgirlslearn', 'repo_url': 'https://github.com/18F/letgirlslearn', 'errors': Exception(\"[ERROR] while getting issues for 18F/letgirlslearn. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'feedback-widget', 'repo_url': 'https://github.com/18F/feedback-widget', 'errors': Exception(\"[ERROR] while getting issues for 18F/feedback-widget. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'labor-viz', 'repo_url': 'https://github.com/18F/labor-viz', 'errors': Exception(\"[ERROR] while getting issues for 18F/labor-viz. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmac_authentication_py', 'repo_url': 'https://github.com/18F/hmac_authentication_py', 'errors': Exception(\"[ERROR] while getting issues for 18F/hmac_authentication_py. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'federalist-garden-build', 'repo_url': 'https://github.com/18F/federalist-garden-build', 'errors': Exception(\"[ERROR] while getting issues for 18F/federalist-garden-build. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'code-style-guide', 'repo_url': 'https://github.com/18F/code-style-guide', 'errors': Exception(\"[ERROR] while getting issues for 18F/code-style-guide. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'web-design-standards-drupal', 'repo_url': 'https://github.com/18F/web-design-standards-drupal', 'errors': Exception(\"[ERROR] while getting issues for 18F/web-design-standards-drupal. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'wg-api', 'repo_url': 'https://github.com/18F/wg-api', 'errors': Exception(\"[ERROR] while getting issues for 18F/wg-api. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'compliance-toolkit', 'repo_url': 'https://github.com/18F/compliance-toolkit', 'errors': Exception(\"[ERROR] while getting issues for 18F/compliance-toolkit. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'FM-WebBill', 'repo_url': 'https://github.com/GSA/FM-WebBill', 'errors': Exception(\"[ERROR] while getting issues for GSA/FM-WebBill. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'data-strategy-classification', 'repo_url': 'https://github.com/GSA/data-strategy-classification', 'errors': Exception(\"[ERROR] while getting issues for GSA/data-strategy-classification. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fbopen', 'repo_url': 'https://github.com/18F/fbopen', 'errors': Exception(\"[ERROR] while getting issues for 18F/fbopen. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'collab-news', 'repo_url': 'https://github.com/cfpb/collab-news', 'errors': Exception(\"[ERROR] while getting issues for cfpb/collab-news. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cms-toolkit', 'repo_url': 'https://github.com/cfpb/cms-toolkit', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cms-toolkit. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'decision-stacker', 'repo_url': 'https://github.com/cfpb/decision-stacker', 'errors': Exception(\"[ERROR] while getting issues for cfpb/decision-stacker. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sifu', 'repo_url': 'https://github.com/cfpb/sifu', 'errors': Exception(\"[ERROR] while getting issues for cfpb/sifu. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'python27-for-el6', 'repo_url': 'https://github.com/cfpb/python27-for-el6', 'errors': Exception(\"[ERROR] while getting issues for cfpb/python27-for-el6. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'fr-notices', 'repo_url': 'https://github.com/cfpb/fr-notices', 'errors': Exception(\"[ERROR] while getting issues for cfpb/fr-notices. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'unitybox', 'repo_url': 'https://github.com/cfpb/unitybox', 'errors': Exception(\"[ERROR] while getting issues for cfpb/unitybox. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-django', 'repo_url': 'https://github.com/cfpb/cfgov-django', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-django. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-explorer-updater', 'repo_url': 'https://github.com/cfpb/hmda-explorer-updater', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-explorer-updater. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-platform', 'repo_url': 'https://github.com/cfpb/hmda-platform', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-platform. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'data-viz-workshop', 'repo_url': 'https://github.com/cfpb/data-viz-workshop', 'errors': Exception(\"[ERROR] while getting issues for cfpb/data-viz-workshop. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hubot-new-relic-alerts', 'repo_url': 'https://github.com/cfpb/hubot-new-relic-alerts', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hubot-new-relic-alerts. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'jenkins-shared-libraries', 'repo_url': 'https://github.com/cfpb/jenkins-shared-libraries', 'errors': Exception(\"[ERROR] while getting issues for cfpb/jenkins-shared-libraries. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'site-index', 'repo_url': 'https://github.com/cfpb/site-index', 'errors': Exception(\"[ERROR] while getting issues for cfpb/site-index. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'credit-card-agreements-ui', 'repo_url': 'https://github.com/cfpb/credit-card-agreements-ui', 'errors': Exception(\"[ERROR] while getting issues for cfpb/credit-card-agreements-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'platformOps-EC', 'repo_url': 'https://github.com/cfpb/platformOps-EC', 'errors': Exception(\"[ERROR] while getting issues for cfpb/platformOps-EC. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'salesforce_file_upload', 'repo_url': 'https://github.com/cfpb/salesforce_file_upload', 'errors': Exception(\"[ERROR] while getting issues for cfpb/salesforce_file_upload. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CommerceGov.github.io', 'repo_url': 'git://github.com/CommerceGov/CommerceGov.github.io.git', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'django-api-test', 'repo_url': 'https://github.com/cfpb/django-api-test', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-api-test. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-rest-framework-selectserializer', 'repo_url': 'https://github.com/cfpb/django-rest-framework-selectserializer', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-rest-framework-selectserializer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pantheon', 'repo_url': 'https://github.com/cfpb/pantheon', 'errors': Exception(\"[ERROR] while getting issues for cfpb/pantheon. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sentia', 'repo_url': 'https://github.com/cfpb/sentia', 'errors': Exception(\"[ERROR] while getting issues for cfpb/sentia. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'flask-eventics', 'repo_url': 'https://github.com/cfpb/flask-eventics', 'errors': Exception(\"[ERROR] while getting issues for cfpb/flask-eventics. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pantheon-helpers', 'repo_url': 'https://github.com/cfpb/pantheon-helpers', 'errors': Exception(\"[ERROR] while getting issues for cfpb/pantheon-helpers. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'sentia-softwarediscovery', 'repo_url': 'https://github.com/cfpb/sentia-softwarediscovery', 'errors': Exception(\"[ERROR] while getting issues for cfpb/sentia-softwarediscovery. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'payment-calculator', 'repo_url': 'https://github.com/cfpb/payment-calculator', 'errors': Exception(\"[ERROR] while getting issues for cfpb/payment-calculator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'django-assets', 'repo_url': 'https://github.com/cfpb/django-assets', 'errors': Exception(\"[ERROR] while getting issues for cfpb/django-assets. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'github-wiki-search', 'repo_url': 'https://github.com/cfpb/github-wiki-search', 'errors': Exception(\"[ERROR] while getting issues for cfpb/github-wiki-search. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-pilot', 'repo_url': 'https://github.com/cfpb/hmda-pilot', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-pilot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'node-wcag-cli', 'repo_url': 'https://github.com/cfpb/node-wcag-cli', 'errors': Exception(\"[ERROR] while getting issues for cfpb/node-wcag-cli. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'kratos-gh', 'repo_url': 'https://github.com/cfpb/kratos-gh', 'errors': Exception(\"[ERROR] while getting issues for cfpb/kratos-gh. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'readme_refresh_day', 'repo_url': 'https://github.com/cfpb/readme_refresh_day', 'errors': Exception(\"[ERROR] while getting issues for cfpb/readme_refresh_day. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hubot-acrogov', 'repo_url': 'https://github.com/cfpb/hubot-acrogov', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hubot-acrogov. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'read2me', 'repo_url': 'https://github.com/cfpb/read2me', 'errors': Exception(\"[ERROR] while getting issues for cfpb/read2me. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'rhobot-for-el6', 'repo_url': 'https://github.com/cfpb/rhobot-for-el6', 'errors': Exception(\"[ERROR] while getting issues for cfpb/rhobot-for-el6. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'maven-for-el6', 'repo_url': 'https://github.com/cfpb/maven-for-el6', 'errors': Exception(\"[ERROR] while getting issues for cfpb/maven-for-el6. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-platform-auth', 'repo_url': 'https://github.com/cfpb/hmda-platform-auth', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-platform-auth. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ccdb5-ui', 'repo_url': 'https://github.com/cfpb/ccdb5-ui', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ccdb5-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ccdb-data-pipeline', 'repo_url': 'https://github.com/cfpb/ccdb-data-pipeline', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ccdb-data-pipeline. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hubot-cfpb-indexer', 'repo_url': 'https://github.com/cfpb/hubot-cfpb-indexer', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hubot-cfpb-indexer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'csv-converter-tool', 'repo_url': 'https://github.com/cfpb/csv-converter-tool', 'errors': Exception(\"[ERROR] while getting issues for cfpb/csv-converter-tool. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-fan', 'repo_url': 'https://github.com/cfpb/hmda-fan', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-fan. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'proxy-methodology', 'repo_url': 'https://github.com/cfpb/proxy-methodology', 'errors': Exception(\"[ERROR] while getting issues for cfpb/proxy-methodology. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckan-installer', 'repo_url': 'https://github.com/cfpb/ckan-installer', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ckan-installer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-cfpb-extrafields', 'repo_url': 'https://github.com/cfpb/ckanext-cfpb-extrafields', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ckanext-cfpb-extrafields. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pantheon-2', 'repo_url': 'https://github.com/cfpb/pantheon-2', 'errors': Exception(\"[ERROR] while getting issues for cfpb/pantheon-2. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'CFPBot', 'repo_url': 'https://github.com/cfpb/CFPBot', 'errors': Exception(\"[ERROR] while getting issues for cfpb/CFPBot. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-notifications', 'repo_url': 'https://github.com/cfpb/cf-notifications', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-notifications. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'delinkenator', 'repo_url': 'https://github.com/cfpb/delinkenator', 'errors': Exception(\"[ERROR] while getting issues for cfpb/delinkenator. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'regulations-schema', 'repo_url': 'https://github.com/cfpb/regulations-schema', 'errors': Exception(\"[ERROR] while getting issues for cfpb/regulations-schema. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cf-modals', 'repo_url': 'https://github.com/cfpb/cf-modals', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cf-modals. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'qm-data-processing', 'repo_url': 'https://github.com/cfpb/qm-data-processing', 'errors': Exception(\"[ERROR] while getting issues for cfpb/qm-data-processing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-platform-ui', 'repo_url': 'https://github.com/cfpb/hmda-platform-ui', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-platform-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ckanext-discourse', 'repo_url': 'https://github.com/cfpb/ckanext-discourse', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ckanext-discourse. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'dashboard', 'repo_url': 'https://github.com/cfpb/dashboard', 'errors': Exception(\"[ERROR] while getting issues for cfpb/dashboard. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'ansible-scl-repos', 'repo_url': 'https://github.com/cfpb/ansible-scl-repos', 'errors': Exception(\"[ERROR] while getting issues for cfpb/ansible-scl-repos. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'payday-disclosure-files', 'repo_url': 'https://github.com/cfpb/payday-disclosure-files', 'errors': Exception(\"[ERROR] while getting issues for cfpb/payday-disclosure-files. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'teachers-digital-platform', 'repo_url': 'https://github.com/cfpb/teachers-digital-platform', 'errors': Exception(\"[ERROR] while getting issues for cfpb/teachers-digital-platform. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-pub-ui', 'repo_url': 'https://github.com/cfpb/hmda-pub-ui', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-pub-ui. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'cfgov-mysql-to-postgres', 'repo_url': 'https://github.com/cfpb/cfgov-mysql-to-postgres', 'errors': Exception(\"[ERROR] while getting issues for cfpb/cfgov-mysql-to-postgres. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'commerce.gov-api', 'repo_url': 'git://github.com/CommerceGov/commerce.gov-api.git', 'error': 'Owner: None or Repo name: None as missing'}, {'repo_name': 'federal spending transparency', 'repo_url': 'https://github.com/fedspendingtransparency/fedspendingtransparency.github.io', 'errors': Exception(\"[ERROR] while getting issues for fedspendingtransparency/fedspendingtransparency.githu. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'wp-json-api', 'repo_url': 'https://github.com/cfpb/wp-json-api', 'errors': Exception(\"[ERROR] while getting issues for cfpb/wp-json-api. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'objectified', 'repo_url': 'https://github.com/cfpb/objectified', 'errors': Exception(\"[ERROR] while getting issues for cfpb/objectified. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'kratos', 'repo_url': 'https://github.com/cfpb/kratos', 'errors': Exception(\"[ERROR] while getting issues for cfpb/kratos. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'porchlight', 'repo_url': 'https://github.com/cfpb/porchlight', 'errors': Exception(\"[ERROR] while getting issues for cfpb/porchlight. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'macropolo', 'repo_url': 'https://github.com/cfpb/macropolo', 'errors': Exception(\"[ERROR] while getting issues for cfpb/macropolo. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'agile-playbook', 'repo_url': 'https://github.com/cfpb/agile-playbook', 'errors': Exception(\"[ERROR] while getting issues for cfpb/agile-playbook. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'pg-common', 'repo_url': 'https://github.com/cfpb/pg-common', 'errors': Exception(\"[ERROR] while getting issues for cfpb/pg-common. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-viz-processing', 'repo_url': 'https://github.com/cfpb/hmda-viz-processing', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-viz-processing. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'elasticizer', 'repo_url': 'https://github.com/cfpb/elasticizer', 'errors': Exception(\"[ERROR] while getting issues for cfpb/elasticizer. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}, {'repo_name': 'hmda-platform-tools', 'repo_url': 'https://github.com/cfpb/hmda-platform-tools', 'errors': Exception(\"[ERROR] while getting issues for cfpb/hmda-platform-tools. Errors: [{'message': 'API rate limit exceeded', 'type': 'RATE_LIMITED'}]\")}]\n"
     ]
    }
   ],
   "source": [
    "print(repos_with_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
